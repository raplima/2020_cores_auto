{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiment.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMA11lO6jP4mq6mWGcWrIfD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raplima/2020_cores_auto/blob/master/pyscripts/experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R8h8U9jzzd4",
        "colab_type": "text"
      },
      "source": [
        "## Install and download\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pV0Cuj2zHSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "\n",
        "# install detectron2:\n",
        "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "!pip install -e detectron2_repo\n",
        "\n",
        "\n",
        "###############################\n",
        "# download, decompress the data\n",
        "!gdown https://drive.google.com/uc?id=1LJfHTdmPC_o-b_5dI2uVdhU5_FKGpBTJ\n",
        "!unzip cores.zip > /dev/null\n",
        "\n",
        "# download class json from github\n",
        "!wget https://raw.githubusercontent.com/raplima/2020_cores_auto/master/data/classes.json\n",
        "!mv classes.json cores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrNfRmUFq-_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import necessary libraries:\n",
        "import os\n",
        "import json\n",
        "from shutil import copy2\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import numpy as np\n",
        "from detectron2.structures import BoxMode\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "# to train\n",
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "# to evaluate\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro6V8pTfW3CD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_dicts(img_dir, files_dict, all_ks, idxs):\n",
        "    \"\"\"\n",
        "    function to format the data into detectron2 input parameters\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    img_dir : string\n",
        "        path to folder with images and a \"classes.json\" dictionary.\n",
        "    files_dict : dict\n",
        "        a dictionary containing image info.\n",
        "    all_ks : list\n",
        "        all keys from the dictionary files_dict.\n",
        "    idxs : array\n",
        "        the selected indexes for this split.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataset_dicts : dict\n",
        "        the dictionary used as input to detectron2 model\n",
        "\n",
        "    \"\"\"\n",
        "    # get the classes:\n",
        "    json_file = os.path.join(img_dir, \"classes.json\")\n",
        "    with open(json_file) as f:\n",
        "        ann_classes = json.load(f)\n",
        "    # transform the dictionary into a list \n",
        "    classes=sorted([it for _, it in ann_classes.items()])\n",
        "\n",
        "    dataset_dicts = []\n",
        "    for idx in idxs:\n",
        "        v = files_dict[all_ks[idx]]\n",
        "        record = {}\n",
        "        \n",
        "        filename = os.path.join(img_dir, v[\"filename\"])\n",
        "        height, width = cv2.imread(filename).shape[:2]\n",
        "        \n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "      \n",
        "        annos = v[\"regions\"]\n",
        "        objs = []\n",
        "        for anno in annos:\n",
        "            #assert not anno[\"region_attributes\"]\n",
        "            region = anno['region_attributes']\n",
        "            anno = anno[\"shape_attributes\"]\n",
        "            px = anno[\"all_points_x\"]\n",
        "            py = anno[\"all_points_y\"]\n",
        "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": classes.index(ann_classes[region['lithofacies']]),\n",
        "                \"iscrowd\": 0\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kacqH7dtrOnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = 'cores'\n",
        "\n",
        "# read main json file\n",
        "json_file = os.path.join(data_dir, \"vanhorn_hawkins_payne_musselman_final_json.json\")\n",
        "with open(json_file) as f:\n",
        "    main_json = json.load(f)\n",
        "\n",
        "# save the dictionary keys:\n",
        "k = list(main_json.keys())\n",
        "# create kfold\n",
        "kf = KFold(n_splits=5, random_state=0, shuffle=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJq9nTk99GjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "4f4c9957-d88f-4cf7-8011-f48f1fdb3f35"
      },
      "source": [
        "dataset_tag = 'cores'\n",
        "\n",
        "# read the classes dictionary\n",
        "json_file = os.path.join(data_dir, \"classes.json\")\n",
        "with open(json_file) as f:\n",
        "    classes = json.load(f)\n",
        "\n",
        "# save a list with same format as function and metadata:\n",
        "thing_classes = sorted([it for _, it in classes.items()])\n",
        "\n",
        "# loop over splits\n",
        "for fold_idx, [train_index, test_index] in enumerate(kf.split(k)):\n",
        "    print(f'setting fold {fold_idx}')\n",
        "    for d, indexes in zip([\"train\", \"val\"], [train_index, test_index]):\n",
        "        tag = f'{dataset_tag}_{d}_{fold_idx}'\n",
        "        DatasetCatalog.register(tag, lambda d=d: get_data_dicts(data_dir, main_json, k, indexes))\n",
        "        MetadataCatalog.get(tag).set(thing_classes=sorted([it for _, it in classes.items()]))\n",
        "print('ok')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 0\n",
            "setting fold 1\n",
            "setting fold 2\n",
            "setting fold 3\n",
            "setting fold 4\n",
            "ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VgbCTtA1qR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dicts = get_data_dicts(data_dir, main_json, k, [1,2,3,4,5,6,7,8,9])\n",
        "\n",
        "d = random.sample(dataset_dicts, 1)[0]\n",
        "\n",
        "img = np.rot90(plt.imread(d[\"file_name\"]), -1)\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(12,15))\n",
        "ax.imshow(img)\n",
        "\n",
        "for annot in d['annotations']:\n",
        "    # select the x and y segmentation points\n",
        "    segx = annot['segmentation'][0][0::2]\n",
        "    segy = annot['segmentation'][0][1::2]\n",
        "    ax.fill(segx, segy, alpha=0.3)\n",
        "    ax.text(np.min(segx), np.mean(segy), \n",
        "        s=thing_classes[annot['category_id']], \n",
        "        bbox=dict(facecolor='white', alpha=0.5))\n",
        "    \n",
        "# check how detectron sees it\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(tag), scale=0.1)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9tKfqgsfWno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print GPU information\n",
        "!nvidia-smi\n",
        "for fold_idx in range(kf.get_n_splits()):   \n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "    cfg.DATASETS.TRAIN = (f\"{dataset_tag}_train_{fold_idx}\",)\n",
        "    cfg.DATASETS.TEST = (f\"{dataset_tag}_val_{fold_idx}\",)\n",
        "    cfg.DATALOADER.NUM_WORKERS = 2\n",
        "    cfg.INPUT.MAX_SIZE_TRAIN = 1000\n",
        "    # Let training initialize from model zoo\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  \n",
        "\n",
        "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "    cfg.SOLVER.BASE_LR = 0.001  \n",
        "    cfg.SOLVER.MAX_ITER = 5    \n",
        "\n",
        "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512  \n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)   # number of classes\n",
        "\n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "    trainer = DefaultTrainer(cfg) \n",
        "    trainer.resume_or_load(resume=False)\n",
        "\n",
        "    # train:\n",
        "    trainer.train()\n",
        "\n",
        "    # copy the weights \n",
        "    copy2(os.path.join(cfg.OUTPUT_DIR, 'model_final.pth'), \n",
        "          os.path.join(cfg.OUTPUT_DIR, f'model_fold_{fold_idx}.pth'))    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}