{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "executer_R50-C4.ipynb",
      "provenance": [],
      "mount_file_id": "1oRN_AAXBA1vXhnXx3V-T-TniT_ivuamJ",
      "authorship_tag": "ABX9TyOAmbCkGTri4YpkpdoAEHTO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raplima/2020_cores_auto/blob/master/scripts/executer_R50_C4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_52_mQ1oMPVQ",
        "colab_type": "text"
      },
      "source": [
        "This [`javascript`](https://stackoverflow.com/questions/54057011/google-colab-session-timeout) function might be helpful to avoid Colab identifying the notebook as idle and disconnecting:\n",
        "\n",
        "```javascript\n",
        "function clickedMe(){\n",
        "  console.log('clicked')\n",
        "  document.querySelector(\"paper-button#comments\").click()\n",
        "}\n",
        "setInterval(clickedMe(), 5*60000)\n",
        "```\n",
        "\n",
        "To execute, press `Ctrl+Shift+i`, copy into the console and run it. The code simple searches the `paper-button#comments` and clicks it. Effetively, the `Comment` box is clicked every 5 minutes. Each fold takes ~2.5 h to run, so this can facilitate the experiment (you shouldn't have to watch the entire training)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCps-FC-Nc5y",
        "colab_type": "text"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cneXQmncDd8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "28b4461e-e6aa-49a3-fe8a-cb661acfff48"
      },
      "source": [
        "# connect to google drive to save results after execution\n",
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHciCqT6BJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "59afcf43-f02b-4287-b2f0-581a566d69ab"
      },
      "source": [
        "# download, decompress the data\n",
        "!gdown https://drive.google.com/uc?id=1n6w9DJmrcepwIvWsJXLhAxAbHM0f2XjR\n",
        "!unzip cores.zip > /dev/null\n",
        "\n",
        "# clone repository\n",
        "!git clone https://github.com/raplima/2020_cores_auto.git\n",
        "\n",
        "# copy files to facilitate execution:\n",
        "!cp 2020_cores_auto/data/* cores\n",
        "!cp 2020_cores_auto/scripts/* .\n",
        "################################################################################\n",
        "# install libraries\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install pyyaml==5.1 pycocotools>=2.0.1\n",
        "# install detectron2:\n",
        "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1n6w9DJmrcepwIvWsJXLhAxAbHM0f2XjR\n",
            "To: /content/cores.zip\n",
            "296MB [00:02, 104MB/s] \n",
            "Cloning into '2020_cores_auto'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 367 (delta 45), reused 57 (delta 16), pack-reused 271\u001b[K\n",
            "Receiving objects: 100% (367/367), 55.96 MiB | 5.92 MiB/s, done.\n",
            "Resolving deltas: 100% (191/191), done.\n",
            "cp: -r not specified; omitting directory '2020_cores_auto/data/results'\n",
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Collecting torch==1.5\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (703.8MB)\n",
            "\u001b[K     |████████████████████████████████| 703.8MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 60.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Successfully installed torch-1.5.0+cu101 torchvision-0.6.0+cu101\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n",
            "Collecting detectron2==0.1.3\n",
            "\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/detectron2-0.1.3%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.2MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2MB 107.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.16.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/81/3b/40e876afde9f5ffa1cfdce10565aba85b0dc2e067ed551dfb566cfee6d4d/yacs-0.1.7-py3-none-any.whl\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (7.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (3.2.2)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (4.41.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (2.2.2)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Collecting fvcore>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/69/f0/dfee20a11c469e43061532e6e1467b9f3614dab10ad5a964e14f78f6631a/fvcore-0.1.1.post20200704.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.8.7)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2==0.1.3) (5.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (2.4.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (47.3.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.30.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.17.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.12.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.2.2)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2020.6.20)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.1.3) (1.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.1.0)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.1.post20200704-cp36-none-any.whl size=41894 sha256=3fc564c2fae77f64d1397d9a9631ef2d67c42e2bba16e9f9ca6821a3b5ee01ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/d2/8e/b6d0f19811e77dabff1ebed6605ce2b59ee9f487079b434c8c\n",
            "Successfully built fvcore\n",
            "Installing collected packages: yacs, portalocker, fvcore, mock, detectron2\n",
            "Successfully installed detectron2-0.1.3+cu101 fvcore-0.1.1.post20200704 mock-4.0.2 portalocker-1.7.0 yacs-0.1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSLrYG8-NiQC",
        "colab_type": "text"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT7kDUqTCDv_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5454db40-c814-4d78-dd17-06dc26afea5c"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '0' --max_iter 2000\n",
        "# donwload results to Google Drive\n",
        "! zip -r results.zip out* \n",
        "! cp results.zip 'gdrive/My Drive'\n",
        "! rm -r results.zip\n",
        "# clean folders if upcoming experiment\n",
        "! rm -r *coco*\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 0\n",
            "\t cores_fold_0_train\n",
            "\t cores_fold_0_val\n",
            "\u001b[32m[07/09 21:22:39 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/09 21:22:53 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 55 images left.\n",
            "\u001b[32m[07/09 21:22:53 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 253          |   brec_Cht    | 21           | lam_Sltst  | 111          |\n",
            "| skel_WkstPkst | 26           | strless_Slt.. | 132          |            |              |\n",
            "|     total     | 543          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/09 21:22:53 d2.data.common]: \u001b[0mSerializing 55 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 21:22:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 21:22:53 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/09 21:22:53 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-09 21:22:53.706359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "model_final_4ce675.pkl: 144MB [00:02, 62.2MB/s]               \n",
            "Unable to load 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (15, 4) in the checkpoint but (3, 4) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (1024, 1024, 3, 3) in the checkpoint but (256, 256, 3, 3) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (256,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (15, 1024, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (15,) in the checkpoint but (3,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (60, 1024, 1, 1) in the checkpoint but (12, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (60,) in the checkpoint but (12,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.deconv.weight' to the model due to incompatible shapes: (2048, 256, 2, 2) in the checkpoint but (256, 256, 2, 2) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/09 21:23:03 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/09 21:24:22 d2.utils.events]: \u001b[0m eta: 2:08:12  iter: 19  total_loss: 42.224  loss_cls: 31.871  loss_box_reg: 0.717  loss_mask: 1.049  loss_rpn_cls: 0.834  loss_rpn_loc: 7.692  time: 3.9033  data_time: 3.1069  lr: 0.000020  max_mem: 6781M\n",
            "\u001b[32m[07/09 21:25:39 d2.utils.events]: \u001b[0m eta: 2:05:54  iter: 39  total_loss: 7.750  loss_cls: 5.954  loss_box_reg: 0.217  loss_mask: 0.583  loss_rpn_cls: 0.271  loss_rpn_loc: 0.860  time: 3.8763  data_time: 2.9608  lr: 0.000040  max_mem: 6781M\n",
            "\u001b[32m[07/09 21:26:58 d2.utils.events]: \u001b[0m eta: 2:05:52  iter: 59  total_loss: 3.018  loss_cls: 1.488  loss_box_reg: 0.335  loss_mask: 0.570  loss_rpn_cls: 0.214  loss_rpn_loc: 0.381  time: 3.8959  data_time: 2.9712  lr: 0.000060  max_mem: 7178M\n",
            "\u001b[32m[07/09 21:28:15 d2.utils.events]: \u001b[0m eta: 2:03:47  iter: 79  total_loss: 2.022  loss_cls: 0.622  loss_box_reg: 0.333  loss_mask: 0.556  loss_rpn_cls: 0.210  loss_rpn_loc: 0.277  time: 3.8868  data_time: 2.8992  lr: 0.000080  max_mem: 7178M\n",
            "\u001b[32m[07/09 21:29:34 d2.utils.events]: \u001b[0m eta: 2:02:45  iter: 99  total_loss: 1.903  loss_cls: 0.509  loss_box_reg: 0.384  loss_mask: 0.547  loss_rpn_cls: 0.175  loss_rpn_loc: 0.260  time: 3.8952  data_time: 2.9510  lr: 0.000100  max_mem: 7287M\n",
            "\u001b[32m[07/09 21:30:51 d2.utils.events]: \u001b[0m eta: 2:01:27  iter: 119  total_loss: 1.691  loss_cls: 0.398  loss_box_reg: 0.420  loss_mask: 0.533  loss_rpn_cls: 0.159  loss_rpn_loc: 0.238  time: 3.8933  data_time: 2.8608  lr: 0.000120  max_mem: 7505M\n",
            "\u001b[32m[07/09 21:32:10 d2.utils.events]: \u001b[0m eta: 2:01:18  iter: 139  total_loss: 1.753  loss_cls: 0.408  loss_box_reg: 0.429  loss_mask: 0.526  loss_rpn_cls: 0.152  loss_rpn_loc: 0.226  time: 3.8960  data_time: 2.9102  lr: 0.000140  max_mem: 7746M\n",
            "\u001b[32m[07/09 21:33:27 d2.utils.events]: \u001b[0m eta: 1:59:59  iter: 159  total_loss: 1.649  loss_cls: 0.396  loss_box_reg: 0.409  loss_mask: 0.504  loss_rpn_cls: 0.153  loss_rpn_loc: 0.208  time: 3.8934  data_time: 2.8708  lr: 0.000160  max_mem: 7888M\n",
            "\u001b[32m[07/09 21:34:45 d2.utils.events]: \u001b[0m eta: 1:57:37  iter: 179  total_loss: 1.633  loss_cls: 0.384  loss_box_reg: 0.401  loss_mask: 0.495  loss_rpn_cls: 0.138  loss_rpn_loc: 0.200  time: 3.8909  data_time: 2.8617  lr: 0.000180  max_mem: 7888M\n",
            "\u001b[32m[07/09 21:36:16 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 21:36:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 21:36:16 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_0_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/09 21:36:16 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_0_train' to COCO format ...)\n",
            "\u001b[32m[07/09 21:36:29 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/09 21:36:29 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 56, #annotations: 543\n",
            "\u001b[32m[07/09 21:36:29 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_0_train_coco_format.json' ...\n",
            "\u001b[32m[07/09 21:36:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0x903aa000 @  0x7faf2166eb6b 0x7faf2168e379 0x7faec4dc304e 0x7faec4dc4f4a 0x7faefdcb367b 0x7faefd9026be 0x7faefdb6b7b5 0x7faefdb5d7c1 0x7faefdb5cd0e 0x7faefdb5d7c1 0x7faeff5b293a 0x7faefdb5d7c1 0x7faefd8fd457 0x7faefd8fe080 0x7faefdc1c71a 0x7faeff69a13e 0x7faefdb5dc72 0x7faf0bbf7a68 0x7faf0bcb2b04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/09 21:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2722 s / img. ETA=0:06:37\n",
            "\u001b[32m[07/09 21:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 12/56. 0.2719 s / img. ETA=0:06:28\n",
            "\u001b[32m[07/09 21:38:27 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2736 s / img. ETA=0:06:20\n",
            "\u001b[32m[07/09 21:38:35 d2.evaluation.evaluator]: \u001b[0mInference done 14/56. 0.2732 s / img. ETA=0:06:11\n",
            "\u001b[32m[07/09 21:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 15/56. 0.2897 s / img. ETA=0:06:03\n",
            "\u001b[32m[07/09 21:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 16/56. 0.2881 s / img. ETA=0:05:54\n",
            "\u001b[32m[07/09 21:39:02 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.2866 s / img. ETA=0:05:46\n",
            "\u001b[32m[07/09 21:39:08 d2.evaluation.evaluator]: \u001b[0mInference done 18/56. 0.2810 s / img. ETA=0:05:26\n",
            "\u001b[32m[07/09 21:39:13 d2.evaluation.evaluator]: \u001b[0mInference done 19/56. 0.2754 s / img. ETA=0:05:09\n",
            "\u001b[32m[07/09 21:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.2705 s / img. ETA=0:04:53\n",
            "\u001b[32m[07/09 21:39:23 d2.evaluation.evaluator]: \u001b[0mInference done 21/56. 0.2667 s / img. ETA=0:04:38\n",
            "\u001b[32m[07/09 21:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 22/56. 0.2629 s / img. ETA=0:04:24\n",
            "\u001b[32m[07/09 21:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 23/56. 0.2595 s / img. ETA=0:04:12\n",
            "\u001b[32m[07/09 21:39:39 d2.evaluation.evaluator]: \u001b[0mInference done 24/56. 0.2565 s / img. ETA=0:04:00\n",
            "\u001b[32m[07/09 21:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 25/56. 0.2538 s / img. ETA=0:03:49\n",
            "\u001b[32m[07/09 21:39:49 d2.evaluation.evaluator]: \u001b[0mInference done 26/56. 0.2517 s / img. ETA=0:03:38\n",
            "\u001b[32m[07/09 21:39:54 d2.evaluation.evaluator]: \u001b[0mInference done 27/56. 0.2495 s / img. ETA=0:03:28\n",
            "\u001b[32m[07/09 21:39:59 d2.evaluation.evaluator]: \u001b[0mInference done 28/56. 0.2475 s / img. ETA=0:03:18\n",
            "\u001b[32m[07/09 21:40:04 d2.evaluation.evaluator]: \u001b[0mInference done 29/56. 0.2456 s / img. ETA=0:03:09\n",
            "\u001b[32m[07/09 21:40:09 d2.evaluation.evaluator]: \u001b[0mInference done 30/56. 0.2439 s / img. ETA=0:03:00\n",
            "\u001b[32m[07/09 21:40:14 d2.evaluation.evaluator]: \u001b[0mInference done 31/56. 0.2423 s / img. ETA=0:02:51\n",
            "\u001b[32m[07/09 21:40:20 d2.evaluation.evaluator]: \u001b[0mInference done 32/56. 0.2408 s / img. ETA=0:02:43\n",
            "\u001b[32m[07/09 21:40:25 d2.evaluation.evaluator]: \u001b[0mInference done 33/56. 0.2393 s / img. ETA=0:02:35\n",
            "\u001b[32m[07/09 21:40:30 d2.evaluation.evaluator]: \u001b[0mInference done 34/56. 0.2380 s / img. ETA=0:02:27\n",
            "\u001b[32m[07/09 21:40:35 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.2370 s / img. ETA=0:02:19\n",
            "\u001b[32m[07/09 21:40:40 d2.evaluation.evaluator]: \u001b[0mInference done 36/56. 0.2358 s / img. ETA=0:02:11\n",
            "\u001b[32m[07/09 21:40:45 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.2347 s / img. ETA=0:02:04\n",
            "\u001b[32m[07/09 21:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.2326 s / img. ETA=0:01:49\n",
            "\u001b[32m[07/09 21:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 40/56. 0.2316 s / img. ETA=0:01:42\n",
            "\u001b[32m[07/09 21:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 43/56. 0.2280 s / img. ETA=0:01:20\n",
            "\u001b[32m[07/09 21:41:21 d2.evaluation.evaluator]: \u001b[0mInference done 44/56. 0.2288 s / img. ETA=0:01:15\n",
            "\u001b[32m[07/09 21:41:29 d2.evaluation.evaluator]: \u001b[0mInference done 45/56. 0.2297 s / img. ETA=0:01:09\n",
            "\u001b[32m[07/09 21:41:37 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.2303 s / img. ETA=0:01:03\n",
            "\u001b[32m[07/09 21:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.2309 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/09 21:41:53 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.2314 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/09 21:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 49/56. 0.2319 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/09 21:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.2324 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/09 21:42:16 d2.evaluation.evaluator]: \u001b[0mInference done 51/56. 0.2329 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/09 21:42:24 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.2334 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/09 21:42:32 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.2337 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/09 21:42:40 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.2340 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/09 21:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 55/56. 0.2343 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/09 21:42:55 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.2346 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 21:42:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:39.690408 (6.660596 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 21:42:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.234637 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 21:42:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 21:42:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 21:42:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.78s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.102\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.027\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.092\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.146\n",
            "\u001b[32m[07/09 21:42:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.364 | 10.207 | 1.413  |  nan  |  nan  | 3.364 |\n",
            "\u001b[32m[07/09 21:42:57 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 21:42:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 6.674 | brec_Cht         | 0.638 | lam_Sltst  | 1.048 |\n",
            "| skel_WkstPkst | 5.149 | strless_SltstSst | 3.314 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.20s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.022\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.133\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.923 | 9.056  | 1.320  |  nan  |  nan  | 2.923 |\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 6.258 | brec_Cht         | 0.177 | lam_Sltst  | 1.038 |\n",
            "| skel_WkstPkst | 4.488 | strless_SltstSst | 2.653 |            |       |\n",
            "\u001b[32m[07/09 21:42:58 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.testing]: \u001b[0mcopypaste: 3.3644,10.2069,1.4133,nan,nan,3.3644\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.testing]: \u001b[0mcopypaste: 2.9229,9.0559,1.3204,nan,nan,2.9229\n",
            "\u001b[32m[07/09 21:43:02 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 56           |   brec_Cht    | 0            | lam_Sltst  | 16           |\n",
            "| skel_WkstPkst | 0            | strless_Slt.. | 41           |            |              |\n",
            "|     total     | 113          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/09 21:43:02 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 21:43:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 21:43:02 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_0_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/09 21:43:02 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_0_val' to COCO format ...)\n",
            "\u001b[32m[07/09 21:43:05 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/09 21:43:05 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 15, #annotations: 113\n",
            "\u001b[32m[07/09 21:43:05 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_0_val_coco_format.json' ...\n",
            "\u001b[32m[07/09 21:43:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 21:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.2030 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/09 21:44:08 d2.evaluation.evaluator]: \u001b[0mInference done 13/15. 0.2089 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.evaluator]: \u001b[0mInference done 15/15. 0.2174 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.201831 (3.620183 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.217375 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.023\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.187\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.003 | 8.774  | 2.297  |  nan  |  nan  | 3.003 |\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 7.190 | brec_Cht         | nan   | lam_Sltst  | 0.000 |\n",
            "| skel_WkstPkst | nan   | strless_SltstSst | 1.819 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.085\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.187\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.766 | 8.461  | 0.886  |  nan  |  nan  | 2.766 |\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 6.425 | brec_Cht         | nan   | lam_Sltst  | 0.000 |\n",
            "| skel_WkstPkst | nan   | strless_SltstSst | 1.873 |            |       |\n",
            "\u001b[32m[07/09 21:44:15 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: 3.0031,8.7741,2.2966,nan,nan,3.0031\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: 2.7659,8.4614,0.8864,nan,nan,2.7659\n",
            "\u001b[32m[07/09 21:44:15 d2.utils.events]: \u001b[0m eta: 1:56:17  iter: 199  total_loss: 1.660  loss_cls: 0.399  loss_box_reg: 0.426  loss_mask: 0.471  loss_rpn_cls: 0.138  loss_rpn_loc: 0.208  time: 3.8906  data_time: 2.8416  lr: 0.000200  max_mem: 8001M\n",
            "\u001b[32m[07/09 21:45:32 d2.utils.events]: \u001b[0m eta: 1:55:09  iter: 219  total_loss: 1.628  loss_cls: 0.410  loss_box_reg: 0.419  loss_mask: 0.447  loss_rpn_cls: 0.131  loss_rpn_loc: 0.197  time: 3.8882  data_time: 2.8213  lr: 0.000220  max_mem: 8074M\n",
            "\u001b[32m[07/09 21:46:50 d2.utils.events]: \u001b[0m eta: 1:54:20  iter: 239  total_loss: 1.657  loss_cls: 0.448  loss_box_reg: 0.468  loss_mask: 0.432  loss_rpn_cls: 0.127  loss_rpn_loc: 0.184  time: 3.8906  data_time: 2.8741  lr: 0.000240  max_mem: 8308M\n",
            "\u001b[32m[07/09 21:48:09 d2.utils.events]: \u001b[0m eta: 1:53:34  iter: 259  total_loss: 1.644  loss_cls: 0.467  loss_box_reg: 0.463  loss_mask: 0.406  loss_rpn_cls: 0.126  loss_rpn_loc: 0.190  time: 3.8947  data_time: 2.9198  lr: 0.000260  max_mem: 8308M\n",
            "\u001b[32m[07/09 21:49:28 d2.utils.events]: \u001b[0m eta: 1:52:14  iter: 279  total_loss: 1.594  loss_cls: 0.462  loss_box_reg: 0.469  loss_mask: 0.389  loss_rpn_cls: 0.115  loss_rpn_loc: 0.176  time: 3.8976  data_time: 2.8903  lr: 0.000280  max_mem: 8308M\n",
            "\u001b[32m[07/09 21:50:46 d2.utils.events]: \u001b[0m eta: 1:50:23  iter: 299  total_loss: 1.613  loss_cls: 0.469  loss_box_reg: 0.464  loss_mask: 0.366  loss_rpn_cls: 0.112  loss_rpn_loc: 0.169  time: 3.8979  data_time: 2.8484  lr: 0.000300  max_mem: 8674M\n",
            "\u001b[32m[07/09 21:52:04 d2.utils.events]: \u001b[0m eta: 1:49:26  iter: 319  total_loss: 1.506  loss_cls: 0.417  loss_box_reg: 0.443  loss_mask: 0.354  loss_rpn_cls: 0.109  loss_rpn_loc: 0.175  time: 3.8980  data_time: 2.8548  lr: 0.000320  max_mem: 8674M\n",
            "\u001b[32m[07/09 21:53:23 d2.utils.events]: \u001b[0m eta: 1:48:14  iter: 339  total_loss: 1.570  loss_cls: 0.468  loss_box_reg: 0.477  loss_mask: 0.346  loss_rpn_cls: 0.109  loss_rpn_loc: 0.174  time: 3.9003  data_time: 2.8656  lr: 0.000340  max_mem: 8674M\n",
            "\u001b[32m[07/09 21:54:42 d2.utils.events]: \u001b[0m eta: 1:47:02  iter: 359  total_loss: 1.557  loss_cls: 0.480  loss_box_reg: 0.478  loss_mask: 0.341  loss_rpn_cls: 0.101  loss_rpn_loc: 0.172  time: 3.9051  data_time: 2.9033  lr: 0.000360  max_mem: 8674M\n",
            "\u001b[32m[07/09 21:56:01 d2.utils.events]: \u001b[0m eta: 1:45:42  iter: 379  total_loss: 1.473  loss_cls: 0.439  loss_box_reg: 0.441  loss_mask: 0.319  loss_rpn_cls: 0.099  loss_rpn_loc: 0.165  time: 3.9058  data_time: 2.8630  lr: 0.000380  max_mem: 8674M\n",
            "\u001b[32m[07/09 21:57:34 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 21:57:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 21:57:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 21:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2689 s / img. ETA=0:02:39\n",
            "\u001b[32m[07/09 21:58:21 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2577 s / img. ETA=0:02:27\n",
            "\u001b[32m[07/09 21:58:27 d2.evaluation.evaluator]: \u001b[0mInference done 15/56. 0.2551 s / img. ETA=0:02:18\n",
            "\u001b[32m[07/09 21:58:32 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.2465 s / img. ETA=0:02:06\n",
            "\u001b[32m[07/09 21:58:39 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.2346 s / img. ETA=0:01:50\n",
            "\u001b[32m[07/09 21:58:46 d2.evaluation.evaluator]: \u001b[0mInference done 23/56. 0.2250 s / img. ETA=0:01:36\n",
            "\u001b[32m[07/09 21:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 26/56. 0.2213 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/09 21:59:00 d2.evaluation.evaluator]: \u001b[0mInference done 29/56. 0.2142 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/09 21:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 32/56. 0.2113 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/09 21:59:15 d2.evaluation.evaluator]: \u001b[0mInference done 34/56. 0.2104 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/09 21:59:25 d2.evaluation.evaluator]: \u001b[0mInference done 36/56. 0.2100 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/09 21:59:34 d2.evaluation.evaluator]: \u001b[0mInference done 38/56. 0.2093 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/09 21:59:40 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.2090 s / img. ETA=0:00:53\n",
            "\u001b[32m[07/09 21:59:46 d2.evaluation.evaluator]: \u001b[0mInference done 42/56. 0.2043 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/09 21:59:52 d2.evaluation.evaluator]: \u001b[0mInference done 44/56. 0.2069 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/09 21:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.2093 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/09 22:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.2117 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/09 22:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.2134 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/09 22:00:18 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.2151 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/09 22:00:24 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.2165 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/09 22:00:30 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.2178 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 22:00:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:37.184890 (3.082057 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:00:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.217812 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:00:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:00:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:00:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.67s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.134\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.073\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.068\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.374\n",
            "\u001b[32m[07/09 22:00:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.375 | 31.642 | 7.290  |  nan  |  nan  | 13.375 |\n",
            "\u001b[32m[07/09 22:00:31 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:00:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.827 | brec_Cht         | 16.320 | lam_Sltst  | 4.027 |\n",
            "| skel_WkstPkst | 13.347 | strless_SltstSst | 12.352 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.90s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.324\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.146\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.692 | 32.442 | 14.622 |  nan  |  nan  | 15.692 |\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.355 | brec_Cht         | 22.405 | lam_Sltst  | 4.146 |\n",
            "| skel_WkstPkst | 15.629 | strless_SltstSst | 12.926 |            |       |\n",
            "\u001b[32m[07/09 22:00:32 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: 13.3746,31.6415,7.2901,nan,nan,13.3746\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: 15.6923,32.4416,14.6219,nan,nan,15.6923\n",
            "\u001b[32m[07/09 22:00:36 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:00:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 22:00:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 22:01:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1993 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/09 22:01:15 d2.evaluation.evaluator]: \u001b[0mInference done 13/15. 0.2070 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/09 22:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 15/15. 0.2107 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 22:01:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.808951 (2.880895 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:01:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.210696 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:01:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:01:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.156\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.298\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 6.203 | 17.690 | 1.525  |  nan  |  nan  | 6.203 |\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 12.057 | brec_Cht         | nan   | lam_Sltst  | 0.597 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 5.954 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 6.535 | 17.357 | 3.426  |  nan  |  nan  | 6.540 |\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 11.404 | brec_Cht         | nan   | lam_Sltst  | 0.597 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 7.603 |            |       |\n",
            "\u001b[32m[07/09 22:01:21 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.testing]: \u001b[0mcopypaste: 6.2029,17.6897,1.5251,nan,nan,6.2029\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.testing]: \u001b[0mcopypaste: 6.5349,17.3574,3.4264,nan,nan,6.5396\n",
            "\u001b[32m[07/09 22:01:21 d2.utils.events]: \u001b[0m eta: 1:44:26  iter: 399  total_loss: 1.489  loss_cls: 0.451  loss_box_reg: 0.444  loss_mask: 0.320  loss_rpn_cls: 0.097  loss_rpn_loc: 0.167  time: 3.9073  data_time: 2.8505  lr: 0.000400  max_mem: 8674M\n",
            "\u001b[32m[07/09 22:02:39 d2.utils.events]: \u001b[0m eta: 1:43:12  iter: 419  total_loss: 1.417  loss_cls: 0.440  loss_box_reg: 0.421  loss_mask: 0.312  loss_rpn_cls: 0.093  loss_rpn_loc: 0.170  time: 3.9059  data_time: 2.8182  lr: 0.000420  max_mem: 8674M\n",
            "\u001b[32m[07/09 22:03:56 d2.utils.events]: \u001b[0m eta: 1:41:48  iter: 439  total_loss: 1.456  loss_cls: 0.455  loss_box_reg: 0.429  loss_mask: 0.314  loss_rpn_cls: 0.091  loss_rpn_loc: 0.162  time: 3.9036  data_time: 2.7728  lr: 0.000440  max_mem: 8674M\n",
            "\u001b[32m[07/09 22:05:14 d2.utils.events]: \u001b[0m eta: 1:40:36  iter: 459  total_loss: 1.410  loss_cls: 0.431  loss_box_reg: 0.429  loss_mask: 0.304  loss_rpn_cls: 0.087  loss_rpn_loc: 0.157  time: 3.9032  data_time: 2.8398  lr: 0.000460  max_mem: 8732M\n",
            "\u001b[32m[07/09 22:06:32 d2.utils.events]: \u001b[0m eta: 1:39:17  iter: 479  total_loss: 1.417  loss_cls: 0.433  loss_box_reg: 0.425  loss_mask: 0.292  loss_rpn_cls: 0.079  loss_rpn_loc: 0.165  time: 3.9035  data_time: 2.8163  lr: 0.000480  max_mem: 8732M\n",
            "\u001b[32m[07/09 22:07:50 d2.utils.events]: \u001b[0m eta: 1:37:54  iter: 499  total_loss: 1.391  loss_cls: 0.444  loss_box_reg: 0.405  loss_mask: 0.290  loss_rpn_cls: 0.085  loss_rpn_loc: 0.166  time: 3.9028  data_time: 2.8003  lr: 0.000500  max_mem: 8732M\n",
            "\u001b[32m[07/09 22:09:08 d2.utils.events]: \u001b[0m eta: 1:36:36  iter: 519  total_loss: 1.378  loss_cls: 0.456  loss_box_reg: 0.416  loss_mask: 0.288  loss_rpn_cls: 0.079  loss_rpn_loc: 0.167  time: 3.9028  data_time: 2.7918  lr: 0.000519  max_mem: 8732M\n",
            "\u001b[32m[07/09 22:10:26 d2.utils.events]: \u001b[0m eta: 1:35:15  iter: 539  total_loss: 1.439  loss_cls: 0.459  loss_box_reg: 0.444  loss_mask: 0.291  loss_rpn_cls: 0.082  loss_rpn_loc: 0.165  time: 3.9028  data_time: 2.8334  lr: 0.000539  max_mem: 8772M\n",
            "\u001b[32m[07/09 22:11:45 d2.utils.events]: \u001b[0m eta: 1:34:04  iter: 559  total_loss: 1.332  loss_cls: 0.421  loss_box_reg: 0.410  loss_mask: 0.280  loss_rpn_cls: 0.081  loss_rpn_loc: 0.152  time: 3.9054  data_time: 2.9010  lr: 0.000559  max_mem: 8772M\n",
            "\u001b[32m[07/09 22:13:05 d2.utils.events]: \u001b[0m eta: 1:32:50  iter: 579  total_loss: 1.363  loss_cls: 0.439  loss_box_reg: 0.447  loss_mask: 0.274  loss_rpn_cls: 0.070  loss_rpn_loc: 0.154  time: 3.9075  data_time: 2.8856  lr: 0.000579  max_mem: 8800M\n",
            "\u001b[32m[07/09 22:14:40 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:14:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 22:14:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 22:15:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2710 s / img. ETA=0:02:45\n",
            "\u001b[32m[07/09 22:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2641 s / img. ETA=0:02:33\n",
            "\u001b[32m[07/09 22:15:37 d2.evaluation.evaluator]: \u001b[0mInference done 15/56. 0.2652 s / img. ETA=0:02:24\n",
            "\u001b[32m[07/09 22:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.2616 s / img. ETA=0:02:13\n",
            "\u001b[32m[07/09 22:15:48 d2.evaluation.evaluator]: \u001b[0mInference done 19/56. 0.2531 s / img. ETA=0:02:02\n",
            "\u001b[32m[07/09 22:15:53 d2.evaluation.evaluator]: \u001b[0mInference done 21/56. 0.2453 s / img. ETA=0:01:52\n",
            "\u001b[32m[07/09 22:15:58 d2.evaluation.evaluator]: \u001b[0mInference done 23/56. 0.2406 s / img. ETA=0:01:44\n",
            "\u001b[32m[07/09 22:16:03 d2.evaluation.evaluator]: \u001b[0mInference done 25/56. 0.2368 s / img. ETA=0:01:36\n",
            "\u001b[32m[07/09 22:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 27/56. 0.2336 s / img. ETA=0:01:29\n",
            "\u001b[32m[07/09 22:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 29/56. 0.2298 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/09 22:16:19 d2.evaluation.evaluator]: \u001b[0mInference done 31/56. 0.2273 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/09 22:16:24 d2.evaluation.evaluator]: \u001b[0mInference done 33/56. 0.2254 s / img. ETA=0:01:08\n",
            "\u001b[32m[07/09 22:16:34 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.2240 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/09 22:16:39 d2.evaluation.evaluator]: \u001b[0mInference done 36/56. 0.2232 s / img. ETA=0:01:03\n",
            "\u001b[32m[07/09 22:16:44 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.2225 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/09 22:16:50 d2.evaluation.evaluator]: \u001b[0mInference done 38/56. 0.2218 s / img. ETA=0:00:59\n",
            "\u001b[32m[07/09 22:16:55 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.2212 s / img. ETA=0:00:56\n",
            "\u001b[32m[07/09 22:17:00 d2.evaluation.evaluator]: \u001b[0mInference done 41/56. 0.2186 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/09 22:17:06 d2.evaluation.evaluator]: \u001b[0mInference done 43/56. 0.2180 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/09 22:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 45/56. 0.2199 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/09 22:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.2219 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/09 22:17:26 d2.evaluation.evaluator]: \u001b[0mInference done 49/56. 0.2232 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/09 22:17:32 d2.evaluation.evaluator]: \u001b[0mInference done 51/56. 0.2245 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/09 22:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.2256 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/09 22:17:45 d2.evaluation.evaluator]: \u001b[0mInference done 55/56. 0.2265 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/09 22:17:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:46.362309 (3.262006 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:17:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.227001 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:17:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:17:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:17:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.66s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.469\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.229\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.101\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
            "\u001b[32m[07/09 22:17:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 22.915 | 46.902 | 20.011 |  nan  |  nan  | 22.915 |\n",
            "\u001b[32m[07/09 22:17:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:17:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 24.748 | brec_Cht         | 26.210 | lam_Sltst  | 18.819 |\n",
            "| skel_WkstPkst | 17.403 | strless_SltstSst | 27.393 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.91s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.470\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.240\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.449\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.565\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.143 | 46.970 | 24.000 |  nan  |  nan  | 25.143 |\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 26.801 | brec_Cht         | 32.486 | lam_Sltst  | 19.288 |\n",
            "| skel_WkstPkst | 18.704 | strless_SltstSst | 28.435 |            |        |\n",
            "\u001b[32m[07/09 22:17:50 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.testing]: \u001b[0mcopypaste: 22.9146,46.9019,20.0113,nan,nan,22.9146\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.testing]: \u001b[0mcopypaste: 25.1428,46.9698,24.0000,nan,nan,25.1428\n",
            "\u001b[32m[07/09 22:17:53 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:17:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 22:17:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 22:18:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.2033 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/09 22:18:33 d2.evaluation.evaluator]: \u001b[0mInference done 13/15. 0.2091 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 15/15. 0.2165 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.880477 (2.988048 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.216466 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.244\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.036\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.023\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.228\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.767 | 24.354 | 3.584  |  nan  |  nan  | 8.767 |\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 14.751 | brec_Cht         | nan   | lam_Sltst  | 1.837 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 9.713 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.22s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.249\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.096\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.240\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.568 | 24.885 | 6.526  |  nan  |  nan  | 9.569 |\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 16.621 | brec_Cht         | nan    | lam_Sltst  | 1.744 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 10.339 |            |       |\n",
            "\u001b[32m[07/09 22:18:40 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.testing]: \u001b[0mcopypaste: 8.7674,24.3542,3.5843,nan,nan,8.7674\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.testing]: \u001b[0mcopypaste: 9.5676,24.8847,6.5261,nan,nan,9.5685\n",
            "\u001b[32m[07/09 22:18:40 d2.utils.events]: \u001b[0m eta: 1:31:37  iter: 599  total_loss: 1.289  loss_cls: 0.406  loss_box_reg: 0.392  loss_mask: 0.276  loss_rpn_cls: 0.067  loss_rpn_loc: 0.158  time: 3.9126  data_time: 2.9658  lr: 0.000599  max_mem: 8800M\n",
            "\u001b[32m[07/09 22:19:58 d2.utils.events]: \u001b[0m eta: 1:30:20  iter: 619  total_loss: 1.308  loss_cls: 0.419  loss_box_reg: 0.411  loss_mask: 0.278  loss_rpn_cls: 0.071  loss_rpn_loc: 0.156  time: 3.9120  data_time: 2.8033  lr: 0.000619  max_mem: 8800M\n",
            "\u001b[32m[07/09 22:21:18 d2.utils.events]: \u001b[0m eta: 1:29:07  iter: 639  total_loss: 1.274  loss_cls: 0.392  loss_box_reg: 0.389  loss_mask: 0.276  loss_rpn_cls: 0.071  loss_rpn_loc: 0.149  time: 3.9147  data_time: 2.9317  lr: 0.000639  max_mem: 8800M\n",
            "\u001b[32m[07/09 22:22:38 d2.utils.events]: \u001b[0m eta: 1:27:56  iter: 659  total_loss: 1.362  loss_cls: 0.429  loss_box_reg: 0.408  loss_mask: 0.260  loss_rpn_cls: 0.064  loss_rpn_loc: 0.159  time: 3.9170  data_time: 2.8851  lr: 0.000659  max_mem: 8800M\n",
            "\u001b[32m[07/09 22:23:57 d2.utils.events]: \u001b[0m eta: 1:26:40  iter: 679  total_loss: 1.326  loss_cls: 0.410  loss_box_reg: 0.402  loss_mask: 0.266  loss_rpn_cls: 0.064  loss_rpn_loc: 0.159  time: 3.9192  data_time: 2.8938  lr: 0.000679  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:25:16 d2.utils.events]: \u001b[0m eta: 1:25:24  iter: 699  total_loss: 1.262  loss_cls: 0.402  loss_box_reg: 0.395  loss_mask: 0.257  loss_rpn_cls: 0.064  loss_rpn_loc: 0.149  time: 3.9194  data_time: 2.8285  lr: 0.000699  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:26:35 d2.utils.events]: \u001b[0m eta: 1:24:06  iter: 719  total_loss: 1.253  loss_cls: 0.395  loss_box_reg: 0.376  loss_mask: 0.257  loss_rpn_cls: 0.060  loss_rpn_loc: 0.150  time: 3.9205  data_time: 2.8734  lr: 0.000719  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:27:53 d2.utils.events]: \u001b[0m eta: 1:22:47  iter: 739  total_loss: 1.229  loss_cls: 0.378  loss_box_reg: 0.398  loss_mask: 0.255  loss_rpn_cls: 0.057  loss_rpn_loc: 0.149  time: 3.9195  data_time: 2.7921  lr: 0.000739  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:29:11 d2.utils.events]: \u001b[0m eta: 1:21:27  iter: 759  total_loss: 1.224  loss_cls: 0.379  loss_box_reg: 0.385  loss_mask: 0.246  loss_rpn_cls: 0.059  loss_rpn_loc: 0.140  time: 3.9191  data_time: 2.8010  lr: 0.000759  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:30:30 d2.utils.events]: \u001b[0m eta: 1:20:09  iter: 779  total_loss: 1.182  loss_cls: 0.363  loss_box_reg: 0.383  loss_mask: 0.248  loss_rpn_cls: 0.056  loss_rpn_loc: 0.140  time: 3.9196  data_time: 2.8223  lr: 0.000779  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:32:02 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:32:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 22:32:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 22:32:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2723 s / img. ETA=0:02:43\n",
            "\u001b[32m[07/09 22:32:52 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2676 s / img. ETA=0:02:34\n",
            "\u001b[32m[07/09 22:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 15/56. 0.2661 s / img. ETA=0:02:24\n",
            "\u001b[32m[07/09 22:33:04 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.2575 s / img. ETA=0:02:12\n",
            "\u001b[32m[07/09 22:33:11 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.2423 s / img. ETA=0:01:54\n",
            "\u001b[32m[07/09 22:33:17 d2.evaluation.evaluator]: \u001b[0mInference done 23/56. 0.2312 s / img. ETA=0:01:39\n",
            "\u001b[32m[07/09 22:33:25 d2.evaluation.evaluator]: \u001b[0mInference done 26/56. 0.2257 s / img. ETA=0:01:28\n",
            "\u001b[32m[07/09 22:33:31 d2.evaluation.evaluator]: \u001b[0mInference done 29/56. 0.2166 s / img. ETA=0:01:16\n",
            "\u001b[32m[07/09 22:33:38 d2.evaluation.evaluator]: \u001b[0mInference done 32/56. 0.2133 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/09 22:33:45 d2.evaluation.evaluator]: \u001b[0mInference done 34/56. 0.2124 s / img. ETA=0:01:02\n",
            "\u001b[32m[07/09 22:33:50 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.2123 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/09 22:34:00 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.2114 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/09 22:34:10 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.2107 s / img. ETA=0:00:53\n",
            "\u001b[32m[07/09 22:34:17 d2.evaluation.evaluator]: \u001b[0mInference done 42/56. 0.2057 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/09 22:34:23 d2.evaluation.evaluator]: \u001b[0mInference done 44/56. 0.2083 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/09 22:34:30 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.2107 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/09 22:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.2130 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/09 22:34:43 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.2148 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/09 22:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.2164 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/09 22:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.2177 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/09 22:35:01 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.2190 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 22:35:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:38.520590 (3.108247 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:35:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.218969 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:35:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:35:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:35:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.64s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.690\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.471\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.409\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.602\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n",
            "\u001b[32m[07/09 22:35:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 40.872 | 69.043 | 47.137 |  nan  |  nan  | 40.872 |\n",
            "\u001b[32m[07/09 22:35:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:35:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 40.369 | brec_Cht         | 54.333 | lam_Sltst  | 32.760 |\n",
            "| skel_WkstPkst | 34.498 | strless_SltstSst | 42.402 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.90s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.689\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.486\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.636\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 43.281 | 68.878 | 48.623 |  nan  |  nan  | 43.281 |\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 43.940 | brec_Cht         | 60.262 | lam_Sltst  | 33.261 |\n",
            "| skel_WkstPkst | 34.735 | strless_SltstSst | 44.204 |            |        |\n",
            "\u001b[32m[07/09 22:35:04 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.testing]: \u001b[0mcopypaste: 40.8724,69.0428,47.1371,nan,nan,40.8724\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.testing]: \u001b[0mcopypaste: 43.2806,68.8776,48.6233,nan,nan,43.2808\n",
            "\u001b[32m[07/09 22:35:07 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:35:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 22:35:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 22:35:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1961 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/09 22:35:46 d2.evaluation.evaluator]: \u001b[0mInference done 13/15. 0.2048 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 15/15. 0.2080 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.982907 (2.898291 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.207993 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.116\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.319 | 29.518 | 11.607 |  nan  |  nan  | 13.319 |\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 19.594 | brec_Cht         | nan    | lam_Sltst  | 8.358 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 12.005 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.143\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.148\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.143\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.518\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.285 | 30.407 | 14.810 |  nan  |  nan  | 14.285 |\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.353 | brec_Cht         | nan    | lam_Sltst  | 8.123 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 13.379 |            |       |\n",
            "\u001b[32m[07/09 22:35:52 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.testing]: \u001b[0mcopypaste: 13.3189,29.5179,11.6066,nan,nan,13.3189\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.testing]: \u001b[0mcopypaste: 14.2849,30.4070,14.8097,nan,nan,14.2849\n",
            "\u001b[32m[07/09 22:35:52 d2.utils.events]: \u001b[0m eta: 1:18:50  iter: 799  total_loss: 1.123  loss_cls: 0.326  loss_box_reg: 0.345  loss_mask: 0.241  loss_rpn_cls: 0.057  loss_rpn_loc: 0.158  time: 3.9200  data_time: 2.8404  lr: 0.000799  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:37:11 d2.utils.events]: \u001b[0m eta: 1:17:32  iter: 819  total_loss: 1.157  loss_cls: 0.356  loss_box_reg: 0.346  loss_mask: 0.247  loss_rpn_cls: 0.057  loss_rpn_loc: 0.152  time: 3.9200  data_time: 2.8149  lr: 0.000819  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:38:29 d2.utils.events]: \u001b[0m eta: 1:16:13  iter: 839  total_loss: 1.186  loss_cls: 0.378  loss_box_reg: 0.370  loss_mask: 0.241  loss_rpn_cls: 0.058  loss_rpn_loc: 0.131  time: 3.9206  data_time: 2.8469  lr: 0.000839  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:39:48 d2.utils.events]: \u001b[0m eta: 1:14:54  iter: 859  total_loss: 1.125  loss_cls: 0.343  loss_box_reg: 0.346  loss_mask: 0.236  loss_rpn_cls: 0.053  loss_rpn_loc: 0.149  time: 3.9203  data_time: 2.8221  lr: 0.000859  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:41:07 d2.utils.events]: \u001b[0m eta: 1:13:37  iter: 879  total_loss: 1.123  loss_cls: 0.334  loss_box_reg: 0.344  loss_mask: 0.237  loss_rpn_cls: 0.051  loss_rpn_loc: 0.149  time: 3.9209  data_time: 2.8419  lr: 0.000879  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:42:26 d2.utils.events]: \u001b[0m eta: 1:12:22  iter: 899  total_loss: 1.101  loss_cls: 0.332  loss_box_reg: 0.343  loss_mask: 0.242  loss_rpn_cls: 0.051  loss_rpn_loc: 0.137  time: 3.9216  data_time: 2.8648  lr: 0.000899  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:43:44 d2.utils.events]: \u001b[0m eta: 1:11:03  iter: 919  total_loss: 1.124  loss_cls: 0.329  loss_box_reg: 0.372  loss_mask: 0.242  loss_rpn_cls: 0.049  loss_rpn_loc: 0.153  time: 3.9217  data_time: 2.8312  lr: 0.000919  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:45:02 d2.utils.events]: \u001b[0m eta: 1:09:45  iter: 939  total_loss: 1.091  loss_cls: 0.323  loss_box_reg: 0.347  loss_mask: 0.235  loss_rpn_cls: 0.050  loss_rpn_loc: 0.142  time: 3.9213  data_time: 2.7984  lr: 0.000939  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:46:22 d2.utils.events]: \u001b[0m eta: 1:08:28  iter: 959  total_loss: 1.064  loss_cls: 0.320  loss_box_reg: 0.338  loss_mask: 0.231  loss_rpn_cls: 0.043  loss_rpn_loc: 0.136  time: 3.9222  data_time: 2.8600  lr: 0.000959  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:47:40 d2.utils.events]: \u001b[0m eta: 1:07:08  iter: 979  total_loss: 1.047  loss_cls: 0.328  loss_box_reg: 0.338  loss_mask: 0.228  loss_rpn_cls: 0.042  loss_rpn_loc: 0.135  time: 3.9220  data_time: 2.8241  lr: 0.000979  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:49:13 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:49:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 22:49:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 22:49:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2590 s / img. ETA=0:02:38\n",
            "\u001b[32m[07/09 22:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2485 s / img. ETA=0:02:26\n",
            "\u001b[32m[07/09 22:50:06 d2.evaluation.evaluator]: \u001b[0mInference done 15/56. 0.2417 s / img. ETA=0:02:14\n",
            "\u001b[32m[07/09 22:50:12 d2.evaluation.evaluator]: \u001b[0mInference done 18/56. 0.2249 s / img. ETA=0:01:54\n",
            "\u001b[32m[07/09 22:50:18 d2.evaluation.evaluator]: \u001b[0mInference done 22/56. 0.1989 s / img. ETA=0:01:29\n",
            "\u001b[32m[07/09 22:50:25 d2.evaluation.evaluator]: \u001b[0mInference done 26/56. 0.1847 s / img. ETA=0:01:13\n",
            "\u001b[32m[07/09 22:50:30 d2.evaluation.evaluator]: \u001b[0mInference done 30/56. 0.1724 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/09 22:50:36 d2.evaluation.evaluator]: \u001b[0mInference done 33/56. 0.1705 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/09 22:50:42 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.1681 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/09 22:50:48 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1659 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/09 22:50:55 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1652 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/09 22:51:02 d2.evaluation.evaluator]: \u001b[0mInference done 43/56. 0.1600 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/09 22:51:07 d2.evaluation.evaluator]: \u001b[0mInference done 45/56. 0.1623 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/09 22:51:14 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.1667 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/09 22:51:20 d2.evaluation.evaluator]: \u001b[0mInference done 49/56. 0.1706 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/09 22:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 51/56. 0.1741 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/09 22:51:33 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.1772 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 22:51:39 d2.evaluation.evaluator]: \u001b[0mInference done 55/56. 0.1801 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 22:51:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:08.763954 (2.524783 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:51:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.181450 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:51:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:51:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:51:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.55s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.733\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.480\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.563\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.627\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n",
            "\u001b[32m[07/09 22:51:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 44.593 | 73.294 | 48.011 |  nan  |  nan  | 44.593 |\n",
            "\u001b[32m[07/09 22:51:43 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:51:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 48.928 | brec_Cht         | 52.022 | lam_Sltst  | 38.682 |\n",
            "| skel_WkstPkst | 34.908 | strless_SltstSst | 48.424 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.15s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.81s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.730\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.548\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.593\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 48.170 | 72.992 | 54.812 |  nan  |  nan  | 48.170 |\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 52.918 | brec_Cht         | 57.708 | lam_Sltst  | 38.665 |\n",
            "| skel_WkstPkst | 42.425 | strless_SltstSst | 49.133 |            |        |\n",
            "\u001b[32m[07/09 22:51:44 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.testing]: \u001b[0mcopypaste: 44.5928,73.2944,48.0109,nan,nan,44.5928\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.testing]: \u001b[0mcopypaste: 48.1697,72.9923,54.8116,nan,nan,48.1697\n",
            "\u001b[32m[07/09 22:51:47 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:51:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 22:51:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 22:52:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1389 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/09 22:52:20 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1606 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.241907 (2.124191 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.156237 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.053\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.057 | 33.288 | 18.645 |  nan  |  nan  | 17.057 |\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 29.801 | brec_Cht         | nan    | lam_Sltst  | 8.806 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 12.565 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.189\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 18.924 | 33.824 | 20.918 |  nan  |  nan  | 18.924 |\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 32.719 | brec_Cht         | nan    | lam_Sltst  | 9.575 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 14.476 |            |       |\n",
            "\u001b[32m[07/09 22:52:22 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.testing]: \u001b[0mcopypaste: 17.0575,33.2877,18.6451,nan,nan,17.0575\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.testing]: \u001b[0mcopypaste: 18.9235,33.8235,20.9184,nan,nan,18.9235\n",
            "\u001b[32m[07/09 22:52:22 d2.utils.events]: \u001b[0m eta: 1:05:48  iter: 999  total_loss: 1.069  loss_cls: 0.312  loss_box_reg: 0.332  loss_mask: 0.230  loss_rpn_cls: 0.041  loss_rpn_loc: 0.140  time: 3.9227  data_time: 2.8565  lr: 0.000999  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:53:40 d2.utils.events]: \u001b[0m eta: 1:04:26  iter: 1019  total_loss: 1.063  loss_cls: 0.305  loss_box_reg: 0.347  loss_mask: 0.222  loss_rpn_cls: 0.046  loss_rpn_loc: 0.136  time: 3.9225  data_time: 2.8028  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:54:58 d2.utils.events]: \u001b[0m eta: 1:03:12  iter: 1039  total_loss: 1.008  loss_cls: 0.279  loss_box_reg: 0.323  loss_mask: 0.219  loss_rpn_cls: 0.040  loss_rpn_loc: 0.134  time: 3.9225  data_time: 2.8097  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:56:17 d2.utils.events]: \u001b[0m eta: 1:01:51  iter: 1059  total_loss: 1.016  loss_cls: 0.278  loss_box_reg: 0.331  loss_mask: 0.227  loss_rpn_cls: 0.039  loss_rpn_loc: 0.149  time: 3.9227  data_time: 2.8236  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:57:36 d2.utils.events]: \u001b[0m eta: 1:00:35  iter: 1079  total_loss: 1.040  loss_cls: 0.309  loss_box_reg: 0.327  loss_mask: 0.226  loss_rpn_cls: 0.039  loss_rpn_loc: 0.138  time: 3.9232  data_time: 2.8334  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:58:54 d2.utils.events]: \u001b[0m eta: 0:59:14  iter: 1099  total_loss: 0.995  loss_cls: 0.279  loss_box_reg: 0.316  loss_mask: 0.216  loss_rpn_cls: 0.035  loss_rpn_loc: 0.132  time: 3.9228  data_time: 2.7869  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:00:12 d2.utils.events]: \u001b[0m eta: 0:57:57  iter: 1119  total_loss: 1.007  loss_cls: 0.282  loss_box_reg: 0.320  loss_mask: 0.219  loss_rpn_cls: 0.035  loss_rpn_loc: 0.130  time: 3.9226  data_time: 2.8231  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:01:30 d2.utils.events]: \u001b[0m eta: 0:56:37  iter: 1139  total_loss: 0.895  loss_cls: 0.232  loss_box_reg: 0.295  loss_mask: 0.212  loss_rpn_cls: 0.035  loss_rpn_loc: 0.125  time: 3.9221  data_time: 2.7802  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:02:49 d2.utils.events]: \u001b[0m eta: 0:55:18  iter: 1159  total_loss: 0.949  loss_cls: 0.263  loss_box_reg: 0.309  loss_mask: 0.207  loss_rpn_cls: 0.038  loss_rpn_loc: 0.123  time: 3.9226  data_time: 2.8449  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:04:08 d2.utils.events]: \u001b[0m eta: 0:54:01  iter: 1179  total_loss: 0.935  loss_cls: 0.268  loss_box_reg: 0.305  loss_mask: 0.208  loss_rpn_cls: 0.034  loss_rpn_loc: 0.127  time: 3.9227  data_time: 2.7864  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:05:40 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:05:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 23:05:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 23:06:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2403 s / img. ETA=0:02:31\n",
            "\u001b[32m[07/09 23:06:24 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2305 s / img. ETA=0:02:19\n",
            "\u001b[32m[07/09 23:06:32 d2.evaluation.evaluator]: \u001b[0mInference done 16/56. 0.2184 s / img. ETA=0:02:01\n",
            "\u001b[32m[07/09 23:06:38 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.1923 s / img. ETA=0:01:34\n",
            "\u001b[32m[07/09 23:06:44 d2.evaluation.evaluator]: \u001b[0mInference done 24/56. 0.1763 s / img. ETA=0:01:16\n",
            "\u001b[32m[07/09 23:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 28/56. 0.1662 s / img. ETA=0:01:02\n",
            "\u001b[32m[07/09 23:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 32/56. 0.1611 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/09 23:07:04 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.1587 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/09 23:07:11 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1576 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/09 23:07:18 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1572 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/09 23:07:25 d2.evaluation.evaluator]: \u001b[0mInference done 43/56. 0.1534 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/09 23:07:30 d2.evaluation.evaluator]: \u001b[0mInference done 45/56. 0.1558 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/09 23:07:37 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.1604 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/09 23:07:43 d2.evaluation.evaluator]: \u001b[0mInference done 49/56. 0.1645 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/09 23:07:49 d2.evaluation.evaluator]: \u001b[0mInference done 51/56. 0.1685 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/09 23:07:55 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.1711 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 23:08:01 d2.evaluation.evaluator]: \u001b[0mInference done 55/56. 0.1735 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:05.233536 (2.455560 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.174922 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.54s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.568\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.856\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.680\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.649\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.692\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.692\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 56.825 | 85.588 | 68.006 |  nan  |  nan  | 56.825 |\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 54.318 | brec_Cht         | 68.325 | lam_Sltst  | 49.699 |\n",
            "| skel_WkstPkst | 53.291 | strless_SltstSst | 58.493 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.73s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.846\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.652\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.696\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.696\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 56.615 | 84.559 | 67.645 |  nan  |  nan  | 56.615 |\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 57.905 | brec_Cht         | 68.479 | lam_Sltst  | 47.757 |\n",
            "| skel_WkstPkst | 51.447 | strless_SltstSst | 57.489 |            |        |\n",
            "\u001b[32m[07/09 23:08:05 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.testing]: \u001b[0mcopypaste: 56.8251,85.5880,68.0063,nan,nan,56.8251\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.testing]: \u001b[0mcopypaste: 56.6153,84.5587,67.6449,nan,nan,56.6153\n",
            "\u001b[32m[07/09 23:08:09 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:08:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 23:08:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 23:08:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1409 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/09 23:08:42 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1634 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.732955 (2.173296 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.158908 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.132\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.151\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.052\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.075 | 30.227 | 13.186 |  nan  |  nan  | 15.075 |\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.371 | brec_Cht         | nan    | lam_Sltst  | 9.278 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 14.575 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.166\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.297\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.176\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.166\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.555\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 16.636 | 29.712 | 17.598 |  nan  |  nan  | 16.636 |\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.633 | brec_Cht         | nan    | lam_Sltst  | 9.618 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 16.657 |            |       |\n",
            "\u001b[32m[07/09 23:08:43 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.testing]: \u001b[0mcopypaste: 15.0750,30.2273,13.1861,nan,nan,15.0750\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.testing]: \u001b[0mcopypaste: 16.6361,29.7120,17.5981,nan,nan,16.6361\n",
            "\u001b[32m[07/09 23:08:43 d2.utils.events]: \u001b[0m eta: 0:52:42  iter: 1199  total_loss: 0.930  loss_cls: 0.247  loss_box_reg: 0.313  loss_mask: 0.206  loss_rpn_cls: 0.031  loss_rpn_loc: 0.134  time: 3.9222  data_time: 2.7785  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:10:01 d2.utils.events]: \u001b[0m eta: 0:51:22  iter: 1219  total_loss: 0.877  loss_cls: 0.225  loss_box_reg: 0.303  loss_mask: 0.201  loss_rpn_cls: 0.032  loss_rpn_loc: 0.125  time: 3.9218  data_time: 2.7776  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:11:20 d2.utils.events]: \u001b[0m eta: 0:50:03  iter: 1239  total_loss: 0.860  loss_cls: 0.228  loss_box_reg: 0.281  loss_mask: 0.205  loss_rpn_cls: 0.032  loss_rpn_loc: 0.112  time: 3.9223  data_time: 2.8578  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:12:39 d2.utils.events]: \u001b[0m eta: 0:48:44  iter: 1259  total_loss: 0.895  loss_cls: 0.241  loss_box_reg: 0.299  loss_mask: 0.201  loss_rpn_cls: 0.026  loss_rpn_loc: 0.124  time: 3.9225  data_time: 2.8266  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:13:58 d2.utils.events]: \u001b[0m eta: 0:47:27  iter: 1279  total_loss: 0.876  loss_cls: 0.236  loss_box_reg: 0.278  loss_mask: 0.202  loss_rpn_cls: 0.031  loss_rpn_loc: 0.126  time: 3.9232  data_time: 2.8592  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:15:17 d2.utils.events]: \u001b[0m eta: 0:46:09  iter: 1299  total_loss: 0.872  loss_cls: 0.226  loss_box_reg: 0.289  loss_mask: 0.204  loss_rpn_cls: 0.029  loss_rpn_loc: 0.123  time: 3.9235  data_time: 2.8240  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:16:36 d2.utils.events]: \u001b[0m eta: 0:44:50  iter: 1319  total_loss: 0.896  loss_cls: 0.251  loss_box_reg: 0.279  loss_mask: 0.200  loss_rpn_cls: 0.030  loss_rpn_loc: 0.128  time: 3.9238  data_time: 2.8621  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:17:55 d2.utils.events]: \u001b[0m eta: 0:43:30  iter: 1339  total_loss: 0.912  loss_cls: 0.258  loss_box_reg: 0.314  loss_mask: 0.196  loss_rpn_cls: 0.030  loss_rpn_loc: 0.127  time: 3.9242  data_time: 2.8261  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:19:14 d2.utils.events]: \u001b[0m eta: 0:42:11  iter: 1359  total_loss: 0.847  loss_cls: 0.226  loss_box_reg: 0.277  loss_mask: 0.201  loss_rpn_cls: 0.030  loss_rpn_loc: 0.121  time: 3.9242  data_time: 2.8450  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:20:33 d2.utils.events]: \u001b[0m eta: 0:40:54  iter: 1379  total_loss: 0.862  loss_cls: 0.226  loss_box_reg: 0.288  loss_mask: 0.196  loss_rpn_cls: 0.031  loss_rpn_loc: 0.115  time: 3.9250  data_time: 2.8466  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:22:05 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:22:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 23:22:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 23:22:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1990 s / img. ETA=0:02:09\n",
            "\u001b[32m[07/09 23:22:46 d2.evaluation.evaluator]: \u001b[0mInference done 14/56. 0.1849 s / img. ETA=0:01:50\n",
            "\u001b[32m[07/09 23:22:52 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.1792 s / img. ETA=0:01:36\n",
            "\u001b[32m[07/09 23:22:57 d2.evaluation.evaluator]: \u001b[0mInference done 22/56. 0.1527 s / img. ETA=0:01:09\n",
            "\u001b[32m[07/09 23:23:02 d2.evaluation.evaluator]: \u001b[0mInference done 27/56. 0.1390 s / img. ETA=0:00:53\n",
            "\u001b[32m[07/09 23:23:09 d2.evaluation.evaluator]: \u001b[0mInference done 32/56. 0.1322 s / img. ETA=0:00:41\n",
            "\u001b[32m[07/09 23:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.1308 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/09 23:23:21 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1305 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/09 23:23:27 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1305 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/09 23:23:32 d2.evaluation.evaluator]: \u001b[0mInference done 43/56. 0.1271 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/09 23:23:39 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.1300 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/09 23:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.1343 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/09 23:23:51 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.1395 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/09 23:23:57 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.1432 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/09 23:24:02 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.1464 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/09 23:24:07 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.1487 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:45.694200 (2.072435 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.148698 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.45s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.934\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.783\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.697\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 64.357 | 93.421 | 78.317 |  nan  |  nan  | 64.357 |\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 64.507 | brec_Cht         | 73.075 | lam_Sltst  | 56.939 |\n",
            "| skel_WkstPkst | 58.137 | strless_SltstSst | 69.127 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.10s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.66s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.932\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.764\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.701\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 64.955 | 93.163 | 76.438 |  nan  |  nan  | 64.955 |\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 64.932 | brec_Cht         | 75.603 | lam_Sltst  | 55.158 |\n",
            "| skel_WkstPkst | 60.363 | strless_SltstSst | 68.721 |            |        |\n",
            "\u001b[32m[07/09 23:24:09 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: 64.3569,93.4207,78.3168,nan,nan,64.3569\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: 64.9555,93.1630,76.4383,nan,nan,64.9555\n",
            "\u001b[32m[07/09 23:24:12 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:24:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 23:24:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 23:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1161 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/09 23:24:40 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1328 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.095279 (1.809528 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.132218 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.153\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.996 | 33.422 | 15.341 |  nan  |  nan  | 15.996 |\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 27.133 | brec_Cht         | nan    | lam_Sltst  | 4.717 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 16.138 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.368\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.515\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 16.707 | 32.289 | 16.000 |  nan  |  nan  | 16.707 |\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 29.050 | brec_Cht         | nan    | lam_Sltst  | 4.200 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 16.871 |            |       |\n",
            "\u001b[32m[07/09 23:24:42 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.testing]: \u001b[0mcopypaste: 15.9959,33.4216,15.3410,nan,nan,15.9959\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.testing]: \u001b[0mcopypaste: 16.7067,32.2889,16.0005,nan,nan,16.7067\n",
            "\u001b[32m[07/09 23:24:42 d2.utils.events]: \u001b[0m eta: 0:39:35  iter: 1399  total_loss: 0.826  loss_cls: 0.216  loss_box_reg: 0.281  loss_mask: 0.195  loss_rpn_cls: 0.028  loss_rpn_loc: 0.118  time: 3.9247  data_time: 2.8047  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:26:00 d2.utils.events]: \u001b[0m eta: 0:38:16  iter: 1419  total_loss: 0.793  loss_cls: 0.194  loss_box_reg: 0.265  loss_mask: 0.192  loss_rpn_cls: 0.028  loss_rpn_loc: 0.107  time: 3.9243  data_time: 2.8040  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:27:18 d2.utils.events]: \u001b[0m eta: 0:36:57  iter: 1439  total_loss: 0.930  loss_cls: 0.238  loss_box_reg: 0.307  loss_mask: 0.218  loss_rpn_cls: 0.030  loss_rpn_loc: 0.139  time: 3.9242  data_time: 2.7938  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:28:38 d2.utils.events]: \u001b[0m eta: 0:35:37  iter: 1459  total_loss: 0.875  loss_cls: 0.236  loss_box_reg: 0.285  loss_mask: 0.196  loss_rpn_cls: 0.030  loss_rpn_loc: 0.126  time: 3.9246  data_time: 2.8575  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:29:56 d2.utils.events]: \u001b[0m eta: 0:34:19  iter: 1479  total_loss: 0.807  loss_cls: 0.198  loss_box_reg: 0.265  loss_mask: 0.191  loss_rpn_cls: 0.031  loss_rpn_loc: 0.119  time: 3.9247  data_time: 2.8038  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:31:16 d2.utils.events]: \u001b[0m eta: 0:33:00  iter: 1499  total_loss: 0.820  loss_cls: 0.193  loss_box_reg: 0.280  loss_mask: 0.191  loss_rpn_cls: 0.027  loss_rpn_loc: 0.119  time: 3.9258  data_time: 2.8948  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:32:35 d2.utils.events]: \u001b[0m eta: 0:31:41  iter: 1519  total_loss: 0.783  loss_cls: 0.186  loss_box_reg: 0.260  loss_mask: 0.183  loss_rpn_cls: 0.028  loss_rpn_loc: 0.126  time: 3.9258  data_time: 2.7949  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:33:54 d2.utils.events]: \u001b[0m eta: 0:30:23  iter: 1539  total_loss: 0.772  loss_cls: 0.189  loss_box_reg: 0.261  loss_mask: 0.187  loss_rpn_cls: 0.029  loss_rpn_loc: 0.111  time: 3.9262  data_time: 2.8437  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:35:14 d2.utils.events]: \u001b[0m eta: 0:29:05  iter: 1559  total_loss: 0.762  loss_cls: 0.177  loss_box_reg: 0.259  loss_mask: 0.181  loss_rpn_cls: 0.025  loss_rpn_loc: 0.114  time: 3.9268  data_time: 2.8560  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:36:33 d2.utils.events]: \u001b[0m eta: 0:27:45  iter: 1579  total_loss: 0.757  loss_cls: 0.174  loss_box_reg: 0.252  loss_mask: 0.183  loss_rpn_cls: 0.022  loss_rpn_loc: 0.116  time: 3.9271  data_time: 2.8191  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:38:06 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:38:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 23:38:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 23:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2136 s / img. ETA=0:02:17\n",
            "\u001b[32m[07/09 23:38:48 d2.evaluation.evaluator]: \u001b[0mInference done 14/56. 0.1943 s / img. ETA=0:01:56\n",
            "\u001b[32m[07/09 23:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.1834 s / img. ETA=0:01:40\n",
            "\u001b[32m[07/09 23:38:59 d2.evaluation.evaluator]: \u001b[0mInference done 22/56. 0.1561 s / img. ETA=0:01:12\n",
            "\u001b[32m[07/09 23:39:04 d2.evaluation.evaluator]: \u001b[0mInference done 27/56. 0.1414 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/09 23:39:10 d2.evaluation.evaluator]: \u001b[0mInference done 32/56. 0.1333 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/09 23:39:16 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.1312 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/09 23:39:21 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1306 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/09 23:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1304 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/09 23:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 43/56. 0.1274 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/09 23:39:39 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.1307 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/09 23:39:46 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.1360 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/09 23:39:52 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.1411 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/09 23:39:58 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.1444 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/09 23:40:04 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.1476 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/09 23:40:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:45.818605 (2.074875 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:40:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.149493 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:40:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:40:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:40:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.43s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.714\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.959\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.874\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.749\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783\n",
            "\u001b[32m[07/09 23:40:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 71.419 | 95.907 | 87.366 |  nan  |  nan  | 71.419 |\n",
            "\u001b[32m[07/09 23:40:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:40:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 70.563 | brec_Cht         | 73.805 | lam_Sltst  | 67.841 |\n",
            "| skel_WkstPkst | 71.160 | strless_SltstSst | 73.726 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.59s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.710\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.959\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.831\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 71.027 | 95.925 | 83.063 |  nan  |  nan  | 71.027 |\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 71.936 | brec_Cht         | 75.912 | lam_Sltst  | 65.658 |\n",
            "| skel_WkstPkst | 68.267 | strless_SltstSst | 73.361 |            |        |\n",
            "\u001b[32m[07/09 23:40:10 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.testing]: \u001b[0mcopypaste: 71.4191,95.9075,87.3663,nan,nan,71.4191\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.testing]: \u001b[0mcopypaste: 71.0269,95.9245,83.0627,nan,nan,71.0270\n",
            "\u001b[32m[07/09 23:40:13 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:40:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 23:40:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 23:40:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1191 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 23:40:42 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1432 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.324570 (1.932457 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.141134 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.147\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.472\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.697 | 29.600 | 13.006 |  nan  |  nan  | 14.697 |\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.669 | brec_Cht         | nan    | lam_Sltst  | 3.565 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 16.856 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.161\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.373\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.200 | 33.357 | 16.132 |  nan  |  nan  | 17.200 |\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 28.649 | brec_Cht         | nan    | lam_Sltst  | 4.363 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 18.587 |            |       |\n",
            "\u001b[32m[07/09 23:40:44 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.testing]: \u001b[0mcopypaste: 14.6968,29.6002,13.0056,nan,nan,14.6968\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.testing]: \u001b[0mcopypaste: 17.1999,33.3572,16.1320,nan,nan,17.1999\n",
            "\u001b[32m[07/09 23:40:44 d2.utils.events]: \u001b[0m eta: 0:26:26  iter: 1599  total_loss: 0.709  loss_cls: 0.160  loss_box_reg: 0.242  loss_mask: 0.178  loss_rpn_cls: 0.025  loss_rpn_loc: 0.099  time: 3.9274  data_time: 2.8504  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:42:02 d2.utils.events]: \u001b[0m eta: 0:25:07  iter: 1619  total_loss: 0.701  loss_cls: 0.160  loss_box_reg: 0.233  loss_mask: 0.174  loss_rpn_cls: 0.021  loss_rpn_loc: 0.105  time: 3.9273  data_time: 2.8008  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:43:22 d2.utils.events]: \u001b[0m eta: 0:23:47  iter: 1639  total_loss: 0.710  loss_cls: 0.166  loss_box_reg: 0.234  loss_mask: 0.176  loss_rpn_cls: 0.021  loss_rpn_loc: 0.109  time: 3.9277  data_time: 2.8724  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:44:41 d2.utils.events]: \u001b[0m eta: 0:22:27  iter: 1659  total_loss: 0.688  loss_cls: 0.165  loss_box_reg: 0.224  loss_mask: 0.170  loss_rpn_cls: 0.020  loss_rpn_loc: 0.108  time: 3.9282  data_time: 2.8485  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:46:00 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 1679  total_loss: 0.727  loss_cls: 0.179  loss_box_reg: 0.252  loss_mask: 0.179  loss_rpn_cls: 0.023  loss_rpn_loc: 0.105  time: 3.9283  data_time: 2.8168  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:47:18 d2.utils.events]: \u001b[0m eta: 0:19:49  iter: 1699  total_loss: 0.681  loss_cls: 0.159  loss_box_reg: 0.227  loss_mask: 0.168  loss_rpn_cls: 0.022  loss_rpn_loc: 0.108  time: 3.9283  data_time: 2.8203  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:48:36 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 1719  total_loss: 0.714  loss_cls: 0.156  loss_box_reg: 0.235  loss_mask: 0.175  loss_rpn_cls: 0.020  loss_rpn_loc: 0.102  time: 3.9279  data_time: 2.7794  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:49:54 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 1739  total_loss: 0.703  loss_cls: 0.165  loss_box_reg: 0.228  loss_mask: 0.166  loss_rpn_cls: 0.019  loss_rpn_loc: 0.102  time: 3.9276  data_time: 2.7811  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:51:13 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 1759  total_loss: 0.664  loss_cls: 0.149  loss_box_reg: 0.227  loss_mask: 0.171  loss_rpn_cls: 0.020  loss_rpn_loc: 0.100  time: 3.9275  data_time: 2.8145  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:52:32 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 1779  total_loss: 0.686  loss_cls: 0.158  loss_box_reg: 0.214  loss_mask: 0.168  loss_rpn_cls: 0.021  loss_rpn_loc: 0.105  time: 3.9277  data_time: 2.8203  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:54:05 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:54:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 23:54:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 23:54:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2191 s / img. ETA=0:02:19\n",
            "\u001b[32m[07/09 23:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2133 s / img. ETA=0:02:10\n",
            "\u001b[32m[07/09 23:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 16/56. 0.2045 s / img. ETA=0:01:53\n",
            "\u001b[32m[07/09 23:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 21/56. 0.1700 s / img. ETA=0:01:20\n",
            "\u001b[32m[07/09 23:55:04 d2.evaluation.evaluator]: \u001b[0mInference done 26/56. 0.1519 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/09 23:55:09 d2.evaluation.evaluator]: \u001b[0mInference done 31/56. 0.1397 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/09 23:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 34/56. 0.1371 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/09 23:55:21 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1344 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/09 23:55:26 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1338 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/09 23:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 44/56. 0.1300 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/09 23:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.1327 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/09 23:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.1365 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/09 23:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.1419 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/09 23:55:56 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.1446 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 23:56:03 d2.evaluation.evaluator]: \u001b[0mInference done 55/56. 0.1483 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:44.085278 (2.040888 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.149552 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.43s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.719\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.971\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.886\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.756\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 71.940 | 97.082 | 88.619 |  nan  |  nan  | 71.940 |\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 71.760 | brec_Cht         | 75.953 | lam_Sltst  | 71.359 |\n",
            "| skel_WkstPkst | 65.174 | strless_SltstSst | 75.453 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.62s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.727\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.969\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.866\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.762\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.790\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.790\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 72.685 | 96.895 | 86.632 |  nan  |  nan  | 72.685 |\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 73.831 | brec_Cht         | 80.185 | lam_Sltst  | 69.454 |\n",
            "| skel_WkstPkst | 63.960 | strless_SltstSst | 75.997 |            |        |\n",
            "\u001b[32m[07/09 23:56:07 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: 71.9398,97.0815,88.6192,nan,nan,71.9398\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: 72.6854,96.8947,86.6316,nan,nan,72.6854\n",
            "\u001b[32m[07/09 23:56:11 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:56:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 23:56:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 23:56:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1229 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 23:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1405 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.934705 (1.893470 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.138525 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.368\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.899 | 36.783 | 16.273 |  nan  |  nan  | 17.899 |\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 26.056 | brec_Cht         | nan    | lam_Sltst  | 7.186 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 20.454 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.182\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.193\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.367\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.518\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 19.307 | 37.380 | 18.219 |  nan  |  nan  | 19.307 |\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 28.347 | brec_Cht         | nan    | lam_Sltst  | 8.040 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 21.534 |            |       |\n",
            "\u001b[32m[07/09 23:56:42 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 23:56:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:56:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:56:42 d2.evaluation.testing]: \u001b[0mcopypaste: 17.8988,36.7828,16.2732,nan,nan,17.8988\n",
            "\u001b[32m[07/09 23:56:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:56:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:56:42 d2.evaluation.testing]: \u001b[0mcopypaste: 19.3071,37.3802,18.2195,nan,nan,19.3071\n",
            "\u001b[32m[07/09 23:56:42 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 1799  total_loss: 0.702  loss_cls: 0.166  loss_box_reg: 0.239  loss_mask: 0.171  loss_rpn_cls: 0.021  loss_rpn_loc: 0.106  time: 3.9283  data_time: 2.8781  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:57:59 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 1819  total_loss: 0.665  loss_cls: 0.152  loss_box_reg: 0.215  loss_mask: 0.163  loss_rpn_cls: 0.025  loss_rpn_loc: 0.103  time: 3.9277  data_time: 2.7659  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:59:18 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 1839  total_loss: 0.674  loss_cls: 0.157  loss_box_reg: 0.229  loss_mask: 0.168  loss_rpn_cls: 0.019  loss_rpn_loc: 0.106  time: 3.9278  data_time: 2.8081  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:00:37 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 1859  total_loss: 0.665  loss_cls: 0.147  loss_box_reg: 0.217  loss_mask: 0.169  loss_rpn_cls: 0.019  loss_rpn_loc: 0.094  time: 3.9282  data_time: 2.8567  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:01:56 d2.utils.events]: \u001b[0m eta: 0:07:57  iter: 1879  total_loss: 0.664  loss_cls: 0.144  loss_box_reg: 0.224  loss_mask: 0.171  loss_rpn_cls: 0.018  loss_rpn_loc: 0.106  time: 3.9281  data_time: 2.7993  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:03:14 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 1899  total_loss: 0.684  loss_cls: 0.156  loss_box_reg: 0.231  loss_mask: 0.169  loss_rpn_cls: 0.021  loss_rpn_loc: 0.106  time: 3.9282  data_time: 2.8422  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:04:34 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 1919  total_loss: 0.676  loss_cls: 0.156  loss_box_reg: 0.232  loss_mask: 0.172  loss_rpn_cls: 0.022  loss_rpn_loc: 0.109  time: 3.9288  data_time: 2.9038  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:05:52 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 1939  total_loss: 0.643  loss_cls: 0.140  loss_box_reg: 0.211  loss_mask: 0.157  loss_rpn_cls: 0.018  loss_rpn_loc: 0.108  time: 3.9284  data_time: 2.7905  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:07:11 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 1959  total_loss: 0.649  loss_cls: 0.140  loss_box_reg: 0.221  loss_mask: 0.159  loss_rpn_cls: 0.019  loss_rpn_loc: 0.102  time: 3.9286  data_time: 2.8381  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:08:29 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 1979  total_loss: 0.605  loss_cls: 0.124  loss_box_reg: 0.208  loss_mask: 0.150  loss_rpn_cls: 0.018  loss_rpn_loc: 0.102  time: 3.9285  data_time: 2.8126  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:10:03 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 00:10:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 00:10:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/10 00:10:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1812 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/10 00:10:39 d2.evaluation.evaluator]: \u001b[0mInference done 14/56. 0.1666 s / img. ETA=0:01:40\n",
            "\u001b[32m[07/10 00:10:44 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.1596 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/10 00:10:49 d2.evaluation.evaluator]: \u001b[0mInference done 23/56. 0.1334 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/10 00:10:55 d2.evaluation.evaluator]: \u001b[0mInference done 29/56. 0.1208 s / img. ETA=0:00:41\n",
            "\u001b[32m[07/10 00:11:01 d2.evaluation.evaluator]: \u001b[0mInference done 34/56. 0.1170 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 00:11:06 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1149 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/10 00:11:13 d2.evaluation.evaluator]: \u001b[0mInference done 40/56. 0.1140 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 00:11:20 d2.evaluation.evaluator]: \u001b[0mInference done 45/56. 0.1137 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/10 00:11:27 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.1186 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 00:11:33 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.1238 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 00:11:39 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.1267 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 00:11:45 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.1293 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 00:11:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:27.764160 (1.720866 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:11:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.129291 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:11:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 00:11:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 00:11:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.35s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.765\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.993\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.944\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.779\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800\n",
            "\u001b[32m[07/10 00:11:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 76.459 | 99.259 | 94.362 |  nan  |  nan  | 76.459 |\n",
            "\u001b[32m[07/10 00:11:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:11:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 74.968 | brec_Cht         | 80.009 | lam_Sltst  | 73.356 |\n",
            "| skel_WkstPkst | 77.024 | strless_SltstSst | 76.940 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.51s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.786\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.993\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.940\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.822\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.822\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 78.641 | 99.259 | 94.004 |  nan  |  nan  | 78.641 |\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 78.059 | brec_Cht         | 83.862 | lam_Sltst  | 72.369 |\n",
            "| skel_WkstPkst | 79.370 | strless_SltstSst | 79.543 |            |        |\n",
            "\u001b[32m[07/10 00:11:47 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.testing]: \u001b[0mcopypaste: 76.4592,99.2592,94.3620,nan,nan,76.4592\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.testing]: \u001b[0mcopypaste: 78.6407,99.2592,94.0041,nan,nan,78.6407\n",
            "\u001b[32m[07/10 00:11:50 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 00:11:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 00:11:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/10 00:12:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1103 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 00:12:18 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1282 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.574525 (1.757452 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.126288 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.788 | 30.824 | 13.678 |  nan  |  nan  | 14.788 |\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.618 | brec_Cht         | nan    | lam_Sltst  | 2.279 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 17.467 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.449 | 31.240 | 18.594 |  nan  |  nan  | 17.449 |\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 30.700 | brec_Cht         | nan    | lam_Sltst  | 2.334 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 19.314 |            |       |\n",
            "\u001b[32m[07/10 00:12:19 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: 14.7882,30.8240,13.6784,nan,nan,14.7882\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: 17.4493,31.2403,18.5942,nan,nan,17.4493\n",
            "\u001b[32m[07/10 00:12:19 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 1999  total_loss: 0.617  loss_cls: 0.127  loss_box_reg: 0.226  loss_mask: 0.159  loss_rpn_cls: 0.019  loss_rpn_loc: 0.096  time: 3.9288  data_time: 2.8162  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:12:19 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 2:10:49 (3.9308 s / it)\n",
            "\u001b[32m[07/10 00:12:19 d2.engine.hooks]: \u001b[0mTotal training time: 2:49:07 (0:38:17 on hooks)\n",
            "\n",
            "\n",
            "**Starting train eval**\n",
            "\u001b[32m[07/10 00:12:33 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 00:12:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 00:12:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/10 00:13:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1826 s / img. ETA=0:03:57\n",
            "\u001b[32m[07/10 00:13:36 d2.evaluation.evaluator]: \u001b[0mInference done 12/56. 0.1845 s / img. ETA=0:03:51\n",
            "\u001b[32m[07/10 00:13:45 d2.evaluation.evaluator]: \u001b[0mInference done 15/56. 0.1666 s / img. ETA=0:03:06\n",
            "\u001b[32m[07/10 00:13:50 d2.evaluation.evaluator]: \u001b[0mInference done 16/56. 0.1677 s / img. ETA=0:03:04\n",
            "\u001b[32m[07/10 00:13:55 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.1592 s / img. ETA=0:02:15\n",
            "\u001b[32m[07/10 00:14:01 d2.evaluation.evaluator]: \u001b[0mInference done 25/56. 0.1395 s / img. ETA=0:01:36\n",
            "\u001b[32m[07/10 00:14:08 d2.evaluation.evaluator]: \u001b[0mInference done 30/56. 0.1294 s / img. ETA=0:01:11\n",
            "\u001b[32m[07/10 00:14:14 d2.evaluation.evaluator]: \u001b[0mInference done 33/56. 0.1268 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/10 00:14:20 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1227 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/10 00:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 40/56. 0.1213 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/10 00:14:33 d2.evaluation.evaluator]: \u001b[0mInference done 44/56. 0.1194 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/10 00:14:42 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.1214 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 00:14:53 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.1246 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 00:15:01 d2.evaluation.evaluator]: \u001b[0mInference done 49/56. 0.1274 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/10 00:15:07 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.1292 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/10 00:15:13 d2.evaluation.evaluator]: \u001b[0mInference done 51/56. 0.1307 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/10 00:15:21 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.1319 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 00:15:27 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.1335 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 00:15:35 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.1343 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 00:15:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:36.070855 (3.060213 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:15:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.134264 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:15:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 00:15:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/10 00:15:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.765\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.993\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.944\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.779\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800\n",
            "\u001b[32m[07/10 00:15:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 76.459 | 99.259 | 94.362 |  nan  |  nan  | 76.459 |\n",
            "\u001b[32m[07/10 00:15:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:15:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 74.968 | brec_Cht         | 80.009 | lam_Sltst  | 73.356 |\n",
            "| skel_WkstPkst | 77.024 | strless_SltstSst | 76.940 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.51s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.786\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.993\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.940\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.822\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.822\n",
            "\u001b[32m[07/10 00:15:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 78.641 | 99.259 | 94.004 |  nan  |  nan  | 78.641 |\n",
            "\u001b[32m[07/10 00:15:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:15:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 78.059 | brec_Cht         | 83.862 | lam_Sltst  | 72.369 |\n",
            "| skel_WkstPkst | 79.370 | strless_SltstSst | 79.543 |            |        |\n",
            "randomly selected cores/Box 8 Depths 10035-45.JPG\n",
            "\n",
            "\n",
            "**Starting val eval**\n",
            "\u001b[32m[07/10 00:16:16 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 00:16:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 00:16:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/10 00:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1113 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 00:16:56 d2.evaluation.evaluator]: \u001b[0mInference done 13/15. 0.1228 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 00:17:02 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1298 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.177241 (2.917724 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.127673 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.788 | 30.824 | 13.678 |  nan  |  nan  | 14.788 |\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.618 | brec_Cht         | nan    | lam_Sltst  | 2.279 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 17.467 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.449 | 31.240 | 18.594 |  nan  |  nan  | 17.449 |\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 30.700 | brec_Cht         | nan    | lam_Sltst  | 2.334 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 19.314 |            |       |\n",
            "randomly selected cores/Boxes 40-42  Depths 7829.5-7838.8 (Dry).JPG\n",
            "Fri Jul 10 00:17:40 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    36W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "CPU times: user 20.8 s, sys: 2.93 s, total: 23.7 s\n",
            "Wall time: 2h 55min 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_hb1WlvLaZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87312ea0-91f3-46ec-ac54-be6db1128f34"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '1' --max_iter 2000\n",
        "# copy results to Google Drive\n",
        "! cp -r output_fold_1 'drive/My Drive/R50-C4'\n",
        "# clean folders if upcoming experiment\n",
        "! rm -r *coco*\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 1\n",
            "\t cores_fold_1_train\n",
            "\t cores_fold_1_val\n",
            "\u001b[32m[07/10 12:33:10 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/10 12:33:22 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 56 images left.\n",
            "\u001b[32m[07/10 12:33:22 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 234          |   brec_Cht    | 4            | lam_Sltst  | 98           |\n",
            "| skel_WkstPkst | 18           | strless_Slt.. | 139          |            |              |\n",
            "|     total     | 493          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/10 12:33:22 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 12:33:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 12:33:22 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/10 12:33:22 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-10 12:33:23.255749: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "model_final_4ce675.pkl: 144MB [00:17, 8.15MB/s]               \n",
            "Unable to load 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (15, 4) in the checkpoint but (3, 4) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (1024, 1024, 3, 3) in the checkpoint but (256, 256, 3, 3) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (256,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (15, 1024, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (15,) in the checkpoint but (3,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (60, 1024, 1, 1) in the checkpoint but (12, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (60,) in the checkpoint but (12,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.deconv.weight' to the model due to incompatible shapes: (2048, 256, 2, 2) in the checkpoint but (256, 256, 2, 2) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/10 12:33:48 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/10 12:34:59 d2.utils.events]: \u001b[0m eta: 1:56:00  iter: 19  total_loss: 44.874  loss_cls: 30.200  loss_box_reg: 0.322  loss_mask: 1.507  loss_rpn_cls: 0.605  loss_rpn_loc: 9.271  time: 3.4944  data_time: 2.7295  lr: 0.000020  max_mem: 6781M\n",
            "\u001b[32m[07/10 12:36:09 d2.utils.events]: \u001b[0m eta: 1:54:40  iter: 39  total_loss: 8.960  loss_cls: 6.726  loss_box_reg: 0.196  loss_mask: 0.583  loss_rpn_cls: 0.272  loss_rpn_loc: 0.984  time: 3.5073  data_time: 2.6801  lr: 0.000040  max_mem: 6782M\n",
            "\u001b[32m[07/10 12:37:19 d2.utils.events]: \u001b[0m eta: 1:53:25  iter: 59  total_loss: 3.233  loss_cls: 1.766  loss_box_reg: 0.308  loss_mask: 0.581  loss_rpn_cls: 0.215  loss_rpn_loc: 0.362  time: 3.4967  data_time: 2.5485  lr: 0.000060  max_mem: 6802M\n",
            "\u001b[32m[07/10 12:38:28 d2.utils.events]: \u001b[0m eta: 1:52:09  iter: 79  total_loss: 1.980  loss_cls: 0.577  loss_box_reg: 0.333  loss_mask: 0.559  loss_rpn_cls: 0.189  loss_rpn_loc: 0.297  time: 3.4907  data_time: 2.5499  lr: 0.000080  max_mem: 7024M\n",
            "\u001b[32m[07/10 12:39:37 d2.utils.events]: \u001b[0m eta: 1:49:34  iter: 99  total_loss: 1.734  loss_cls: 0.378  loss_box_reg: 0.354  loss_mask: 0.545  loss_rpn_cls: 0.190  loss_rpn_loc: 0.273  time: 3.4845  data_time: 2.5441  lr: 0.000100  max_mem: 7057M\n",
            "\u001b[32m[07/10 12:40:46 d2.utils.events]: \u001b[0m eta: 1:48:19  iter: 119  total_loss: 1.649  loss_cls: 0.326  loss_box_reg: 0.374  loss_mask: 0.534  loss_rpn_cls: 0.165  loss_rpn_loc: 0.247  time: 3.4789  data_time: 2.5276  lr: 0.000120  max_mem: 7371M\n",
            "\u001b[32m[07/10 12:41:55 d2.utils.events]: \u001b[0m eta: 1:47:16  iter: 139  total_loss: 1.630  loss_cls: 0.374  loss_box_reg: 0.369  loss_mask: 0.523  loss_rpn_cls: 0.158  loss_rpn_loc: 0.226  time: 3.4716  data_time: 2.4844  lr: 0.000140  max_mem: 7371M\n",
            "\u001b[32m[07/10 12:43:03 d2.utils.events]: \u001b[0m eta: 1:45:48  iter: 159  total_loss: 1.620  loss_cls: 0.350  loss_box_reg: 0.383  loss_mask: 0.509  loss_rpn_cls: 0.158  loss_rpn_loc: 0.214  time: 3.4651  data_time: 2.4682  lr: 0.000160  max_mem: 7569M\n",
            "\u001b[32m[07/10 12:44:12 d2.utils.events]: \u001b[0m eta: 1:44:45  iter: 179  total_loss: 1.611  loss_cls: 0.346  loss_box_reg: 0.406  loss_mask: 0.486  loss_rpn_cls: 0.153  loss_rpn_loc: 0.215  time: 3.4631  data_time: 2.4963  lr: 0.000180  max_mem: 7569M\n",
            "\u001b[32m[07/10 12:45:34 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 12:45:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 12:45:34 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_1_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/10 12:45:34 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_1_train' to COCO format ...)\n",
            "\u001b[32m[07/10 12:45:45 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/10 12:45:45 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 57, #annotations: 493\n",
            "\u001b[32m[07/10 12:45:45 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_1_train_coco_format.json' ...\n",
            "\u001b[32m[07/10 12:45:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0x8f5e4000 @  0x7fba7ceccb6b 0x7fba7ceec379 0x7fba2062104e 0x7fba20622f4a 0x7fba5951167b 0x7fba591606be 0x7fba593c97b5 0x7fba593bb7c1 0x7fba593bad0e 0x7fba593bb7c1 0x7fba5ae1093a 0x7fba593bb7c1 0x7fba5915b457 0x7fba5915c080 0x7fba5947a71a 0x7fba5aef813e 0x7fba593bbc72 0x7fba67455a68 0x7fba67510b04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/10 12:46:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2976 s / img. ETA=0:02:24\n",
            "\u001b[32m[07/10 12:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2888 s / img. ETA=0:02:16\n",
            "\u001b[32m[07/10 12:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2712 s / img. ETA=0:02:14\n",
            "\u001b[32m[07/10 12:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.2595 s / img. ETA=0:02:17\n",
            "\u001b[32m[07/10 12:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2511 s / img. ETA=0:02:17\n",
            "\u001b[32m[07/10 12:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.2453 s / img. ETA=0:02:15\n",
            "\u001b[32m[07/10 12:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2408 s / img. ETA=0:02:11\n",
            "\u001b[32m[07/10 12:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2369 s / img. ETA=0:02:06\n",
            "\u001b[32m[07/10 12:47:32 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.2336 s / img. ETA=0:02:00\n",
            "\u001b[32m[07/10 12:47:41 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.2309 s / img. ETA=0:01:54\n",
            "\u001b[32m[07/10 12:47:50 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2291 s / img. ETA=0:01:47\n",
            "\u001b[32m[07/10 12:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.2257 s / img. ETA=0:01:38\n",
            "\u001b[32m[07/10 12:48:08 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.2240 s / img. ETA=0:01:31\n",
            "\u001b[32m[07/10 12:48:15 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.2226 s / img. ETA=0:01:22\n",
            "\u001b[32m[07/10 12:48:24 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.2212 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/10 12:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.2200 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/10 12:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.2192 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/10 12:48:49 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.2210 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/10 12:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.2226 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/10 12:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.2240 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/10 12:49:07 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.2251 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/10 12:49:13 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.2262 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 12:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.2271 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 12:49:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:17.765396 (3.803181 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 12:49:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.227488 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 12:49:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 12:49:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 12:49:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.61s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.146\n",
            "\u001b[32m[07/10 12:49:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.540 | 9.104  | 0.291  |  nan  |  nan  | 2.540 |\n",
            "\u001b[32m[07/10 12:49:22 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 12:49:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 8.073 | brec_Cht         | 0.000 | lam_Sltst  | 1.275 |\n",
            "| skel_WkstPkst | 0.248 | strless_SltstSst | 3.102 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.19s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.87s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.022\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.022\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.135\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.135\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.193 | 8.777  | 0.220  |  nan  |  nan  | 2.193 |\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 7.217 | brec_Cht         | 0.000 | lam_Sltst  | 1.052 |\n",
            "| skel_WkstPkst | 0.099 | strless_SltstSst | 2.596 |            |       |\n",
            "\u001b[32m[07/10 12:49:23 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.testing]: \u001b[0mcopypaste: 2.5396,9.1036,0.2913,nan,nan,2.5396\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.testing]: \u001b[0mcopypaste: 2.1926,8.7774,0.2196,nan,nan,2.1926\n",
            "\u001b[32m[07/10 12:49:27 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 75           |   brec_Cht    | 17           | lam_Sltst  | 29           |\n",
            "| skel_WkstPkst | 8            | strless_Slt.. | 34           |            |              |\n",
            "|     total     | 163          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/10 12:49:27 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 12:49:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 12:49:27 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_1_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/10 12:49:27 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_1_val' to COCO format ...)\n",
            "\u001b[32m[07/10 12:49:30 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/10 12:49:30 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 14, #annotations: 163\n",
            "\u001b[32m[07/10 12:49:30 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_1_val_coco_format.json' ...\n",
            "\u001b[32m[07/10 12:49:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 12:50:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2194 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 12:50:18 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2267 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 12:50:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.248777 (3.694309 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 12:50:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.229143 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 12:50:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 12:50:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 12:50:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.101\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.101\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 1.450 | 5.476  | 0.253  |  nan  |  nan  | 1.450 |\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 4.435 | brec_Cht         | 0.000 | lam_Sltst  | 0.267 |\n",
            "| skel_WkstPkst | 0.000 | strless_SltstSst | 2.548 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.097\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 1.391 | 5.533  | 0.199  |  nan  |  nan  | 1.391 |\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 4.117 | brec_Cht         | 0.000 | lam_Sltst  | 0.284 |\n",
            "| skel_WkstPkst | 0.000 | strless_SltstSst | 2.554 |            |       |\n",
            "\u001b[32m[07/10 12:50:22 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.testing]: \u001b[0mcopypaste: 1.4499,5.4756,0.2531,nan,nan,1.4499\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.testing]: \u001b[0mcopypaste: 1.3910,5.5332,0.1988,nan,nan,1.3910\n",
            "\u001b[32m[07/10 12:50:22 d2.utils.events]: \u001b[0m eta: 1:43:26  iter: 199  total_loss: 1.591  loss_cls: 0.355  loss_box_reg: 0.405  loss_mask: 0.471  loss_rpn_cls: 0.142  loss_rpn_loc: 0.221  time: 3.4616  data_time: 2.5002  lr: 0.000200  max_mem: 7786M\n",
            "\u001b[32m[07/10 12:51:30 d2.utils.events]: \u001b[0m eta: 1:42:17  iter: 219  total_loss: 1.585  loss_cls: 0.372  loss_box_reg: 0.425  loss_mask: 0.455  loss_rpn_cls: 0.142  loss_rpn_loc: 0.204  time: 3.4565  data_time: 2.4220  lr: 0.000220  max_mem: 7786M\n",
            "\u001b[32m[07/10 12:52:39 d2.utils.events]: \u001b[0m eta: 1:41:12  iter: 239  total_loss: 1.561  loss_cls: 0.382  loss_box_reg: 0.415  loss_mask: 0.430  loss_rpn_cls: 0.133  loss_rpn_loc: 0.193  time: 3.4566  data_time: 2.4995  lr: 0.000240  max_mem: 7786M\n",
            "\u001b[32m[07/10 12:53:48 d2.utils.events]: \u001b[0m eta: 1:39:55  iter: 259  total_loss: 1.529  loss_cls: 0.377  loss_box_reg: 0.415  loss_mask: 0.410  loss_rpn_cls: 0.125  loss_rpn_loc: 0.185  time: 3.4552  data_time: 2.4523  lr: 0.000260  max_mem: 7928M\n",
            "\u001b[32m[07/10 12:54:57 d2.utils.events]: \u001b[0m eta: 1:38:41  iter: 279  total_loss: 1.531  loss_cls: 0.410  loss_box_reg: 0.419  loss_mask: 0.389  loss_rpn_cls: 0.119  loss_rpn_loc: 0.198  time: 3.4536  data_time: 2.4392  lr: 0.000280  max_mem: 7928M\n",
            "\u001b[32m[07/10 12:56:06 d2.utils.events]: \u001b[0m eta: 1:37:37  iter: 299  total_loss: 1.566  loss_cls: 0.425  loss_box_reg: 0.435  loss_mask: 0.370  loss_rpn_cls: 0.121  loss_rpn_loc: 0.192  time: 3.4536  data_time: 2.4314  lr: 0.000300  max_mem: 8004M\n",
            "\u001b[32m[07/10 12:57:15 d2.utils.events]: \u001b[0m eta: 1:36:32  iter: 319  total_loss: 1.430  loss_cls: 0.362  loss_box_reg: 0.409  loss_mask: 0.346  loss_rpn_cls: 0.108  loss_rpn_loc: 0.181  time: 3.4539  data_time: 2.4736  lr: 0.000320  max_mem: 8267M\n",
            "\u001b[32m[07/10 12:58:25 d2.utils.events]: \u001b[0m eta: 1:35:27  iter: 339  total_loss: 1.466  loss_cls: 0.418  loss_box_reg: 0.438  loss_mask: 0.352  loss_rpn_cls: 0.104  loss_rpn_loc: 0.176  time: 3.4570  data_time: 2.4794  lr: 0.000340  max_mem: 8267M\n",
            "\u001b[32m[07/10 12:59:34 d2.utils.events]: \u001b[0m eta: 1:34:22  iter: 359  total_loss: 1.376  loss_cls: 0.367  loss_box_reg: 0.412  loss_mask: 0.333  loss_rpn_cls: 0.100  loss_rpn_loc: 0.184  time: 3.4553  data_time: 2.4309  lr: 0.000360  max_mem: 8267M\n",
            "\u001b[32m[07/10 13:00:43 d2.utils.events]: \u001b[0m eta: 1:33:19  iter: 379  total_loss: 1.403  loss_cls: 0.391  loss_box_reg: 0.401  loss_mask: 0.320  loss_rpn_cls: 0.100  loss_rpn_loc: 0.181  time: 3.4565  data_time: 2.4705  lr: 0.000380  max_mem: 8267M\n",
            "\u001b[32m[07/10 13:02:04 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:02:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 13:02:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 13:02:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2690 s / img. ETA=0:02:20\n",
            "\u001b[32m[07/10 13:02:46 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2680 s / img. ETA=0:02:12\n",
            "\u001b[32m[07/10 13:02:56 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2548 s / img. ETA=0:02:19\n",
            "\u001b[32m[07/10 13:03:04 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.2436 s / img. ETA=0:02:18\n",
            "\u001b[32m[07/10 13:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2378 s / img. ETA=0:02:18\n",
            "\u001b[32m[07/10 13:03:22 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.2332 s / img. ETA=0:02:15\n",
            "\u001b[32m[07/10 13:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2297 s / img. ETA=0:02:10\n",
            "\u001b[32m[07/10 13:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2269 s / img. ETA=0:02:05\n",
            "\u001b[32m[07/10 13:03:50 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.2244 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/10 13:03:59 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.2225 s / img. ETA=0:01:52\n",
            "\u001b[32m[07/10 13:04:08 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2200 s / img. ETA=0:01:45\n",
            "\u001b[32m[07/10 13:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.2187 s / img. ETA=0:01:37\n",
            "\u001b[32m[07/10 13:04:26 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.2172 s / img. ETA=0:01:30\n",
            "\u001b[32m[07/10 13:04:35 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.2162 s / img. ETA=0:01:22\n",
            "\u001b[32m[07/10 13:04:44 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.2151 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/10 13:04:53 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.2142 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/10 13:05:02 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.2137 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/10 13:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.2114 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/10 13:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.2135 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/10 13:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.2154 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/10 13:05:26 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.2169 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/10 13:05:31 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.2183 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 13:05:37 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.2195 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 13:05:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:17.155810 (3.791458 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:05:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.220058 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:05:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:05:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:05:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.65s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.134\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.322\n",
            "\u001b[32m[07/10 13:05:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.400 | 32.817 | 6.494  |  nan  |  nan  | 13.400 |\n",
            "\u001b[32m[07/10 13:05:40 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:05:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.702 | brec_Cht         | 0.000  | lam_Sltst  | 9.003 |\n",
            "| skel_WkstPkst | 14.410 | strless_SltstSst | 22.888 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.77s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.151\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.103 | 33.270 | 9.606  |  nan  |  nan  | 15.104 |\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 23.410 | brec_Cht         | 0.000  | lam_Sltst  | 10.077 |\n",
            "| skel_WkstPkst | 18.127 | strless_SltstSst | 23.901 |            |        |\n",
            "\u001b[32m[07/10 13:05:41 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.testing]: \u001b[0mcopypaste: 13.4004,32.8171,6.4936,nan,nan,13.4004\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.testing]: \u001b[0mcopypaste: 15.1028,33.2698,9.6058,nan,nan,15.1041\n",
            "\u001b[32m[07/10 13:05:45 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:05:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 13:05:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 13:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2176 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 13:06:31 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2256 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:31.902724 (3.544747 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.228205 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.210\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.318 | 9.672  | 1.627  |  nan  |  nan  | 3.318 |\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 8.976 | brec_Cht         | 0.000 | lam_Sltst  | 0.999 |\n",
            "| skel_WkstPkst | 1.684 | strless_SltstSst | 4.930 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.105\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.158\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 4.171 | 10.480 | 2.889  |  nan  |  nan  | 4.171 |\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 11.152 | brec_Cht         | 0.000 | lam_Sltst  | 1.329 |\n",
            "| skel_WkstPkst | 2.453  | strless_SltstSst | 5.921 |            |       |\n",
            "\u001b[32m[07/10 13:06:34 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: 3.3178,9.6720,1.6274,nan,nan,3.3178\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: 4.1711,10.4803,2.8893,nan,nan,4.1711\n",
            "\u001b[32m[07/10 13:06:34 d2.utils.events]: \u001b[0m eta: 1:32:12  iter: 399  total_loss: 1.324  loss_cls: 0.364  loss_box_reg: 0.380  loss_mask: 0.310  loss_rpn_cls: 0.097  loss_rpn_loc: 0.167  time: 3.4547  data_time: 2.4031  lr: 0.000400  max_mem: 8267M\n",
            "\u001b[32m[07/10 13:07:43 d2.utils.events]: \u001b[0m eta: 1:31:03  iter: 419  total_loss: 1.391  loss_cls: 0.397  loss_box_reg: 0.398  loss_mask: 0.307  loss_rpn_cls: 0.097  loss_rpn_loc: 0.198  time: 3.4534  data_time: 2.4386  lr: 0.000420  max_mem: 8267M\n",
            "\u001b[32m[07/10 13:08:52 d2.utils.events]: \u001b[0m eta: 1:29:54  iter: 439  total_loss: 1.375  loss_cls: 0.409  loss_box_reg: 0.409  loss_mask: 0.306  loss_rpn_cls: 0.093  loss_rpn_loc: 0.183  time: 3.4528  data_time: 2.4185  lr: 0.000440  max_mem: 8267M\n",
            "\u001b[32m[07/10 13:10:01 d2.utils.events]: \u001b[0m eta: 1:28:41  iter: 459  total_loss: 1.317  loss_cls: 0.374  loss_box_reg: 0.377  loss_mask: 0.301  loss_rpn_cls: 0.091  loss_rpn_loc: 0.165  time: 3.4536  data_time: 2.4560  lr: 0.000460  max_mem: 8480M\n",
            "\u001b[32m[07/10 13:11:11 d2.utils.events]: \u001b[0m eta: 1:27:31  iter: 479  total_loss: 1.354  loss_cls: 0.355  loss_box_reg: 0.379  loss_mask: 0.293  loss_rpn_cls: 0.088  loss_rpn_loc: 0.171  time: 3.4541  data_time: 2.4440  lr: 0.000480  max_mem: 8480M\n",
            "\u001b[32m[07/10 13:12:20 d2.utils.events]: \u001b[0m eta: 1:26:22  iter: 499  total_loss: 1.309  loss_cls: 0.380  loss_box_reg: 0.382  loss_mask: 0.295  loss_rpn_cls: 0.082  loss_rpn_loc: 0.176  time: 3.4538  data_time: 2.4135  lr: 0.000500  max_mem: 8480M\n",
            "\u001b[32m[07/10 13:13:28 d2.utils.events]: \u001b[0m eta: 1:25:12  iter: 519  total_loss: 1.285  loss_cls: 0.364  loss_box_reg: 0.366  loss_mask: 0.294  loss_rpn_cls: 0.085  loss_rpn_loc: 0.172  time: 3.4528  data_time: 2.4252  lr: 0.000519  max_mem: 8480M\n",
            "\u001b[32m[07/10 13:14:38 d2.utils.events]: \u001b[0m eta: 1:24:05  iter: 539  total_loss: 1.261  loss_cls: 0.359  loss_box_reg: 0.370  loss_mask: 0.281  loss_rpn_cls: 0.083  loss_rpn_loc: 0.168  time: 3.4542  data_time: 2.4584  lr: 0.000539  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:15:47 d2.utils.events]: \u001b[0m eta: 1:22:57  iter: 559  total_loss: 1.241  loss_cls: 0.359  loss_box_reg: 0.377  loss_mask: 0.277  loss_rpn_cls: 0.078  loss_rpn_loc: 0.171  time: 3.4545  data_time: 2.4317  lr: 0.000559  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:16:57 d2.utils.events]: \u001b[0m eta: 1:21:50  iter: 579  total_loss: 1.237  loss_cls: 0.370  loss_box_reg: 0.369  loss_mask: 0.270  loss_rpn_cls: 0.074  loss_rpn_loc: 0.175  time: 3.4552  data_time: 2.4685  lr: 0.000579  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:18:18 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:18:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 13:18:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 13:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2612 s / img. ETA=0:02:16\n",
            "\u001b[32m[07/10 13:18:59 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2526 s / img. ETA=0:02:05\n",
            "\u001b[32m[07/10 13:19:07 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2374 s / img. ETA=0:02:08\n",
            "\u001b[32m[07/10 13:19:13 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.2206 s / img. ETA=0:02:00\n",
            "\u001b[32m[07/10 13:19:21 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2146 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/10 13:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.2083 s / img. ETA=0:01:55\n",
            "\u001b[32m[07/10 13:19:34 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2006 s / img. ETA=0:01:47\n",
            "\u001b[32m[07/10 13:19:41 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.1978 s / img. ETA=0:01:43\n",
            "\u001b[32m[07/10 13:19:49 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.1956 s / img. ETA=0:01:38\n",
            "\u001b[32m[07/10 13:19:57 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.1950 s / img. ETA=0:01:34\n",
            "\u001b[32m[07/10 13:20:03 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1911 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/10 13:20:11 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1844 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/10 13:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.1855 s / img. ETA=0:01:10\n",
            "\u001b[32m[07/10 13:20:29 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1864 s / img. ETA=0:01:04\n",
            "\u001b[32m[07/10 13:20:38 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1867 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/10 13:20:47 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1876 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/10 13:20:53 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1859 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/10 13:21:00 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1881 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/10 13:21:06 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1911 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/10 13:21:12 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1938 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 13:21:17 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1962 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 13:21:23 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1983 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 13:21:28 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.1999 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 13:21:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:51.554732 (3.299129 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:21:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.199925 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:21:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:21:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:21:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.52s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.547\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.254\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.280\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.452\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
            "\u001b[32m[07/10 13:21:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.036 | 54.744 | 25.430 |  nan  |  nan  | 28.036 |\n",
            "\u001b[32m[07/10 13:21:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:21:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 32.969 | brec_Cht         | 20.220 | lam_Sltst  | 17.103 |\n",
            "| skel_WkstPkst | 37.243 | strless_SltstSst | 32.646 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.73s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.547\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 29.543 | 54.665 | 31.315 |  nan  |  nan  | 29.543 |\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 34.650 | brec_Cht         | 21.884 | lam_Sltst  | 19.888 |\n",
            "| skel_WkstPkst | 37.378 | strless_SltstSst | 33.916 |            |        |\n",
            "\u001b[32m[07/10 13:21:30 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: 28.0363,54.7442,25.4300,nan,nan,28.0363\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: 29.5432,54.6653,31.3149,nan,nan,29.5432\n",
            "\u001b[32m[07/10 13:21:33 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:21:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 13:21:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 13:22:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2052 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 13:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2162 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 13:22:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.867206 (3.318578 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:22:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.219825 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:22:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:22:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:22:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.063\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.156\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.041\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 6.254 | 15.648 | 4.072  |  nan  |  nan  | 6.254 |\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 16.444 | brec_Cht         | 1.126 | lam_Sltst  | 5.573 |\n",
            "| skel_WkstPkst | 1.563  | strless_SltstSst | 6.561 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.155\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.070\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.212\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.329\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 6.997 | 15.466 | 5.813  |  nan  |  nan  | 6.997 |\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 17.085 | brec_Cht         | 2.095 | lam_Sltst  | 5.260 |\n",
            "| skel_WkstPkst | 2.433  | strless_SltstSst | 8.112 |            |       |\n",
            "\u001b[32m[07/10 13:22:21 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.testing]: \u001b[0mcopypaste: 6.2535,15.6483,4.0724,nan,nan,6.2535\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.testing]: \u001b[0mcopypaste: 6.9970,15.4658,5.8128,nan,nan,6.9970\n",
            "\u001b[32m[07/10 13:22:21 d2.utils.events]: \u001b[0m eta: 1:20:41  iter: 599  total_loss: 1.258  loss_cls: 0.374  loss_box_reg: 0.390  loss_mask: 0.271  loss_rpn_cls: 0.076  loss_rpn_loc: 0.164  time: 3.4557  data_time: 2.4301  lr: 0.000599  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:23:29 d2.utils.events]: \u001b[0m eta: 1:19:30  iter: 619  total_loss: 1.232  loss_cls: 0.346  loss_box_reg: 0.381  loss_mask: 0.262  loss_rpn_cls: 0.073  loss_rpn_loc: 0.165  time: 3.4541  data_time: 2.3753  lr: 0.000619  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:24:39 d2.utils.events]: \u001b[0m eta: 1:18:21  iter: 639  total_loss: 1.195  loss_cls: 0.346  loss_box_reg: 0.366  loss_mask: 0.267  loss_rpn_cls: 0.073  loss_rpn_loc: 0.148  time: 3.4547  data_time: 2.4271  lr: 0.000639  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:25:49 d2.utils.events]: \u001b[0m eta: 1:17:13  iter: 659  total_loss: 1.236  loss_cls: 0.378  loss_box_reg: 0.388  loss_mask: 0.267  loss_rpn_cls: 0.064  loss_rpn_loc: 0.155  time: 3.4561  data_time: 2.4797  lr: 0.000659  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:26:57 d2.utils.events]: \u001b[0m eta: 1:16:03  iter: 679  total_loss: 1.162  loss_cls: 0.330  loss_box_reg: 0.350  loss_mask: 0.253  loss_rpn_cls: 0.066  loss_rpn_loc: 0.164  time: 3.4550  data_time: 2.4109  lr: 0.000679  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:28:06 d2.utils.events]: \u001b[0m eta: 1:14:54  iter: 699  total_loss: 1.165  loss_cls: 0.328  loss_box_reg: 0.360  loss_mask: 0.258  loss_rpn_cls: 0.063  loss_rpn_loc: 0.157  time: 3.4555  data_time: 2.4409  lr: 0.000699  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:29:16 d2.utils.events]: \u001b[0m eta: 1:13:47  iter: 719  total_loss: 1.185  loss_cls: 0.336  loss_box_reg: 0.361  loss_mask: 0.264  loss_rpn_cls: 0.063  loss_rpn_loc: 0.169  time: 3.4563  data_time: 2.4228  lr: 0.000719  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:30:25 d2.utils.events]: \u001b[0m eta: 1:12:37  iter: 739  total_loss: 1.174  loss_cls: 0.343  loss_box_reg: 0.370  loss_mask: 0.259  loss_rpn_cls: 0.062  loss_rpn_loc: 0.149  time: 3.4559  data_time: 2.4160  lr: 0.000739  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:31:35 d2.utils.events]: \u001b[0m eta: 1:11:31  iter: 759  total_loss: 1.127  loss_cls: 0.320  loss_box_reg: 0.354  loss_mask: 0.253  loss_rpn_cls: 0.056  loss_rpn_loc: 0.157  time: 3.4574  data_time: 2.4644  lr: 0.000759  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:32:44 d2.utils.events]: \u001b[0m eta: 1:10:21  iter: 779  total_loss: 1.109  loss_cls: 0.311  loss_box_reg: 0.348  loss_mask: 0.245  loss_rpn_cls: 0.060  loss_rpn_loc: 0.159  time: 3.4568  data_time: 2.4122  lr: 0.000779  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:34:07 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:34:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 13:34:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 13:34:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2606 s / img. ETA=0:02:32\n",
            "\u001b[32m[07/10 13:34:51 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2540 s / img. ETA=0:02:18\n",
            "\u001b[32m[07/10 13:34:58 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2352 s / img. ETA=0:02:15\n",
            "\u001b[32m[07/10 13:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.2193 s / img. ETA=0:02:06\n",
            "\u001b[32m[07/10 13:35:12 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2127 s / img. ETA=0:02:04\n",
            "\u001b[32m[07/10 13:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.2069 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/10 13:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.1990 s / img. ETA=0:01:51\n",
            "\u001b[32m[07/10 13:35:33 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.1957 s / img. ETA=0:01:46\n",
            "\u001b[32m[07/10 13:35:39 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.1923 s / img. ETA=0:01:39\n",
            "\u001b[32m[07/10 13:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.1907 s / img. ETA=0:01:34\n",
            "\u001b[32m[07/10 13:35:53 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1863 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/10 13:35:59 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.1834 s / img. ETA=0:01:19\n",
            "\u001b[32m[07/10 13:36:06 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1814 s / img. ETA=0:01:12\n",
            "\u001b[32m[07/10 13:36:15 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1826 s / img. ETA=0:01:07\n",
            "\u001b[32m[07/10 13:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1822 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/10 13:36:31 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1831 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/10 13:36:41 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1840 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/10 13:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1829 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/10 13:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1864 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 13:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1894 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/10 13:37:05 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1920 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 13:37:11 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1944 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 13:37:16 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1965 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:52.625024 (3.319712 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.196894 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.52s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.793\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.461\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.562\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.614\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 45.818 | 79.304 | 46.057 |  nan  |  nan  | 45.818 |\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 43.065 | brec_Cht         | 62.970 | lam_Sltst  | 30.432 |\n",
            "| skel_WkstPkst | 43.246 | strless_SltstSst | 49.378 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.82s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.447\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.605\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 44.241 | 76.963 | 44.740 |  nan  |  nan  | 44.241 |\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 45.560 | brec_Cht         | 53.267 | lam_Sltst  | 29.941 |\n",
            "| skel_WkstPkst | 43.392 | strless_SltstSst | 49.045 |            |        |\n",
            "\u001b[32m[07/10 13:37:21 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.testing]: \u001b[0mcopypaste: 45.8181,79.3041,46.0569,nan,nan,45.8181\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.testing]: \u001b[0mcopypaste: 44.2410,76.9628,44.7404,nan,nan,44.2412\n",
            "\u001b[32m[07/10 13:37:24 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:37:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 13:37:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 13:38:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1991 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 13:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2115 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.752897 (3.305877 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.215650 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.073\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.048\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.192\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.298\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 7.268 | 16.388 | 4.844  |  nan  |  nan  | 7.268 |\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 16.399 | brec_Cht         | 3.416  | lam_Sltst  | 2.748 |\n",
            "| skel_WkstPkst | 2.939  | strless_SltstSst | 10.838 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.173\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.072\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.218\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.366 | 17.341 | 7.159  |  nan  |  nan  | 8.366 |\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 18.152 | brec_Cht         | 4.307  | lam_Sltst  | 2.759 |\n",
            "| skel_WkstPkst | 3.659  | strless_SltstSst | 12.953 |            |       |\n",
            "\u001b[32m[07/10 13:38:12 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: 7.2680,16.3879,4.8442,nan,nan,7.2680\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: 8.3662,17.3409,7.1592,nan,nan,8.3662\n",
            "\u001b[32m[07/10 13:38:12 d2.utils.events]: \u001b[0m eta: 1:09:12  iter: 799  total_loss: 1.101  loss_cls: 0.305  loss_box_reg: 0.343  loss_mask: 0.236  loss_rpn_cls: 0.058  loss_rpn_loc: 0.147  time: 3.4582  data_time: 2.4653  lr: 0.000799  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:39:22 d2.utils.events]: \u001b[0m eta: 1:08:04  iter: 819  total_loss: 1.073  loss_cls: 0.281  loss_box_reg: 0.343  loss_mask: 0.248  loss_rpn_cls: 0.053  loss_rpn_loc: 0.152  time: 3.4585  data_time: 2.4381  lr: 0.000819  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:40:31 d2.utils.events]: \u001b[0m eta: 1:06:55  iter: 839  total_loss: 1.154  loss_cls: 0.335  loss_box_reg: 0.338  loss_mask: 0.242  loss_rpn_cls: 0.049  loss_rpn_loc: 0.172  time: 3.4588  data_time: 2.4235  lr: 0.000839  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:41:40 d2.utils.events]: \u001b[0m eta: 1:05:46  iter: 859  total_loss: 1.149  loss_cls: 0.329  loss_box_reg: 0.346  loss_mask: 0.237  loss_rpn_cls: 0.057  loss_rpn_loc: 0.157  time: 3.4590  data_time: 2.4254  lr: 0.000859  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:42:50 d2.utils.events]: \u001b[0m eta: 1:04:36  iter: 879  total_loss: 1.097  loss_cls: 0.311  loss_box_reg: 0.333  loss_mask: 0.241  loss_rpn_cls: 0.054  loss_rpn_loc: 0.155  time: 3.4595  data_time: 2.4174  lr: 0.000879  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:43:59 d2.utils.events]: \u001b[0m eta: 1:03:27  iter: 899  total_loss: 1.032  loss_cls: 0.292  loss_box_reg: 0.339  loss_mask: 0.230  loss_rpn_cls: 0.046  loss_rpn_loc: 0.138  time: 3.4595  data_time: 2.4379  lr: 0.000899  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:45:09 d2.utils.events]: \u001b[0m eta: 1:02:18  iter: 919  total_loss: 1.003  loss_cls: 0.282  loss_box_reg: 0.320  loss_mask: 0.227  loss_rpn_cls: 0.052  loss_rpn_loc: 0.134  time: 3.4594  data_time: 2.4075  lr: 0.000919  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:46:18 d2.utils.events]: \u001b[0m eta: 1:01:09  iter: 939  total_loss: 0.992  loss_cls: 0.246  loss_box_reg: 0.303  loss_mask: 0.226  loss_rpn_cls: 0.050  loss_rpn_loc: 0.146  time: 3.4595  data_time: 2.4574  lr: 0.000939  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:47:27 d2.utils.events]: \u001b[0m eta: 1:00:00  iter: 959  total_loss: 1.004  loss_cls: 0.284  loss_box_reg: 0.320  loss_mask: 0.223  loss_rpn_cls: 0.045  loss_rpn_loc: 0.145  time: 3.4598  data_time: 2.4245  lr: 0.000959  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:48:37 d2.utils.events]: \u001b[0m eta: 0:58:50  iter: 979  total_loss: 1.003  loss_cls: 0.263  loss_box_reg: 0.314  loss_mask: 0.225  loss_rpn_cls: 0.044  loss_rpn_loc: 0.142  time: 3.4599  data_time: 2.4304  lr: 0.000979  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:49:58 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:49:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 13:49:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 13:50:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2432 s / img. ETA=0:02:09\n",
            "\u001b[32m[07/10 13:50:41 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2253 s / img. ETA=0:01:57\n",
            "\u001b[32m[07/10 13:50:46 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.2078 s / img. ETA=0:01:51\n",
            "\u001b[32m[07/10 13:50:51 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1956 s / img. ETA=0:01:44\n",
            "\u001b[32m[07/10 13:50:57 d2.evaluation.evaluator]: \u001b[0mInference done 20/57. 0.1883 s / img. ETA=0:01:40\n",
            "\u001b[32m[07/10 13:51:03 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1819 s / img. ETA=0:01:35\n",
            "\u001b[32m[07/10 13:51:09 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.1787 s / img. ETA=0:01:32\n",
            "\u001b[32m[07/10 13:51:15 d2.evaluation.evaluator]: \u001b[0mInference done 26/57. 0.1747 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/10 13:51:22 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1730 s / img. ETA=0:01:22\n",
            "\u001b[32m[07/10 13:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 30/57. 0.1702 s / img. ETA=0:01:16\n",
            "\u001b[32m[07/10 13:51:35 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.1651 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/10 13:51:41 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1637 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/10 13:51:49 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1648 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/10 13:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1650 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/10 13:52:04 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1661 s / img. ETA=0:00:47\n",
            "\u001b[32m[07/10 13:52:13 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1675 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/10 13:52:18 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1666 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 13:52:24 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1707 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 13:52:30 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1745 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 13:52:35 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1777 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/10 13:52:41 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1807 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 13:52:46 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1834 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 13:52:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:31.438258 (2.912274 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:52:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.183105 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:52:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:52:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:52:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.49s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.784\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.525\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.597\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 46.184 | 78.380 | 52.548 |  nan  |  nan  | 46.184 |\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 48.004 | brec_Cht         | 48.994 | lam_Sltst  | 39.080 |\n",
            "| skel_WkstPkst | 47.182 | strless_SltstSst | 47.663 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.69s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.780\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.602\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.627\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 50.811 | 78.027 | 60.169 |  nan  |  nan  | 50.811 |\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 53.687 | brec_Cht         | 55.068 | lam_Sltst  | 37.127 |\n",
            "| skel_WkstPkst | 53.448 | strless_SltstSst | 54.726 |            |        |\n",
            "\u001b[32m[07/10 13:52:49 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: 46.1844,78.3797,52.5477,nan,nan,46.1844\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: 50.8113,78.0273,60.1689,nan,nan,50.8113\n",
            "\u001b[32m[07/10 13:52:53 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:52:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 13:52:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 13:53:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1918 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 13:53:35 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2060 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.633990 (3.070443 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.210778 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.043\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.215\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 6.542 | 15.847 | 4.309  |  nan  |  nan  | 6.542 |\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 14.301 | brec_Cht         | 4.921 | lam_Sltst  | 3.717 |\n",
            "| skel_WkstPkst | 1.498  | strless_SltstSst | 8.270 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.22s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.085\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.161\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.083\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.051\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.358\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.508 | 16.112 | 8.287  |  nan  |  nan  | 8.508 |\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 17.992 | brec_Cht         | 7.465  | lam_Sltst  | 4.995 |\n",
            "| skel_WkstPkst | 1.341  | strless_SltstSst | 10.749 |            |       |\n",
            "\u001b[32m[07/10 13:53:39 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.testing]: \u001b[0mcopypaste: 6.5416,15.8469,4.3092,nan,nan,6.5416\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.testing]: \u001b[0mcopypaste: 8.5084,16.1123,8.2872,nan,nan,8.5084\n",
            "\u001b[32m[07/10 13:53:39 d2.utils.events]: \u001b[0m eta: 0:57:41  iter: 999  total_loss: 0.987  loss_cls: 0.277  loss_box_reg: 0.326  loss_mask: 0.219  loss_rpn_cls: 0.041  loss_rpn_loc: 0.141  time: 3.4602  data_time: 2.4259  lr: 0.000999  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:54:47 d2.utils.events]: \u001b[0m eta: 0:56:31  iter: 1019  total_loss: 0.974  loss_cls: 0.254  loss_box_reg: 0.332  loss_mask: 0.226  loss_rpn_cls: 0.044  loss_rpn_loc: 0.137  time: 3.4596  data_time: 2.3589  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:55:56 d2.utils.events]: \u001b[0m eta: 0:55:21  iter: 1039  total_loss: 0.935  loss_cls: 0.241  loss_box_reg: 0.307  loss_mask: 0.221  loss_rpn_cls: 0.037  loss_rpn_loc: 0.131  time: 3.4596  data_time: 2.4517  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:57:06 d2.utils.events]: \u001b[0m eta: 0:54:13  iter: 1059  total_loss: 0.952  loss_cls: 0.255  loss_box_reg: 0.302  loss_mask: 0.209  loss_rpn_cls: 0.040  loss_rpn_loc: 0.142  time: 3.4601  data_time: 2.4218  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:58:16 d2.utils.events]: \u001b[0m eta: 0:53:04  iter: 1079  total_loss: 0.895  loss_cls: 0.232  loss_box_reg: 0.292  loss_mask: 0.207  loss_rpn_cls: 0.039  loss_rpn_loc: 0.146  time: 3.4603  data_time: 2.4401  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:59:25 d2.utils.events]: \u001b[0m eta: 0:51:56  iter: 1099  total_loss: 0.943  loss_cls: 0.239  loss_box_reg: 0.305  loss_mask: 0.208  loss_rpn_cls: 0.035  loss_rpn_loc: 0.140  time: 3.4609  data_time: 2.4423  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:00:35 d2.utils.events]: \u001b[0m eta: 0:50:46  iter: 1119  total_loss: 0.923  loss_cls: 0.226  loss_box_reg: 0.289  loss_mask: 0.211  loss_rpn_cls: 0.040  loss_rpn_loc: 0.145  time: 3.4609  data_time: 2.4205  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:01:44 d2.utils.events]: \u001b[0m eta: 0:49:38  iter: 1139  total_loss: 0.971  loss_cls: 0.259  loss_box_reg: 0.319  loss_mask: 0.219  loss_rpn_cls: 0.033  loss_rpn_loc: 0.155  time: 3.4614  data_time: 2.4463  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:02:53 d2.utils.events]: \u001b[0m eta: 0:48:32  iter: 1159  total_loss: 0.907  loss_cls: 0.230  loss_box_reg: 0.284  loss_mask: 0.208  loss_rpn_cls: 0.037  loss_rpn_loc: 0.148  time: 3.4612  data_time: 2.3983  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:04:03 d2.utils.events]: \u001b[0m eta: 0:47:22  iter: 1179  total_loss: 0.869  loss_cls: 0.213  loss_box_reg: 0.287  loss_mask: 0.205  loss_rpn_cls: 0.037  loss_rpn_loc: 0.133  time: 3.4612  data_time: 2.4129  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:05:25 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:05:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 14:05:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 14:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2467 s / img. ETA=0:02:10\n",
            "\u001b[32m[07/10 14:06:08 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2243 s / img. ETA=0:01:57\n",
            "\u001b[32m[07/10 14:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.1976 s / img. ETA=0:01:44\n",
            "\u001b[32m[07/10 14:06:20 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1903 s / img. ETA=0:01:41\n",
            "\u001b[32m[07/10 14:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1907 s / img. ETA=0:01:35\n",
            "\u001b[32m[07/10 14:06:33 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.1794 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/10 14:06:38 d2.evaluation.evaluator]: \u001b[0mInference done 26/57. 0.1743 s / img. ETA=0:01:20\n",
            "\u001b[32m[07/10 14:06:44 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1721 s / img. ETA=0:01:16\n",
            "\u001b[32m[07/10 14:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1648 s / img. ETA=0:01:07\n",
            "\u001b[32m[07/10 14:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1585 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/10 14:07:03 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.1589 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/10 14:07:09 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1585 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/10 14:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1586 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/10 14:07:24 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1593 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/10 14:07:30 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.1560 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 14:07:35 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1596 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 14:07:41 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1639 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 14:07:47 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1678 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 14:07:52 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1713 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 14:07:58 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1744 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 14:08:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:19.266574 (2.678203 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:08:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.175551 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:08:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:08:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:08:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.46s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.560\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.880\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.665\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.560\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.648\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682\n",
            "\u001b[32m[07/10 14:08:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 55.993 | 87.994 | 66.522 |  nan  |  nan  | 55.993 |\n",
            "\u001b[32m[07/10 14:08:03 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:08:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 60.761 | brec_Cht         | 54.505 | lam_Sltst  | 51.989 |\n",
            "| skel_WkstPkst | 54.772 | strless_SltstSst | 57.939 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.67s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.569\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.881\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.656\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.569\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.658\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.694\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 56.929 | 88.074 | 65.564 |  nan  |  nan  | 56.929 |\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 65.047 | brec_Cht         | 51.782 | lam_Sltst  | 51.895 |\n",
            "| skel_WkstPkst | 54.596 | strless_SltstSst | 61.323 |            |        |\n",
            "\u001b[32m[07/10 14:08:04 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.testing]: \u001b[0mcopypaste: 55.9932,87.9938,66.5218,nan,nan,55.9932\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.testing]: \u001b[0mcopypaste: 56.9285,88.0740,65.5639,nan,nan,56.9285\n",
            "\u001b[32m[07/10 14:08:07 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:08:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 14:08:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 14:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1784 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 14:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1960 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.801179 (2.866798 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.201926 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.081\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.220\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.062 | 17.400 | 7.373  |  nan  |  nan  | 8.062 |\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.523 | brec_Cht         | 2.680  | lam_Sltst  | 2.266 |\n",
            "| skel_WkstPkst | 1.057  | strless_SltstSst | 13.785 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.096\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.269\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.352\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.610 | 17.853 | 9.667  |  nan  |  nan  | 9.611 |\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.811 | brec_Cht         | 4.244  | lam_Sltst  | 3.078 |\n",
            "| skel_WkstPkst | 1.212  | strless_SltstSst | 15.706 |            |       |\n",
            "\u001b[32m[07/10 14:08:51 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.testing]: \u001b[0mcopypaste: 8.0621,17.3996,7.3725,nan,nan,8.0621\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.testing]: \u001b[0mcopypaste: 9.6101,17.8533,9.6668,nan,nan,9.6110\n",
            "\u001b[32m[07/10 14:08:51 d2.utils.events]: \u001b[0m eta: 0:46:16  iter: 1199  total_loss: 0.938  loss_cls: 0.241  loss_box_reg: 0.308  loss_mask: 0.203  loss_rpn_cls: 0.037  loss_rpn_loc: 0.137  time: 3.4617  data_time: 2.4245  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:10:01 d2.utils.events]: \u001b[0m eta: 0:45:07  iter: 1219  total_loss: 0.879  loss_cls: 0.214  loss_box_reg: 0.297  loss_mask: 0.207  loss_rpn_cls: 0.033  loss_rpn_loc: 0.134  time: 3.4619  data_time: 2.4251  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:11:12 d2.utils.events]: \u001b[0m eta: 0:43:59  iter: 1239  total_loss: 0.931  loss_cls: 0.233  loss_box_reg: 0.313  loss_mask: 0.205  loss_rpn_cls: 0.035  loss_rpn_loc: 0.136  time: 3.4632  data_time: 2.4866  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:12:21 d2.utils.events]: \u001b[0m eta: 0:42:51  iter: 1259  total_loss: 0.836  loss_cls: 0.210  loss_box_reg: 0.271  loss_mask: 0.202  loss_rpn_cls: 0.033  loss_rpn_loc: 0.130  time: 3.4630  data_time: 2.3937  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:13:30 d2.utils.events]: \u001b[0m eta: 0:41:45  iter: 1279  total_loss: 0.834  loss_cls: 0.204  loss_box_reg: 0.261  loss_mask: 0.190  loss_rpn_cls: 0.029  loss_rpn_loc: 0.120  time: 3.4631  data_time: 2.4182  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:14:40 d2.utils.events]: \u001b[0m eta: 0:40:33  iter: 1299  total_loss: 0.801  loss_cls: 0.181  loss_box_reg: 0.258  loss_mask: 0.195  loss_rpn_cls: 0.028  loss_rpn_loc: 0.127  time: 3.4633  data_time: 2.4106  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:15:49 d2.utils.events]: \u001b[0m eta: 0:39:24  iter: 1319  total_loss: 0.805  loss_cls: 0.187  loss_box_reg: 0.270  loss_mask: 0.199  loss_rpn_cls: 0.026  loss_rpn_loc: 0.134  time: 3.4635  data_time: 2.4233  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:16:58 d2.utils.events]: \u001b[0m eta: 0:38:13  iter: 1339  total_loss: 0.779  loss_cls: 0.173  loss_box_reg: 0.259  loss_mask: 0.181  loss_rpn_cls: 0.028  loss_rpn_loc: 0.134  time: 3.4633  data_time: 2.3990  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:18:08 d2.utils.events]: \u001b[0m eta: 0:37:03  iter: 1359  total_loss: 0.791  loss_cls: 0.186  loss_box_reg: 0.257  loss_mask: 0.198  loss_rpn_cls: 0.029  loss_rpn_loc: 0.126  time: 3.4637  data_time: 2.4424  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:19:17 d2.utils.events]: \u001b[0m eta: 0:35:52  iter: 1379  total_loss: 0.808  loss_cls: 0.197  loss_box_reg: 0.255  loss_mask: 0.193  loss_rpn_cls: 0.029  loss_rpn_loc: 0.128  time: 3.4637  data_time: 2.4330  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:20:39 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:20:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 14:20:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 14:21:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1958 s / img. ETA=0:01:52\n",
            "\u001b[32m[07/10 14:21:16 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.1824 s / img. ETA=0:01:38\n",
            "\u001b[32m[07/10 14:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1546 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/10 14:21:28 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1441 s / img. ETA=0:01:12\n",
            "\u001b[32m[07/10 14:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.1349 s / img. ETA=0:01:02\n",
            "\u001b[32m[07/10 14:21:40 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1316 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/10 14:21:46 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.1254 s / img. ETA=0:00:47\n",
            "\u001b[32m[07/10 14:21:52 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1227 s / img. ETA=0:00:41\n",
            "\u001b[32m[07/10 14:21:57 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1231 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/10 14:22:05 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1237 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/10 14:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1247 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 14:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1241 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/10 14:22:25 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1295 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 14:22:31 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1337 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 14:22:36 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1386 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 14:22:41 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1422 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 14:22:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:49.837943 (2.112268 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:22:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.143203 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:22:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:22:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:22:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.38s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.939\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.812\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.660\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.206\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.702\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 66.032 | 93.916 | 81.185 |  nan  |  nan  | 66.032 |\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 68.838 | brec_Cht         | 67.723 | lam_Sltst  | 61.035 |\n",
            "| skel_WkstPkst | 63.298 | strless_SltstSst | 69.267 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.55s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.938\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.772\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.653\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.701\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.732\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 65.300 | 93.806 | 77.158 |  nan  |  nan  | 65.300 |\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 70.691 | brec_Cht         | 65.248 | lam_Sltst  | 57.233 |\n",
            "| skel_WkstPkst | 62.705 | strless_SltstSst | 70.624 |            |        |\n",
            "\u001b[32m[07/10 14:22:46 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.testing]: \u001b[0mcopypaste: 66.0323,93.9156,81.1846,nan,nan,66.0323\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.testing]: \u001b[0mcopypaste: 65.3000,93.8065,77.1576,nan,nan,65.3000\n",
            "\u001b[32m[07/10 14:22:50 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:22:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 14:22:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 14:23:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1588 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 14:23:27 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1812 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 14:23:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.239056 (2.582117 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:23:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.188747 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:23:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:23:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:23:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.079\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.079\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.320\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 7.869 | 16.375 | 6.826  |  nan  |  nan  | 7.869 |\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 21.255 | brec_Cht         | 3.237 | lam_Sltst  | 6.111 |\n",
            "| skel_WkstPkst | 0.683  | strless_SltstSst | 8.057 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.182\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.095\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.388\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.484 | 18.226 | 8.854  |  nan  |  nan  | 9.484 |\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 24.063 | brec_Cht         | 6.210 | lam_Sltst  | 6.848 |\n",
            "| skel_WkstPkst | 0.602  | strless_SltstSst | 9.697 |            |       |\n",
            "\u001b[32m[07/10 14:23:30 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: 7.8685,16.3755,6.8258,nan,nan,7.8685\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: 9.4841,18.2258,8.8544,nan,nan,9.4841\n",
            "\u001b[32m[07/10 14:23:30 d2.utils.events]: \u001b[0m eta: 0:34:43  iter: 1399  total_loss: 0.787  loss_cls: 0.179  loss_box_reg: 0.259  loss_mask: 0.192  loss_rpn_cls: 0.026  loss_rpn_loc: 0.114  time: 3.4639  data_time: 2.4251  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:24:39 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 1419  total_loss: 0.752  loss_cls: 0.168  loss_box_reg: 0.245  loss_mask: 0.184  loss_rpn_cls: 0.026  loss_rpn_loc: 0.120  time: 3.4635  data_time: 2.3730  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:25:49 d2.utils.events]: \u001b[0m eta: 0:32:22  iter: 1439  total_loss: 0.730  loss_cls: 0.162  loss_box_reg: 0.241  loss_mask: 0.185  loss_rpn_cls: 0.023  loss_rpn_loc: 0.121  time: 3.4642  data_time: 2.4485  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:26:58 d2.utils.events]: \u001b[0m eta: 0:31:15  iter: 1459  total_loss: 0.763  loss_cls: 0.167  loss_box_reg: 0.248  loss_mask: 0.179  loss_rpn_cls: 0.027  loss_rpn_loc: 0.133  time: 3.4644  data_time: 2.4491  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:28:09 d2.utils.events]: \u001b[0m eta: 0:30:06  iter: 1479  total_loss: 0.720  loss_cls: 0.154  loss_box_reg: 0.243  loss_mask: 0.178  loss_rpn_cls: 0.029  loss_rpn_loc: 0.113  time: 3.4651  data_time: 2.4459  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:29:20 d2.utils.events]: \u001b[0m eta: 0:28:57  iter: 1499  total_loss: 0.711  loss_cls: 0.152  loss_box_reg: 0.233  loss_mask: 0.177  loss_rpn_cls: 0.024  loss_rpn_loc: 0.115  time: 3.4662  data_time: 2.4902  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:30:33 d2.utils.events]: \u001b[0m eta: 0:27:51  iter: 1519  total_loss: 0.686  loss_cls: 0.142  loss_box_reg: 0.218  loss_mask: 0.174  loss_rpn_cls: 0.026  loss_rpn_loc: 0.112  time: 3.4685  data_time: 2.5697  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:31:43 d2.utils.events]: \u001b[0m eta: 0:26:42  iter: 1539  total_loss: 0.698  loss_cls: 0.154  loss_box_reg: 0.233  loss_mask: 0.177  loss_rpn_cls: 0.022  loss_rpn_loc: 0.110  time: 3.4694  data_time: 2.4618  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:32:54 d2.utils.events]: \u001b[0m eta: 0:25:33  iter: 1559  total_loss: 0.655  loss_cls: 0.135  loss_box_reg: 0.228  loss_mask: 0.167  loss_rpn_cls: 0.028  loss_rpn_loc: 0.119  time: 3.4703  data_time: 2.4796  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:34:07 d2.utils.events]: \u001b[0m eta: 0:24:25  iter: 1579  total_loss: 0.659  loss_cls: 0.150  loss_box_reg: 0.220  loss_mask: 0.172  loss_rpn_cls: 0.022  loss_rpn_loc: 0.112  time: 3.4722  data_time: 2.5460  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:35:32 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:35:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 14:35:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 14:36:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1757 s / img. ETA=0:01:52\n",
            "\u001b[32m[07/10 14:36:10 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.1613 s / img. ETA=0:01:37\n",
            "\u001b[32m[07/10 14:36:16 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1391 s / img. ETA=0:01:19\n",
            "\u001b[32m[07/10 14:36:21 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1313 s / img. ETA=0:01:11\n",
            "\u001b[32m[07/10 14:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.1236 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/10 14:36:34 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1207 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/10 14:36:40 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.1159 s / img. ETA=0:00:46\n",
            "\u001b[32m[07/10 14:36:45 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1142 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/10 14:36:50 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1150 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/10 14:36:58 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1153 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/10 14:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1164 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 14:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.1149 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/10 14:37:16 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1192 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/10 14:37:21 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1229 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/10 14:37:28 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1282 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 14:37:33 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1318 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 14:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1352 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 14:37:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:50.953309 (2.133717 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:37:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.134769 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:37:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:37:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:37:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.38s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.702\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.962\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.882\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.702\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.205\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.766\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.766\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 70.177 | 96.213 | 88.153 |  nan  |  nan  | 70.177 |\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 69.138 | brec_Cht         | 82.574 | lam_Sltst  | 70.327 |\n",
            "| skel_WkstPkst | 55.544 | strless_SltstSst | 73.299 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.54s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.716\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.964\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.865\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.759\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.784\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.784\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 71.552 | 96.369 | 86.511 |  nan  |  nan  | 71.553 |\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 75.441 | brec_Cht         | 77.624 | lam_Sltst  | 67.952 |\n",
            "| skel_WkstPkst | 59.727 | strless_SltstSst | 77.019 |            |        |\n",
            "\u001b[32m[07/10 14:37:41 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.testing]: \u001b[0mcopypaste: 70.1766,96.2134,88.1529,nan,nan,70.1766\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.testing]: \u001b[0mcopypaste: 71.5524,96.3694,86.5107,nan,nan,71.5525\n",
            "\u001b[32m[07/10 14:37:45 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:37:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 14:37:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 14:38:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1592 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 14:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1785 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.035627 (2.781736 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.186314 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.053\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.232\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.818 | 18.928 | 7.021  |  nan  |  nan  | 8.818 |\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 17.531 | brec_Cht         | 3.859  | lam_Sltst  | 5.886 |\n",
            "| skel_WkstPkst | 1.443  | strless_SltstSst | 15.369 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.201\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.105\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.908 | 20.060 | 10.491 |  nan  |  nan  | 10.908 |\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.875 | brec_Cht         | 5.126  | lam_Sltst  | 8.231 |\n",
            "| skel_WkstPkst | 1.518  | strless_SltstSst | 18.789 |            |       |\n",
            "\u001b[32m[07/10 14:38:29 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: 8.8175,18.9283,7.0210,nan,nan,8.8175\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: 10.9078,20.0599,10.4911,nan,nan,10.9078\n",
            "\u001b[32m[07/10 14:38:29 d2.utils.events]: \u001b[0m eta: 0:23:16  iter: 1599  total_loss: 0.684  loss_cls: 0.146  loss_box_reg: 0.216  loss_mask: 0.166  loss_rpn_cls: 0.025  loss_rpn_loc: 0.108  time: 3.4741  data_time: 2.5397  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:39:40 d2.utils.events]: \u001b[0m eta: 0:22:09  iter: 1619  total_loss: 0.655  loss_cls: 0.127  loss_box_reg: 0.210  loss_mask: 0.168  loss_rpn_cls: 0.024  loss_rpn_loc: 0.109  time: 3.4756  data_time: 2.5222  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:40:54 d2.utils.events]: \u001b[0m eta: 0:21:00  iter: 1639  total_loss: 0.640  loss_cls: 0.132  loss_box_reg: 0.217  loss_mask: 0.168  loss_rpn_cls: 0.021  loss_rpn_loc: 0.108  time: 3.4780  data_time: 2.5971  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:42:08 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 1659  total_loss: 0.662  loss_cls: 0.144  loss_box_reg: 0.219  loss_mask: 0.169  loss_rpn_cls: 0.022  loss_rpn_loc: 0.103  time: 3.4805  data_time: 2.5954  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:43:22 d2.utils.events]: \u001b[0m eta: 0:18:43  iter: 1679  total_loss: 0.644  loss_cls: 0.138  loss_box_reg: 0.219  loss_mask: 0.161  loss_rpn_cls: 0.019  loss_rpn_loc: 0.111  time: 3.4831  data_time: 2.6438  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:44:35 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 1699  total_loss: 0.625  loss_cls: 0.119  loss_box_reg: 0.210  loss_mask: 0.159  loss_rpn_cls: 0.019  loss_rpn_loc: 0.105  time: 3.4854  data_time: 2.5953  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:45:48 d2.utils.events]: \u001b[0m eta: 0:16:25  iter: 1719  total_loss: 0.653  loss_cls: 0.143  loss_box_reg: 0.222  loss_mask: 0.167  loss_rpn_cls: 0.021  loss_rpn_loc: 0.110  time: 3.4873  data_time: 2.5515  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:46:59 d2.utils.events]: \u001b[0m eta: 0:15:16  iter: 1739  total_loss: 0.682  loss_cls: 0.147  loss_box_reg: 0.237  loss_mask: 0.173  loss_rpn_cls: 0.025  loss_rpn_loc: 0.104  time: 3.4876  data_time: 2.4506  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:48:08 d2.utils.events]: \u001b[0m eta: 0:14:05  iter: 1759  total_loss: 0.639  loss_cls: 0.135  loss_box_reg: 0.223  loss_mask: 0.159  loss_rpn_cls: 0.019  loss_rpn_loc: 0.108  time: 3.4874  data_time: 2.4170  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:49:18 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 1779  total_loss: 0.643  loss_cls: 0.139  loss_box_reg: 0.208  loss_mask: 0.166  loss_rpn_cls: 0.024  loss_rpn_loc: 0.111  time: 3.4876  data_time: 2.4479  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:50:39 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:50:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 14:50:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 14:51:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1569 s / img. ETA=0:01:31\n",
            "\u001b[32m[07/10 14:51:11 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.1497 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/10 14:51:16 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1291 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/10 14:51:22 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.1147 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/10 14:51:28 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1078 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/10 14:51:33 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.1022 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/10 14:51:40 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1015 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 14:51:45 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1012 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/10 14:51:51 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1013 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 14:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1019 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/10 14:52:03 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1068 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 14:52:09 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1123 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 14:52:15 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1179 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 14:52:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:24.120118 (1.617695 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:52:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.118447 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:52:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:52:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:52:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.32s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.977\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.906\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.756\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.779\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 73.331 | 97.736 | 90.612 |  nan  |  nan  | 73.331 |\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 72.854 | brec_Cht         | 69.604 | lam_Sltst  | 71.669 |\n",
            "| skel_WkstPkst | 71.970 | strless_SltstSst | 80.557 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.46s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.742\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.974\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.917\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.766\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.790\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.790\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 74.188 | 97.446 | 91.721 |  nan  |  nan  | 74.188 |\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 76.038 | brec_Cht         | 73.069 | lam_Sltst  | 69.339 |\n",
            "| skel_WkstPkst | 70.857 | strless_SltstSst | 81.633 |            |        |\n",
            "\u001b[32m[07/10 14:52:19 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.testing]: \u001b[0mcopypaste: 73.3307,97.7357,90.6124,nan,nan,73.3307\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.testing]: \u001b[0mcopypaste: 74.1875,97.4462,91.7209,nan,nan,74.1875\n",
            "\u001b[32m[07/10 14:52:22 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:52:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 14:52:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 14:52:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1354 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 14:52:55 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1598 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.494950 (2.277217 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.169836 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.073\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.050\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.309\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.450 | 18.603 | 7.330  |  nan  |  nan  | 8.450 |\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 18.927 | brec_Cht         | 0.658  | lam_Sltst  | 4.140 |\n",
            "| skel_WkstPkst | 2.843  | strless_SltstSst | 15.681 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.196\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.092\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.272\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.884 | 19.647 | 9.222  |  nan  |  nan  | 9.887 |\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.149 | brec_Cht         | 1.942  | lam_Sltst  | 4.638 |\n",
            "| skel_WkstPkst | 3.250  | strless_SltstSst | 18.443 |            |       |\n",
            "\u001b[32m[07/10 14:52:59 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.testing]: \u001b[0mcopypaste: 8.4496,18.6033,7.3304,nan,nan,8.4496\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.testing]: \u001b[0mcopypaste: 9.8845,19.6469,9.2220,nan,nan,9.8871\n",
            "\u001b[32m[07/10 14:52:59 d2.utils.events]: \u001b[0m eta: 0:11:44  iter: 1799  total_loss: 0.637  loss_cls: 0.124  loss_box_reg: 0.211  loss_mask: 0.163  loss_rpn_cls: 0.021  loss_rpn_loc: 0.103  time: 3.4871  data_time: 2.3973  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:54:08 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 1819  total_loss: 0.580  loss_cls: 0.110  loss_box_reg: 0.189  loss_mask: 0.154  loss_rpn_cls: 0.021  loss_rpn_loc: 0.106  time: 3.4870  data_time: 2.4097  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:55:17 d2.utils.events]: \u001b[0m eta: 0:09:24  iter: 1839  total_loss: 0.626  loss_cls: 0.135  loss_box_reg: 0.198  loss_mask: 0.161  loss_rpn_cls: 0.021  loss_rpn_loc: 0.103  time: 3.4867  data_time: 2.4133  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:56:28 d2.utils.events]: \u001b[0m eta: 0:08:14  iter: 1859  total_loss: 0.631  loss_cls: 0.127  loss_box_reg: 0.201  loss_mask: 0.163  loss_rpn_cls: 0.020  loss_rpn_loc: 0.107  time: 3.4871  data_time: 2.4500  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:57:37 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1879  total_loss: 0.634  loss_cls: 0.125  loss_box_reg: 0.221  loss_mask: 0.159  loss_rpn_cls: 0.021  loss_rpn_loc: 0.110  time: 3.4871  data_time: 2.4323  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:58:47 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 1899  total_loss: 0.563  loss_cls: 0.107  loss_box_reg: 0.196  loss_mask: 0.154  loss_rpn_cls: 0.019  loss_rpn_loc: 0.099  time: 3.4867  data_time: 2.3944  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:59:56 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 1919  total_loss: 0.609  loss_cls: 0.122  loss_box_reg: 0.212  loss_mask: 0.161  loss_rpn_cls: 0.023  loss_rpn_loc: 0.104  time: 3.4868  data_time: 2.4070  lr: 0.001000  max_mem: 8945M\n",
            "\u001b[32m[07/10 15:01:06 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 1939  total_loss: 0.603  loss_cls: 0.122  loss_box_reg: 0.205  loss_mask: 0.152  loss_rpn_cls: 0.020  loss_rpn_loc: 0.109  time: 3.4865  data_time: 2.4124  lr: 0.001000  max_mem: 8945M\n",
            "\u001b[32m[07/10 15:02:15 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 1959  total_loss: 0.591  loss_cls: 0.110  loss_box_reg: 0.203  loss_mask: 0.154  loss_rpn_cls: 0.017  loss_rpn_loc: 0.106  time: 3.4865  data_time: 2.4260  lr: 0.001000  max_mem: 8945M\n",
            "\u001b[32m[07/10 15:03:25 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 1979  total_loss: 0.573  loss_cls: 0.104  loss_box_reg: 0.199  loss_mask: 0.156  loss_rpn_cls: 0.014  loss_rpn_loc: 0.101  time: 3.4863  data_time: 2.3864  lr: 0.001000  max_mem: 8945M\n",
            "\u001b[32m[07/10 15:04:48 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:04:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 15:04:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 15:05:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1412 s / img. ETA=0:01:18\n",
            "\u001b[32m[07/10 15:05:16 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.1260 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/10 15:05:22 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1066 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/10 15:05:27 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.0969 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/10 15:05:33 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.0916 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/10 15:05:38 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.0911 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/10 15:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.0907 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/10 15:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.0913 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 15:05:56 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.0962 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 15:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1027 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 15:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1075 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 15:06:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:11.756741 (1.379937 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:06:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.107987 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:06:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:06:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:06:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.771\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.995\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.928\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.785\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.805\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 77.100 | 99.474 | 92.826 |  nan  |  nan  | 77.100 |\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 81.418 | brec_Cht         | 78.861 | lam_Sltst  | 74.657 |\n",
            "| skel_WkstPkst | 74.121 | strless_SltstSst | 76.444 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.39s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.903\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.740\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.781\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 74.047 | 99.001 | 90.327 |  nan  |  nan  | 74.047 |\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 81.030 | brec_Cht         | 77.525 | lam_Sltst  | 67.393 |\n",
            "| skel_WkstPkst | 71.085 | strless_SltstSst | 73.204 |            |        |\n",
            "\u001b[32m[07/10 15:06:13 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.testing]: \u001b[0mcopypaste: 77.1004,99.4742,92.8255,nan,nan,77.1004\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.testing]: \u001b[0mcopypaste: 74.0473,99.0009,90.3266,nan,nan,74.0473\n",
            "\u001b[32m[07/10 15:06:16 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:06:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 15:06:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 15:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1157 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 15:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1446 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.166835 (2.018537 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.153583 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.052\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.082 | 19.229 | 7.363  |  nan  |  nan  | 9.082 |\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.376 | brec_Cht         | 5.051  | lam_Sltst  | 3.410 |\n",
            "| skel_WkstPkst | 2.432  | strless_SltstSst | 14.142 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.382\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.823 | 19.747 | 8.841  |  nan  |  nan  | 9.823 |\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 22.100 | brec_Cht         | 5.788  | lam_Sltst  | 3.899 |\n",
            "| skel_WkstPkst | 3.093  | strless_SltstSst | 14.233 |            |       |\n",
            "\u001b[32m[07/10 15:06:48 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: 9.0822,19.2291,7.3635,nan,nan,9.0822\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: 9.8226,19.7468,8.8411,nan,nan,9.8226\n",
            "\u001b[32m[07/10 15:06:48 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 1999  total_loss: 0.557  loss_cls: 0.111  loss_box_reg: 0.193  loss_mask: 0.152  loss_rpn_cls: 0.016  loss_rpn_loc: 0.100  time: 3.4864  data_time: 2.4498  lr: 0.001000  max_mem: 8945M\n",
            "\u001b[32m[07/10 15:06:48 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 1:56:05 (3.4882 s / it)\n",
            "\u001b[32m[07/10 15:06:48 d2.engine.hooks]: \u001b[0mTotal training time: 2:32:52 (0:36:46 on hooks)\n",
            "\n",
            "\n",
            "**Starting train eval**\n",
            "\u001b[32m[07/10 15:07:01 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:07:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 15:07:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 15:07:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1397 s / img. ETA=0:02:34\n",
            "\u001b[32m[07/10 15:07:49 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.1349 s / img. ETA=0:02:18\n",
            "\u001b[32m[07/10 15:07:55 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1147 s / img. ETA=0:01:32\n",
            "\u001b[32m[07/10 15:08:01 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.1011 s / img. ETA=0:01:03\n",
            "\u001b[32m[07/10 15:08:06 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.0956 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/10 15:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.0912 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/10 15:08:18 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.0908 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 15:08:24 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.0912 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/10 15:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.0927 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 15:08:41 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.0962 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 15:08:50 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1002 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 15:08:57 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1027 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 15:09:02 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1049 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 15:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1076 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:51.622252 (2.146582 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.108077 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.771\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.995\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.928\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.785\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.805\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 77.100 | 99.474 | 92.826 |  nan  |  nan  | 77.100 |\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 81.418 | brec_Cht         | 78.861 | lam_Sltst  | 74.657 |\n",
            "| skel_WkstPkst | 74.121 | strless_SltstSst | 76.444 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.40s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.903\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.740\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.781\n",
            "\u001b[32m[07/10 15:09:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 74.047 | 99.001 | 90.327 |  nan  |  nan  | 74.047 |\n",
            "\u001b[32m[07/10 15:09:17 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:09:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 81.030 | brec_Cht         | 77.525 | lam_Sltst  | 67.393 |\n",
            "| skel_WkstPkst | 71.085 | strless_SltstSst | 73.204 |            |        |\n",
            "randomly selected cores/Box 7 Depths 10025-35.JPG\n",
            "\n",
            "\n",
            "**Starting val eval**\n",
            "\u001b[32m[07/10 15:10:01 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:10:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 15:10:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 15:10:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1144 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 15:10:47 d2.evaluation.evaluator]: \u001b[0mInference done 12/14. 0.1335 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.353440 (2.817049 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.152671 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.052\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.082 | 19.229 | 7.363  |  nan  |  nan  | 9.082 |\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.376 | brec_Cht         | 5.051  | lam_Sltst  | 3.410 |\n",
            "| skel_WkstPkst | 2.432  | strless_SltstSst | 14.142 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.382\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.823 | 19.747 | 8.841  |  nan  |  nan  | 9.823 |\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 22.100 | brec_Cht         | 5.788  | lam_Sltst  | 3.899 |\n",
            "| skel_WkstPkst | 3.093  | strless_SltstSst | 14.233 |            |       |\n",
            "randomly selected cores/Boxes 76-78  Depths 7929.1-7938.7 (Dry).JPG\n",
            "Fri Jul 10 15:12:03 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "CPU times: user 17.8 s, sys: 2.23 s, total: 20 s\n",
            "Wall time: 2h 39min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0chfOFVBLbj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "538106b4-7a38-452a-a423-e0a909e093a8"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '2' --max_iter 2000\n",
        "# copy results to Google Drive\n",
        "! cp -r output_fold_2 'drive/My Drive/R50-C4'\n",
        "# clean folders if upcoming experiment\n",
        "! rm -r *coco*\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 2\n",
            "\t cores_fold_2_train\n",
            "\t cores_fold_2_val\n",
            "\u001b[32m[07/10 15:12:19 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/10 15:12:31 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 57 images left.\n",
            "\u001b[32m[07/10 15:12:31 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 261          |   brec_Cht    | 21           | lam_Sltst  | 103          |\n",
            "| skel_WkstPkst | 24           | strless_Slt.. | 142          |            |              |\n",
            "|     total     | 551          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/10 15:12:31 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:12:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 15:12:31 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/10 15:12:31 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-10 15:12:32.201200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Unable to load 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (15, 4) in the checkpoint but (3, 4) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (1024, 1024, 3, 3) in the checkpoint but (256, 256, 3, 3) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (256,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (15, 1024, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (15,) in the checkpoint but (3,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (60, 1024, 1, 1) in the checkpoint but (12, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (60,) in the checkpoint but (12,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.deconv.weight' to the model due to incompatible shapes: (2048, 256, 2, 2) in the checkpoint but (256, 256, 2, 2) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/10 15:12:34 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/10 15:13:45 d2.utils.events]: \u001b[0m eta: 1:56:07  iter: 19  total_loss: 44.948  loss_cls: 34.629  loss_box_reg: 0.433  loss_mask: 1.501  loss_rpn_cls: 0.819  loss_rpn_loc: 6.910  time: 3.5204  data_time: 2.7661  lr: 0.000020  max_mem: 6785M\n",
            "\u001b[32m[07/10 15:14:54 d2.utils.events]: \u001b[0m eta: 1:54:27  iter: 39  total_loss: 7.703  loss_cls: 5.789  loss_box_reg: 0.229  loss_mask: 0.610  loss_rpn_cls: 0.264  loss_rpn_loc: 0.898  time: 3.5076  data_time: 2.5916  lr: 0.000040  max_mem: 6785M\n",
            "\u001b[32m[07/10 15:16:04 d2.utils.events]: \u001b[0m eta: 1:52:40  iter: 59  total_loss: 2.531  loss_cls: 1.100  loss_box_reg: 0.308  loss_mask: 0.580  loss_rpn_cls: 0.241  loss_rpn_loc: 0.385  time: 3.5006  data_time: 2.5722  lr: 0.000060  max_mem: 6945M\n",
            "\u001b[32m[07/10 15:17:15 d2.utils.events]: \u001b[0m eta: 1:51:42  iter: 79  total_loss: 2.036  loss_cls: 0.678  loss_box_reg: 0.329  loss_mask: 0.570  loss_rpn_cls: 0.178  loss_rpn_loc: 0.300  time: 3.5107  data_time: 2.5956  lr: 0.000080  max_mem: 7032M\n",
            "\u001b[32m[07/10 15:18:25 d2.utils.events]: \u001b[0m eta: 1:50:38  iter: 99  total_loss: 1.843  loss_cls: 0.439  loss_box_reg: 0.381  loss_mask: 0.550  loss_rpn_cls: 0.177  loss_rpn_loc: 0.264  time: 3.5065  data_time: 2.5370  lr: 0.000100  max_mem: 7311M\n",
            "\u001b[32m[07/10 15:19:35 d2.utils.events]: \u001b[0m eta: 1:49:37  iter: 119  total_loss: 1.757  loss_cls: 0.407  loss_box_reg: 0.400  loss_mask: 0.534  loss_rpn_cls: 0.159  loss_rpn_loc: 0.241  time: 3.5085  data_time: 2.5528  lr: 0.000120  max_mem: 7322M\n",
            "\u001b[32m[07/10 15:20:47 d2.utils.events]: \u001b[0m eta: 1:49:05  iter: 139  total_loss: 1.768  loss_cls: 0.416  loss_box_reg: 0.433  loss_mask: 0.519  loss_rpn_cls: 0.166  loss_rpn_loc: 0.225  time: 3.5210  data_time: 2.6293  lr: 0.000140  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:21:58 d2.utils.events]: \u001b[0m eta: 1:47:57  iter: 159  total_loss: 1.668  loss_cls: 0.376  loss_box_reg: 0.419  loss_mask: 0.523  loss_rpn_cls: 0.137  loss_rpn_loc: 0.218  time: 3.5247  data_time: 2.5938  lr: 0.000160  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:23:08 d2.utils.events]: \u001b[0m eta: 1:46:40  iter: 179  total_loss: 1.645  loss_cls: 0.377  loss_box_reg: 0.408  loss_mask: 0.498  loss_rpn_cls: 0.144  loss_rpn_loc: 0.206  time: 3.5226  data_time: 2.5405  lr: 0.000180  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:24:32 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:24:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 15:24:32 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_2_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/10 15:24:32 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_2_train' to COCO format ...)\n",
            "\u001b[32m[07/10 15:24:43 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/10 15:24:44 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 57, #annotations: 551\n",
            "\u001b[32m[07/10 15:24:44 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_2_train_coco_format.json' ...\n",
            "\u001b[32m[07/10 15:24:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0x8f526000 @  0x7fc9ccdf2b6b 0x7fc9cce12379 0x7fc97054704e 0x7fc970548f4a 0x7fc9a943767b 0x7fc9a90866be 0x7fc9a92ef7b5 0x7fc9a92e17c1 0x7fc9a92e0d0e 0x7fc9a92e17c1 0x7fc9aad3693a 0x7fc9a92e17c1 0x7fc9a9081457 0x7fc9a9082080 0x7fc9a93a071a 0x7fc9aae1e13e 0x7fc9a92e1c72 0x7fc9b737ba68 0x7fc9b7436b04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/10 15:26:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2701 s / img. ETA=0:06:18\n",
            "\u001b[32m[07/10 15:26:24 d2.evaluation.evaluator]: \u001b[0mInference done 12/57. 0.2699 s / img. ETA=0:06:09\n",
            "\u001b[32m[07/10 15:26:32 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2697 s / img. ETA=0:06:00\n",
            "\u001b[32m[07/10 15:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2887 s / img. ETA=0:05:52\n",
            "\u001b[32m[07/10 15:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2870 s / img. ETA=0:05:43\n",
            "\u001b[32m[07/10 15:26:58 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.2733 s / img. ETA=0:05:04\n",
            "\u001b[32m[07/10 15:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2629 s / img. ETA=0:04:34\n",
            "\u001b[32m[07/10 15:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.2553 s / img. ETA=0:04:09\n",
            "\u001b[32m[07/10 15:27:27 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2493 s / img. ETA=0:03:47\n",
            "\u001b[32m[07/10 15:27:34 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2449 s / img. ETA=0:03:23\n",
            "\u001b[32m[07/10 15:27:41 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.2393 s / img. ETA=0:02:49\n",
            "\u001b[32m[07/10 15:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2348 s / img. ETA=0:02:21\n",
            "\u001b[32m[07/10 15:27:56 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2313 s / img. ETA=0:01:58\n",
            "\u001b[32m[07/10 15:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.2291 s / img. ETA=0:01:45\n",
            "\u001b[32m[07/10 15:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.2264 s / img. ETA=0:01:25\n",
            "\u001b[32m[07/10 15:28:15 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.2249 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/10 15:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.2253 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/10 15:28:30 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.2267 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/10 15:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.2280 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/10 15:28:41 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.2292 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/10 15:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.2301 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 15:28:53 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.2311 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/10 15:28:58 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.2318 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 15:29:04 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.2324 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 15:29:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:37.013337 (4.173333 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:29:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.232426 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:29:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:29:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:29:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.68s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.027\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.101\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
            "\u001b[32m[07/10 15:29:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.758 | 8.377  | 1.086  |  nan  |  nan  | 2.758 |\n",
            "\u001b[32m[07/10 15:29:05 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:29:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 7.120 | brec_Cht         | 0.051 | lam_Sltst  | 0.216 |\n",
            "| skel_WkstPkst | 2.261 | strless_SltstSst | 4.142 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.94s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.142\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.444 | 8.032  | 0.735  |  nan  |  nan  | 2.444 |\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 7.068 | brec_Cht         | 0.051 | lam_Sltst  | 0.206 |\n",
            "| skel_WkstPkst | 1.201 | strless_SltstSst | 3.696 |            |       |\n",
            "\u001b[32m[07/10 15:29:06 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: 2.7579,8.3770,1.0864,nan,nan,2.7579\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: 2.4443,8.0320,0.7347,nan,nan,2.4443\n",
            "\u001b[32m[07/10 15:29:09 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 48           |   brec_Cht    | 0            | lam_Sltst  | 24           |\n",
            "| skel_WkstPkst | 2            | strless_Slt.. | 31           |            |              |\n",
            "|     total     | 105          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/10 15:29:09 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:29:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 15:29:09 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_2_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/10 15:29:09 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_2_val' to COCO format ...)\n",
            "\u001b[32m[07/10 15:29:11 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/10 15:29:11 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 14, #annotations: 105\n",
            "\u001b[32m[07/10 15:29:11 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_2_val_coco_format.json' ...\n",
            "\u001b[32m[07/10 15:29:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 15:29:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1913 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 15:29:48 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1995 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 15:29:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.594578 (2.288286 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:29:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.199464 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:29:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:29:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:29:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.092\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.161\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.499 | 10.297 | 1.331  |  nan  |  nan  | 3.499 |\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 11.242 | brec_Cht         | nan   | lam_Sltst  | 1.072 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 1.683 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.150\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.070 | 9.920  | 0.838  |  nan  |  nan  | 3.070 |\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 9.897 | brec_Cht         | nan   | lam_Sltst  | 0.817 |\n",
            "| skel_WkstPkst | 0.000 | strless_SltstSst | 1.566 |            |       |\n",
            "\u001b[32m[07/10 15:29:49 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.testing]: \u001b[0mcopypaste: 3.4993,10.2965,1.3305,nan,nan,3.4993\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.testing]: \u001b[0mcopypaste: 3.0700,9.9200,0.8381,nan,nan,3.0700\n",
            "\u001b[32m[07/10 15:29:49 d2.utils.events]: \u001b[0m eta: 1:45:31  iter: 199  total_loss: 1.647  loss_cls: 0.396  loss_box_reg: 0.428  loss_mask: 0.481  loss_rpn_cls: 0.134  loss_rpn_loc: 0.199  time: 3.5247  data_time: 2.5693  lr: 0.000200  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:31:00 d2.utils.events]: \u001b[0m eta: 1:44:26  iter: 219  total_loss: 1.656  loss_cls: 0.416  loss_box_reg: 0.445  loss_mask: 0.451  loss_rpn_cls: 0.129  loss_rpn_loc: 0.193  time: 3.5281  data_time: 2.5776  lr: 0.000220  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:32:12 d2.utils.events]: \u001b[0m eta: 1:43:17  iter: 239  total_loss: 1.611  loss_cls: 0.419  loss_box_reg: 0.442  loss_mask: 0.433  loss_rpn_cls: 0.126  loss_rpn_loc: 0.193  time: 3.5335  data_time: 2.5872  lr: 0.000240  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:33:25 d2.utils.events]: \u001b[0m eta: 1:42:28  iter: 259  total_loss: 1.617  loss_cls: 0.415  loss_box_reg: 0.461  loss_mask: 0.415  loss_rpn_cls: 0.125  loss_rpn_loc: 0.191  time: 3.5411  data_time: 2.6293  lr: 0.000260  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:34:38 d2.utils.events]: \u001b[0m eta: 1:41:46  iter: 279  total_loss: 1.539  loss_cls: 0.421  loss_box_reg: 0.434  loss_mask: 0.390  loss_rpn_cls: 0.111  loss_rpn_loc: 0.181  time: 3.5517  data_time: 2.6628  lr: 0.000280  max_mem: 8489M\n",
            "\u001b[32m[07/10 15:35:51 d2.utils.events]: \u001b[0m eta: 1:40:37  iter: 299  total_loss: 1.598  loss_cls: 0.466  loss_box_reg: 0.470  loss_mask: 0.373  loss_rpn_cls: 0.112  loss_rpn_loc: 0.179  time: 3.5569  data_time: 2.5922  lr: 0.000300  max_mem: 8489M\n",
            "\u001b[32m[07/10 15:37:04 d2.utils.events]: \u001b[0m eta: 1:39:40  iter: 319  total_loss: 1.480  loss_cls: 0.430  loss_box_reg: 0.431  loss_mask: 0.351  loss_rpn_cls: 0.107  loss_rpn_loc: 0.172  time: 3.5637  data_time: 2.6380  lr: 0.000320  max_mem: 8489M\n",
            "\u001b[32m[07/10 15:38:18 d2.utils.events]: \u001b[0m eta: 1:38:48  iter: 339  total_loss: 1.526  loss_cls: 0.469  loss_box_reg: 0.450  loss_mask: 0.346  loss_rpn_cls: 0.104  loss_rpn_loc: 0.181  time: 3.5711  data_time: 2.6361  lr: 0.000340  max_mem: 8747M\n",
            "\u001b[32m[07/10 15:39:31 d2.utils.events]: \u001b[0m eta: 1:37:51  iter: 359  total_loss: 1.450  loss_cls: 0.428  loss_box_reg: 0.413  loss_mask: 0.328  loss_rpn_cls: 0.097  loss_rpn_loc: 0.180  time: 3.5757  data_time: 2.6107  lr: 0.000360  max_mem: 8747M\n",
            "\u001b[32m[07/10 15:40:45 d2.utils.events]: \u001b[0m eta: 1:36:52  iter: 379  total_loss: 1.529  loss_cls: 0.484  loss_box_reg: 0.428  loss_mask: 0.324  loss_rpn_cls: 0.100  loss_rpn_loc: 0.176  time: 3.5806  data_time: 2.6413  lr: 0.000380  max_mem: 8747M\n",
            "\u001b[32m[07/10 15:42:11 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:42:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 15:42:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 15:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2667 s / img. ETA=0:02:40\n",
            "\u001b[32m[07/10 15:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2519 s / img. ETA=0:02:23\n",
            "\u001b[32m[07/10 15:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.2766 s / img. ETA=0:02:05\n",
            "\u001b[32m[07/10 15:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2592 s / img. ETA=0:01:50\n",
            "\u001b[32m[07/10 15:43:18 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.2489 s / img. ETA=0:01:39\n",
            "\u001b[32m[07/10 15:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2417 s / img. ETA=0:01:29\n",
            "\u001b[32m[07/10 15:43:33 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.2364 s / img. ETA=0:01:19\n",
            "\u001b[32m[07/10 15:43:39 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2292 s / img. ETA=0:01:09\n",
            "\u001b[32m[07/10 15:43:47 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2264 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/10 15:43:54 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.2238 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/10 15:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.2217 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/10 15:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.2214 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/10 15:44:16 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.2232 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/10 15:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.2247 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 15:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.2260 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 15:44:34 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.2271 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 15:44:41 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.2283 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 15:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.2291 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 15:44:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:21.467664 (2.720532 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:44:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.228533 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:44:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:44:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:44:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.60s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.135\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.079\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.135\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397\n",
            "\u001b[32m[07/10 15:44:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.495 | 32.340 | 7.896  |  nan  |  nan  | 13.495 |\n",
            "\u001b[32m[07/10 15:44:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:44:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 17.785 | brec_Cht         | 14.366 | lam_Sltst  | 4.923 |\n",
            "| skel_WkstPkst | 13.542 | strless_SltstSst | 16.859 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.93s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.092\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.452\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 16.426 | 32.619 | 13.083 |  nan  |  nan  | 16.426 |\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.607 | brec_Cht         | 21.149 | lam_Sltst  | 5.274 |\n",
            "| skel_WkstPkst | 16.198 | strless_SltstSst | 18.899 |            |       |\n",
            "\u001b[32m[07/10 15:44:54 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: 13.4950,32.3400,7.8962,nan,nan,13.4950\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: 16.4255,32.6191,13.0829,nan,nan,16.4255\n",
            "\u001b[32m[07/10 15:44:56 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:44:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 15:44:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 15:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1879 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1974 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.073986 (2.341554 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.197427 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.239\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.049\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.095\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.271\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.484 | 23.928 | 4.868  |  nan  |  nan  | 9.484 |\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 25.399 | brec_Cht         | nan   | lam_Sltst  | 5.155 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 7.382 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.257\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.072\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.188\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.302\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.836 | 25.702 | 7.174  |  nan  |  nan  | 10.836 |\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 28.432 | brec_Cht         | nan   | lam_Sltst  | 6.610 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 8.302 |            |       |\n",
            "\u001b[32m[07/10 15:45:35 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.testing]: \u001b[0mcopypaste: 9.4838,23.9278,4.8676,nan,nan,9.4838\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.testing]: \u001b[0mcopypaste: 10.8359,25.7023,7.1740,nan,nan,10.8359\n",
            "\u001b[32m[07/10 15:45:35 d2.utils.events]: \u001b[0m eta: 1:35:45  iter: 399  total_loss: 1.447  loss_cls: 0.441  loss_box_reg: 0.441  loss_mask: 0.320  loss_rpn_cls: 0.091  loss_rpn_loc: 0.171  time: 3.5831  data_time: 2.5676  lr: 0.000400  max_mem: 8747M\n",
            "\u001b[32m[07/10 15:46:48 d2.utils.events]: \u001b[0m eta: 1:34:44  iter: 419  total_loss: 1.466  loss_cls: 0.441  loss_box_reg: 0.438  loss_mask: 0.310  loss_rpn_cls: 0.096  loss_rpn_loc: 0.165  time: 3.5859  data_time: 2.6163  lr: 0.000420  max_mem: 8747M\n",
            "\u001b[32m[07/10 15:48:02 d2.utils.events]: \u001b[0m eta: 1:33:38  iter: 439  total_loss: 1.426  loss_cls: 0.431  loss_box_reg: 0.414  loss_mask: 0.308  loss_rpn_cls: 0.091  loss_rpn_loc: 0.160  time: 3.5907  data_time: 2.6346  lr: 0.000440  max_mem: 8829M\n",
            "\u001b[32m[07/10 15:49:15 d2.utils.events]: \u001b[0m eta: 1:32:29  iter: 459  total_loss: 1.373  loss_cls: 0.436  loss_box_reg: 0.422  loss_mask: 0.297  loss_rpn_cls: 0.087  loss_rpn_loc: 0.160  time: 3.5939  data_time: 2.5896  lr: 0.000460  max_mem: 8829M\n",
            "\u001b[32m[07/10 15:50:29 d2.utils.events]: \u001b[0m eta: 1:31:21  iter: 479  total_loss: 1.465  loss_cls: 0.486  loss_box_reg: 0.419  loss_mask: 0.290  loss_rpn_cls: 0.088  loss_rpn_loc: 0.162  time: 3.5978  data_time: 2.6460  lr: 0.000480  max_mem: 8829M\n",
            "\u001b[32m[07/10 15:51:43 d2.utils.events]: \u001b[0m eta: 1:30:17  iter: 499  total_loss: 1.339  loss_cls: 0.416  loss_box_reg: 0.394  loss_mask: 0.291  loss_rpn_cls: 0.080  loss_rpn_loc: 0.155  time: 3.6026  data_time: 2.6479  lr: 0.000500  max_mem: 8885M\n",
            "\u001b[32m[07/10 15:52:58 d2.utils.events]: \u001b[0m eta: 1:29:25  iter: 519  total_loss: 1.361  loss_cls: 0.427  loss_box_reg: 0.423  loss_mask: 0.288  loss_rpn_cls: 0.079  loss_rpn_loc: 0.154  time: 3.6081  data_time: 2.6903  lr: 0.000519  max_mem: 8885M\n",
            "\u001b[32m[07/10 15:54:13 d2.utils.events]: \u001b[0m eta: 1:28:15  iter: 539  total_loss: 1.346  loss_cls: 0.427  loss_box_reg: 0.417  loss_mask: 0.282  loss_rpn_cls: 0.071  loss_rpn_loc: 0.148  time: 3.6123  data_time: 2.6639  lr: 0.000539  max_mem: 8885M\n",
            "\u001b[32m[07/10 15:55:27 d2.utils.events]: \u001b[0m eta: 1:27:06  iter: 559  total_loss: 1.306  loss_cls: 0.401  loss_box_reg: 0.389  loss_mask: 0.275  loss_rpn_cls: 0.079  loss_rpn_loc: 0.166  time: 3.6164  data_time: 2.6622  lr: 0.000559  max_mem: 8885M\n",
            "\u001b[32m[07/10 15:56:40 d2.utils.events]: \u001b[0m eta: 1:25:56  iter: 579  total_loss: 1.303  loss_cls: 0.401  loss_box_reg: 0.408  loss_mask: 0.272  loss_rpn_cls: 0.076  loss_rpn_loc: 0.159  time: 3.6175  data_time: 2.5910  lr: 0.000579  max_mem: 8885M\n",
            "\u001b[32m[07/10 15:58:10 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:58:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 15:58:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 15:58:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2717 s / img. ETA=0:02:35\n",
            "\u001b[32m[07/10 15:58:55 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2603 s / img. ETA=0:02:21\n",
            "\u001b[32m[07/10 15:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.2444 s / img. ETA=0:02:01\n",
            "\u001b[32m[07/10 15:59:08 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2308 s / img. ETA=0:01:45\n",
            "\u001b[32m[07/10 15:59:15 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.2249 s / img. ETA=0:01:34\n",
            "\u001b[32m[07/10 15:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2206 s / img. ETA=0:01:24\n",
            "\u001b[32m[07/10 15:59:29 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.2171 s / img. ETA=0:01:15\n",
            "\u001b[32m[07/10 15:59:34 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2092 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/10 15:59:41 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2084 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/10 15:59:48 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.2077 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/10 15:59:56 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.2069 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/10 16:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.2078 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/10 16:00:10 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.2105 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 16:00:16 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.2126 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 16:00:22 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.2144 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 16:00:28 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.2160 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 16:00:34 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.2175 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 16:00:40 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.2188 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:15.607190 (2.607831 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.218303 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.62s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.245\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.412\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 24.544 | 50.292 | 17.862 |  nan  |  nan  | 24.544 |\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 31.061 | brec_Cht         | 28.246 | lam_Sltst  | 15.180 |\n",
            "| skel_WkstPkst | 18.929 | strless_SltstSst | 29.303 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.84s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.552\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 27.525 | 50.258 | 28.548 |  nan  |  nan  | 27.525 |\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 34.344 | brec_Cht         | 32.601 | lam_Sltst  | 15.885 |\n",
            "| skel_WkstPkst | 21.050 | strless_SltstSst | 33.744 |            |        |\n",
            "\u001b[32m[07/10 16:00:47 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.testing]: \u001b[0mcopypaste: 24.5437,50.2916,17.8621,nan,nan,24.5437\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.testing]: \u001b[0mcopypaste: 27.5248,50.2576,28.5479,nan,nan,27.5248\n",
            "\u001b[32m[07/10 16:00:50 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:00:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 16:00:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 16:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1847 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1939 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.144749 (2.238305 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.193878 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 7.358 | 19.960 | 2.991  |  nan  |  nan  | 7.358 |\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 17.054 | brec_Cht         | nan   | lam_Sltst  | 4.000 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 8.379 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.060\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.197\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.330\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.736 | 20.819 | 5.963  |  nan  |  nan  | 8.736 |\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 19.822 | brec_Cht         | nan   | lam_Sltst  | 5.412 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 9.711 |            |       |\n",
            "\u001b[32m[07/10 16:01:27 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.testing]: \u001b[0mcopypaste: 7.3582,19.9597,2.9906,nan,nan,7.3582\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.testing]: \u001b[0mcopypaste: 8.7363,20.8189,5.9633,nan,nan,8.7363\n",
            "\u001b[32m[07/10 16:01:27 d2.utils.events]: \u001b[0m eta: 1:24:49  iter: 599  total_loss: 1.302  loss_cls: 0.393  loss_box_reg: 0.400  loss_mask: 0.269  loss_rpn_cls: 0.071  loss_rpn_loc: 0.164  time: 3.6237  data_time: 2.7460  lr: 0.000599  max_mem: 8885M\n",
            "\u001b[32m[07/10 16:02:41 d2.utils.events]: \u001b[0m eta: 1:23:41  iter: 619  total_loss: 1.289  loss_cls: 0.394  loss_box_reg: 0.404  loss_mask: 0.263  loss_rpn_cls: 0.068  loss_rpn_loc: 0.168  time: 3.6260  data_time: 2.6032  lr: 0.000619  max_mem: 8885M\n",
            "\u001b[32m[07/10 16:03:58 d2.utils.events]: \u001b[0m eta: 1:22:36  iter: 639  total_loss: 1.393  loss_cls: 0.449  loss_box_reg: 0.413  loss_mask: 0.264  loss_rpn_cls: 0.067  loss_rpn_loc: 0.171  time: 3.6320  data_time: 2.7656  lr: 0.000639  max_mem: 8885M\n",
            "\u001b[32m[07/10 16:05:12 d2.utils.events]: \u001b[0m eta: 1:21:29  iter: 659  total_loss: 1.278  loss_cls: 0.409  loss_box_reg: 0.391  loss_mask: 0.255  loss_rpn_cls: 0.071  loss_rpn_loc: 0.167  time: 3.6346  data_time: 2.6539  lr: 0.000659  max_mem: 8885M\n",
            "\u001b[32m[07/10 16:06:27 d2.utils.events]: \u001b[0m eta: 1:20:18  iter: 679  total_loss: 1.206  loss_cls: 0.375  loss_box_reg: 0.370  loss_mask: 0.252  loss_rpn_cls: 0.065  loss_rpn_loc: 0.157  time: 3.6374  data_time: 2.6623  lr: 0.000679  max_mem: 8885M\n",
            "\u001b[32m[07/10 16:07:42 d2.utils.events]: \u001b[0m eta: 1:19:08  iter: 699  total_loss: 1.254  loss_cls: 0.404  loss_box_reg: 0.396  loss_mask: 0.259  loss_rpn_cls: 0.061  loss_rpn_loc: 0.152  time: 3.6411  data_time: 2.6790  lr: 0.000699  max_mem: 8885M\n",
            "\u001b[32m[07/10 16:08:58 d2.utils.events]: \u001b[0m eta: 1:17:58  iter: 719  total_loss: 1.216  loss_cls: 0.395  loss_box_reg: 0.380  loss_mask: 0.246  loss_rpn_cls: 0.061  loss_rpn_loc: 0.146  time: 3.6450  data_time: 2.7001  lr: 0.000719  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:10:13 d2.utils.events]: \u001b[0m eta: 1:16:55  iter: 739  total_loss: 1.242  loss_cls: 0.414  loss_box_reg: 0.391  loss_mask: 0.254  loss_rpn_cls: 0.059  loss_rpn_loc: 0.148  time: 3.6482  data_time: 2.6929  lr: 0.000739  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:11:28 d2.utils.events]: \u001b[0m eta: 1:15:42  iter: 759  total_loss: 1.216  loss_cls: 0.372  loss_box_reg: 0.380  loss_mask: 0.246  loss_rpn_cls: 0.054  loss_rpn_loc: 0.147  time: 3.6507  data_time: 2.6560  lr: 0.000759  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:12:42 d2.utils.events]: \u001b[0m eta: 1:14:32  iter: 779  total_loss: 1.196  loss_cls: 0.360  loss_box_reg: 0.375  loss_mask: 0.241  loss_rpn_cls: 0.059  loss_rpn_loc: 0.148  time: 3.6521  data_time: 2.6386  lr: 0.000779  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:14:11 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:14:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 16:14:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 16:14:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2704 s / img. ETA=0:02:31\n",
            "\u001b[32m[07/10 16:14:56 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2661 s / img. ETA=0:02:21\n",
            "\u001b[32m[07/10 16:15:01 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2580 s / img. ETA=0:02:08\n",
            "\u001b[32m[07/10 16:15:08 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2263 s / img. ETA=0:01:42\n",
            "\u001b[32m[07/10 16:15:13 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2032 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/10 16:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.1915 s / img. ETA=0:01:07\n",
            "\u001b[32m[07/10 16:15:26 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1813 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/10 16:15:32 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1808 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/10 16:15:38 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1795 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/10 16:15:45 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1793 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/10 16:15:51 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1792 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 16:15:57 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1831 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 16:16:03 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1866 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/10 16:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1897 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 16:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1924 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 16:16:20 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1950 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 16:16:26 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1972 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 16:16:31 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1993 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 16:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:03.186278 (2.368967 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.198723 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:16:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:16:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:16:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.57s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.616\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.578\n",
            "\u001b[32m[07/10 16:16:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 35.487 | 61.560 | 39.628 |  nan  |  nan  | 35.487 |\n",
            "\u001b[32m[07/10 16:16:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:16:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 40.755 | brec_Cht         | 47.417 | lam_Sltst  | 21.199 |\n",
            "| skel_WkstPkst | 27.761 | strless_SltstSst | 40.301 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.78s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.369\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.612\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.389\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.369\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.599\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.599\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 36.855 | 61.191 | 38.926 |  nan  |  nan  | 36.855 |\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 44.182 | brec_Cht         | 51.547 | lam_Sltst  | 21.017 |\n",
            "| skel_WkstPkst | 28.314 | strless_SltstSst | 39.213 |            |        |\n",
            "\u001b[32m[07/10 16:16:35 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.testing]: \u001b[0mcopypaste: 35.4866,61.5597,39.6283,nan,nan,35.4866\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.testing]: \u001b[0mcopypaste: 36.8547,61.1911,38.9263,nan,nan,36.8547\n",
            "\u001b[32m[07/10 16:16:38 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:16:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 16:16:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 16:17:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1529 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1714 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.675509 (1.963945 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.171357 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.080\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 7.985 | 19.223 | 5.549  |  nan  |  nan  | 7.985 |\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 19.496 | brec_Cht         | nan   | lam_Sltst  | 2.012 |\n",
            "| skel_WkstPkst | 1.537  | strless_SltstSst | 8.894 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.383\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.383\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.741 | 19.257 | 6.849  |  nan  |  nan  | 8.741 |\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 22.129 | brec_Cht         | nan   | lam_Sltst  | 1.849 |\n",
            "| skel_WkstPkst | 1.537  | strless_SltstSst | 9.448 |            |       |\n",
            "\u001b[32m[07/10 16:17:11 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: 7.9849,19.2229,5.5489,nan,nan,7.9849\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: 8.7406,19.2569,6.8492,nan,nan,8.7406\n",
            "\u001b[32m[07/10 16:17:11 d2.utils.events]: \u001b[0m eta: 1:13:21  iter: 799  total_loss: 1.148  loss_cls: 0.361  loss_box_reg: 0.376  loss_mask: 0.237  loss_rpn_cls: 0.052  loss_rpn_loc: 0.150  time: 3.6550  data_time: 2.6968  lr: 0.000799  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:18:25 d2.utils.events]: \u001b[0m eta: 1:12:11  iter: 819  total_loss: 1.062  loss_cls: 0.324  loss_box_reg: 0.323  loss_mask: 0.225  loss_rpn_cls: 0.050  loss_rpn_loc: 0.141  time: 3.6564  data_time: 2.6122  lr: 0.000819  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:19:41 d2.utils.events]: \u001b[0m eta: 1:11:00  iter: 839  total_loss: 1.125  loss_cls: 0.342  loss_box_reg: 0.340  loss_mask: 0.243  loss_rpn_cls: 0.055  loss_rpn_loc: 0.144  time: 3.6586  data_time: 2.6621  lr: 0.000839  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:20:56 d2.utils.events]: \u001b[0m eta: 1:09:52  iter: 859  total_loss: 1.162  loss_cls: 0.343  loss_box_reg: 0.368  loss_mask: 0.236  loss_rpn_cls: 0.047  loss_rpn_loc: 0.137  time: 3.6608  data_time: 2.6484  lr: 0.000859  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:22:11 d2.utils.events]: \u001b[0m eta: 1:08:43  iter: 879  total_loss: 1.110  loss_cls: 0.330  loss_box_reg: 0.362  loss_mask: 0.231  loss_rpn_cls: 0.046  loss_rpn_loc: 0.138  time: 3.6633  data_time: 2.7048  lr: 0.000879  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:23:25 d2.utils.events]: \u001b[0m eta: 1:07:29  iter: 899  total_loss: 1.089  loss_cls: 0.313  loss_box_reg: 0.344  loss_mask: 0.227  loss_rpn_cls: 0.048  loss_rpn_loc: 0.145  time: 3.6642  data_time: 2.6325  lr: 0.000899  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:24:41 d2.utils.events]: \u001b[0m eta: 1:06:16  iter: 919  total_loss: 1.100  loss_cls: 0.312  loss_box_reg: 0.361  loss_mask: 0.235  loss_rpn_cls: 0.051  loss_rpn_loc: 0.138  time: 3.6665  data_time: 2.6860  lr: 0.000919  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:25:56 d2.utils.events]: \u001b[0m eta: 1:05:05  iter: 939  total_loss: 1.049  loss_cls: 0.294  loss_box_reg: 0.362  loss_mask: 0.228  loss_rpn_cls: 0.043  loss_rpn_loc: 0.136  time: 3.6683  data_time: 2.6742  lr: 0.000939  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:27:11 d2.utils.events]: \u001b[0m eta: 1:03:54  iter: 959  total_loss: 1.061  loss_cls: 0.300  loss_box_reg: 0.347  loss_mask: 0.236  loss_rpn_cls: 0.047  loss_rpn_loc: 0.137  time: 3.6709  data_time: 2.7089  lr: 0.000959  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:28:27 d2.utils.events]: \u001b[0m eta: 1:02:44  iter: 979  total_loss: 1.137  loss_cls: 0.347  loss_box_reg: 0.368  loss_mask: 0.234  loss_rpn_cls: 0.046  loss_rpn_loc: 0.150  time: 3.6730  data_time: 2.6757  lr: 0.000979  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:29:56 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:29:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 16:29:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 16:30:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2396 s / img. ETA=0:02:17\n",
            "\u001b[32m[07/10 16:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2283 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/10 16:30:43 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1932 s / img. ETA=0:01:30\n",
            "\u001b[32m[07/10 16:30:48 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1739 s / img. ETA=0:01:12\n",
            "\u001b[32m[07/10 16:30:54 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.1583 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/10 16:31:00 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.1491 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/10 16:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.1476 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/10 16:31:11 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1471 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/10 16:31:16 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1472 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 16:31:22 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1491 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/10 16:31:30 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1536 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/10 16:31:35 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1574 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 16:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1615 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 16:31:47 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1648 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 16:31:55 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1688 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 16:31:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:43.302247 (1.986582 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:31:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.167907 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:31:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:31:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:31:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.48s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.705\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.482\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.545\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633\n",
            "\u001b[32m[07/10 16:31:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 41.747 | 70.546 | 48.158 |  nan  |  nan  | 41.747 |\n",
            "\u001b[32m[07/10 16:31:57 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:31:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 48.326 | brec_Cht         | 44.741 | lam_Sltst  | 33.231 |\n",
            "| skel_WkstPkst | 31.196 | strless_SltstSst | 51.239 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.11s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.68s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.683\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.495\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.443\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.574\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666\n",
            "\u001b[32m[07/10 16:31:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 44.315 | 68.303 | 49.479 |  nan  |  nan  | 44.315 |\n",
            "\u001b[32m[07/10 16:31:57 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:31:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 53.128 | brec_Cht         | 48.529 | lam_Sltst  | 34.648 |\n",
            "| skel_WkstPkst | 31.916 | strless_SltstSst | 53.354 |            |        |\n",
            "\u001b[32m[07/10 16:31:58 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 16:31:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:31:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:31:58 d2.evaluation.testing]: \u001b[0mcopypaste: 41.7467,70.5462,48.1579,nan,nan,41.7467\n",
            "\u001b[32m[07/10 16:31:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:31:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:31:58 d2.evaluation.testing]: \u001b[0mcopypaste: 44.3152,68.3033,49.4787,nan,nan,44.3152\n",
            "\u001b[32m[07/10 16:32:00 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:32:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 16:32:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 16:32:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1222 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1413 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.072379 (1.563598 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.141276 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.214\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.237\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.327\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.151 | 21.422 | 8.874  |  nan  |  nan  | 10.151 |\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.284 | brec_Cht         | nan    | lam_Sltst  | 4.919 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 15.401 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.114\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.224\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.122\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.114\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.258\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.425 | 22.439 | 12.231 |  nan  |  nan  | 11.425 |\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.909 | brec_Cht         | nan    | lam_Sltst  | 4.918 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 16.874 |            |       |\n",
            "\u001b[32m[07/10 16:32:28 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.testing]: \u001b[0mcopypaste: 10.1510,21.4218,8.8738,nan,nan,10.1510\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.testing]: \u001b[0mcopypaste: 11.4253,22.4390,12.2310,nan,nan,11.4253\n",
            "\u001b[32m[07/10 16:32:28 d2.utils.events]: \u001b[0m eta: 1:01:32  iter: 999  total_loss: 1.019  loss_cls: 0.296  loss_box_reg: 0.325  loss_mask: 0.223  loss_rpn_cls: 0.042  loss_rpn_loc: 0.142  time: 3.6747  data_time: 2.6964  lr: 0.000999  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:33:43 d2.utils.events]: \u001b[0m eta: 1:00:22  iter: 1019  total_loss: 1.061  loss_cls: 0.313  loss_box_reg: 0.336  loss_mask: 0.214  loss_rpn_cls: 0.044  loss_rpn_loc: 0.133  time: 3.6766  data_time: 2.6654  lr: 0.001000  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:34:58 d2.utils.events]: \u001b[0m eta: 0:59:11  iter: 1039  total_loss: 0.993  loss_cls: 0.280  loss_box_reg: 0.326  loss_mask: 0.218  loss_rpn_cls: 0.043  loss_rpn_loc: 0.131  time: 3.6776  data_time: 2.6365  lr: 0.001000  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:36:14 d2.utils.events]: \u001b[0m eta: 0:58:01  iter: 1059  total_loss: 1.044  loss_cls: 0.298  loss_box_reg: 0.347  loss_mask: 0.217  loss_rpn_cls: 0.040  loss_rpn_loc: 0.131  time: 3.6797  data_time: 2.7016  lr: 0.001000  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:37:28 d2.utils.events]: \u001b[0m eta: 0:56:50  iter: 1079  total_loss: 0.976  loss_cls: 0.262  loss_box_reg: 0.327  loss_mask: 0.213  loss_rpn_cls: 0.038  loss_rpn_loc: 0.138  time: 3.6803  data_time: 2.6441  lr: 0.001000  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:38:43 d2.utils.events]: \u001b[0m eta: 0:55:37  iter: 1099  total_loss: 0.979  loss_cls: 0.268  loss_box_reg: 0.327  loss_mask: 0.209  loss_rpn_cls: 0.033  loss_rpn_loc: 0.131  time: 3.6811  data_time: 2.6360  lr: 0.001000  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:39:57 d2.utils.events]: \u001b[0m eta: 0:54:26  iter: 1119  total_loss: 0.976  loss_cls: 0.277  loss_box_reg: 0.328  loss_mask: 0.207  loss_rpn_cls: 0.037  loss_rpn_loc: 0.132  time: 3.6820  data_time: 2.6340  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:41:12 d2.utils.events]: \u001b[0m eta: 0:53:14  iter: 1139  total_loss: 0.957  loss_cls: 0.268  loss_box_reg: 0.315  loss_mask: 0.209  loss_rpn_cls: 0.038  loss_rpn_loc: 0.131  time: 3.6831  data_time: 2.6546  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:42:27 d2.utils.events]: \u001b[0m eta: 0:52:08  iter: 1159  total_loss: 0.935  loss_cls: 0.266  loss_box_reg: 0.305  loss_mask: 0.203  loss_rpn_cls: 0.038  loss_rpn_loc: 0.127  time: 3.6841  data_time: 2.6606  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:43:42 d2.utils.events]: \u001b[0m eta: 0:50:59  iter: 1179  total_loss: 0.964  loss_cls: 0.278  loss_box_reg: 0.309  loss_mask: 0.206  loss_rpn_cls: 0.035  loss_rpn_loc: 0.136  time: 3.6849  data_time: 2.6329  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:45:10 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:45:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 16:45:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 16:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2194 s / img. ETA=0:02:03\n",
            "\u001b[32m[07/10 16:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2145 s / img. ETA=0:01:50\n",
            "\u001b[32m[07/10 16:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1738 s / img. ETA=0:01:17\n",
            "\u001b[32m[07/10 16:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.1530 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/10 16:46:05 d2.evaluation.evaluator]: \u001b[0mInference done 30/57. 0.1386 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/10 16:46:11 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1363 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/10 16:46:17 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1343 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/10 16:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1343 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 16:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1354 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 16:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1398 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 16:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1444 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 16:46:47 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1493 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 16:46:52 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1528 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 16:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1572 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:34.974928 (1.826441 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.156626 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.42s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.840\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.627\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.161\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 52.851 | 83.987 | 62.696 |  nan  |  nan  | 52.851 |\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 56.832 | brec_Cht         | 55.153 | lam_Sltst  | 50.120 |\n",
            "| skel_WkstPkst | 44.813 | strless_SltstSst | 57.335 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.61s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.823\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.662\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.649\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.704\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.704\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 56.082 | 82.283 | 66.217 |  nan  |  nan  | 56.082 |\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 61.914 | brec_Cht         | 58.071 | lam_Sltst  | 50.523 |\n",
            "| skel_WkstPkst | 46.869 | strless_SltstSst | 63.035 |            |        |\n",
            "\u001b[32m[07/10 16:47:02 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.testing]: \u001b[0mcopypaste: 52.8505,83.9866,62.6963,nan,nan,52.8505\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.testing]: \u001b[0mcopypaste: 56.0824,82.2832,66.2172,nan,nan,56.0824\n",
            "\u001b[32m[07/10 16:47:05 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:47:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 16:47:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 16:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1161 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 16:47:31 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1349 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 16:47:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.568770 (1.507641 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:47:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.134926 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:47:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:47:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:47:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.219\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.259\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.194 | 21.915 | 8.426  |  nan  |  nan  | 10.194 |\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.476 | brec_Cht         | nan    | lam_Sltst  | 4.376 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 14.925 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.111\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.062 | 19.983 | 11.978 |  nan  |  nan  | 11.062 |\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 25.173 | brec_Cht         | nan    | lam_Sltst  | 3.310 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 15.764 |            |       |\n",
            "\u001b[32m[07/10 16:47:32 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.testing]: \u001b[0mcopypaste: 10.1944,21.9145,8.4264,nan,nan,10.1944\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.testing]: \u001b[0mcopypaste: 11.0619,19.9831,11.9780,nan,nan,11.0619\n",
            "\u001b[32m[07/10 16:47:32 d2.utils.events]: \u001b[0m eta: 0:49:49  iter: 1199  total_loss: 0.916  loss_cls: 0.249  loss_box_reg: 0.314  loss_mask: 0.199  loss_rpn_cls: 0.033  loss_rpn_loc: 0.132  time: 3.6858  data_time: 2.6235  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:48:46 d2.utils.events]: \u001b[0m eta: 0:48:36  iter: 1219  total_loss: 0.935  loss_cls: 0.248  loss_box_reg: 0.322  loss_mask: 0.203  loss_rpn_cls: 0.031  loss_rpn_loc: 0.127  time: 3.6859  data_time: 2.5952  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:50:01 d2.utils.events]: \u001b[0m eta: 0:47:24  iter: 1239  total_loss: 0.910  loss_cls: 0.240  loss_box_reg: 0.301  loss_mask: 0.198  loss_rpn_cls: 0.029  loss_rpn_loc: 0.131  time: 3.6875  data_time: 2.7139  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:51:16 d2.utils.events]: \u001b[0m eta: 0:46:10  iter: 1259  total_loss: 0.902  loss_cls: 0.250  loss_box_reg: 0.308  loss_mask: 0.203  loss_rpn_cls: 0.032  loss_rpn_loc: 0.119  time: 3.6884  data_time: 2.6646  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:52:32 d2.utils.events]: \u001b[0m eta: 0:44:56  iter: 1279  total_loss: 0.873  loss_cls: 0.223  loss_box_reg: 0.316  loss_mask: 0.197  loss_rpn_cls: 0.028  loss_rpn_loc: 0.120  time: 3.6896  data_time: 2.6731  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:53:47 d2.utils.events]: \u001b[0m eta: 0:43:45  iter: 1299  total_loss: 0.855  loss_cls: 0.212  loss_box_reg: 0.281  loss_mask: 0.191  loss_rpn_cls: 0.027  loss_rpn_loc: 0.121  time: 3.6909  data_time: 2.6812  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:55:02 d2.utils.events]: \u001b[0m eta: 0:42:31  iter: 1319  total_loss: 0.844  loss_cls: 0.225  loss_box_reg: 0.294  loss_mask: 0.193  loss_rpn_cls: 0.029  loss_rpn_loc: 0.112  time: 3.6917  data_time: 2.6683  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:56:15 d2.utils.events]: \u001b[0m eta: 0:41:16  iter: 1339  total_loss: 0.783  loss_cls: 0.200  loss_box_reg: 0.268  loss_mask: 0.190  loss_rpn_cls: 0.030  loss_rpn_loc: 0.120  time: 3.6909  data_time: 2.5408  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:57:28 d2.utils.events]: \u001b[0m eta: 0:40:01  iter: 1359  total_loss: 0.860  loss_cls: 0.223  loss_box_reg: 0.283  loss_mask: 0.201  loss_rpn_cls: 0.028  loss_rpn_loc: 0.120  time: 3.6906  data_time: 2.5947  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:58:42 d2.utils.events]: \u001b[0m eta: 0:38:46  iter: 1379  total_loss: 0.892  loss_cls: 0.220  loss_box_reg: 0.307  loss_mask: 0.198  loss_rpn_cls: 0.028  loss_rpn_loc: 0.120  time: 3.6903  data_time: 2.5547  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:00:08 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:00:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 17:00:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 17:00:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1896 s / img. ETA=0:01:56\n",
            "\u001b[32m[07/10 17:00:43 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.1828 s / img. ETA=0:01:41\n",
            "\u001b[32m[07/10 17:00:49 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1389 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/10 17:00:55 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1212 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/10 17:01:00 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.1160 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 17:01:06 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1146 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 17:01:12 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1146 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 17:01:19 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1171 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 17:01:26 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1215 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 17:01:32 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1270 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 17:01:38 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1305 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 17:01:44 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.1332 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 17:01:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:22.089747 (1.578649 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:01:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.133217 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:01:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:01:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:01:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.39s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.626\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.927\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.767\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.678\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.716\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            "\u001b[32m[07/10 17:01:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 62.646 | 92.653 | 76.678 |  nan  |  nan  | 62.646 |\n",
            "\u001b[32m[07/10 17:01:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:01:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 64.301 | brec_Cht         | 67.615 | lam_Sltst  | 56.204 |\n",
            "| skel_WkstPkst | 56.021 | strless_SltstSst | 69.090 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.53s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.916\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.780\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.701\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.738\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 64.574 | 91.619 | 77.978 |  nan  |  nan  | 64.574 |\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 66.901 | brec_Cht         | 72.909 | lam_Sltst  | 53.097 |\n",
            "| skel_WkstPkst | 59.442 | strless_SltstSst | 70.522 |            |        |\n",
            "\u001b[32m[07/10 17:01:46 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.testing]: \u001b[0mcopypaste: 62.6462,92.6528,76.6779,nan,nan,62.6462\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.testing]: \u001b[0mcopypaste: 64.5741,91.6193,77.9777,nan,nan,64.5741\n",
            "\u001b[32m[07/10 17:01:49 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:01:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 17:01:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 17:02:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.0962 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.824958 (1.202773 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.109601 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.118\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.268\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.077\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.051\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.814 | 26.788 | 7.663  |  nan  |  nan  | 11.814 |\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.791 | brec_Cht         | nan    | lam_Sltst  | 3.950 |\n",
            "| skel_WkstPkst | 1.683  | strless_SltstSst | 16.830 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.130\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.055\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.396\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 12.965 | 26.043 | 10.269 |  nan  |  nan  | 12.965 |\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 28.808 | brec_Cht         | nan    | lam_Sltst  | 3.471 |\n",
            "| skel_WkstPkst | 2.946  | strless_SltstSst | 16.637 |            |       |\n",
            "\u001b[32m[07/10 17:02:09 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.testing]: \u001b[0mcopypaste: 11.8137,26.7882,7.6628,nan,nan,11.8137\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.testing]: \u001b[0mcopypaste: 12.9652,26.0434,10.2685,nan,nan,12.9652\n",
            "\u001b[32m[07/10 17:02:09 d2.utils.events]: \u001b[0m eta: 0:37:32  iter: 1399  total_loss: 0.825  loss_cls: 0.221  loss_box_reg: 0.285  loss_mask: 0.186  loss_rpn_cls: 0.027  loss_rpn_loc: 0.123  time: 3.6899  data_time: 2.5528  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:03:23 d2.utils.events]: \u001b[0m eta: 0:36:17  iter: 1419  total_loss: 0.840  loss_cls: 0.226  loss_box_reg: 0.303  loss_mask: 0.191  loss_rpn_cls: 0.031  loss_rpn_loc: 0.122  time: 3.6899  data_time: 2.5959  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:04:38 d2.utils.events]: \u001b[0m eta: 0:35:03  iter: 1439  total_loss: 0.809  loss_cls: 0.208  loss_box_reg: 0.277  loss_mask: 0.183  loss_rpn_cls: 0.026  loss_rpn_loc: 0.115  time: 3.6906  data_time: 2.6340  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:05:53 d2.utils.events]: \u001b[0m eta: 0:33:50  iter: 1459  total_loss: 0.745  loss_cls: 0.178  loss_box_reg: 0.245  loss_mask: 0.177  loss_rpn_cls: 0.029  loss_rpn_loc: 0.120  time: 3.6910  data_time: 2.6080  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:07:07 d2.utils.events]: \u001b[0m eta: 0:32:38  iter: 1479  total_loss: 0.769  loss_cls: 0.193  loss_box_reg: 0.255  loss_mask: 0.183  loss_rpn_cls: 0.023  loss_rpn_loc: 0.117  time: 3.6913  data_time: 2.6217  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:08:21 d2.utils.events]: \u001b[0m eta: 0:31:23  iter: 1499  total_loss: 0.785  loss_cls: 0.184  loss_box_reg: 0.269  loss_mask: 0.179  loss_rpn_cls: 0.025  loss_rpn_loc: 0.123  time: 3.6913  data_time: 2.6219  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:09:35 d2.utils.events]: \u001b[0m eta: 0:30:07  iter: 1519  total_loss: 0.760  loss_cls: 0.165  loss_box_reg: 0.258  loss_mask: 0.178  loss_rpn_cls: 0.025  loss_rpn_loc: 0.116  time: 3.6919  data_time: 2.6234  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:10:50 d2.utils.events]: \u001b[0m eta: 0:28:50  iter: 1539  total_loss: 0.776  loss_cls: 0.206  loss_box_reg: 0.259  loss_mask: 0.177  loss_rpn_cls: 0.024  loss_rpn_loc: 0.113  time: 3.6924  data_time: 2.6500  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:12:04 d2.utils.events]: \u001b[0m eta: 0:27:35  iter: 1559  total_loss: 0.806  loss_cls: 0.201  loss_box_reg: 0.275  loss_mask: 0.183  loss_rpn_cls: 0.022  loss_rpn_loc: 0.111  time: 3.6927  data_time: 2.6039  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:13:20 d2.utils.events]: \u001b[0m eta: 0:26:20  iter: 1579  total_loss: 0.741  loss_cls: 0.186  loss_box_reg: 0.255  loss_mask: 0.172  loss_rpn_cls: 0.026  loss_rpn_loc: 0.108  time: 3.6937  data_time: 2.6769  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:14:52 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:14:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 17:14:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 17:15:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2188 s / img. ETA=0:02:15\n",
            "\u001b[32m[07/10 17:15:33 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2083 s / img. ETA=0:01:56\n",
            "\u001b[32m[07/10 17:15:39 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1694 s / img. ETA=0:01:20\n",
            "\u001b[32m[07/10 17:15:44 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.1558 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/10 17:15:50 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1441 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/10 17:15:56 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.1373 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/10 17:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1356 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/10 17:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1339 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 17:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1344 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 17:16:19 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1376 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/10 17:16:24 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1405 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 17:16:31 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1455 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 17:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1500 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 17:16:44 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1537 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:38.612141 (1.896387 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.153985 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.42s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.952\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.773\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.698\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.725\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 63.293 | 95.195 | 77.325 |  nan  |  nan  | 63.293 |\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 66.134 | brec_Cht         | 76.482 | lam_Sltst  | 53.617 |\n",
            "| skel_WkstPkst | 56.671 | strless_SltstSst | 63.561 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.10s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.64s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.946\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.771\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.706\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 64.285 | 94.649 | 77.062 |  nan  |  nan  | 64.285 |\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 68.559 | brec_Cht         | 78.512 | lam_Sltst  | 49.672 |\n",
            "| skel_WkstPkst | 60.185 | strless_SltstSst | 64.498 |            |        |\n",
            "\u001b[32m[07/10 17:16:49 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: 63.2930,95.1953,77.3247,nan,nan,63.2930\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: 64.2854,94.6490,77.0623,nan,nan,64.2854\n",
            "\u001b[32m[07/10 17:16:52 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:16:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 17:16:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 17:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1127 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1324 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.033471 (1.559275 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.132446 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.101\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.222\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.101\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.241\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.066 | 22.228 | 8.238  |  nan  |  nan  | 10.066 |\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.776 | brec_Cht         | nan    | lam_Sltst  | 3.872 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 14.614 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.236\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.324\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.800 | 23.614 | 10.009 |  nan  |  nan  | 10.800 |\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.758 | brec_Cht         | nan    | lam_Sltst  | 4.738 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 13.704 |            |       |\n",
            "\u001b[32m[07/10 17:17:19 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: 10.0656,22.2279,8.2382,nan,nan,10.0656\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: 10.7999,23.6140,10.0095,nan,nan,10.7999\n",
            "\u001b[32m[07/10 17:17:19 d2.utils.events]: \u001b[0m eta: 0:25:05  iter: 1599  total_loss: 0.710  loss_cls: 0.180  loss_box_reg: 0.240  loss_mask: 0.178  loss_rpn_cls: 0.022  loss_rpn_loc: 0.102  time: 3.6961  data_time: 2.8009  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:18:33 d2.utils.events]: \u001b[0m eta: 0:23:49  iter: 1619  total_loss: 0.710  loss_cls: 0.171  loss_box_reg: 0.247  loss_mask: 0.175  loss_rpn_cls: 0.023  loss_rpn_loc: 0.103  time: 3.6962  data_time: 2.5839  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:19:50 d2.utils.events]: \u001b[0m eta: 0:22:34  iter: 1639  total_loss: 0.711  loss_cls: 0.168  loss_box_reg: 0.234  loss_mask: 0.171  loss_rpn_cls: 0.022  loss_rpn_loc: 0.113  time: 3.6977  data_time: 2.7203  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:21:05 d2.utils.events]: \u001b[0m eta: 0:21:20  iter: 1659  total_loss: 0.770  loss_cls: 0.185  loss_box_reg: 0.251  loss_mask: 0.174  loss_rpn_cls: 0.022  loss_rpn_loc: 0.117  time: 3.6987  data_time: 2.6671  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:22:21 d2.utils.events]: \u001b[0m eta: 0:20:06  iter: 1679  total_loss: 0.753  loss_cls: 0.180  loss_box_reg: 0.256  loss_mask: 0.180  loss_rpn_cls: 0.022  loss_rpn_loc: 0.107  time: 3.6996  data_time: 2.6633  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:23:36 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 1699  total_loss: 0.738  loss_cls: 0.157  loss_box_reg: 0.242  loss_mask: 0.174  loss_rpn_cls: 0.023  loss_rpn_loc: 0.118  time: 3.7002  data_time: 2.6773  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:24:52 d2.utils.events]: \u001b[0m eta: 0:17:35  iter: 1719  total_loss: 0.733  loss_cls: 0.178  loss_box_reg: 0.252  loss_mask: 0.171  loss_rpn_cls: 0.022  loss_rpn_loc: 0.121  time: 3.7013  data_time: 2.6940  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:26:07 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 1739  total_loss: 0.753  loss_cls: 0.185  loss_box_reg: 0.256  loss_mask: 0.168  loss_rpn_cls: 0.022  loss_rpn_loc: 0.110  time: 3.7022  data_time: 2.6535  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:27:23 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 1759  total_loss: 0.704  loss_cls: 0.164  loss_box_reg: 0.254  loss_mask: 0.163  loss_rpn_cls: 0.022  loss_rpn_loc: 0.111  time: 3.7031  data_time: 2.6633  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:28:39 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 1779  total_loss: 0.687  loss_cls: 0.160  loss_box_reg: 0.240  loss_mask: 0.163  loss_rpn_cls: 0.021  loss_rpn_loc: 0.104  time: 3.7042  data_time: 2.7006  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:30:08 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:30:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 17:30:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 17:30:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1859 s / img. ETA=0:01:47\n",
            "\u001b[32m[07/10 17:30:41 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.1815 s / img. ETA=0:01:34\n",
            "\u001b[32m[07/10 17:30:47 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1379 s / img. ETA=0:00:56\n",
            "\u001b[32m[07/10 17:30:52 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1211 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/10 17:30:57 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1138 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 17:31:02 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1105 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 17:31:07 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1094 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 17:31:13 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1131 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 17:31:19 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1179 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 17:31:25 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1233 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 17:31:31 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1270 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.1293 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.982140 (1.441964 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.129350 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.34s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.737\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.974\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.888\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.737\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.802\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 73.720 | 97.376 | 88.766 |  nan  |  nan  | 73.720 |\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 73.661 | brec_Cht         | 72.796 | lam_Sltst  | 73.416 |\n",
            "| skel_WkstPkst | 69.459 | strless_SltstSst | 79.271 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.48s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.971\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.896\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.784\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.805\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 74.317 | 97.065 | 89.610 |  nan  |  nan  | 74.317 |\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 75.937 | brec_Cht         | 78.756 | lam_Sltst  | 68.397 |\n",
            "| skel_WkstPkst | 68.786 | strless_SltstSst | 79.709 |            |        |\n",
            "\u001b[32m[07/10 17:31:38 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: 73.7204,97.3757,88.7660,nan,nan,73.7204\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: 74.3170,97.0654,89.6098,nan,nan,74.3170\n",
            "\u001b[32m[07/10 17:31:41 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:31:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 17:31:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 17:31:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.0925 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.771365 (1.196818 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.111036 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.142\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.055\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.413\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.459\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.118 | 27.872 | 14.245 |  nan  |  nan  | 14.118 |\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 19.842 | brec_Cht         | nan    | lam_Sltst  | 3.225 |\n",
            "| skel_WkstPkst | 16.700 | strless_SltstSst | 16.705 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.145\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.895 | 27.654 | 14.528 |  nan  |  nan  | 15.895 |\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.954 | brec_Cht         | nan    | lam_Sltst  | 2.917 |\n",
            "| skel_WkstPkst | 21.262 | strless_SltstSst | 15.446 |            |       |\n",
            "\u001b[32m[07/10 17:32:02 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.testing]: \u001b[0mcopypaste: 14.1178,27.8719,14.2451,nan,nan,14.1178\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.testing]: \u001b[0mcopypaste: 15.8948,27.6536,14.5278,nan,nan,15.8948\n",
            "\u001b[32m[07/10 17:32:02 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 1799  total_loss: 0.684  loss_cls: 0.154  loss_box_reg: 0.231  loss_mask: 0.159  loss_rpn_cls: 0.020  loss_rpn_loc: 0.096  time: 3.7050  data_time: 2.6629  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:33:16 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 1819  total_loss: 0.634  loss_cls: 0.139  loss_box_reg: 0.212  loss_mask: 0.158  loss_rpn_cls: 0.020  loss_rpn_loc: 0.105  time: 3.7050  data_time: 2.5886  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:34:31 d2.utils.events]: \u001b[0m eta: 0:10:04  iter: 1839  total_loss: 0.653  loss_cls: 0.146  loss_box_reg: 0.232  loss_mask: 0.161  loss_rpn_cls: 0.019  loss_rpn_loc: 0.092  time: 3.7053  data_time: 2.6267  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:35:46 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 1859  total_loss: 0.631  loss_cls: 0.142  loss_box_reg: 0.218  loss_mask: 0.157  loss_rpn_cls: 0.017  loss_rpn_loc: 0.105  time: 3.7062  data_time: 2.6943  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:37:02 d2.utils.events]: \u001b[0m eta: 0:07:34  iter: 1879  total_loss: 0.631  loss_cls: 0.141  loss_box_reg: 0.216  loss_mask: 0.160  loss_rpn_cls: 0.021  loss_rpn_loc: 0.097  time: 3.7071  data_time: 2.7001  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:38:18 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 1899  total_loss: 0.645  loss_cls: 0.146  loss_box_reg: 0.217  loss_mask: 0.156  loss_rpn_cls: 0.020  loss_rpn_loc: 0.096  time: 3.7081  data_time: 2.6941  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:39:34 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 1919  total_loss: 0.597  loss_cls: 0.129  loss_box_reg: 0.204  loss_mask: 0.154  loss_rpn_cls: 0.019  loss_rpn_loc: 0.091  time: 3.7086  data_time: 2.6520  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:40:49 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 1939  total_loss: 0.602  loss_cls: 0.128  loss_box_reg: 0.200  loss_mask: 0.148  loss_rpn_cls: 0.018  loss_rpn_loc: 0.099  time: 3.7094  data_time: 2.6719  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:42:05 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 1959  total_loss: 0.614  loss_cls: 0.136  loss_box_reg: 0.211  loss_mask: 0.151  loss_rpn_cls: 0.018  loss_rpn_loc: 0.099  time: 3.7100  data_time: 2.6710  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:43:19 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1979  total_loss: 0.585  loss_cls: 0.120  loss_box_reg: 0.201  loss_mask: 0.153  loss_rpn_cls: 0.017  loss_rpn_loc: 0.098  time: 3.7103  data_time: 2.6468  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:44:51 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:44:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 17:44:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 17:45:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1738 s / img. ETA=0:01:41\n",
            "\u001b[32m[07/10 17:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.1570 s / img. ETA=0:01:19\n",
            "\u001b[32m[07/10 17:45:28 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1257 s / img. ETA=0:00:50\n",
            "\u001b[32m[07/10 17:45:33 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.1117 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/10 17:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1080 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 17:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1055 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 17:45:51 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1066 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 17:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1104 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 17:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1172 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 17:46:10 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1212 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 17:46:16 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1247 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 17:46:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:15.107944 (1.444384 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:46:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.124919 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:46:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:46:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:46:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.34s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.724\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.987\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.895\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.753\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.779\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 72.363 | 98.679 | 89.455 |  nan  |  nan  | 72.363 |\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 76.078 | brec_Cht         | 77.222 | lam_Sltst  | 69.865 |\n",
            "| skel_WkstPkst | 69.567 | strless_SltstSst | 69.084 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.57s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.754\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.986\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.904\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.778\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.804\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.804\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 75.401 | 98.611 | 90.419 |  nan  |  nan  | 75.401 |\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 80.205 | brec_Cht         | 81.026 | lam_Sltst  | 69.724 |\n",
            "| skel_WkstPkst | 66.041 | strless_SltstSst | 80.009 |            |        |\n",
            "\u001b[32m[07/10 17:46:19 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.testing]: \u001b[0mcopypaste: 72.3632,98.6786,89.4548,nan,nan,72.3632\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.testing]: \u001b[0mcopypaste: 75.4008,98.6106,90.4191,nan,nan,75.4008\n",
            "\u001b[32m[07/10 17:46:22 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:46:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 17:46:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 17:46:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.0905 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.456082 (1.161787 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.107765 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.695 | 28.341 | 11.098 |  nan  |  nan  | 13.695 |\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.221 | brec_Cht         | nan    | lam_Sltst  | 6.764 |\n",
            "| skel_WkstPkst | 12.233 | strless_SltstSst | 14.562 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.931 | 28.019 | 17.477 |  nan  |  nan  | 15.931 |\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.156 | brec_Cht         | nan    | lam_Sltst  | 7.729 |\n",
            "| skel_WkstPkst | 15.556 | strless_SltstSst | 16.282 |            |       |\n",
            "\u001b[32m[07/10 17:46:44 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: 13.6951,28.3412,11.0983,nan,nan,13.6951\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: 15.9308,28.0195,17.4770,nan,nan,15.9308\n",
            "\u001b[32m[07/10 17:46:44 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 1999  total_loss: 0.649  loss_cls: 0.135  loss_box_reg: 0.223  loss_mask: 0.166  loss_rpn_cls: 0.017  loss_rpn_loc: 0.104  time: 3.7114  data_time: 2.7297  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:46:44 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 2:03:35 (3.7133 s / it)\n",
            "\u001b[32m[07/10 17:46:44 d2.engine.hooks]: \u001b[0mTotal training time: 2:34:02 (0:30:26 on hooks)\n",
            "\n",
            "\n",
            "**Starting train eval**\n",
            "\u001b[32m[07/10 17:46:57 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:46:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 17:46:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 17:47:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1731 s / img. ETA=0:03:14\n",
            "\u001b[32m[07/10 17:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.1634 s / img. ETA=0:02:49\n",
            "\u001b[32m[07/10 17:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.1570 s / img. ETA=0:02:31\n",
            "\u001b[32m[07/10 17:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1249 s / img. ETA=0:01:24\n",
            "\u001b[32m[07/10 17:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.1113 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/10 17:48:11 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1073 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/10 17:48:16 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1049 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/10 17:48:23 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1061 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 17:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1090 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/10 17:48:39 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1119 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 17:48:44 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1145 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 17:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1171 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/10 17:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1192 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 17:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1210 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 17:49:08 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1228 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 17:49:13 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1245 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 17:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.1247 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:59.959707 (2.306917 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.124741 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.32s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.724\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.987\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.895\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.753\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.779\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 72.363 | 98.679 | 89.455 |  nan  |  nan  | 72.363 |\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 76.078 | brec_Cht         | 77.222 | lam_Sltst  | 69.865 |\n",
            "| skel_WkstPkst | 69.567 | strless_SltstSst | 69.084 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.47s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.754\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.986\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.904\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.778\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.804\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.804\n",
            "\u001b[32m[07/10 17:49:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 75.401 | 98.611 | 90.419 |  nan  |  nan  | 75.401 |\n",
            "\u001b[32m[07/10 17:49:20 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:49:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 80.205 | brec_Cht         | 81.026 | lam_Sltst  | 69.724 |\n",
            "| skel_WkstPkst | 66.041 | strless_SltstSst | 80.009 |            |        |\n",
            "randomly selected cores/Box 7 Depths 10025-35.JPG\n",
            "\n",
            "\n",
            "**Starting val eval**\n",
            "\u001b[32m[07/10 17:50:07 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:50:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 17:50:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 17:50:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.0914 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1082 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.485729 (2.053970 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.108231 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.695 | 28.341 | 11.098 |  nan  |  nan  | 13.695 |\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.221 | brec_Cht         | nan    | lam_Sltst  | 6.764 |\n",
            "| skel_WkstPkst | 12.233 | strless_SltstSst | 14.562 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.931 | 28.019 | 17.477 |  nan  |  nan  | 15.931 |\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.156 | brec_Cht         | nan    | lam_Sltst  | 7.729 |\n",
            "| skel_WkstPkst | 15.556 | strless_SltstSst | 16.282 |            |       |\n",
            "randomly selected cores/Boxes 43-45  Depths 7838.8-7847.4 (Dry).JPG\n",
            "  adding: output_fold_1/ (stored 0%)\n",
            "  adding: output_fold_1/training_log.txt (deflated 88%)\n",
            "  adding: output_fold_1/metrics.json (deflated 77%)\n",
            "  adding: output_fold_1/cores_fold_1_val_cores-Boxes 76-78  Depths 7929.1-7938.7 (Dry).JPG.pdf (deflated 0%)\n",
            "  adding: output_fold_1/events.out.tfevents.1594384404.fce45445a1b1.318.0 (deflated 72%)\n",
            "  adding: output_fold_1/model_final.pth (deflated 7%)\n",
            "  adding: output_fold_1/cocoeval_val_1.json (deflated 55%)\n",
            "  adding: output_fold_1/cores_fold_1_train_cores-Box 7 Depths 10025-35.JPG.pdf (deflated 0%)\n",
            "  adding: output_fold_1/last_checkpoint (stored 0%)\n",
            "  adding: output_fold_1/cocoeval_train_1.json (deflated 55%)\n",
            "  adding: output_fold_2/ (stored 0%)\n",
            "  adding: output_fold_2/training_log.txt (deflated 88%)\n",
            "  adding: output_fold_2/metrics.json (deflated 77%)\n",
            "  adding: output_fold_2/events.out.tfevents.1594393953.fce45445a1b1.544.0 (deflated 72%)\n",
            "  adding: output_fold_2/cores_fold_2_val_cores-Boxes 43-45  Depths 7838.8-7847.4 (Dry).JPG.pdf (deflated 0%)\n",
            "  adding: output_fold_2/cores_fold_2_train_cores-Box 7 Depths 10025-35.JPG.pdf (deflated 0%)\n",
            "  adding: output_fold_2/cocoeval_train_2.json (deflated 55%)\n",
            "  adding: output_fold_2/model_final.pth (deflated 7%)\n",
            "  adding: output_fold_2/cocoeval_val_2.json (deflated 56%)\n",
            "  adding: output_fold_2/last_checkpoint (stored 0%)\n",
            "cp: cannot create regular file 'gdrive/My Drive': No such file or directory\n",
            "Fri Jul 10 17:52:04 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "CPU times: user 17.8 s, sys: 2.33 s, total: 20.1 s\n",
            "Wall time: 2h 39min 52s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY-P57y_Lcnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0b8b246-07e4-481b-9429-88250075188b"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '3' --max_iter 2000\n",
        "# copy results to Google Drive\n",
        "! cp -r output_fold_3 'drive/My Drive/R50-C4'\n",
        "# clean folders if upcoming experiment\n",
        "! rm -r *coco*\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 3\n",
            "\t cores_fold_3_train\n",
            "\t cores_fold_3_val\n",
            "\u001b[32m[07/10 17:57:45 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/10 17:57:57 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 56 images left.\n",
            "\u001b[32m[07/10 17:57:57 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 243          |   brec_Cht    | 21           | lam_Sltst  | 102          |\n",
            "| skel_WkstPkst | 20           | strless_Slt.. | 157          |            |              |\n",
            "|     total     | 543          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/10 17:57:57 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:57:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 17:57:57 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/10 17:57:57 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-10 17:57:58.006528: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Unable to load 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (15, 4) in the checkpoint but (3, 4) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (1024, 1024, 3, 3) in the checkpoint but (256, 256, 3, 3) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (256,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (15, 1024, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (15,) in the checkpoint but (3,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (60, 1024, 1, 1) in the checkpoint but (12, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (60,) in the checkpoint but (12,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.deconv.weight' to the model due to incompatible shapes: (2048, 256, 2, 2) in the checkpoint but (256, 256, 2, 2) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/10 17:57:59 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/10 17:59:11 d2.utils.events]: \u001b[0m eta: 1:57:36  iter: 19  total_loss: 44.474  loss_cls: 32.996  loss_box_reg: 1.455  loss_mask: 1.134  loss_rpn_cls: 0.716  loss_rpn_loc: 6.482  time: 3.5779  data_time: 2.7952  lr: 0.000020  max_mem: 6784M\n",
            "\u001b[32m[07/10 18:00:24 d2.utils.events]: \u001b[0m eta: 1:56:50  iter: 39  total_loss: 9.006  loss_cls: 6.956  loss_box_reg: 0.289  loss_mask: 0.591  loss_rpn_cls: 0.324  loss_rpn_loc: 0.856  time: 3.5993  data_time: 2.7293  lr: 0.000040  max_mem: 7056M\n",
            "\u001b[32m[07/10 18:01:35 d2.utils.events]: \u001b[0m eta: 1:55:10  iter: 59  total_loss: 2.911  loss_cls: 1.369  loss_box_reg: 0.296  loss_mask: 0.571  loss_rpn_cls: 0.236  loss_rpn_loc: 0.420  time: 3.5908  data_time: 2.6299  lr: 0.000060  max_mem: 7068M\n",
            "\u001b[32m[07/10 18:02:50 d2.utils.events]: \u001b[0m eta: 1:54:27  iter: 79  total_loss: 2.105  loss_cls: 0.716  loss_box_reg: 0.327  loss_mask: 0.549  loss_rpn_cls: 0.204  loss_rpn_loc: 0.310  time: 3.6261  data_time: 2.7726  lr: 0.000080  max_mem: 7068M\n",
            "\u001b[32m[07/10 18:04:04 d2.utils.events]: \u001b[0m eta: 1:54:24  iter: 99  total_loss: 1.774  loss_cls: 0.426  loss_box_reg: 0.334  loss_mask: 0.540  loss_rpn_cls: 0.187  loss_rpn_loc: 0.277  time: 3.6407  data_time: 2.7572  lr: 0.000100  max_mem: 7269M\n",
            "\u001b[32m[07/10 18:05:18 d2.utils.events]: \u001b[0m eta: 1:54:29  iter: 119  total_loss: 1.742  loss_cls: 0.387  loss_box_reg: 0.399  loss_mask: 0.525  loss_rpn_cls: 0.176  loss_rpn_loc: 0.252  time: 3.6532  data_time: 2.7279  lr: 0.000120  max_mem: 7467M\n",
            "\u001b[32m[07/10 18:06:33 d2.utils.events]: \u001b[0m eta: 1:53:27  iter: 139  total_loss: 1.701  loss_cls: 0.357  loss_box_reg: 0.392  loss_mask: 0.520  loss_rpn_cls: 0.172  loss_rpn_loc: 0.242  time: 3.6630  data_time: 2.7319  lr: 0.000140  max_mem: 7814M\n",
            "\u001b[32m[07/10 18:07:47 d2.utils.events]: \u001b[0m eta: 1:52:14  iter: 159  total_loss: 1.620  loss_cls: 0.355  loss_box_reg: 0.384  loss_mask: 0.500  loss_rpn_cls: 0.157  loss_rpn_loc: 0.225  time: 3.6707  data_time: 2.7188  lr: 0.000160  max_mem: 7814M\n",
            "\u001b[32m[07/10 18:09:02 d2.utils.events]: \u001b[0m eta: 1:51:43  iter: 179  total_loss: 1.660  loss_cls: 0.381  loss_box_reg: 0.416  loss_mask: 0.488  loss_rpn_cls: 0.154  loss_rpn_loc: 0.210  time: 3.6806  data_time: 2.7800  lr: 0.000180  max_mem: 7814M\n",
            "\u001b[32m[07/10 18:10:30 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 18:10:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 18:10:30 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_3_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/10 18:10:30 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_3_train' to COCO format ...)\n",
            "\u001b[32m[07/10 18:10:43 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/10 18:10:43 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 57, #annotations: 543\n",
            "\u001b[32m[07/10 18:10:43 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_3_train_coco_format.json' ...\n",
            "\u001b[32m[07/10 18:10:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0x90910000 @  0x7fb8f36ddb6b 0x7fb8f36fd379 0x7fb896e3204e 0x7fb896e33f4a 0x7fb8cfd2267b 0x7fb8cf9716be 0x7fb8cfbda7b5 0x7fb8cfbcc7c1 0x7fb8cfbcbd0e 0x7fb8cfbcc7c1 0x7fb8d162193a 0x7fb8cfbcc7c1 0x7fb8cf96c457 0x7fb8cf96d080 0x7fb8cfc8b71a 0x7fb8d170913e 0x7fb8cfbccc72 0x7fb8ddc66a68 0x7fb8ddd21b04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/10 18:11:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2701 s / img. ETA=0:02:47\n",
            "\u001b[32m[07/10 18:11:33 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.3174 s / img. ETA=0:02:39\n",
            "\u001b[32m[07/10 18:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.3046 s / img. ETA=0:02:42\n",
            "\u001b[32m[07/10 18:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2943 s / img. ETA=0:02:44\n",
            "\u001b[32m[07/10 18:11:48 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.2859 s / img. ETA=0:02:44\n",
            "\u001b[32m[07/10 18:11:58 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.2729 s / img. ETA=0:02:42\n",
            "\u001b[32m[07/10 18:12:03 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2678 s / img. ETA=0:02:40\n",
            "\u001b[32m[07/10 18:12:13 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.2595 s / img. ETA=0:02:35\n",
            "\u001b[32m[07/10 18:12:18 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.2562 s / img. ETA=0:02:32\n",
            "\u001b[32m[07/10 18:12:23 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2538 s / img. ETA=0:02:29\n",
            "\u001b[32m[07/10 18:12:28 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.2511 s / img. ETA=0:02:26\n",
            "\u001b[32m[07/10 18:12:33 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2486 s / img. ETA=0:02:23\n",
            "\u001b[32m[07/10 18:12:38 d2.evaluation.evaluator]: \u001b[0mInference done 26/57. 0.2464 s / img. ETA=0:02:19\n",
            "\u001b[32m[07/10 18:12:44 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.2443 s / img. ETA=0:02:16\n",
            "\u001b[32m[07/10 18:12:49 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.2425 s / img. ETA=0:02:12\n",
            "\u001b[32m[07/10 18:12:54 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.2408 s / img. ETA=0:02:08\n",
            "\u001b[32m[07/10 18:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 30/57. 0.2392 s / img. ETA=0:02:04\n",
            "\u001b[32m[07/10 18:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2378 s / img. ETA=0:02:00\n",
            "\u001b[32m[07/10 18:13:14 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.2353 s / img. ETA=0:01:51\n",
            "\u001b[32m[07/10 18:13:24 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.2329 s / img. ETA=0:01:42\n",
            "\u001b[32m[07/10 18:13:34 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.2308 s / img. ETA=0:01:33\n",
            "\u001b[32m[07/10 18:13:44 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.2289 s / img. ETA=0:01:24\n",
            "\u001b[32m[07/10 18:13:54 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.2277 s / img. ETA=0:01:15\n",
            "\u001b[32m[07/10 18:14:05 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.2242 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/10 18:14:13 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.2250 s / img. ETA=0:00:56\n",
            "\u001b[32m[07/10 18:14:20 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.2258 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/10 18:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.2271 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/10 18:14:32 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.2285 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 18:14:38 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.2298 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/10 18:14:44 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.2308 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 18:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.2315 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 18:14:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:48.375685 (4.391840 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 18:14:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.231822 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 18:14:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 18:14:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 18:14:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.71s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.127\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.022\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.114\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.168\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.168\n",
            "\u001b[32m[07/10 18:14:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.948 | 12.705 | 0.929  |  nan  |  nan  | 3.948 |\n",
            "\u001b[32m[07/10 18:14:53 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 18:14:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 6.883 | brec_Cht         | 1.520 | lam_Sltst  | 1.312 |\n",
            "| skel_WkstPkst | 1.960 | strless_SltstSst | 8.067 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.00s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.124\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.151\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.151\n",
            "\u001b[32m[07/10 18:14:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.532 | 12.383 | 0.756  |  nan  |  nan  | 3.532 |\n",
            "\u001b[32m[07/10 18:14:55 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 18:14:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 6.770 | brec_Cht         | 1.028 | lam_Sltst  | 1.114 |\n",
            "| skel_WkstPkst | 1.461 | strless_SltstSst | 7.289 |            |       |\n",
            "\u001b[32m[07/10 18:14:55 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 18:14:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 18:14:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 18:14:55 d2.evaluation.testing]: \u001b[0mcopypaste: 3.9484,12.7046,0.9293,nan,nan,3.9484\n",
            "\u001b[32m[07/10 18:14:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 18:14:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 18:14:55 d2.evaluation.testing]: \u001b[0mcopypaste: 3.5324,12.3830,0.7559,nan,nan,3.5324\n",
            "\u001b[32m[07/10 18:14:58 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 66           |   brec_Cht    | 0            | lam_Sltst  | 25           |\n",
            "| skel_WkstPkst | 6            | strless_Slt.. | 16           |            |              |\n",
            "|     total     | 113          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/10 18:14:58 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 18:14:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 18:14:58 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_3_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/10 18:14:58 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_3_val' to COCO format ...)\n",
            "\u001b[32m[07/10 18:15:01 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/10 18:15:01 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 14, #annotations: 113\n",
            "\u001b[32m[07/10 18:15:01 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_3_val_coco_format.json' ...\n",
            "\u001b[32m[07/10 18:15:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 18:15:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2017 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 18:15:45 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2149 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.231689 (3.025743 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.218779 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.040\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.121\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.096\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.992 | 12.082 | 1.469  |  nan  |  nan  | 3.992 |\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 7.118 | brec_Cht         | nan   | lam_Sltst  | 0.447 |\n",
            "| skel_WkstPkst | 0.572 | strless_SltstSst | 7.833 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.124\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.092\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.160\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.901 | 12.411 | 1.495  |  nan  |  nan  | 3.901 |\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 7.461 | brec_Cht         | nan   | lam_Sltst  | 0.551 |\n",
            "| skel_WkstPkst | 0.572 | strless_SltstSst | 7.022 |            |       |\n",
            "\u001b[32m[07/10 18:15:48 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.testing]: \u001b[0mcopypaste: 3.9924,12.0816,1.4690,nan,nan,3.9924\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 18:15:48 d2.evaluation.testing]: \u001b[0mcopypaste: 3.9014,12.4107,1.4947,nan,nan,3.9014\n",
            "\u001b[32m[07/10 18:15:48 d2.utils.events]: \u001b[0m eta: 1:51:09  iter: 199  total_loss: 1.639  loss_cls: 0.371  loss_box_reg: 0.426  loss_mask: 0.474  loss_rpn_cls: 0.147  loss_rpn_loc: 0.200  time: 3.6841  data_time: 2.7221  lr: 0.000200  max_mem: 7814M\n",
            "\u001b[32m[07/10 18:17:01 d2.utils.events]: \u001b[0m eta: 1:49:51  iter: 219  total_loss: 1.579  loss_cls: 0.387  loss_box_reg: 0.429  loss_mask: 0.447  loss_rpn_cls: 0.144  loss_rpn_loc: 0.198  time: 3.6796  data_time: 2.6427  lr: 0.000220  max_mem: 7814M\n",
            "\u001b[32m[07/10 18:18:14 d2.utils.events]: \u001b[0m eta: 1:48:03  iter: 239  total_loss: 1.614  loss_cls: 0.416  loss_box_reg: 0.448  loss_mask: 0.431  loss_rpn_cls: 0.132  loss_rpn_loc: 0.187  time: 3.6780  data_time: 2.6403  lr: 0.000240  max_mem: 8044M\n",
            "\u001b[32m[07/10 18:19:27 d2.utils.events]: \u001b[0m eta: 1:46:31  iter: 259  total_loss: 1.619  loss_cls: 0.453  loss_box_reg: 0.460  loss_mask: 0.406  loss_rpn_cls: 0.127  loss_rpn_loc: 0.186  time: 3.6736  data_time: 2.5903  lr: 0.000260  max_mem: 8109M\n",
            "\u001b[32m[07/10 18:20:40 d2.utils.events]: \u001b[0m eta: 1:45:08  iter: 279  total_loss: 1.634  loss_cls: 0.472  loss_box_reg: 0.459  loss_mask: 0.391  loss_rpn_cls: 0.123  loss_rpn_loc: 0.180  time: 3.6734  data_time: 2.6191  lr: 0.000280  max_mem: 8161M\n",
            "\u001b[32m[07/10 18:21:53 d2.utils.events]: \u001b[0m eta: 1:43:52  iter: 299  total_loss: 1.555  loss_cls: 0.455  loss_box_reg: 0.452  loss_mask: 0.371  loss_rpn_cls: 0.124  loss_rpn_loc: 0.181  time: 3.6703  data_time: 2.6075  lr: 0.000300  max_mem: 8282M\n",
            "\u001b[32m[07/10 18:23:04 d2.utils.events]: \u001b[0m eta: 1:42:10  iter: 319  total_loss: 1.565  loss_cls: 0.455  loss_box_reg: 0.461  loss_mask: 0.353  loss_rpn_cls: 0.113  loss_rpn_loc: 0.185  time: 3.6648  data_time: 2.5430  lr: 0.000320  max_mem: 8282M\n",
            "\u001b[32m[07/10 18:24:16 d2.utils.events]: \u001b[0m eta: 1:40:53  iter: 339  total_loss: 1.525  loss_cls: 0.442  loss_box_reg: 0.442  loss_mask: 0.340  loss_rpn_cls: 0.106  loss_rpn_loc: 0.182  time: 3.6600  data_time: 2.5630  lr: 0.000340  max_mem: 8371M\n",
            "\u001b[32m[07/10 18:25:26 d2.utils.events]: \u001b[0m eta: 1:39:32  iter: 359  total_loss: 1.493  loss_cls: 0.434  loss_box_reg: 0.425  loss_mask: 0.336  loss_rpn_cls: 0.102  loss_rpn_loc: 0.183  time: 3.6508  data_time: 2.4402  lr: 0.000360  max_mem: 8468M\n",
            "\u001b[32m[07/10 18:26:36 d2.utils.events]: \u001b[0m eta: 1:38:04  iter: 379  total_loss: 1.548  loss_cls: 0.458  loss_box_reg: 0.441  loss_mask: 0.321  loss_rpn_cls: 0.101  loss_rpn_loc: 0.188  time: 3.6435  data_time: 2.4841  lr: 0.000380  max_mem: 8468M\n",
            "\u001b[32m[07/10 18:27:59 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 18:27:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 18:27:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 18:28:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2865 s / img. ETA=0:02:02\n",
            "\u001b[32m[07/10 18:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2533 s / img. ETA=0:01:46\n",
            "\u001b[32m[07/10 18:28:43 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.2332 s / img. ETA=0:01:34\n",
            "\u001b[32m[07/10 18:28:49 d2.evaluation.evaluator]: \u001b[0mInference done 20/57. 0.2254 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/10 18:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2163 s / img. ETA=0:01:17\n",
            "\u001b[32m[07/10 18:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 26/57. 0.2102 s / img. ETA=0:01:08\n",
            "\u001b[32m[07/10 18:29:07 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.2048 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/10 18:29:12 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.2002 s / img. ETA=0:00:53\n",
            "\u001b[32m[07/10 18:29:19 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2002 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/10 18:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.2005 s / img. ETA=0:00:50\n",
            "\u001b[32m[07/10 18:29:38 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.2004 s / img. ETA=0:00:47\n",
            "\u001b[32m[07/10 18:29:45 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.2003 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/10 18:29:50 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1953 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/10 18:29:56 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1968 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/10 18:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.1974 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 18:30:08 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1988 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 18:30:15 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.2004 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 18:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.2017 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 18:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.2029 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/10 18:30:35 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.2039 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 18:30:41 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.2050 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/10 18:30:48 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.2059 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 18:30:54 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.2069 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 18:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.2080 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 18:31:07 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.2088 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 18:31:14 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.2096 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 18:31:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:02.436318 (3.508391 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 18:31:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.208406 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 18:31:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 18:31:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 18:31:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.57s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.076\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.366\n",
            "\u001b[32m[07/10 18:31:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.142 | 32.551 | 7.642  |  nan  |  nan  | 14.142 |\n",
            "\u001b[32m[07/10 18:31:18 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 18:31:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.887 | brec_Cht         | 13.571 | lam_Sltst  | 7.162 |\n",
            "| skel_WkstPkst | 8.607  | strless_SltstSst | 20.484 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.78s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.149\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.080\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.410\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410\n",
            "\u001b[32m[07/10 18:31:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 16.268 | 32.642 | 14.903 |  nan  |  nan  | 16.268 |\n",
            "\u001b[32m[07/10 18:31:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 18:31:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.639 | brec_Cht         | 18.317 | lam_Sltst  | 6.312 |\n",
            "| skel_WkstPkst | 12.669 | strless_SltstSst | 20.404 |            |       |\n",
            "\u001b[32m[07/10 18:31:19 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 18:31:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 18:31:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 18:31:19 d2.evaluation.testing]: \u001b[0mcopypaste: 14.1422,32.5506,7.6424,nan,nan,14.1422\n",
            "\u001b[32m[07/10 18:31:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 18:31:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 18:31:19 d2.evaluation.testing]: \u001b[0mcopypaste: 16.2683,32.6422,14.9034,nan,nan,16.2683\n",
            "\u001b[32m[07/10 18:31:22 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 18:31:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 18:31:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 18:31:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1840 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 18:31:55 d2.evaluation.evaluator]: \u001b[0mInference done 12/14. 0.1957 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 18:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2022 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 18:32:07 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.2060 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 18:32:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.444414 (3.716046 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 18:32:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.206021 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 18:32:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 18:32:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 18:32:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.230\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.107\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.227\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
            "\u001b[32m[07/10 18:32:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.667 | 22.980 | 10.745 |  nan  |  nan  | 10.667 |\n",
            "\u001b[32m[07/10 18:32:08 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 18:32:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 16.472 | brec_Cht         | nan    | lam_Sltst  | 0.829 |\n",
            "| skel_WkstPkst | 10.286 | strless_SltstSst | 15.081 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.118\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.241\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.259\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.329\n",
            "\u001b[32m[07/10 18:32:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.793 | 24.134 | 10.309 |  nan  |  nan  | 11.793 |\n",
            "\u001b[32m[07/10 18:32:08 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 18:32:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.089 | brec_Cht         | nan    | lam_Sltst  | 1.150 |\n",
            "| skel_WkstPkst | 12.343 | strless_SltstSst | 13.591 |            |       |\n",
            "\u001b[32m[07/10 18:32:08 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 18:32:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 18:32:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 18:32:08 d2.evaluation.testing]: \u001b[0mcopypaste: 10.6668,22.9800,10.7447,nan,nan,10.6668\n",
            "\u001b[32m[07/10 18:32:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 18:32:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 18:32:08 d2.evaluation.testing]: \u001b[0mcopypaste: 11.7935,24.1337,10.3085,nan,nan,11.7935\n",
            "\u001b[32m[07/10 18:32:08 d2.utils.events]: \u001b[0m eta: 1:36:38  iter: 399  total_loss: 1.428  loss_cls: 0.426  loss_box_reg: 0.407  loss_mask: 0.305  loss_rpn_cls: 0.102  loss_rpn_loc: 0.182  time: 3.6369  data_time: 2.4806  lr: 0.000400  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:33:18 d2.utils.events]: \u001b[0m eta: 1:35:19  iter: 419  total_loss: 1.435  loss_cls: 0.425  loss_box_reg: 0.434  loss_mask: 0.319  loss_rpn_cls: 0.100  loss_rpn_loc: 0.170  time: 3.6304  data_time: 2.4518  lr: 0.000420  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:34:28 d2.utils.events]: \u001b[0m eta: 1:33:54  iter: 439  total_loss: 1.450  loss_cls: 0.429  loss_box_reg: 0.431  loss_mask: 0.305  loss_rpn_cls: 0.098  loss_rpn_loc: 0.166  time: 3.6242  data_time: 2.4290  lr: 0.000440  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:35:38 d2.utils.events]: \u001b[0m eta: 1:32:38  iter: 459  total_loss: 1.455  loss_cls: 0.454  loss_box_reg: 0.432  loss_mask: 0.302  loss_rpn_cls: 0.091  loss_rpn_loc: 0.160  time: 3.6187  data_time: 2.4309  lr: 0.000460  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:36:48 d2.utils.events]: \u001b[0m eta: 1:31:25  iter: 479  total_loss: 1.406  loss_cls: 0.423  loss_box_reg: 0.417  loss_mask: 0.299  loss_rpn_cls: 0.089  loss_rpn_loc: 0.164  time: 3.6153  data_time: 2.4969  lr: 0.000480  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:37:59 d2.utils.events]: \u001b[0m eta: 1:30:13  iter: 499  total_loss: 1.401  loss_cls: 0.434  loss_box_reg: 0.421  loss_mask: 0.289  loss_rpn_cls: 0.085  loss_rpn_loc: 0.167  time: 3.6116  data_time: 2.4746  lr: 0.000500  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:39:10 d2.utils.events]: \u001b[0m eta: 1:29:00  iter: 519  total_loss: 1.368  loss_cls: 0.426  loss_box_reg: 0.404  loss_mask: 0.286  loss_rpn_cls: 0.085  loss_rpn_loc: 0.160  time: 3.6090  data_time: 2.5023  lr: 0.000519  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:40:20 d2.utils.events]: \u001b[0m eta: 1:27:46  iter: 539  total_loss: 1.393  loss_cls: 0.436  loss_box_reg: 0.410  loss_mask: 0.298  loss_rpn_cls: 0.082  loss_rpn_loc: 0.161  time: 3.6058  data_time: 2.4709  lr: 0.000539  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:41:30 d2.utils.events]: \u001b[0m eta: 1:26:31  iter: 559  total_loss: 1.373  loss_cls: 0.410  loss_box_reg: 0.420  loss_mask: 0.283  loss_rpn_cls: 0.078  loss_rpn_loc: 0.160  time: 3.6016  data_time: 2.4380  lr: 0.000559  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:42:40 d2.utils.events]: \u001b[0m eta: 1:25:14  iter: 579  total_loss: 1.302  loss_cls: 0.415  loss_box_reg: 0.384  loss_mask: 0.275  loss_rpn_cls: 0.073  loss_rpn_loc: 0.160  time: 3.5985  data_time: 2.4763  lr: 0.000579  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:44:02 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 18:44:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 18:44:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 18:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2339 s / img. ETA=0:02:09\n",
            "\u001b[32m[07/10 18:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2226 s / img. ETA=0:01:54\n",
            "\u001b[32m[07/10 18:44:49 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1989 s / img. ETA=0:01:32\n",
            "\u001b[32m[07/10 18:44:55 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1915 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/10 18:45:00 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.1879 s / img. ETA=0:01:12\n",
            "\u001b[32m[07/10 18:45:06 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.1841 s / img. ETA=0:01:04\n",
            "\u001b[32m[07/10 18:45:13 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1790 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/10 18:45:21 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1795 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/10 18:45:30 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.1799 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/10 18:45:38 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1805 s / img. ETA=0:00:46\n",
            "\u001b[32m[07/10 18:45:45 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1816 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/10 18:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1797 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 18:46:03 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.1814 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/10 18:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1832 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/10 18:46:16 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1853 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/10 18:46:22 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1869 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 18:46:29 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1884 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/10 18:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1898 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 18:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1911 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/10 18:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1924 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 18:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1937 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 18:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1951 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 18:47:06 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1962 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 18:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1972 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 18:47:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:56.985845 (3.403574 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 18:47:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.196148 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 18:47:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 18:47:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 18:47:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.55s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.486\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.154\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.222\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.064\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.392\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.469\n",
            "\u001b[32m[07/10 18:47:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 22.241 | 48.617 | 15.377 |  nan  |  nan  | 22.241 |\n",
            "\u001b[32m[07/10 18:47:16 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 18:47:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 30.513 | brec_Cht         | 22.826 | lam_Sltst  | 13.231 |\n",
            "| skel_WkstPkst | 17.654 | strless_SltstSst | 26.979 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.75s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.487\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.246\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.520\n",
            "\u001b[32m[07/10 18:47:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.477 | 48.682 | 24.580 |  nan  |  nan  | 25.477 |\n",
            "\u001b[32m[07/10 18:47:17 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 18:47:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 33.919 | brec_Cht         | 31.601 | lam_Sltst  | 14.018 |\n",
            "| skel_WkstPkst | 20.247 | strless_SltstSst | 27.601 |            |        |\n",
            "\u001b[32m[07/10 18:47:17 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 18:47:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 18:47:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 18:47:17 d2.evaluation.testing]: \u001b[0mcopypaste: 22.2406,48.6171,15.3769,nan,nan,22.2406\n",
            "\u001b[32m[07/10 18:47:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 18:47:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 18:47:17 d2.evaluation.testing]: \u001b[0mcopypaste: 25.4775,48.6820,24.5803,nan,nan,25.4775\n",
            "\u001b[32m[07/10 18:47:20 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 18:47:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 18:47:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 18:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1726 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 18:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 12/14. 0.1855 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 18:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1934 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 18:48:06 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1996 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 18:48:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.359928 (3.595548 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 18:48:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.199571 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 18:48:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 18:48:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 18:48:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.256\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.087\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.387\n",
            "\u001b[32m[07/10 18:48:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.213 | 25.555 | 8.729  |  nan  |  nan  | 10.213 |\n",
            "\u001b[32m[07/10 18:48:06 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 18:48:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 19.484 | brec_Cht         | nan    | lam_Sltst  | 1.556 |\n",
            "| skel_WkstPkst | 3.197  | strless_SltstSst | 16.616 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.118\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.217\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.118\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.427\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.427\n",
            "\u001b[32m[07/10 18:48:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.780 | 21.699 | 11.797 |  nan  |  nan  | 11.780 |\n",
            "\u001b[32m[07/10 18:48:07 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 18:48:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.532 | brec_Cht         | nan    | lam_Sltst  | 1.966 |\n",
            "| skel_WkstPkst | 3.396  | strless_SltstSst | 18.226 |            |       |\n",
            "\u001b[32m[07/10 18:48:07 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 18:48:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 18:48:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 18:48:07 d2.evaluation.testing]: \u001b[0mcopypaste: 10.2134,25.5551,8.7295,nan,nan,10.2134\n",
            "\u001b[32m[07/10 18:48:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 18:48:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 18:48:07 d2.evaluation.testing]: \u001b[0mcopypaste: 11.7801,21.6990,11.7968,nan,nan,11.7801\n",
            "\u001b[32m[07/10 18:48:07 d2.utils.events]: \u001b[0m eta: 1:23:57  iter: 599  total_loss: 1.315  loss_cls: 0.394  loss_box_reg: 0.402  loss_mask: 0.279  loss_rpn_cls: 0.073  loss_rpn_loc: 0.180  time: 3.5946  data_time: 2.4020  lr: 0.000599  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:49:16 d2.utils.events]: \u001b[0m eta: 1:22:36  iter: 619  total_loss: 1.328  loss_cls: 0.395  loss_box_reg: 0.379  loss_mask: 0.285  loss_rpn_cls: 0.077  loss_rpn_loc: 0.178  time: 3.5907  data_time: 2.4305  lr: 0.000619  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:50:26 d2.utils.events]: \u001b[0m eta: 1:21:19  iter: 639  total_loss: 1.274  loss_cls: 0.365  loss_box_reg: 0.402  loss_mask: 0.269  loss_rpn_cls: 0.067  loss_rpn_loc: 0.149  time: 3.5881  data_time: 2.4505  lr: 0.000639  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:51:37 d2.utils.events]: \u001b[0m eta: 1:20:05  iter: 659  total_loss: 1.316  loss_cls: 0.387  loss_box_reg: 0.433  loss_mask: 0.262  loss_rpn_cls: 0.069  loss_rpn_loc: 0.166  time: 3.5864  data_time: 2.4803  lr: 0.000659  max_mem: 8824M\n",
            "\u001b[32m[07/10 18:52:46 d2.utils.events]: \u001b[0m eta: 1:18:49  iter: 679  total_loss: 1.308  loss_cls: 0.400  loss_box_reg: 0.409  loss_mask: 0.271  loss_rpn_cls: 0.073  loss_rpn_loc: 0.153  time: 3.5830  data_time: 2.4063  lr: 0.000679  max_mem: 8879M\n",
            "\u001b[32m[07/10 18:53:57 d2.utils.events]: \u001b[0m eta: 1:17:37  iter: 699  total_loss: 1.270  loss_cls: 0.377  loss_box_reg: 0.376  loss_mask: 0.261  loss_rpn_cls: 0.066  loss_rpn_loc: 0.146  time: 3.5814  data_time: 2.4767  lr: 0.000699  max_mem: 8879M\n",
            "\u001b[32m[07/10 18:55:08 d2.utils.events]: \u001b[0m eta: 1:16:26  iter: 719  total_loss: 1.354  loss_cls: 0.407  loss_box_reg: 0.422  loss_mask: 0.269  loss_rpn_cls: 0.070  loss_rpn_loc: 0.161  time: 3.5802  data_time: 2.4968  lr: 0.000719  max_mem: 8879M\n",
            "\u001b[32m[07/10 18:56:19 d2.utils.events]: \u001b[0m eta: 1:15:15  iter: 739  total_loss: 1.293  loss_cls: 0.394  loss_box_reg: 0.402  loss_mask: 0.261  loss_rpn_cls: 0.060  loss_rpn_loc: 0.164  time: 3.5800  data_time: 2.4971  lr: 0.000739  max_mem: 8879M\n",
            "\u001b[32m[07/10 18:57:30 d2.utils.events]: \u001b[0m eta: 1:14:02  iter: 759  total_loss: 1.240  loss_cls: 0.396  loss_box_reg: 0.365  loss_mask: 0.256  loss_rpn_cls: 0.058  loss_rpn_loc: 0.168  time: 3.5791  data_time: 2.4992  lr: 0.000759  max_mem: 8879M\n",
            "\u001b[32m[07/10 18:58:39 d2.utils.events]: \u001b[0m eta: 1:12:47  iter: 779  total_loss: 1.194  loss_cls: 0.344  loss_box_reg: 0.374  loss_mask: 0.255  loss_rpn_cls: 0.058  loss_rpn_loc: 0.139  time: 3.5759  data_time: 2.3700  lr: 0.000779  max_mem: 8912M\n",
            "\u001b[32m[07/10 19:00:03 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 19:00:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 19:00:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 19:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2694 s / img. ETA=0:02:28\n",
            "\u001b[32m[07/10 19:00:47 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2715 s / img. ETA=0:02:21\n",
            "\u001b[32m[07/10 19:00:54 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.2472 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/10 19:01:00 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2353 s / img. ETA=0:01:44\n",
            "\u001b[32m[07/10 19:01:06 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.2244 s / img. ETA=0:01:31\n",
            "\u001b[32m[07/10 19:01:12 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2175 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/10 19:01:19 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.2126 s / img. ETA=0:01:11\n",
            "\u001b[32m[07/10 19:01:24 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2073 s / img. ETA=0:01:02\n",
            "\u001b[32m[07/10 19:01:33 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2063 s / img. ETA=0:00:56\n",
            "\u001b[32m[07/10 19:01:43 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.2061 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/10 19:01:52 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.2057 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/10 19:01:59 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.2053 s / img. ETA=0:00:47\n",
            "\u001b[32m[07/10 19:02:05 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.2024 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/10 19:02:11 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.2037 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/10 19:02:18 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.2051 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/10 19:02:24 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.2065 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 19:02:31 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.2076 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 19:02:37 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.2087 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 19:02:43 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.2098 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 19:02:50 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.2107 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/10 19:02:56 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.2116 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 19:03:02 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.2124 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/10 19:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.2132 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 19:03:15 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.2142 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 19:03:21 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.2149 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 19:03:27 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.2156 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 19:03:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:09.955937 (3.652999 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:03:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.215066 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:03:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 19:03:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 19:03:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.58s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.603\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.330\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.316\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.112\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.547\n",
            "\u001b[32m[07/10 19:03:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 31.609 | 60.261 | 32.951 |  nan  |  nan  | 31.609 |\n",
            "\u001b[32m[07/10 19:03:32 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:03:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 34.974 | brec_Cht         | 38.266 | lam_Sltst  | 26.764 |\n",
            "| skel_WkstPkst | 17.720 | strless_SltstSst | 40.322 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.15s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.78s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.608\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.602\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n",
            "\u001b[32m[07/10 19:03:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 34.978 | 60.840 | 38.381 |  nan  |  nan  | 34.978 |\n",
            "\u001b[32m[07/10 19:03:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:03:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 39.750 | brec_Cht         | 41.631 | lam_Sltst  | 26.941 |\n",
            "| skel_WkstPkst | 22.412 | strless_SltstSst | 44.157 |            |        |\n",
            "\u001b[32m[07/10 19:03:33 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 19:03:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 19:03:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:03:33 d2.evaluation.testing]: \u001b[0mcopypaste: 31.6089,60.2609,32.9512,nan,nan,31.6089\n",
            "\u001b[32m[07/10 19:03:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 19:03:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:03:33 d2.evaluation.testing]: \u001b[0mcopypaste: 34.9783,60.8398,38.3808,nan,nan,34.9783\n",
            "\u001b[32m[07/10 19:03:36 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 19:03:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 19:03:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 19:04:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1873 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 19:04:16 d2.evaluation.evaluator]: \u001b[0mInference done 12/14. 0.1966 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 19:04:22 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2031 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 19:04:28 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.2082 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.407846 (3.823094 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.208183 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.343\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.414\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.414\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.136 | 34.283 | 7.383  |  nan  |  nan  | 14.136 |\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.740 | brec_Cht         | nan    | lam_Sltst  | 3.793 |\n",
            "| skel_WkstPkst | 11.893 | strless_SltstSst | 20.117 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.357\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.138\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.348\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.471\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.114 | 35.710 | 13.780 |  nan  |  nan  | 17.114 |\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 25.267 | brec_Cht         | nan    | lam_Sltst  | 3.799 |\n",
            "| skel_WkstPkst | 14.112 | strless_SltstSst | 25.278 |            |       |\n",
            "\u001b[32m[07/10 19:04:29 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.testing]: \u001b[0mcopypaste: 14.1356,34.2826,7.3826,nan,nan,14.1356\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:04:29 d2.evaluation.testing]: \u001b[0mcopypaste: 17.1141,35.7097,13.7798,nan,nan,17.1141\n",
            "\u001b[32m[07/10 19:04:29 d2.utils.events]: \u001b[0m eta: 1:11:36  iter: 799  total_loss: 1.224  loss_cls: 0.370  loss_box_reg: 0.402  loss_mask: 0.250  loss_rpn_cls: 0.060  loss_rpn_loc: 0.157  time: 3.5753  data_time: 2.5008  lr: 0.000799  max_mem: 8912M\n",
            "\u001b[32m[07/10 19:05:39 d2.utils.events]: \u001b[0m eta: 1:10:22  iter: 819  total_loss: 1.151  loss_cls: 0.310  loss_box_reg: 0.352  loss_mask: 0.256  loss_rpn_cls: 0.054  loss_rpn_loc: 0.147  time: 3.5737  data_time: 2.4645  lr: 0.000819  max_mem: 8912M\n",
            "\u001b[32m[07/10 19:06:49 d2.utils.events]: \u001b[0m eta: 1:09:04  iter: 839  total_loss: 1.122  loss_cls: 0.313  loss_box_reg: 0.365  loss_mask: 0.255  loss_rpn_cls: 0.050  loss_rpn_loc: 0.134  time: 3.5714  data_time: 2.3947  lr: 0.000839  max_mem: 8912M\n",
            "\u001b[32m[07/10 19:07:59 d2.utils.events]: \u001b[0m eta: 1:07:50  iter: 859  total_loss: 1.150  loss_cls: 0.330  loss_box_reg: 0.354  loss_mask: 0.240  loss_rpn_cls: 0.055  loss_rpn_loc: 0.146  time: 3.5696  data_time: 2.4020  lr: 0.000859  max_mem: 8912M\n",
            "\u001b[32m[07/10 19:09:09 d2.utils.events]: \u001b[0m eta: 1:06:37  iter: 879  total_loss: 1.078  loss_cls: 0.302  loss_box_reg: 0.330  loss_mask: 0.226  loss_rpn_cls: 0.055  loss_rpn_loc: 0.148  time: 3.5681  data_time: 2.4221  lr: 0.000879  max_mem: 8912M\n",
            "\u001b[32m[07/10 19:10:19 d2.utils.events]: \u001b[0m eta: 1:05:23  iter: 899  total_loss: 1.062  loss_cls: 0.312  loss_box_reg: 0.331  loss_mask: 0.228  loss_rpn_cls: 0.055  loss_rpn_loc: 0.141  time: 3.5664  data_time: 2.4274  lr: 0.000899  max_mem: 8912M\n",
            "\u001b[32m[07/10 19:11:29 d2.utils.events]: \u001b[0m eta: 1:04:10  iter: 919  total_loss: 1.112  loss_cls: 0.314  loss_box_reg: 0.344  loss_mask: 0.243  loss_rpn_cls: 0.051  loss_rpn_loc: 0.142  time: 3.5650  data_time: 2.4422  lr: 0.000919  max_mem: 8912M\n",
            "\u001b[32m[07/10 19:12:38 d2.utils.events]: \u001b[0m eta: 1:02:55  iter: 939  total_loss: 1.067  loss_cls: 0.297  loss_box_reg: 0.342  loss_mask: 0.243  loss_rpn_cls: 0.054  loss_rpn_loc: 0.145  time: 3.5629  data_time: 2.3882  lr: 0.000939  max_mem: 8989M\n",
            "\u001b[32m[07/10 19:13:48 d2.utils.events]: \u001b[0m eta: 1:01:43  iter: 959  total_loss: 1.136  loss_cls: 0.316  loss_box_reg: 0.345  loss_mask: 0.236  loss_rpn_cls: 0.051  loss_rpn_loc: 0.159  time: 3.5618  data_time: 2.4333  lr: 0.000959  max_mem: 8989M\n",
            "\u001b[32m[07/10 19:14:59 d2.utils.events]: \u001b[0m eta: 1:00:31  iter: 979  total_loss: 1.129  loss_cls: 0.346  loss_box_reg: 0.342  loss_mask: 0.232  loss_rpn_cls: 0.047  loss_rpn_loc: 0.141  time: 3.5609  data_time: 2.4187  lr: 0.000979  max_mem: 8989M\n",
            "\u001b[32m[07/10 19:16:21 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 19:16:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 19:16:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 19:16:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2691 s / img. ETA=0:02:22\n",
            "\u001b[32m[07/10 19:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2701 s / img. ETA=0:02:14\n",
            "\u001b[32m[07/10 19:17:10 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.2304 s / img. ETA=0:01:44\n",
            "\u001b[32m[07/10 19:17:16 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.2075 s / img. ETA=0:01:24\n",
            "\u001b[32m[07/10 19:17:22 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.1992 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/10 19:17:27 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.1954 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/10 19:17:33 d2.evaluation.evaluator]: \u001b[0mInference done 30/57. 0.1901 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/10 19:17:39 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.1895 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/10 19:17:47 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1890 s / img. ETA=0:00:50\n",
            "\u001b[32m[07/10 19:17:55 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1882 s / img. ETA=0:00:47\n",
            "\u001b[32m[07/10 19:18:04 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1887 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/10 19:18:10 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1871 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/10 19:18:18 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1879 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/10 19:18:25 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.1895 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/10 19:18:31 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1911 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 19:18:38 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1929 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 19:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1943 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 19:18:51 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1956 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/10 19:18:57 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1970 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 19:19:03 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1982 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/10 19:19:09 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1993 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 19:19:16 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.2004 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 19:19:22 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.2017 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 19:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.2026 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 19:19:34 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.2035 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 19:19:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:00.741107 (3.475791 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:19:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.203563 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:19:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 19:19:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 19:19:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.57s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.728\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.481\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.546\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.620\n",
            "\u001b[32m[07/10 19:19:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 43.290 | 72.843 | 48.078 |  nan  |  nan  | 43.290 |\n",
            "\u001b[32m[07/10 19:19:40 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:19:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 43.448 | brec_Cht         | 50.386 | lam_Sltst  | 33.221 |\n",
            "| skel_WkstPkst | 39.090 | strless_SltstSst | 50.307 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.78s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.746\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.539\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.141\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.580\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n",
            "\u001b[32m[07/10 19:19:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 46.619 | 74.600 | 53.899 |  nan  |  nan  | 46.619 |\n",
            "\u001b[32m[07/10 19:19:41 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:19:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 48.152 | brec_Cht         | 56.432 | lam_Sltst  | 31.240 |\n",
            "| skel_WkstPkst | 42.506 | strless_SltstSst | 54.764 |            |        |\n",
            "\u001b[32m[07/10 19:19:41 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 19:19:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 19:19:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:19:41 d2.evaluation.testing]: \u001b[0mcopypaste: 43.2903,72.8433,48.0775,nan,nan,43.2903\n",
            "\u001b[32m[07/10 19:19:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 19:19:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:19:41 d2.evaluation.testing]: \u001b[0mcopypaste: 46.6187,74.5996,53.8994,nan,nan,46.6187\n",
            "\u001b[32m[07/10 19:19:44 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 19:19:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 19:19:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 19:20:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1788 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 19:20:23 d2.evaluation.evaluator]: \u001b[0mInference done 12/14. 0.1905 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 19:20:29 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1979 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 19:20:35 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.2036 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 19:20:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.554675 (3.728297 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:20:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.203561 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:20:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 19:20:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 19:20:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.283\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
            "\u001b[32m[07/10 19:20:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.562 | 33.373 | 9.684  |  nan  |  nan  | 14.562 |\n",
            "\u001b[32m[07/10 19:20:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:20:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.740 | brec_Cht         | nan    | lam_Sltst  | 4.844 |\n",
            "| skel_WkstPkst | 6.568  | strless_SltstSst | 25.096 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.429\n",
            "\u001b[32m[07/10 19:20:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.231 | 34.355 | 11.453 |  nan  |  nan  | 17.231 |\n",
            "\u001b[32m[07/10 19:20:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:20:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.195 | brec_Cht         | nan    | lam_Sltst  | 5.861 |\n",
            "| skel_WkstPkst | 8.486  | strless_SltstSst | 30.384 |            |       |\n",
            "\u001b[32m[07/10 19:20:36 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 19:20:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 19:20:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:20:36 d2.evaluation.testing]: \u001b[0mcopypaste: 14.5619,33.3733,9.6840,nan,nan,14.5619\n",
            "\u001b[32m[07/10 19:20:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 19:20:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:20:36 d2.evaluation.testing]: \u001b[0mcopypaste: 17.2314,34.3549,11.4529,nan,nan,17.2314\n",
            "\u001b[32m[07/10 19:20:36 d2.utils.events]: \u001b[0m eta: 0:59:20  iter: 999  total_loss: 1.103  loss_cls: 0.293  loss_box_reg: 0.339  loss_mask: 0.230  loss_rpn_cls: 0.048  loss_rpn_loc: 0.154  time: 3.5596  data_time: 2.4057  lr: 0.000999  max_mem: 8989M\n",
            "\u001b[32m[07/10 19:21:46 d2.utils.events]: \u001b[0m eta: 0:58:08  iter: 1019  total_loss: 1.052  loss_cls: 0.298  loss_box_reg: 0.337  loss_mask: 0.230  loss_rpn_cls: 0.046  loss_rpn_loc: 0.135  time: 3.5584  data_time: 2.4049  lr: 0.001000  max_mem: 8989M\n",
            "\u001b[32m[07/10 19:22:56 d2.utils.events]: \u001b[0m eta: 0:56:55  iter: 1039  total_loss: 1.014  loss_cls: 0.264  loss_box_reg: 0.319  loss_mask: 0.222  loss_rpn_cls: 0.043  loss_rpn_loc: 0.147  time: 3.5575  data_time: 2.4743  lr: 0.001000  max_mem: 8989M\n",
            "\u001b[32m[07/10 19:24:06 d2.utils.events]: \u001b[0m eta: 0:55:45  iter: 1059  total_loss: 1.032  loss_cls: 0.293  loss_box_reg: 0.340  loss_mask: 0.229  loss_rpn_cls: 0.042  loss_rpn_loc: 0.143  time: 3.5570  data_time: 2.4417  lr: 0.001000  max_mem: 8989M\n",
            "\u001b[32m[07/10 19:25:16 d2.utils.events]: \u001b[0m eta: 0:54:33  iter: 1079  total_loss: 1.012  loss_cls: 0.273  loss_box_reg: 0.322  loss_mask: 0.229  loss_rpn_cls: 0.043  loss_rpn_loc: 0.142  time: 3.5557  data_time: 2.4224  lr: 0.001000  max_mem: 8989M\n",
            "\u001b[32m[07/10 19:26:27 d2.utils.events]: \u001b[0m eta: 0:53:19  iter: 1099  total_loss: 0.957  loss_cls: 0.256  loss_box_reg: 0.305  loss_mask: 0.208  loss_rpn_cls: 0.036  loss_rpn_loc: 0.146  time: 3.5550  data_time: 2.4537  lr: 0.001000  max_mem: 8989M\n",
            "\u001b[32m[07/10 19:27:37 d2.utils.events]: \u001b[0m eta: 0:52:03  iter: 1119  total_loss: 0.985  loss_cls: 0.265  loss_box_reg: 0.321  loss_mask: 0.215  loss_rpn_cls: 0.039  loss_rpn_loc: 0.136  time: 3.5543  data_time: 2.4423  lr: 0.001000  max_mem: 8989M\n",
            "\u001b[32m[07/10 19:28:48 d2.utils.events]: \u001b[0m eta: 0:50:50  iter: 1139  total_loss: 0.924  loss_cls: 0.249  loss_box_reg: 0.308  loss_mask: 0.212  loss_rpn_cls: 0.034  loss_rpn_loc: 0.129  time: 3.5542  data_time: 2.4726  lr: 0.001000  max_mem: 8989M\n",
            "\u001b[32m[07/10 19:30:00 d2.utils.events]: \u001b[0m eta: 0:49:38  iter: 1159  total_loss: 0.926  loss_cls: 0.227  loss_box_reg: 0.306  loss_mask: 0.207  loss_rpn_cls: 0.036  loss_rpn_loc: 0.126  time: 3.5553  data_time: 2.5380  lr: 0.001000  max_mem: 8989M\n",
            "\u001b[32m[07/10 19:31:13 d2.utils.events]: \u001b[0m eta: 0:48:26  iter: 1179  total_loss: 0.898  loss_cls: 0.226  loss_box_reg: 0.290  loss_mask: 0.208  loss_rpn_cls: 0.036  loss_rpn_loc: 0.126  time: 3.5568  data_time: 2.5633  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:32:40 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 19:32:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 19:32:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 19:33:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2529 s / img. ETA=0:02:38\n",
            "\u001b[32m[07/10 19:33:25 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2435 s / img. ETA=0:02:23\n",
            "\u001b[32m[07/10 19:33:31 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1880 s / img. ETA=0:01:35\n",
            "\u001b[32m[07/10 19:33:36 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.1634 s / img. ETA=0:01:10\n",
            "\u001b[32m[07/10 19:33:42 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1490 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/10 19:33:48 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.1445 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/10 19:33:53 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1411 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/10 19:34:01 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1394 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/10 19:34:06 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1384 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 19:34:15 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.1360 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/10 19:34:23 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1378 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 19:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1396 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/10 19:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1431 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 19:34:46 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1454 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 19:34:52 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1480 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 19:34:58 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1496 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 19:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1516 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 19:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1529 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 19:35:16 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1547 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 19:35:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:18.880972 (2.670788 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:35:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.153968 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:35:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 19:35:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 19:35:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.42s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.871\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.687\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.578\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.659\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.710\n",
            "\u001b[32m[07/10 19:35:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 57.848 | 87.110 | 68.734 |  nan  |  nan  | 57.848 |\n",
            "\u001b[32m[07/10 19:35:18 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:35:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 55.657 | brec_Cht         | 69.983 | lam_Sltst  | 52.357 |\n",
            "| skel_WkstPkst | 46.557 | strless_SltstSst | 64.684 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.10s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.60s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.573\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.861\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.680\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.573\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.657\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.712\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.712\n",
            "\u001b[32m[07/10 19:35:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 57.347 | 86.141 | 67.998 |  nan  |  nan  | 57.347 |\n",
            "\u001b[32m[07/10 19:35:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:35:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 57.432 | brec_Cht         | 70.700 | lam_Sltst  | 46.781 |\n",
            "| skel_WkstPkst | 48.674 | strless_SltstSst | 63.150 |            |        |\n",
            "\u001b[32m[07/10 19:35:19 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 19:35:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 19:35:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:35:19 d2.evaluation.testing]: \u001b[0mcopypaste: 57.8477,87.1097,68.7340,nan,nan,57.8477\n",
            "\u001b[32m[07/10 19:35:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 19:35:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:35:19 d2.evaluation.testing]: \u001b[0mcopypaste: 57.3474,86.1406,67.9982,nan,nan,57.3474\n",
            "\u001b[32m[07/10 19:35:22 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 19:35:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 19:35:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 19:35:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1207 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 19:35:54 d2.evaluation.evaluator]: \u001b[0mInference done 12/14. 0.1362 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 19:36:01 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1502 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 19:36:06 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1596 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.495837 (3.166204 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.159585 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.126\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.126\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.402\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 12.648 | 30.777 | 6.596  |  nan  |  nan  | 12.648 |\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 18.526 | brec_Cht         | nan    | lam_Sltst  | 5.595 |\n",
            "| skel_WkstPkst | 7.878  | strless_SltstSst | 18.593 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.114\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.366\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.452\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.739 | 31.147 | 11.383 |  nan  |  nan  | 15.739 |\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.636 | brec_Cht         | nan    | lam_Sltst  | 5.469 |\n",
            "| skel_WkstPkst | 14.310 | strless_SltstSst | 21.542 |            |       |\n",
            "\u001b[32m[07/10 19:36:07 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.testing]: \u001b[0mcopypaste: 12.6482,30.7774,6.5957,nan,nan,12.6482\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:36:07 d2.evaluation.testing]: \u001b[0mcopypaste: 15.7392,31.1470,11.3827,nan,nan,15.7392\n",
            "\u001b[32m[07/10 19:36:07 d2.utils.events]: \u001b[0m eta: 0:47:14  iter: 1199  total_loss: 0.925  loss_cls: 0.238  loss_box_reg: 0.293  loss_mask: 0.203  loss_rpn_cls: 0.036  loss_rpn_loc: 0.137  time: 3.5589  data_time: 2.5973  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:37:16 d2.utils.events]: \u001b[0m eta: 0:46:01  iter: 1219  total_loss: 0.846  loss_cls: 0.215  loss_box_reg: 0.280  loss_mask: 0.202  loss_rpn_cls: 0.031  loss_rpn_loc: 0.133  time: 3.5575  data_time: 2.4106  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:38:27 d2.utils.events]: \u001b[0m eta: 0:44:47  iter: 1239  total_loss: 0.945  loss_cls: 0.238  loss_box_reg: 0.307  loss_mask: 0.205  loss_rpn_cls: 0.033  loss_rpn_loc: 0.143  time: 3.5570  data_time: 2.4765  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:39:37 d2.utils.events]: \u001b[0m eta: 0:43:35  iter: 1259  total_loss: 0.912  loss_cls: 0.245  loss_box_reg: 0.300  loss_mask: 0.203  loss_rpn_cls: 0.035  loss_rpn_loc: 0.127  time: 3.5563  data_time: 2.4185  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:40:48 d2.utils.events]: \u001b[0m eta: 0:42:22  iter: 1279  total_loss: 0.893  loss_cls: 0.237  loss_box_reg: 0.284  loss_mask: 0.201  loss_rpn_cls: 0.031  loss_rpn_loc: 0.126  time: 3.5557  data_time: 2.4436  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:41:57 d2.utils.events]: \u001b[0m eta: 0:41:09  iter: 1299  total_loss: 0.831  loss_cls: 0.200  loss_box_reg: 0.281  loss_mask: 0.195  loss_rpn_cls: 0.032  loss_rpn_loc: 0.130  time: 3.5546  data_time: 2.4084  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:43:08 d2.utils.events]: \u001b[0m eta: 0:39:59  iter: 1319  total_loss: 0.859  loss_cls: 0.219  loss_box_reg: 0.284  loss_mask: 0.196  loss_rpn_cls: 0.027  loss_rpn_loc: 0.127  time: 3.5543  data_time: 2.4884  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:44:17 d2.utils.events]: \u001b[0m eta: 0:38:46  iter: 1339  total_loss: 0.827  loss_cls: 0.185  loss_box_reg: 0.280  loss_mask: 0.190  loss_rpn_cls: 0.028  loss_rpn_loc: 0.123  time: 3.5530  data_time: 2.3805  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:45:28 d2.utils.events]: \u001b[0m eta: 0:37:35  iter: 1359  total_loss: 0.821  loss_cls: 0.208  loss_box_reg: 0.280  loss_mask: 0.194  loss_rpn_cls: 0.026  loss_rpn_loc: 0.122  time: 3.5528  data_time: 2.4403  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:46:38 d2.utils.events]: \u001b[0m eta: 0:36:25  iter: 1379  total_loss: 0.835  loss_cls: 0.204  loss_box_reg: 0.270  loss_mask: 0.194  loss_rpn_cls: 0.028  loss_rpn_loc: 0.120  time: 3.5521  data_time: 2.4325  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:48:01 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 19:48:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 19:48:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 19:48:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1900 s / img. ETA=0:01:56\n",
            "\u001b[32m[07/10 19:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.1637 s / img. ETA=0:01:27\n",
            "\u001b[32m[07/10 19:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 20/57. 0.1393 s / img. ETA=0:01:04\n",
            "\u001b[32m[07/10 19:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.1274 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/10 19:48:52 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1203 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/10 19:48:59 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1186 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 19:49:05 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1178 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/10 19:49:11 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1157 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/10 19:49:16 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.1151 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/10 19:49:22 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1169 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 19:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1196 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 19:49:37 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1226 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 19:49:43 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1254 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 19:49:49 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1276 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 19:50:00 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1315 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 19:50:08 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1332 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 19:50:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:54.662542 (2.205049 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:50:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.132601 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:50:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 19:50:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 19:50:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.45s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.920\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.832\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.655\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.175\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.703\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.738\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n",
            "\u001b[32m[07/10 19:50:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 65.455 | 91.968 | 83.181 |  nan  |  nan  | 65.455 |\n",
            "\u001b[32m[07/10 19:50:10 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:50:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 65.387 | brec_Cht         | 75.015 | lam_Sltst  | 59.720 |\n",
            "| skel_WkstPkst | 60.701 | strless_SltstSst | 66.454 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.51s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.916\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.809\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.655\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.736\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.736\n",
            "\u001b[32m[07/10 19:50:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 65.471 | 91.557 | 80.883 |  nan  |  nan  | 65.471 |\n",
            "\u001b[32m[07/10 19:50:11 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:50:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 67.083 | brec_Cht         | 74.796 | lam_Sltst  | 55.309 |\n",
            "| skel_WkstPkst | 61.698 | strless_SltstSst | 68.467 |            |        |\n",
            "\u001b[32m[07/10 19:50:11 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 19:50:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 19:50:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:50:11 d2.evaluation.testing]: \u001b[0mcopypaste: 65.4555,91.9683,83.1806,nan,nan,65.4555\n",
            "\u001b[32m[07/10 19:50:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 19:50:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:50:11 d2.evaluation.testing]: \u001b[0mcopypaste: 65.4705,91.5568,80.8826,nan,nan,65.4705\n",
            "\u001b[32m[07/10 19:50:14 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 19:50:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 19:50:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 19:50:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1123 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 19:50:45 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1378 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 19:50:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:24.373855 (2.708206 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:50:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.144432 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 19:50:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 19:50:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 19:50:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.116\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.079\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.116\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.279\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.372\n",
            "\u001b[32m[07/10 19:50:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.647 | 28.824 | 7.904  |  nan  |  nan  | 11.647 |\n",
            "\u001b[32m[07/10 19:50:50 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:50:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.653 | brec_Cht         | nan    | lam_Sltst  | 3.876 |\n",
            "| skel_WkstPkst | 4.037  | strless_SltstSst | 17.023 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.292\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.147\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
            "\u001b[32m[07/10 19:50:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.804 | 29.153 | 14.716 |  nan  |  nan  | 14.804 |\n",
            "\u001b[32m[07/10 19:50:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 19:50:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 25.838 | brec_Cht         | nan    | lam_Sltst  | 4.088 |\n",
            "| skel_WkstPkst | 5.230  | strless_SltstSst | 24.062 |            |       |\n",
            "\u001b[32m[07/10 19:50:51 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 19:50:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 19:50:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:50:51 d2.evaluation.testing]: \u001b[0mcopypaste: 11.6471,28.8236,7.9036,nan,nan,11.6471\n",
            "\u001b[32m[07/10 19:50:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 19:50:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 19:50:51 d2.evaluation.testing]: \u001b[0mcopypaste: 14.8044,29.1530,14.7164,nan,nan,14.8044\n",
            "\u001b[32m[07/10 19:50:51 d2.utils.events]: \u001b[0m eta: 0:35:14  iter: 1399  total_loss: 0.788  loss_cls: 0.191  loss_box_reg: 0.272  loss_mask: 0.186  loss_rpn_cls: 0.026  loss_rpn_loc: 0.111  time: 3.5512  data_time: 2.4213  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:52:00 d2.utils.events]: \u001b[0m eta: 0:34:04  iter: 1419  total_loss: 0.796  loss_cls: 0.192  loss_box_reg: 0.266  loss_mask: 0.199  loss_rpn_cls: 0.030  loss_rpn_loc: 0.111  time: 3.5502  data_time: 2.4031  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:53:11 d2.utils.events]: \u001b[0m eta: 0:32:54  iter: 1439  total_loss: 0.768  loss_cls: 0.179  loss_box_reg: 0.261  loss_mask: 0.182  loss_rpn_cls: 0.028  loss_rpn_loc: 0.119  time: 3.5499  data_time: 2.4495  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:54:21 d2.utils.events]: \u001b[0m eta: 0:31:43  iter: 1459  total_loss: 0.778  loss_cls: 0.177  loss_box_reg: 0.251  loss_mask: 0.188  loss_rpn_cls: 0.028  loss_rpn_loc: 0.117  time: 3.5492  data_time: 2.4215  lr: 0.001000  max_mem: 9153M\n",
            "\u001b[32m[07/10 19:55:31 d2.utils.events]: \u001b[0m eta: 0:30:33  iter: 1479  total_loss: 0.785  loss_cls: 0.187  loss_box_reg: 0.272  loss_mask: 0.190  loss_rpn_cls: 0.032  loss_rpn_loc: 0.106  time: 3.5487  data_time: 2.4089  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 19:56:41 d2.utils.events]: \u001b[0m eta: 0:29:22  iter: 1499  total_loss: 0.739  loss_cls: 0.174  loss_box_reg: 0.245  loss_mask: 0.182  loss_rpn_cls: 0.026  loss_rpn_loc: 0.106  time: 3.5479  data_time: 2.4085  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 19:57:52 d2.utils.events]: \u001b[0m eta: 0:28:12  iter: 1519  total_loss: 0.833  loss_cls: 0.204  loss_box_reg: 0.264  loss_mask: 0.206  loss_rpn_cls: 0.027  loss_rpn_loc: 0.124  time: 3.5477  data_time: 2.4512  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 19:59:01 d2.utils.events]: \u001b[0m eta: 0:27:01  iter: 1539  total_loss: 0.764  loss_cls: 0.170  loss_box_reg: 0.243  loss_mask: 0.184  loss_rpn_cls: 0.028  loss_rpn_loc: 0.111  time: 3.5470  data_time: 2.3968  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:00:12 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 1559  total_loss: 0.756  loss_cls: 0.174  loss_box_reg: 0.242  loss_mask: 0.191  loss_rpn_cls: 0.028  loss_rpn_loc: 0.109  time: 3.5467  data_time: 2.4212  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:01:22 d2.utils.events]: \u001b[0m eta: 0:24:41  iter: 1579  total_loss: 0.731  loss_cls: 0.160  loss_box_reg: 0.243  loss_mask: 0.183  loss_rpn_cls: 0.027  loss_rpn_loc: 0.116  time: 3.5464  data_time: 2.4560  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:02:46 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 20:02:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 20:02:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 20:03:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1893 s / img. ETA=0:01:55\n",
            "\u001b[32m[07/10 20:03:20 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.1584 s / img. ETA=0:01:24\n",
            "\u001b[32m[07/10 20:03:25 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1235 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/10 20:03:30 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.1092 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/10 20:03:35 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1054 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 20:03:42 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1040 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/10 20:03:48 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1011 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/10 20:03:56 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1038 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/10 20:04:03 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1068 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 20:04:12 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1103 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 20:04:18 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1133 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 20:04:24 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1159 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 20:04:33 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1192 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 20:04:41 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1212 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/10 20:04:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:42.440963 (1.970019 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 20:04:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.120722 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 20:04:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 20:04:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 20:04:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.33s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.697\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.951\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.863\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.763\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.763\n",
            "\u001b[32m[07/10 20:04:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 69.699 | 95.127 | 86.269 |  nan  |  nan  | 69.699 |\n",
            "\u001b[32m[07/10 20:04:43 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 20:04:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 72.505 | brec_Cht         | 69.486 | lam_Sltst  | 66.563 |\n",
            "| skel_WkstPkst | 63.715 | strless_SltstSst | 76.224 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.46s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.729\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.950\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.883\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.747\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.788\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788\n",
            "\u001b[32m[07/10 20:04:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 72.871 | 95.020 | 88.312 |  nan  |  nan  | 72.871 |\n",
            "\u001b[32m[07/10 20:04:43 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 20:04:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 75.263 | brec_Cht         | 74.844 | lam_Sltst  | 67.297 |\n",
            "| skel_WkstPkst | 67.913 | strless_SltstSst | 79.036 |            |        |\n",
            "\u001b[32m[07/10 20:04:43 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 20:04:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 20:04:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 20:04:43 d2.evaluation.testing]: \u001b[0mcopypaste: 69.6987,95.1267,86.2685,nan,nan,69.6987\n",
            "\u001b[32m[07/10 20:04:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 20:04:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 20:04:43 d2.evaluation.testing]: \u001b[0mcopypaste: 72.8705,95.0204,88.3116,nan,nan,72.8705\n",
            "\u001b[32m[07/10 20:04:46 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 20:04:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 20:04:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 20:05:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.0964 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 20:05:18 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1280 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.756816 (2.528535 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.133163 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.353\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.181\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.177\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.356\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.693 | 35.271 | 18.117 |  nan  |  nan  | 17.693 |\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 27.016 | brec_Cht         | nan    | lam_Sltst  | 8.149 |\n",
            "| skel_WkstPkst | 11.026 | strless_SltstSst | 24.582 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.356\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.204\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.203\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.095\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 20.349 | 35.631 | 20.420 |  nan  |  nan  | 20.349 |\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 29.860 | brec_Cht         | nan    | lam_Sltst  | 9.681 |\n",
            "| skel_WkstPkst | 13.415 | strless_SltstSst | 28.441 |            |       |\n",
            "\u001b[32m[07/10 20:05:22 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.testing]: \u001b[0mcopypaste: 17.6933,35.2708,18.1166,nan,nan,17.6933\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 20:05:22 d2.evaluation.testing]: \u001b[0mcopypaste: 20.3492,35.6310,20.4199,nan,nan,20.3493\n",
            "\u001b[32m[07/10 20:05:22 d2.utils.events]: \u001b[0m eta: 0:23:31  iter: 1599  total_loss: 0.707  loss_cls: 0.164  loss_box_reg: 0.243  loss_mask: 0.170  loss_rpn_cls: 0.024  loss_rpn_loc: 0.108  time: 3.5464  data_time: 2.4456  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:06:31 d2.utils.events]: \u001b[0m eta: 0:22:20  iter: 1619  total_loss: 0.694  loss_cls: 0.145  loss_box_reg: 0.236  loss_mask: 0.172  loss_rpn_cls: 0.029  loss_rpn_loc: 0.104  time: 3.5454  data_time: 2.3876  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:07:42 d2.utils.events]: \u001b[0m eta: 0:21:11  iter: 1639  total_loss: 0.809  loss_cls: 0.186  loss_box_reg: 0.268  loss_mask: 0.188  loss_rpn_cls: 0.027  loss_rpn_loc: 0.121  time: 3.5449  data_time: 2.4042  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:08:53 d2.utils.events]: \u001b[0m eta: 0:20:01  iter: 1659  total_loss: 0.768  loss_cls: 0.178  loss_box_reg: 0.253  loss_mask: 0.184  loss_rpn_cls: 0.025  loss_rpn_loc: 0.126  time: 3.5452  data_time: 2.4591  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:10:05 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 1679  total_loss: 0.653  loss_cls: 0.134  loss_box_reg: 0.225  loss_mask: 0.170  loss_rpn_cls: 0.022  loss_rpn_loc: 0.116  time: 3.5457  data_time: 2.5095  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:11:16 d2.utils.events]: \u001b[0m eta: 0:17:41  iter: 1699  total_loss: 0.665  loss_cls: 0.141  loss_box_reg: 0.222  loss_mask: 0.172  loss_rpn_cls: 0.022  loss_rpn_loc: 0.109  time: 3.5461  data_time: 2.5022  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:12:28 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 1719  total_loss: 0.691  loss_cls: 0.155  loss_box_reg: 0.226  loss_mask: 0.167  loss_rpn_cls: 0.020  loss_rpn_loc: 0.109  time: 3.5463  data_time: 2.4822  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:13:39 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 1739  total_loss: 0.651  loss_cls: 0.153  loss_box_reg: 0.220  loss_mask: 0.166  loss_rpn_cls: 0.023  loss_rpn_loc: 0.103  time: 3.5463  data_time: 2.4668  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:14:49 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 1759  total_loss: 0.690  loss_cls: 0.150  loss_box_reg: 0.230  loss_mask: 0.170  loss_rpn_cls: 0.022  loss_rpn_loc: 0.095  time: 3.5457  data_time: 2.4188  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:15:59 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 1779  total_loss: 0.655  loss_cls: 0.140  loss_box_reg: 0.220  loss_mask: 0.164  loss_rpn_cls: 0.022  loss_rpn_loc: 0.099  time: 3.5454  data_time: 2.4249  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:17:22 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 20:17:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 20:17:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 20:17:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1632 s / img. ETA=0:01:39\n",
            "\u001b[32m[07/10 20:17:53 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.1271 s / img. ETA=0:01:02\n",
            "\u001b[32m[07/10 20:17:58 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.1112 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/10 20:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 30/57. 0.1016 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/10 20:18:08 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1020 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/10 20:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1020 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/10 20:18:19 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1018 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 20:18:26 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.1012 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 20:18:33 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1029 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 20:18:41 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1058 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 20:18:47 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1084 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 20:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1109 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 20:19:00 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1133 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 20:19:07 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1149 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/10 20:19:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:34.245251 (1.812409 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 20:19:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.114585 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 20:19:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 20:19:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 20:19:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.30s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.718\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.962\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.915\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.718\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.748\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.776\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776\n",
            "\u001b[32m[07/10 20:19:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 71.826 | 96.152 | 91.455 |  nan  |  nan  | 71.826 |\n",
            "\u001b[32m[07/10 20:19:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 20:19:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 70.838 | brec_Cht         | 77.649 | lam_Sltst  | 70.734 |\n",
            "| skel_WkstPkst | 63.479 | strless_SltstSst | 76.430 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.44s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.755\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.957\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.917\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.779\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.808\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.808\n",
            "\u001b[32m[07/10 20:19:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 75.520 | 95.688 | 91.669 |  nan  |  nan  | 75.522 |\n",
            "\u001b[32m[07/10 20:19:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 20:19:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 76.515 | brec_Cht         | 80.042 | lam_Sltst  | 68.079 |\n",
            "| skel_WkstPkst | 73.189 | strless_SltstSst | 79.775 |            |        |\n",
            "\u001b[32m[07/10 20:19:09 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 20:19:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 20:19:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 20:19:09 d2.evaluation.testing]: \u001b[0mcopypaste: 71.8262,96.1517,91.4550,nan,nan,71.8262\n",
            "\u001b[32m[07/10 20:19:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 20:19:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 20:19:09 d2.evaluation.testing]: \u001b[0mcopypaste: 75.5199,95.6880,91.6690,nan,nan,75.5221\n",
            "\u001b[32m[07/10 20:19:12 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 20:19:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 20:19:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 20:19:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.0994 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 20:19:40 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1220 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.499674 (2.388853 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.129107 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.361\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.152\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.186\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.052\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.356\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.410\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 18.618 | 36.118 | 15.229 |  nan  |  nan  | 18.618 |\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 26.085 | brec_Cht         | nan    | lam_Sltst  | 4.646 |\n",
            "| skel_WkstPkst | 10.660 | strless_SltstSst | 33.083 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.423\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.474\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 21.949 | 36.979 | 22.907 |  nan  |  nan  | 21.949 |\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 31.102 | brec_Cht         | nan    | lam_Sltst  | 5.740 |\n",
            "| skel_WkstPkst | 14.328 | strless_SltstSst | 36.624 |            |       |\n",
            "\u001b[32m[07/10 20:19:44 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.testing]: \u001b[0mcopypaste: 18.6184,36.1180,15.2291,nan,nan,18.6184\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 20:19:44 d2.evaluation.testing]: \u001b[0mcopypaste: 21.9486,36.9785,22.9074,nan,nan,21.9488\n",
            "\u001b[32m[07/10 20:19:44 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 1799  total_loss: 0.695  loss_cls: 0.144  loss_box_reg: 0.227  loss_mask: 0.173  loss_rpn_cls: 0.021  loss_rpn_loc: 0.104  time: 3.5451  data_time: 2.4238  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:20:55 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 1819  total_loss: 0.639  loss_cls: 0.128  loss_box_reg: 0.213  loss_mask: 0.165  loss_rpn_cls: 0.020  loss_rpn_loc: 0.101  time: 3.5449  data_time: 2.4254  lr: 0.001000  max_mem: 9210M\n",
            "\u001b[32m[07/10 20:22:05 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 1839  total_loss: 0.678  loss_cls: 0.146  loss_box_reg: 0.232  loss_mask: 0.173  loss_rpn_cls: 0.022  loss_rpn_loc: 0.098  time: 3.5447  data_time: 2.4570  lr: 0.001000  max_mem: 9210M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hUqQJAOLd-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '4' --max_iter 2000\n",
        "# copy results to Google Drive\n",
        "! cp -r output_fold_4 'drive/My Drive/R50-C4'\n",
        "# clean folders if upcoming experiment\n",
        "! rm -r *coco*\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m19G2u9UEw0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output_fold_0"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}