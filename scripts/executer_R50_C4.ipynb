{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "executer_R50-C4.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raplima/2020_cores_auto/blob/master/scripts/executer_R50_C4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_52_mQ1oMPVQ",
        "colab_type": "text"
      },
      "source": [
        "This [`javascript`](https://stackoverflow.com/questions/54057011/google-colab-session-timeout) function might be helpful to avoid Colab identifying the notebook as idle and disconnecting:\n",
        "\n",
        "```javascript\n",
        "function clickedMe(){\n",
        "  console.log('clicked')\n",
        "  document.querySelector(\"paper-button#comments\").click()\n",
        "}\n",
        "setInterval(clickedMe(), 5*60000)\n",
        "```\n",
        "\n",
        "To execute, press `Ctrl+Shift+i`, copy into the console and run it. The code simple searches the `paper-button#comments` and clicks it. Effetively, the `Comment` box is clicked every 5 minutes. Each fold takes ~2.5 h to run, so this can facilitate the experiment (you shouldn't have to watch the entire training)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCps-FC-Nc5y",
        "colab_type": "text"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cneXQmncDd8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "77a4d5b2-e84e-4051-f7a8-8a84a92473e4"
      },
      "source": [
        "# connect to google drive to save results after execution\n",
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHciCqT6BJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e92f2052-1179-4829-971b-4228cd142d35"
      },
      "source": [
        "# download, decompress the data\n",
        "!gdown https://drive.google.com/uc?id=1n6w9DJmrcepwIvWsJXLhAxAbHM0f2XjR\n",
        "!unzip cores.zip > /dev/null\n",
        "\n",
        "# clone repository\n",
        "!git clone https://github.com/raplima/2020_cores_auto.git\n",
        "\n",
        "# copy files to facilitate execution:\n",
        "!cp 2020_cores_auto/data/* cores\n",
        "!cp 2020_cores_auto/scripts/* .\n",
        "################################################################################\n",
        "# install libraries\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install pyyaml==5.1 pycocotools>=2.0.1\n",
        "# install detectron2:\n",
        "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1n6w9DJmrcepwIvWsJXLhAxAbHM0f2XjR\n",
            "To: /content/cores.zip\n",
            "296MB [00:04, 69.6MB/s]\n",
            "Cloning into '2020_cores_auto'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 391 (delta 54), reused 68 (delta 17), pack-reused 271\u001b[K\n",
            "Receiving objects: 100% (391/391), 56.09 MiB | 11.04 MiB/s, done.\n",
            "Resolving deltas: 100% (200/200), done.\n",
            "cp: -r not specified; omitting directory '2020_cores_auto/data/results'\n",
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Collecting torch==1.5\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (703.8MB)\n",
            "\u001b[K     |████████████████████████████████| 703.8MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Successfully installed torch-1.5.0+cu101 torchvision-0.6.0+cu101\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n",
            "Collecting detectron2==0.1.3\n",
            "\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/detectron2-0.1.3%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.2MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2MB 7.5MB/s \n",
            "\u001b[?25hCollecting fvcore>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/69/f0/dfee20a11c469e43061532e6e1467b9f3614dab10ad5a964e14f78f6631a/fvcore-0.1.1.post20200704.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (7.0.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/81/3b/40e876afde9f5ffa1cfdce10565aba85b0dc2e067ed551dfb566cfee6d4d/yacs-0.1.7-py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (3.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.8.7)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (2.2.2)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (4.41.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (1.18.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (5.1)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot->detectron2==0.1.3) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (0.10.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.6.0.post3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (47.3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.30.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.1.3) (1.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.1.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (3.1.0)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.1.post20200704-cp36-none-any.whl size=41894 sha256=81e826da22fa411d8272df9923f7c7201e16cd45b2f8fafc01623cab53f6ce3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/d2/8e/b6d0f19811e77dabff1ebed6605ce2b59ee9f487079b434c8c\n",
            "Successfully built fvcore\n",
            "Installing collected packages: yacs, portalocker, fvcore, mock, detectron2\n",
            "Successfully installed detectron2-0.1.3+cu101 fvcore-0.1.1.post20200704 mock-4.0.2 portalocker-1.7.0 yacs-0.1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSLrYG8-NiQC",
        "colab_type": "text"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT7kDUqTCDv_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5454db40-c814-4d78-dd17-06dc26afea5c"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '0' --max_iter 2000\n",
        "# donwload results to Google Drive\n",
        "! zip -r results.zip out* \n",
        "! cp results.zip 'gdrive/My Drive'\n",
        "! rm -r results.zip\n",
        "# clean folders if upcoming experiment\n",
        "! rm -r *coco*\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 0\n",
            "\t cores_fold_0_train\n",
            "\t cores_fold_0_val\n",
            "\u001b[32m[07/09 21:22:39 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/09 21:22:53 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 55 images left.\n",
            "\u001b[32m[07/09 21:22:53 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 253          |   brec_Cht    | 21           | lam_Sltst  | 111          |\n",
            "| skel_WkstPkst | 26           | strless_Slt.. | 132          |            |              |\n",
            "|     total     | 543          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/09 21:22:53 d2.data.common]: \u001b[0mSerializing 55 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 21:22:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 21:22:53 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/09 21:22:53 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-09 21:22:53.706359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "model_final_4ce675.pkl: 144MB [00:02, 62.2MB/s]               \n",
            "Unable to load 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (15, 4) in the checkpoint but (3, 4) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (1024, 1024, 3, 3) in the checkpoint but (256, 256, 3, 3) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (256,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (15, 1024, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (15,) in the checkpoint but (3,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (60, 1024, 1, 1) in the checkpoint but (12, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (60,) in the checkpoint but (12,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.deconv.weight' to the model due to incompatible shapes: (2048, 256, 2, 2) in the checkpoint but (256, 256, 2, 2) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/09 21:23:03 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/09 21:24:22 d2.utils.events]: \u001b[0m eta: 2:08:12  iter: 19  total_loss: 42.224  loss_cls: 31.871  loss_box_reg: 0.717  loss_mask: 1.049  loss_rpn_cls: 0.834  loss_rpn_loc: 7.692  time: 3.9033  data_time: 3.1069  lr: 0.000020  max_mem: 6781M\n",
            "\u001b[32m[07/09 21:25:39 d2.utils.events]: \u001b[0m eta: 2:05:54  iter: 39  total_loss: 7.750  loss_cls: 5.954  loss_box_reg: 0.217  loss_mask: 0.583  loss_rpn_cls: 0.271  loss_rpn_loc: 0.860  time: 3.8763  data_time: 2.9608  lr: 0.000040  max_mem: 6781M\n",
            "\u001b[32m[07/09 21:26:58 d2.utils.events]: \u001b[0m eta: 2:05:52  iter: 59  total_loss: 3.018  loss_cls: 1.488  loss_box_reg: 0.335  loss_mask: 0.570  loss_rpn_cls: 0.214  loss_rpn_loc: 0.381  time: 3.8959  data_time: 2.9712  lr: 0.000060  max_mem: 7178M\n",
            "\u001b[32m[07/09 21:28:15 d2.utils.events]: \u001b[0m eta: 2:03:47  iter: 79  total_loss: 2.022  loss_cls: 0.622  loss_box_reg: 0.333  loss_mask: 0.556  loss_rpn_cls: 0.210  loss_rpn_loc: 0.277  time: 3.8868  data_time: 2.8992  lr: 0.000080  max_mem: 7178M\n",
            "\u001b[32m[07/09 21:29:34 d2.utils.events]: \u001b[0m eta: 2:02:45  iter: 99  total_loss: 1.903  loss_cls: 0.509  loss_box_reg: 0.384  loss_mask: 0.547  loss_rpn_cls: 0.175  loss_rpn_loc: 0.260  time: 3.8952  data_time: 2.9510  lr: 0.000100  max_mem: 7287M\n",
            "\u001b[32m[07/09 21:30:51 d2.utils.events]: \u001b[0m eta: 2:01:27  iter: 119  total_loss: 1.691  loss_cls: 0.398  loss_box_reg: 0.420  loss_mask: 0.533  loss_rpn_cls: 0.159  loss_rpn_loc: 0.238  time: 3.8933  data_time: 2.8608  lr: 0.000120  max_mem: 7505M\n",
            "\u001b[32m[07/09 21:32:10 d2.utils.events]: \u001b[0m eta: 2:01:18  iter: 139  total_loss: 1.753  loss_cls: 0.408  loss_box_reg: 0.429  loss_mask: 0.526  loss_rpn_cls: 0.152  loss_rpn_loc: 0.226  time: 3.8960  data_time: 2.9102  lr: 0.000140  max_mem: 7746M\n",
            "\u001b[32m[07/09 21:33:27 d2.utils.events]: \u001b[0m eta: 1:59:59  iter: 159  total_loss: 1.649  loss_cls: 0.396  loss_box_reg: 0.409  loss_mask: 0.504  loss_rpn_cls: 0.153  loss_rpn_loc: 0.208  time: 3.8934  data_time: 2.8708  lr: 0.000160  max_mem: 7888M\n",
            "\u001b[32m[07/09 21:34:45 d2.utils.events]: \u001b[0m eta: 1:57:37  iter: 179  total_loss: 1.633  loss_cls: 0.384  loss_box_reg: 0.401  loss_mask: 0.495  loss_rpn_cls: 0.138  loss_rpn_loc: 0.200  time: 3.8909  data_time: 2.8617  lr: 0.000180  max_mem: 7888M\n",
            "\u001b[32m[07/09 21:36:16 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 21:36:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 21:36:16 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_0_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/09 21:36:16 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_0_train' to COCO format ...)\n",
            "\u001b[32m[07/09 21:36:29 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/09 21:36:29 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 56, #annotations: 543\n",
            "\u001b[32m[07/09 21:36:29 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_0_train_coco_format.json' ...\n",
            "\u001b[32m[07/09 21:36:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0x903aa000 @  0x7faf2166eb6b 0x7faf2168e379 0x7faec4dc304e 0x7faec4dc4f4a 0x7faefdcb367b 0x7faefd9026be 0x7faefdb6b7b5 0x7faefdb5d7c1 0x7faefdb5cd0e 0x7faefdb5d7c1 0x7faeff5b293a 0x7faefdb5d7c1 0x7faefd8fd457 0x7faefd8fe080 0x7faefdc1c71a 0x7faeff69a13e 0x7faefdb5dc72 0x7faf0bbf7a68 0x7faf0bcb2b04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/09 21:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2722 s / img. ETA=0:06:37\n",
            "\u001b[32m[07/09 21:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 12/56. 0.2719 s / img. ETA=0:06:28\n",
            "\u001b[32m[07/09 21:38:27 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2736 s / img. ETA=0:06:20\n",
            "\u001b[32m[07/09 21:38:35 d2.evaluation.evaluator]: \u001b[0mInference done 14/56. 0.2732 s / img. ETA=0:06:11\n",
            "\u001b[32m[07/09 21:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 15/56. 0.2897 s / img. ETA=0:06:03\n",
            "\u001b[32m[07/09 21:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 16/56. 0.2881 s / img. ETA=0:05:54\n",
            "\u001b[32m[07/09 21:39:02 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.2866 s / img. ETA=0:05:46\n",
            "\u001b[32m[07/09 21:39:08 d2.evaluation.evaluator]: \u001b[0mInference done 18/56. 0.2810 s / img. ETA=0:05:26\n",
            "\u001b[32m[07/09 21:39:13 d2.evaluation.evaluator]: \u001b[0mInference done 19/56. 0.2754 s / img. ETA=0:05:09\n",
            "\u001b[32m[07/09 21:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.2705 s / img. ETA=0:04:53\n",
            "\u001b[32m[07/09 21:39:23 d2.evaluation.evaluator]: \u001b[0mInference done 21/56. 0.2667 s / img. ETA=0:04:38\n",
            "\u001b[32m[07/09 21:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 22/56. 0.2629 s / img. ETA=0:04:24\n",
            "\u001b[32m[07/09 21:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 23/56. 0.2595 s / img. ETA=0:04:12\n",
            "\u001b[32m[07/09 21:39:39 d2.evaluation.evaluator]: \u001b[0mInference done 24/56. 0.2565 s / img. ETA=0:04:00\n",
            "\u001b[32m[07/09 21:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 25/56. 0.2538 s / img. ETA=0:03:49\n",
            "\u001b[32m[07/09 21:39:49 d2.evaluation.evaluator]: \u001b[0mInference done 26/56. 0.2517 s / img. ETA=0:03:38\n",
            "\u001b[32m[07/09 21:39:54 d2.evaluation.evaluator]: \u001b[0mInference done 27/56. 0.2495 s / img. ETA=0:03:28\n",
            "\u001b[32m[07/09 21:39:59 d2.evaluation.evaluator]: \u001b[0mInference done 28/56. 0.2475 s / img. ETA=0:03:18\n",
            "\u001b[32m[07/09 21:40:04 d2.evaluation.evaluator]: \u001b[0mInference done 29/56. 0.2456 s / img. ETA=0:03:09\n",
            "\u001b[32m[07/09 21:40:09 d2.evaluation.evaluator]: \u001b[0mInference done 30/56. 0.2439 s / img. ETA=0:03:00\n",
            "\u001b[32m[07/09 21:40:14 d2.evaluation.evaluator]: \u001b[0mInference done 31/56. 0.2423 s / img. ETA=0:02:51\n",
            "\u001b[32m[07/09 21:40:20 d2.evaluation.evaluator]: \u001b[0mInference done 32/56. 0.2408 s / img. ETA=0:02:43\n",
            "\u001b[32m[07/09 21:40:25 d2.evaluation.evaluator]: \u001b[0mInference done 33/56. 0.2393 s / img. ETA=0:02:35\n",
            "\u001b[32m[07/09 21:40:30 d2.evaluation.evaluator]: \u001b[0mInference done 34/56. 0.2380 s / img. ETA=0:02:27\n",
            "\u001b[32m[07/09 21:40:35 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.2370 s / img. ETA=0:02:19\n",
            "\u001b[32m[07/09 21:40:40 d2.evaluation.evaluator]: \u001b[0mInference done 36/56. 0.2358 s / img. ETA=0:02:11\n",
            "\u001b[32m[07/09 21:40:45 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.2347 s / img. ETA=0:02:04\n",
            "\u001b[32m[07/09 21:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.2326 s / img. ETA=0:01:49\n",
            "\u001b[32m[07/09 21:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 40/56. 0.2316 s / img. ETA=0:01:42\n",
            "\u001b[32m[07/09 21:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 43/56. 0.2280 s / img. ETA=0:01:20\n",
            "\u001b[32m[07/09 21:41:21 d2.evaluation.evaluator]: \u001b[0mInference done 44/56. 0.2288 s / img. ETA=0:01:15\n",
            "\u001b[32m[07/09 21:41:29 d2.evaluation.evaluator]: \u001b[0mInference done 45/56. 0.2297 s / img. ETA=0:01:09\n",
            "\u001b[32m[07/09 21:41:37 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.2303 s / img. ETA=0:01:03\n",
            "\u001b[32m[07/09 21:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.2309 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/09 21:41:53 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.2314 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/09 21:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 49/56. 0.2319 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/09 21:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.2324 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/09 21:42:16 d2.evaluation.evaluator]: \u001b[0mInference done 51/56. 0.2329 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/09 21:42:24 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.2334 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/09 21:42:32 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.2337 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/09 21:42:40 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.2340 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/09 21:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 55/56. 0.2343 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/09 21:42:55 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.2346 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 21:42:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:39.690408 (6.660596 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 21:42:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.234637 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 21:42:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 21:42:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 21:42:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.78s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.102\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.027\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.092\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.146\n",
            "\u001b[32m[07/09 21:42:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.364 | 10.207 | 1.413  |  nan  |  nan  | 3.364 |\n",
            "\u001b[32m[07/09 21:42:57 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 21:42:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 6.674 | brec_Cht         | 0.638 | lam_Sltst  | 1.048 |\n",
            "| skel_WkstPkst | 5.149 | strless_SltstSst | 3.314 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.20s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.022\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.133\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.923 | 9.056  | 1.320  |  nan  |  nan  | 2.923 |\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 6.258 | brec_Cht         | 0.177 | lam_Sltst  | 1.038 |\n",
            "| skel_WkstPkst | 4.488 | strless_SltstSst | 2.653 |            |       |\n",
            "\u001b[32m[07/09 21:42:58 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.testing]: \u001b[0mcopypaste: 3.3644,10.2069,1.4133,nan,nan,3.3644\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 21:42:58 d2.evaluation.testing]: \u001b[0mcopypaste: 2.9229,9.0559,1.3204,nan,nan,2.9229\n",
            "\u001b[32m[07/09 21:43:02 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 56           |   brec_Cht    | 0            | lam_Sltst  | 16           |\n",
            "| skel_WkstPkst | 0            | strless_Slt.. | 41           |            |              |\n",
            "|     total     | 113          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/09 21:43:02 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 21:43:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 21:43:02 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_0_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/09 21:43:02 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_0_val' to COCO format ...)\n",
            "\u001b[32m[07/09 21:43:05 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/09 21:43:05 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 15, #annotations: 113\n",
            "\u001b[32m[07/09 21:43:05 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_0_val_coco_format.json' ...\n",
            "\u001b[32m[07/09 21:43:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 21:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.2030 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/09 21:44:08 d2.evaluation.evaluator]: \u001b[0mInference done 13/15. 0.2089 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.evaluator]: \u001b[0mInference done 15/15. 0.2174 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.201831 (3.620183 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.217375 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.023\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.187\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.003 | 8.774  | 2.297  |  nan  |  nan  | 3.003 |\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 21:44:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 7.190 | brec_Cht         | nan   | lam_Sltst  | 0.000 |\n",
            "| skel_WkstPkst | nan   | strless_SltstSst | 1.819 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.085\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.187\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.766 | 8.461  | 0.886  |  nan  |  nan  | 2.766 |\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 6.425 | brec_Cht         | nan   | lam_Sltst  | 0.000 |\n",
            "| skel_WkstPkst | nan   | strless_SltstSst | 1.873 |            |       |\n",
            "\u001b[32m[07/09 21:44:15 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: 3.0031,8.7741,2.2966,nan,nan,3.0031\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 21:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: 2.7659,8.4614,0.8864,nan,nan,2.7659\n",
            "\u001b[32m[07/09 21:44:15 d2.utils.events]: \u001b[0m eta: 1:56:17  iter: 199  total_loss: 1.660  loss_cls: 0.399  loss_box_reg: 0.426  loss_mask: 0.471  loss_rpn_cls: 0.138  loss_rpn_loc: 0.208  time: 3.8906  data_time: 2.8416  lr: 0.000200  max_mem: 8001M\n",
            "\u001b[32m[07/09 21:45:32 d2.utils.events]: \u001b[0m eta: 1:55:09  iter: 219  total_loss: 1.628  loss_cls: 0.410  loss_box_reg: 0.419  loss_mask: 0.447  loss_rpn_cls: 0.131  loss_rpn_loc: 0.197  time: 3.8882  data_time: 2.8213  lr: 0.000220  max_mem: 8074M\n",
            "\u001b[32m[07/09 21:46:50 d2.utils.events]: \u001b[0m eta: 1:54:20  iter: 239  total_loss: 1.657  loss_cls: 0.448  loss_box_reg: 0.468  loss_mask: 0.432  loss_rpn_cls: 0.127  loss_rpn_loc: 0.184  time: 3.8906  data_time: 2.8741  lr: 0.000240  max_mem: 8308M\n",
            "\u001b[32m[07/09 21:48:09 d2.utils.events]: \u001b[0m eta: 1:53:34  iter: 259  total_loss: 1.644  loss_cls: 0.467  loss_box_reg: 0.463  loss_mask: 0.406  loss_rpn_cls: 0.126  loss_rpn_loc: 0.190  time: 3.8947  data_time: 2.9198  lr: 0.000260  max_mem: 8308M\n",
            "\u001b[32m[07/09 21:49:28 d2.utils.events]: \u001b[0m eta: 1:52:14  iter: 279  total_loss: 1.594  loss_cls: 0.462  loss_box_reg: 0.469  loss_mask: 0.389  loss_rpn_cls: 0.115  loss_rpn_loc: 0.176  time: 3.8976  data_time: 2.8903  lr: 0.000280  max_mem: 8308M\n",
            "\u001b[32m[07/09 21:50:46 d2.utils.events]: \u001b[0m eta: 1:50:23  iter: 299  total_loss: 1.613  loss_cls: 0.469  loss_box_reg: 0.464  loss_mask: 0.366  loss_rpn_cls: 0.112  loss_rpn_loc: 0.169  time: 3.8979  data_time: 2.8484  lr: 0.000300  max_mem: 8674M\n",
            "\u001b[32m[07/09 21:52:04 d2.utils.events]: \u001b[0m eta: 1:49:26  iter: 319  total_loss: 1.506  loss_cls: 0.417  loss_box_reg: 0.443  loss_mask: 0.354  loss_rpn_cls: 0.109  loss_rpn_loc: 0.175  time: 3.8980  data_time: 2.8548  lr: 0.000320  max_mem: 8674M\n",
            "\u001b[32m[07/09 21:53:23 d2.utils.events]: \u001b[0m eta: 1:48:14  iter: 339  total_loss: 1.570  loss_cls: 0.468  loss_box_reg: 0.477  loss_mask: 0.346  loss_rpn_cls: 0.109  loss_rpn_loc: 0.174  time: 3.9003  data_time: 2.8656  lr: 0.000340  max_mem: 8674M\n",
            "\u001b[32m[07/09 21:54:42 d2.utils.events]: \u001b[0m eta: 1:47:02  iter: 359  total_loss: 1.557  loss_cls: 0.480  loss_box_reg: 0.478  loss_mask: 0.341  loss_rpn_cls: 0.101  loss_rpn_loc: 0.172  time: 3.9051  data_time: 2.9033  lr: 0.000360  max_mem: 8674M\n",
            "\u001b[32m[07/09 21:56:01 d2.utils.events]: \u001b[0m eta: 1:45:42  iter: 379  total_loss: 1.473  loss_cls: 0.439  loss_box_reg: 0.441  loss_mask: 0.319  loss_rpn_cls: 0.099  loss_rpn_loc: 0.165  time: 3.9058  data_time: 2.8630  lr: 0.000380  max_mem: 8674M\n",
            "\u001b[32m[07/09 21:57:34 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 21:57:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 21:57:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 21:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2689 s / img. ETA=0:02:39\n",
            "\u001b[32m[07/09 21:58:21 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2577 s / img. ETA=0:02:27\n",
            "\u001b[32m[07/09 21:58:27 d2.evaluation.evaluator]: \u001b[0mInference done 15/56. 0.2551 s / img. ETA=0:02:18\n",
            "\u001b[32m[07/09 21:58:32 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.2465 s / img. ETA=0:02:06\n",
            "\u001b[32m[07/09 21:58:39 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.2346 s / img. ETA=0:01:50\n",
            "\u001b[32m[07/09 21:58:46 d2.evaluation.evaluator]: \u001b[0mInference done 23/56. 0.2250 s / img. ETA=0:01:36\n",
            "\u001b[32m[07/09 21:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 26/56. 0.2213 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/09 21:59:00 d2.evaluation.evaluator]: \u001b[0mInference done 29/56. 0.2142 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/09 21:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 32/56. 0.2113 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/09 21:59:15 d2.evaluation.evaluator]: \u001b[0mInference done 34/56. 0.2104 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/09 21:59:25 d2.evaluation.evaluator]: \u001b[0mInference done 36/56. 0.2100 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/09 21:59:34 d2.evaluation.evaluator]: \u001b[0mInference done 38/56. 0.2093 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/09 21:59:40 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.2090 s / img. ETA=0:00:53\n",
            "\u001b[32m[07/09 21:59:46 d2.evaluation.evaluator]: \u001b[0mInference done 42/56. 0.2043 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/09 21:59:52 d2.evaluation.evaluator]: \u001b[0mInference done 44/56. 0.2069 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/09 21:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.2093 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/09 22:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.2117 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/09 22:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.2134 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/09 22:00:18 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.2151 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/09 22:00:24 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.2165 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/09 22:00:30 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.2178 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 22:00:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:37.184890 (3.082057 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:00:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.217812 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:00:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:00:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:00:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.67s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.134\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.073\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.068\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.374\n",
            "\u001b[32m[07/09 22:00:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.375 | 31.642 | 7.290  |  nan  |  nan  | 13.375 |\n",
            "\u001b[32m[07/09 22:00:31 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:00:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.827 | brec_Cht         | 16.320 | lam_Sltst  | 4.027 |\n",
            "| skel_WkstPkst | 13.347 | strless_SltstSst | 12.352 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.90s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.324\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.146\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.692 | 32.442 | 14.622 |  nan  |  nan  | 15.692 |\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.355 | brec_Cht         | 22.405 | lam_Sltst  | 4.146 |\n",
            "| skel_WkstPkst | 15.629 | strless_SltstSst | 12.926 |            |       |\n",
            "\u001b[32m[07/09 22:00:32 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: 13.3746,31.6415,7.2901,nan,nan,13.3746\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:00:32 d2.evaluation.testing]: \u001b[0mcopypaste: 15.6923,32.4416,14.6219,nan,nan,15.6923\n",
            "\u001b[32m[07/09 22:00:36 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:00:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 22:00:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 22:01:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1993 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/09 22:01:15 d2.evaluation.evaluator]: \u001b[0mInference done 13/15. 0.2070 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/09 22:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 15/15. 0.2107 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 22:01:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.808951 (2.880895 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:01:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.210696 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:01:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:01:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.156\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.298\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 6.203 | 17.690 | 1.525  |  nan  |  nan  | 6.203 |\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 12.057 | brec_Cht         | nan   | lam_Sltst  | 0.597 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 5.954 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 6.535 | 17.357 | 3.426  |  nan  |  nan  | 6.540 |\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 11.404 | brec_Cht         | nan   | lam_Sltst  | 0.597 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 7.603 |            |       |\n",
            "\u001b[32m[07/09 22:01:21 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.testing]: \u001b[0mcopypaste: 6.2029,17.6897,1.5251,nan,nan,6.2029\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:01:21 d2.evaluation.testing]: \u001b[0mcopypaste: 6.5349,17.3574,3.4264,nan,nan,6.5396\n",
            "\u001b[32m[07/09 22:01:21 d2.utils.events]: \u001b[0m eta: 1:44:26  iter: 399  total_loss: 1.489  loss_cls: 0.451  loss_box_reg: 0.444  loss_mask: 0.320  loss_rpn_cls: 0.097  loss_rpn_loc: 0.167  time: 3.9073  data_time: 2.8505  lr: 0.000400  max_mem: 8674M\n",
            "\u001b[32m[07/09 22:02:39 d2.utils.events]: \u001b[0m eta: 1:43:12  iter: 419  total_loss: 1.417  loss_cls: 0.440  loss_box_reg: 0.421  loss_mask: 0.312  loss_rpn_cls: 0.093  loss_rpn_loc: 0.170  time: 3.9059  data_time: 2.8182  lr: 0.000420  max_mem: 8674M\n",
            "\u001b[32m[07/09 22:03:56 d2.utils.events]: \u001b[0m eta: 1:41:48  iter: 439  total_loss: 1.456  loss_cls: 0.455  loss_box_reg: 0.429  loss_mask: 0.314  loss_rpn_cls: 0.091  loss_rpn_loc: 0.162  time: 3.9036  data_time: 2.7728  lr: 0.000440  max_mem: 8674M\n",
            "\u001b[32m[07/09 22:05:14 d2.utils.events]: \u001b[0m eta: 1:40:36  iter: 459  total_loss: 1.410  loss_cls: 0.431  loss_box_reg: 0.429  loss_mask: 0.304  loss_rpn_cls: 0.087  loss_rpn_loc: 0.157  time: 3.9032  data_time: 2.8398  lr: 0.000460  max_mem: 8732M\n",
            "\u001b[32m[07/09 22:06:32 d2.utils.events]: \u001b[0m eta: 1:39:17  iter: 479  total_loss: 1.417  loss_cls: 0.433  loss_box_reg: 0.425  loss_mask: 0.292  loss_rpn_cls: 0.079  loss_rpn_loc: 0.165  time: 3.9035  data_time: 2.8163  lr: 0.000480  max_mem: 8732M\n",
            "\u001b[32m[07/09 22:07:50 d2.utils.events]: \u001b[0m eta: 1:37:54  iter: 499  total_loss: 1.391  loss_cls: 0.444  loss_box_reg: 0.405  loss_mask: 0.290  loss_rpn_cls: 0.085  loss_rpn_loc: 0.166  time: 3.9028  data_time: 2.8003  lr: 0.000500  max_mem: 8732M\n",
            "\u001b[32m[07/09 22:09:08 d2.utils.events]: \u001b[0m eta: 1:36:36  iter: 519  total_loss: 1.378  loss_cls: 0.456  loss_box_reg: 0.416  loss_mask: 0.288  loss_rpn_cls: 0.079  loss_rpn_loc: 0.167  time: 3.9028  data_time: 2.7918  lr: 0.000519  max_mem: 8732M\n",
            "\u001b[32m[07/09 22:10:26 d2.utils.events]: \u001b[0m eta: 1:35:15  iter: 539  total_loss: 1.439  loss_cls: 0.459  loss_box_reg: 0.444  loss_mask: 0.291  loss_rpn_cls: 0.082  loss_rpn_loc: 0.165  time: 3.9028  data_time: 2.8334  lr: 0.000539  max_mem: 8772M\n",
            "\u001b[32m[07/09 22:11:45 d2.utils.events]: \u001b[0m eta: 1:34:04  iter: 559  total_loss: 1.332  loss_cls: 0.421  loss_box_reg: 0.410  loss_mask: 0.280  loss_rpn_cls: 0.081  loss_rpn_loc: 0.152  time: 3.9054  data_time: 2.9010  lr: 0.000559  max_mem: 8772M\n",
            "\u001b[32m[07/09 22:13:05 d2.utils.events]: \u001b[0m eta: 1:32:50  iter: 579  total_loss: 1.363  loss_cls: 0.439  loss_box_reg: 0.447  loss_mask: 0.274  loss_rpn_cls: 0.070  loss_rpn_loc: 0.154  time: 3.9075  data_time: 2.8856  lr: 0.000579  max_mem: 8800M\n",
            "\u001b[32m[07/09 22:14:40 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:14:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 22:14:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 22:15:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2710 s / img. ETA=0:02:45\n",
            "\u001b[32m[07/09 22:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2641 s / img. ETA=0:02:33\n",
            "\u001b[32m[07/09 22:15:37 d2.evaluation.evaluator]: \u001b[0mInference done 15/56. 0.2652 s / img. ETA=0:02:24\n",
            "\u001b[32m[07/09 22:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.2616 s / img. ETA=0:02:13\n",
            "\u001b[32m[07/09 22:15:48 d2.evaluation.evaluator]: \u001b[0mInference done 19/56. 0.2531 s / img. ETA=0:02:02\n",
            "\u001b[32m[07/09 22:15:53 d2.evaluation.evaluator]: \u001b[0mInference done 21/56. 0.2453 s / img. ETA=0:01:52\n",
            "\u001b[32m[07/09 22:15:58 d2.evaluation.evaluator]: \u001b[0mInference done 23/56. 0.2406 s / img. ETA=0:01:44\n",
            "\u001b[32m[07/09 22:16:03 d2.evaluation.evaluator]: \u001b[0mInference done 25/56. 0.2368 s / img. ETA=0:01:36\n",
            "\u001b[32m[07/09 22:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 27/56. 0.2336 s / img. ETA=0:01:29\n",
            "\u001b[32m[07/09 22:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 29/56. 0.2298 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/09 22:16:19 d2.evaluation.evaluator]: \u001b[0mInference done 31/56. 0.2273 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/09 22:16:24 d2.evaluation.evaluator]: \u001b[0mInference done 33/56. 0.2254 s / img. ETA=0:01:08\n",
            "\u001b[32m[07/09 22:16:34 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.2240 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/09 22:16:39 d2.evaluation.evaluator]: \u001b[0mInference done 36/56. 0.2232 s / img. ETA=0:01:03\n",
            "\u001b[32m[07/09 22:16:44 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.2225 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/09 22:16:50 d2.evaluation.evaluator]: \u001b[0mInference done 38/56. 0.2218 s / img. ETA=0:00:59\n",
            "\u001b[32m[07/09 22:16:55 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.2212 s / img. ETA=0:00:56\n",
            "\u001b[32m[07/09 22:17:00 d2.evaluation.evaluator]: \u001b[0mInference done 41/56. 0.2186 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/09 22:17:06 d2.evaluation.evaluator]: \u001b[0mInference done 43/56. 0.2180 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/09 22:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 45/56. 0.2199 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/09 22:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.2219 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/09 22:17:26 d2.evaluation.evaluator]: \u001b[0mInference done 49/56. 0.2232 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/09 22:17:32 d2.evaluation.evaluator]: \u001b[0mInference done 51/56. 0.2245 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/09 22:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.2256 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/09 22:17:45 d2.evaluation.evaluator]: \u001b[0mInference done 55/56. 0.2265 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/09 22:17:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:46.362309 (3.262006 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:17:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.227001 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:17:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:17:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:17:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.66s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.469\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.229\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.101\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
            "\u001b[32m[07/09 22:17:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 22.915 | 46.902 | 20.011 |  nan  |  nan  | 22.915 |\n",
            "\u001b[32m[07/09 22:17:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:17:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 24.748 | brec_Cht         | 26.210 | lam_Sltst  | 18.819 |\n",
            "| skel_WkstPkst | 17.403 | strless_SltstSst | 27.393 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.91s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.470\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.240\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.449\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.565\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.143 | 46.970 | 24.000 |  nan  |  nan  | 25.143 |\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 26.801 | brec_Cht         | 32.486 | lam_Sltst  | 19.288 |\n",
            "| skel_WkstPkst | 18.704 | strless_SltstSst | 28.435 |            |        |\n",
            "\u001b[32m[07/09 22:17:50 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.testing]: \u001b[0mcopypaste: 22.9146,46.9019,20.0113,nan,nan,22.9146\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:17:50 d2.evaluation.testing]: \u001b[0mcopypaste: 25.1428,46.9698,24.0000,nan,nan,25.1428\n",
            "\u001b[32m[07/09 22:17:53 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:17:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 22:17:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 22:18:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.2033 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/09 22:18:33 d2.evaluation.evaluator]: \u001b[0mInference done 13/15. 0.2091 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 15/15. 0.2165 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.880477 (2.988048 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.216466 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.244\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.036\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.023\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.228\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.767 | 24.354 | 3.584  |  nan  |  nan  | 8.767 |\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:18:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 14.751 | brec_Cht         | nan   | lam_Sltst  | 1.837 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 9.713 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.22s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.249\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.096\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.240\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.568 | 24.885 | 6.526  |  nan  |  nan  | 9.569 |\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 16.621 | brec_Cht         | nan    | lam_Sltst  | 1.744 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 10.339 |            |       |\n",
            "\u001b[32m[07/09 22:18:40 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.testing]: \u001b[0mcopypaste: 8.7674,24.3542,3.5843,nan,nan,8.7674\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:18:40 d2.evaluation.testing]: \u001b[0mcopypaste: 9.5676,24.8847,6.5261,nan,nan,9.5685\n",
            "\u001b[32m[07/09 22:18:40 d2.utils.events]: \u001b[0m eta: 1:31:37  iter: 599  total_loss: 1.289  loss_cls: 0.406  loss_box_reg: 0.392  loss_mask: 0.276  loss_rpn_cls: 0.067  loss_rpn_loc: 0.158  time: 3.9126  data_time: 2.9658  lr: 0.000599  max_mem: 8800M\n",
            "\u001b[32m[07/09 22:19:58 d2.utils.events]: \u001b[0m eta: 1:30:20  iter: 619  total_loss: 1.308  loss_cls: 0.419  loss_box_reg: 0.411  loss_mask: 0.278  loss_rpn_cls: 0.071  loss_rpn_loc: 0.156  time: 3.9120  data_time: 2.8033  lr: 0.000619  max_mem: 8800M\n",
            "\u001b[32m[07/09 22:21:18 d2.utils.events]: \u001b[0m eta: 1:29:07  iter: 639  total_loss: 1.274  loss_cls: 0.392  loss_box_reg: 0.389  loss_mask: 0.276  loss_rpn_cls: 0.071  loss_rpn_loc: 0.149  time: 3.9147  data_time: 2.9317  lr: 0.000639  max_mem: 8800M\n",
            "\u001b[32m[07/09 22:22:38 d2.utils.events]: \u001b[0m eta: 1:27:56  iter: 659  total_loss: 1.362  loss_cls: 0.429  loss_box_reg: 0.408  loss_mask: 0.260  loss_rpn_cls: 0.064  loss_rpn_loc: 0.159  time: 3.9170  data_time: 2.8851  lr: 0.000659  max_mem: 8800M\n",
            "\u001b[32m[07/09 22:23:57 d2.utils.events]: \u001b[0m eta: 1:26:40  iter: 679  total_loss: 1.326  loss_cls: 0.410  loss_box_reg: 0.402  loss_mask: 0.266  loss_rpn_cls: 0.064  loss_rpn_loc: 0.159  time: 3.9192  data_time: 2.8938  lr: 0.000679  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:25:16 d2.utils.events]: \u001b[0m eta: 1:25:24  iter: 699  total_loss: 1.262  loss_cls: 0.402  loss_box_reg: 0.395  loss_mask: 0.257  loss_rpn_cls: 0.064  loss_rpn_loc: 0.149  time: 3.9194  data_time: 2.8285  lr: 0.000699  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:26:35 d2.utils.events]: \u001b[0m eta: 1:24:06  iter: 719  total_loss: 1.253  loss_cls: 0.395  loss_box_reg: 0.376  loss_mask: 0.257  loss_rpn_cls: 0.060  loss_rpn_loc: 0.150  time: 3.9205  data_time: 2.8734  lr: 0.000719  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:27:53 d2.utils.events]: \u001b[0m eta: 1:22:47  iter: 739  total_loss: 1.229  loss_cls: 0.378  loss_box_reg: 0.398  loss_mask: 0.255  loss_rpn_cls: 0.057  loss_rpn_loc: 0.149  time: 3.9195  data_time: 2.7921  lr: 0.000739  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:29:11 d2.utils.events]: \u001b[0m eta: 1:21:27  iter: 759  total_loss: 1.224  loss_cls: 0.379  loss_box_reg: 0.385  loss_mask: 0.246  loss_rpn_cls: 0.059  loss_rpn_loc: 0.140  time: 3.9191  data_time: 2.8010  lr: 0.000759  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:30:30 d2.utils.events]: \u001b[0m eta: 1:20:09  iter: 779  total_loss: 1.182  loss_cls: 0.363  loss_box_reg: 0.383  loss_mask: 0.248  loss_rpn_cls: 0.056  loss_rpn_loc: 0.140  time: 3.9196  data_time: 2.8223  lr: 0.000779  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:32:02 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:32:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 22:32:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 22:32:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2723 s / img. ETA=0:02:43\n",
            "\u001b[32m[07/09 22:32:52 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2676 s / img. ETA=0:02:34\n",
            "\u001b[32m[07/09 22:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 15/56. 0.2661 s / img. ETA=0:02:24\n",
            "\u001b[32m[07/09 22:33:04 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.2575 s / img. ETA=0:02:12\n",
            "\u001b[32m[07/09 22:33:11 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.2423 s / img. ETA=0:01:54\n",
            "\u001b[32m[07/09 22:33:17 d2.evaluation.evaluator]: \u001b[0mInference done 23/56. 0.2312 s / img. ETA=0:01:39\n",
            "\u001b[32m[07/09 22:33:25 d2.evaluation.evaluator]: \u001b[0mInference done 26/56. 0.2257 s / img. ETA=0:01:28\n",
            "\u001b[32m[07/09 22:33:31 d2.evaluation.evaluator]: \u001b[0mInference done 29/56. 0.2166 s / img. ETA=0:01:16\n",
            "\u001b[32m[07/09 22:33:38 d2.evaluation.evaluator]: \u001b[0mInference done 32/56. 0.2133 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/09 22:33:45 d2.evaluation.evaluator]: \u001b[0mInference done 34/56. 0.2124 s / img. ETA=0:01:02\n",
            "\u001b[32m[07/09 22:33:50 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.2123 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/09 22:34:00 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.2114 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/09 22:34:10 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.2107 s / img. ETA=0:00:53\n",
            "\u001b[32m[07/09 22:34:17 d2.evaluation.evaluator]: \u001b[0mInference done 42/56. 0.2057 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/09 22:34:23 d2.evaluation.evaluator]: \u001b[0mInference done 44/56. 0.2083 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/09 22:34:30 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.2107 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/09 22:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.2130 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/09 22:34:43 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.2148 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/09 22:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.2164 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/09 22:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.2177 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/09 22:35:01 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.2190 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 22:35:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:38.520590 (3.108247 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:35:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.218969 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:35:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:35:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:35:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.64s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.690\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.471\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.409\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.602\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n",
            "\u001b[32m[07/09 22:35:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 40.872 | 69.043 | 47.137 |  nan  |  nan  | 40.872 |\n",
            "\u001b[32m[07/09 22:35:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:35:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 40.369 | brec_Cht         | 54.333 | lam_Sltst  | 32.760 |\n",
            "| skel_WkstPkst | 34.498 | strless_SltstSst | 42.402 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.90s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.689\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.486\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.636\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 43.281 | 68.878 | 48.623 |  nan  |  nan  | 43.281 |\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 43.940 | brec_Cht         | 60.262 | lam_Sltst  | 33.261 |\n",
            "| skel_WkstPkst | 34.735 | strless_SltstSst | 44.204 |            |        |\n",
            "\u001b[32m[07/09 22:35:04 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.testing]: \u001b[0mcopypaste: 40.8724,69.0428,47.1371,nan,nan,40.8724\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:35:04 d2.evaluation.testing]: \u001b[0mcopypaste: 43.2806,68.8776,48.6233,nan,nan,43.2808\n",
            "\u001b[32m[07/09 22:35:07 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:35:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 22:35:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 22:35:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1961 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/09 22:35:46 d2.evaluation.evaluator]: \u001b[0mInference done 13/15. 0.2048 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 15/15. 0.2080 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.982907 (2.898291 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.207993 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.116\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.319 | 29.518 | 11.607 |  nan  |  nan  | 13.319 |\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 19.594 | brec_Cht         | nan    | lam_Sltst  | 8.358 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 12.005 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.143\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.148\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.143\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.518\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.285 | 30.407 | 14.810 |  nan  |  nan  | 14.285 |\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.353 | brec_Cht         | nan    | lam_Sltst  | 8.123 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 13.379 |            |       |\n",
            "\u001b[32m[07/09 22:35:52 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.testing]: \u001b[0mcopypaste: 13.3189,29.5179,11.6066,nan,nan,13.3189\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:35:52 d2.evaluation.testing]: \u001b[0mcopypaste: 14.2849,30.4070,14.8097,nan,nan,14.2849\n",
            "\u001b[32m[07/09 22:35:52 d2.utils.events]: \u001b[0m eta: 1:18:50  iter: 799  total_loss: 1.123  loss_cls: 0.326  loss_box_reg: 0.345  loss_mask: 0.241  loss_rpn_cls: 0.057  loss_rpn_loc: 0.158  time: 3.9200  data_time: 2.8404  lr: 0.000799  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:37:11 d2.utils.events]: \u001b[0m eta: 1:17:32  iter: 819  total_loss: 1.157  loss_cls: 0.356  loss_box_reg: 0.346  loss_mask: 0.247  loss_rpn_cls: 0.057  loss_rpn_loc: 0.152  time: 3.9200  data_time: 2.8149  lr: 0.000819  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:38:29 d2.utils.events]: \u001b[0m eta: 1:16:13  iter: 839  total_loss: 1.186  loss_cls: 0.378  loss_box_reg: 0.370  loss_mask: 0.241  loss_rpn_cls: 0.058  loss_rpn_loc: 0.131  time: 3.9206  data_time: 2.8469  lr: 0.000839  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:39:48 d2.utils.events]: \u001b[0m eta: 1:14:54  iter: 859  total_loss: 1.125  loss_cls: 0.343  loss_box_reg: 0.346  loss_mask: 0.236  loss_rpn_cls: 0.053  loss_rpn_loc: 0.149  time: 3.9203  data_time: 2.8221  lr: 0.000859  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:41:07 d2.utils.events]: \u001b[0m eta: 1:13:37  iter: 879  total_loss: 1.123  loss_cls: 0.334  loss_box_reg: 0.344  loss_mask: 0.237  loss_rpn_cls: 0.051  loss_rpn_loc: 0.149  time: 3.9209  data_time: 2.8419  lr: 0.000879  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:42:26 d2.utils.events]: \u001b[0m eta: 1:12:22  iter: 899  total_loss: 1.101  loss_cls: 0.332  loss_box_reg: 0.343  loss_mask: 0.242  loss_rpn_cls: 0.051  loss_rpn_loc: 0.137  time: 3.9216  data_time: 2.8648  lr: 0.000899  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:43:44 d2.utils.events]: \u001b[0m eta: 1:11:03  iter: 919  total_loss: 1.124  loss_cls: 0.329  loss_box_reg: 0.372  loss_mask: 0.242  loss_rpn_cls: 0.049  loss_rpn_loc: 0.153  time: 3.9217  data_time: 2.8312  lr: 0.000919  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:45:02 d2.utils.events]: \u001b[0m eta: 1:09:45  iter: 939  total_loss: 1.091  loss_cls: 0.323  loss_box_reg: 0.347  loss_mask: 0.235  loss_rpn_cls: 0.050  loss_rpn_loc: 0.142  time: 3.9213  data_time: 2.7984  lr: 0.000939  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:46:22 d2.utils.events]: \u001b[0m eta: 1:08:28  iter: 959  total_loss: 1.064  loss_cls: 0.320  loss_box_reg: 0.338  loss_mask: 0.231  loss_rpn_cls: 0.043  loss_rpn_loc: 0.136  time: 3.9222  data_time: 2.8600  lr: 0.000959  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:47:40 d2.utils.events]: \u001b[0m eta: 1:07:08  iter: 979  total_loss: 1.047  loss_cls: 0.328  loss_box_reg: 0.338  loss_mask: 0.228  loss_rpn_cls: 0.042  loss_rpn_loc: 0.135  time: 3.9220  data_time: 2.8241  lr: 0.000979  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:49:13 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:49:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 22:49:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 22:49:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2590 s / img. ETA=0:02:38\n",
            "\u001b[32m[07/09 22:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2485 s / img. ETA=0:02:26\n",
            "\u001b[32m[07/09 22:50:06 d2.evaluation.evaluator]: \u001b[0mInference done 15/56. 0.2417 s / img. ETA=0:02:14\n",
            "\u001b[32m[07/09 22:50:12 d2.evaluation.evaluator]: \u001b[0mInference done 18/56. 0.2249 s / img. ETA=0:01:54\n",
            "\u001b[32m[07/09 22:50:18 d2.evaluation.evaluator]: \u001b[0mInference done 22/56. 0.1989 s / img. ETA=0:01:29\n",
            "\u001b[32m[07/09 22:50:25 d2.evaluation.evaluator]: \u001b[0mInference done 26/56. 0.1847 s / img. ETA=0:01:13\n",
            "\u001b[32m[07/09 22:50:30 d2.evaluation.evaluator]: \u001b[0mInference done 30/56. 0.1724 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/09 22:50:36 d2.evaluation.evaluator]: \u001b[0mInference done 33/56. 0.1705 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/09 22:50:42 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.1681 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/09 22:50:48 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1659 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/09 22:50:55 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1652 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/09 22:51:02 d2.evaluation.evaluator]: \u001b[0mInference done 43/56. 0.1600 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/09 22:51:07 d2.evaluation.evaluator]: \u001b[0mInference done 45/56. 0.1623 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/09 22:51:14 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.1667 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/09 22:51:20 d2.evaluation.evaluator]: \u001b[0mInference done 49/56. 0.1706 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/09 22:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 51/56. 0.1741 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/09 22:51:33 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.1772 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 22:51:39 d2.evaluation.evaluator]: \u001b[0mInference done 55/56. 0.1801 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 22:51:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:08.763954 (2.524783 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:51:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.181450 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:51:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:51:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:51:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.55s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.733\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.480\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.563\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.627\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n",
            "\u001b[32m[07/09 22:51:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 44.593 | 73.294 | 48.011 |  nan  |  nan  | 44.593 |\n",
            "\u001b[32m[07/09 22:51:43 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:51:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 48.928 | brec_Cht         | 52.022 | lam_Sltst  | 38.682 |\n",
            "| skel_WkstPkst | 34.908 | strless_SltstSst | 48.424 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.15s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.81s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.730\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.548\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.593\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 48.170 | 72.992 | 54.812 |  nan  |  nan  | 48.170 |\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 52.918 | brec_Cht         | 57.708 | lam_Sltst  | 38.665 |\n",
            "| skel_WkstPkst | 42.425 | strless_SltstSst | 49.133 |            |        |\n",
            "\u001b[32m[07/09 22:51:44 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.testing]: \u001b[0mcopypaste: 44.5928,73.2944,48.0109,nan,nan,44.5928\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:51:44 d2.evaluation.testing]: \u001b[0mcopypaste: 48.1697,72.9923,54.8116,nan,nan,48.1697\n",
            "\u001b[32m[07/09 22:51:47 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 22:51:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 22:51:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 22:52:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1389 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/09 22:52:20 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1606 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.241907 (2.124191 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.156237 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.053\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.057 | 33.288 | 18.645 |  nan  |  nan  | 17.057 |\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:52:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 29.801 | brec_Cht         | nan    | lam_Sltst  | 8.806 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 12.565 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.189\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 18.924 | 33.824 | 20.918 |  nan  |  nan  | 18.924 |\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 32.719 | brec_Cht         | nan    | lam_Sltst  | 9.575 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 14.476 |            |       |\n",
            "\u001b[32m[07/09 22:52:22 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.testing]: \u001b[0mcopypaste: 17.0575,33.2877,18.6451,nan,nan,17.0575\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 22:52:22 d2.evaluation.testing]: \u001b[0mcopypaste: 18.9235,33.8235,20.9184,nan,nan,18.9235\n",
            "\u001b[32m[07/09 22:52:22 d2.utils.events]: \u001b[0m eta: 1:05:48  iter: 999  total_loss: 1.069  loss_cls: 0.312  loss_box_reg: 0.332  loss_mask: 0.230  loss_rpn_cls: 0.041  loss_rpn_loc: 0.140  time: 3.9227  data_time: 2.8565  lr: 0.000999  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:53:40 d2.utils.events]: \u001b[0m eta: 1:04:26  iter: 1019  total_loss: 1.063  loss_cls: 0.305  loss_box_reg: 0.347  loss_mask: 0.222  loss_rpn_cls: 0.046  loss_rpn_loc: 0.136  time: 3.9225  data_time: 2.8028  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:54:58 d2.utils.events]: \u001b[0m eta: 1:03:12  iter: 1039  total_loss: 1.008  loss_cls: 0.279  loss_box_reg: 0.323  loss_mask: 0.219  loss_rpn_cls: 0.040  loss_rpn_loc: 0.134  time: 3.9225  data_time: 2.8097  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:56:17 d2.utils.events]: \u001b[0m eta: 1:01:51  iter: 1059  total_loss: 1.016  loss_cls: 0.278  loss_box_reg: 0.331  loss_mask: 0.227  loss_rpn_cls: 0.039  loss_rpn_loc: 0.149  time: 3.9227  data_time: 2.8236  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:57:36 d2.utils.events]: \u001b[0m eta: 1:00:35  iter: 1079  total_loss: 1.040  loss_cls: 0.309  loss_box_reg: 0.327  loss_mask: 0.226  loss_rpn_cls: 0.039  loss_rpn_loc: 0.138  time: 3.9232  data_time: 2.8334  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 22:58:54 d2.utils.events]: \u001b[0m eta: 0:59:14  iter: 1099  total_loss: 0.995  loss_cls: 0.279  loss_box_reg: 0.316  loss_mask: 0.216  loss_rpn_cls: 0.035  loss_rpn_loc: 0.132  time: 3.9228  data_time: 2.7869  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:00:12 d2.utils.events]: \u001b[0m eta: 0:57:57  iter: 1119  total_loss: 1.007  loss_cls: 0.282  loss_box_reg: 0.320  loss_mask: 0.219  loss_rpn_cls: 0.035  loss_rpn_loc: 0.130  time: 3.9226  data_time: 2.8231  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:01:30 d2.utils.events]: \u001b[0m eta: 0:56:37  iter: 1139  total_loss: 0.895  loss_cls: 0.232  loss_box_reg: 0.295  loss_mask: 0.212  loss_rpn_cls: 0.035  loss_rpn_loc: 0.125  time: 3.9221  data_time: 2.7802  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:02:49 d2.utils.events]: \u001b[0m eta: 0:55:18  iter: 1159  total_loss: 0.949  loss_cls: 0.263  loss_box_reg: 0.309  loss_mask: 0.207  loss_rpn_cls: 0.038  loss_rpn_loc: 0.123  time: 3.9226  data_time: 2.8449  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:04:08 d2.utils.events]: \u001b[0m eta: 0:54:01  iter: 1179  total_loss: 0.935  loss_cls: 0.268  loss_box_reg: 0.305  loss_mask: 0.208  loss_rpn_cls: 0.034  loss_rpn_loc: 0.127  time: 3.9227  data_time: 2.7864  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:05:40 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:05:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 23:05:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 23:06:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2403 s / img. ETA=0:02:31\n",
            "\u001b[32m[07/09 23:06:24 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2305 s / img. ETA=0:02:19\n",
            "\u001b[32m[07/09 23:06:32 d2.evaluation.evaluator]: \u001b[0mInference done 16/56. 0.2184 s / img. ETA=0:02:01\n",
            "\u001b[32m[07/09 23:06:38 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.1923 s / img. ETA=0:01:34\n",
            "\u001b[32m[07/09 23:06:44 d2.evaluation.evaluator]: \u001b[0mInference done 24/56. 0.1763 s / img. ETA=0:01:16\n",
            "\u001b[32m[07/09 23:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 28/56. 0.1662 s / img. ETA=0:01:02\n",
            "\u001b[32m[07/09 23:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 32/56. 0.1611 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/09 23:07:04 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.1587 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/09 23:07:11 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1576 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/09 23:07:18 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1572 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/09 23:07:25 d2.evaluation.evaluator]: \u001b[0mInference done 43/56. 0.1534 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/09 23:07:30 d2.evaluation.evaluator]: \u001b[0mInference done 45/56. 0.1558 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/09 23:07:37 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.1604 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/09 23:07:43 d2.evaluation.evaluator]: \u001b[0mInference done 49/56. 0.1645 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/09 23:07:49 d2.evaluation.evaluator]: \u001b[0mInference done 51/56. 0.1685 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/09 23:07:55 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.1711 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 23:08:01 d2.evaluation.evaluator]: \u001b[0mInference done 55/56. 0.1735 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:05.233536 (2.455560 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.174922 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.54s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.568\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.856\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.680\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.649\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.692\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.692\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 56.825 | 85.588 | 68.006 |  nan  |  nan  | 56.825 |\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:08:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 54.318 | brec_Cht         | 68.325 | lam_Sltst  | 49.699 |\n",
            "| skel_WkstPkst | 53.291 | strless_SltstSst | 58.493 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.73s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.846\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.652\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.696\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.696\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 56.615 | 84.559 | 67.645 |  nan  |  nan  | 56.615 |\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 57.905 | brec_Cht         | 68.479 | lam_Sltst  | 47.757 |\n",
            "| skel_WkstPkst | 51.447 | strless_SltstSst | 57.489 |            |        |\n",
            "\u001b[32m[07/09 23:08:05 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.testing]: \u001b[0mcopypaste: 56.8251,85.5880,68.0063,nan,nan,56.8251\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:08:05 d2.evaluation.testing]: \u001b[0mcopypaste: 56.6153,84.5587,67.6449,nan,nan,56.6153\n",
            "\u001b[32m[07/09 23:08:09 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:08:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 23:08:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 23:08:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1409 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/09 23:08:42 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1634 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.732955 (2.173296 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.158908 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.132\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.151\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.052\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.075 | 30.227 | 13.186 |  nan  |  nan  | 15.075 |\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.371 | brec_Cht         | nan    | lam_Sltst  | 9.278 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 14.575 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.166\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.297\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.176\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.166\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.555\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 16.636 | 29.712 | 17.598 |  nan  |  nan  | 16.636 |\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.633 | brec_Cht         | nan    | lam_Sltst  | 9.618 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 16.657 |            |       |\n",
            "\u001b[32m[07/09 23:08:43 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.testing]: \u001b[0mcopypaste: 15.0750,30.2273,13.1861,nan,nan,15.0750\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:08:43 d2.evaluation.testing]: \u001b[0mcopypaste: 16.6361,29.7120,17.5981,nan,nan,16.6361\n",
            "\u001b[32m[07/09 23:08:43 d2.utils.events]: \u001b[0m eta: 0:52:42  iter: 1199  total_loss: 0.930  loss_cls: 0.247  loss_box_reg: 0.313  loss_mask: 0.206  loss_rpn_cls: 0.031  loss_rpn_loc: 0.134  time: 3.9222  data_time: 2.7785  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:10:01 d2.utils.events]: \u001b[0m eta: 0:51:22  iter: 1219  total_loss: 0.877  loss_cls: 0.225  loss_box_reg: 0.303  loss_mask: 0.201  loss_rpn_cls: 0.032  loss_rpn_loc: 0.125  time: 3.9218  data_time: 2.7776  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:11:20 d2.utils.events]: \u001b[0m eta: 0:50:03  iter: 1239  total_loss: 0.860  loss_cls: 0.228  loss_box_reg: 0.281  loss_mask: 0.205  loss_rpn_cls: 0.032  loss_rpn_loc: 0.112  time: 3.9223  data_time: 2.8578  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:12:39 d2.utils.events]: \u001b[0m eta: 0:48:44  iter: 1259  total_loss: 0.895  loss_cls: 0.241  loss_box_reg: 0.299  loss_mask: 0.201  loss_rpn_cls: 0.026  loss_rpn_loc: 0.124  time: 3.9225  data_time: 2.8266  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:13:58 d2.utils.events]: \u001b[0m eta: 0:47:27  iter: 1279  total_loss: 0.876  loss_cls: 0.236  loss_box_reg: 0.278  loss_mask: 0.202  loss_rpn_cls: 0.031  loss_rpn_loc: 0.126  time: 3.9232  data_time: 2.8592  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:15:17 d2.utils.events]: \u001b[0m eta: 0:46:09  iter: 1299  total_loss: 0.872  loss_cls: 0.226  loss_box_reg: 0.289  loss_mask: 0.204  loss_rpn_cls: 0.029  loss_rpn_loc: 0.123  time: 3.9235  data_time: 2.8240  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:16:36 d2.utils.events]: \u001b[0m eta: 0:44:50  iter: 1319  total_loss: 0.896  loss_cls: 0.251  loss_box_reg: 0.279  loss_mask: 0.200  loss_rpn_cls: 0.030  loss_rpn_loc: 0.128  time: 3.9238  data_time: 2.8621  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:17:55 d2.utils.events]: \u001b[0m eta: 0:43:30  iter: 1339  total_loss: 0.912  loss_cls: 0.258  loss_box_reg: 0.314  loss_mask: 0.196  loss_rpn_cls: 0.030  loss_rpn_loc: 0.127  time: 3.9242  data_time: 2.8261  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:19:14 d2.utils.events]: \u001b[0m eta: 0:42:11  iter: 1359  total_loss: 0.847  loss_cls: 0.226  loss_box_reg: 0.277  loss_mask: 0.201  loss_rpn_cls: 0.030  loss_rpn_loc: 0.121  time: 3.9242  data_time: 2.8450  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:20:33 d2.utils.events]: \u001b[0m eta: 0:40:54  iter: 1379  total_loss: 0.862  loss_cls: 0.226  loss_box_reg: 0.288  loss_mask: 0.196  loss_rpn_cls: 0.031  loss_rpn_loc: 0.115  time: 3.9250  data_time: 2.8466  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:22:05 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:22:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 23:22:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 23:22:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1990 s / img. ETA=0:02:09\n",
            "\u001b[32m[07/09 23:22:46 d2.evaluation.evaluator]: \u001b[0mInference done 14/56. 0.1849 s / img. ETA=0:01:50\n",
            "\u001b[32m[07/09 23:22:52 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.1792 s / img. ETA=0:01:36\n",
            "\u001b[32m[07/09 23:22:57 d2.evaluation.evaluator]: \u001b[0mInference done 22/56. 0.1527 s / img. ETA=0:01:09\n",
            "\u001b[32m[07/09 23:23:02 d2.evaluation.evaluator]: \u001b[0mInference done 27/56. 0.1390 s / img. ETA=0:00:53\n",
            "\u001b[32m[07/09 23:23:09 d2.evaluation.evaluator]: \u001b[0mInference done 32/56. 0.1322 s / img. ETA=0:00:41\n",
            "\u001b[32m[07/09 23:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.1308 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/09 23:23:21 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1305 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/09 23:23:27 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1305 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/09 23:23:32 d2.evaluation.evaluator]: \u001b[0mInference done 43/56. 0.1271 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/09 23:23:39 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.1300 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/09 23:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.1343 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/09 23:23:51 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.1395 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/09 23:23:57 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.1432 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/09 23:24:02 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.1464 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/09 23:24:07 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.1487 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:45.694200 (2.072435 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.148698 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.45s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.934\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.783\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.697\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 64.357 | 93.421 | 78.317 |  nan  |  nan  | 64.357 |\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:24:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 64.507 | brec_Cht         | 73.075 | lam_Sltst  | 56.939 |\n",
            "| skel_WkstPkst | 58.137 | strless_SltstSst | 69.127 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.10s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.66s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.932\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.764\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.701\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 64.955 | 93.163 | 76.438 |  nan  |  nan  | 64.955 |\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 64.932 | brec_Cht         | 75.603 | lam_Sltst  | 55.158 |\n",
            "| skel_WkstPkst | 60.363 | strless_SltstSst | 68.721 |            |        |\n",
            "\u001b[32m[07/09 23:24:09 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: 64.3569,93.4207,78.3168,nan,nan,64.3569\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: 64.9555,93.1630,76.4383,nan,nan,64.9555\n",
            "\u001b[32m[07/09 23:24:12 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:24:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 23:24:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 23:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1161 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/09 23:24:40 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1328 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.095279 (1.809528 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.132218 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.153\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.996 | 33.422 | 15.341 |  nan  |  nan  | 15.996 |\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 27.133 | brec_Cht         | nan    | lam_Sltst  | 4.717 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 16.138 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.368\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.515\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 16.707 | 32.289 | 16.000 |  nan  |  nan  | 16.707 |\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 29.050 | brec_Cht         | nan    | lam_Sltst  | 4.200 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 16.871 |            |       |\n",
            "\u001b[32m[07/09 23:24:42 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.testing]: \u001b[0mcopypaste: 15.9959,33.4216,15.3410,nan,nan,15.9959\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:24:42 d2.evaluation.testing]: \u001b[0mcopypaste: 16.7067,32.2889,16.0005,nan,nan,16.7067\n",
            "\u001b[32m[07/09 23:24:42 d2.utils.events]: \u001b[0m eta: 0:39:35  iter: 1399  total_loss: 0.826  loss_cls: 0.216  loss_box_reg: 0.281  loss_mask: 0.195  loss_rpn_cls: 0.028  loss_rpn_loc: 0.118  time: 3.9247  data_time: 2.8047  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:26:00 d2.utils.events]: \u001b[0m eta: 0:38:16  iter: 1419  total_loss: 0.793  loss_cls: 0.194  loss_box_reg: 0.265  loss_mask: 0.192  loss_rpn_cls: 0.028  loss_rpn_loc: 0.107  time: 3.9243  data_time: 2.8040  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:27:18 d2.utils.events]: \u001b[0m eta: 0:36:57  iter: 1439  total_loss: 0.930  loss_cls: 0.238  loss_box_reg: 0.307  loss_mask: 0.218  loss_rpn_cls: 0.030  loss_rpn_loc: 0.139  time: 3.9242  data_time: 2.7938  lr: 0.001000  max_mem: 8998M\n",
            "\u001b[32m[07/09 23:28:38 d2.utils.events]: \u001b[0m eta: 0:35:37  iter: 1459  total_loss: 0.875  loss_cls: 0.236  loss_box_reg: 0.285  loss_mask: 0.196  loss_rpn_cls: 0.030  loss_rpn_loc: 0.126  time: 3.9246  data_time: 2.8575  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:29:56 d2.utils.events]: \u001b[0m eta: 0:34:19  iter: 1479  total_loss: 0.807  loss_cls: 0.198  loss_box_reg: 0.265  loss_mask: 0.191  loss_rpn_cls: 0.031  loss_rpn_loc: 0.119  time: 3.9247  data_time: 2.8038  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:31:16 d2.utils.events]: \u001b[0m eta: 0:33:00  iter: 1499  total_loss: 0.820  loss_cls: 0.193  loss_box_reg: 0.280  loss_mask: 0.191  loss_rpn_cls: 0.027  loss_rpn_loc: 0.119  time: 3.9258  data_time: 2.8948  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:32:35 d2.utils.events]: \u001b[0m eta: 0:31:41  iter: 1519  total_loss: 0.783  loss_cls: 0.186  loss_box_reg: 0.260  loss_mask: 0.183  loss_rpn_cls: 0.028  loss_rpn_loc: 0.126  time: 3.9258  data_time: 2.7949  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:33:54 d2.utils.events]: \u001b[0m eta: 0:30:23  iter: 1539  total_loss: 0.772  loss_cls: 0.189  loss_box_reg: 0.261  loss_mask: 0.187  loss_rpn_cls: 0.029  loss_rpn_loc: 0.111  time: 3.9262  data_time: 2.8437  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:35:14 d2.utils.events]: \u001b[0m eta: 0:29:05  iter: 1559  total_loss: 0.762  loss_cls: 0.177  loss_box_reg: 0.259  loss_mask: 0.181  loss_rpn_cls: 0.025  loss_rpn_loc: 0.114  time: 3.9268  data_time: 2.8560  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:36:33 d2.utils.events]: \u001b[0m eta: 0:27:45  iter: 1579  total_loss: 0.757  loss_cls: 0.174  loss_box_reg: 0.252  loss_mask: 0.183  loss_rpn_cls: 0.022  loss_rpn_loc: 0.116  time: 3.9271  data_time: 2.8191  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:38:06 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:38:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 23:38:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 23:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2136 s / img. ETA=0:02:17\n",
            "\u001b[32m[07/09 23:38:48 d2.evaluation.evaluator]: \u001b[0mInference done 14/56. 0.1943 s / img. ETA=0:01:56\n",
            "\u001b[32m[07/09 23:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.1834 s / img. ETA=0:01:40\n",
            "\u001b[32m[07/09 23:38:59 d2.evaluation.evaluator]: \u001b[0mInference done 22/56. 0.1561 s / img. ETA=0:01:12\n",
            "\u001b[32m[07/09 23:39:04 d2.evaluation.evaluator]: \u001b[0mInference done 27/56. 0.1414 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/09 23:39:10 d2.evaluation.evaluator]: \u001b[0mInference done 32/56. 0.1333 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/09 23:39:16 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.1312 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/09 23:39:21 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1306 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/09 23:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1304 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/09 23:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 43/56. 0.1274 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/09 23:39:39 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.1307 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/09 23:39:46 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.1360 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/09 23:39:52 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.1411 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/09 23:39:58 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.1444 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/09 23:40:04 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.1476 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/09 23:40:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:45.818605 (2.074875 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:40:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.149493 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:40:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:40:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:40:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.43s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.714\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.959\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.874\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.749\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783\n",
            "\u001b[32m[07/09 23:40:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 71.419 | 95.907 | 87.366 |  nan  |  nan  | 71.419 |\n",
            "\u001b[32m[07/09 23:40:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:40:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 70.563 | brec_Cht         | 73.805 | lam_Sltst  | 67.841 |\n",
            "| skel_WkstPkst | 71.160 | strless_SltstSst | 73.726 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.59s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.710\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.959\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.831\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 71.027 | 95.925 | 83.063 |  nan  |  nan  | 71.027 |\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 71.936 | brec_Cht         | 75.912 | lam_Sltst  | 65.658 |\n",
            "| skel_WkstPkst | 68.267 | strless_SltstSst | 73.361 |            |        |\n",
            "\u001b[32m[07/09 23:40:10 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.testing]: \u001b[0mcopypaste: 71.4191,95.9075,87.3663,nan,nan,71.4191\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:40:10 d2.evaluation.testing]: \u001b[0mcopypaste: 71.0269,95.9245,83.0627,nan,nan,71.0270\n",
            "\u001b[32m[07/09 23:40:13 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:40:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 23:40:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 23:40:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1191 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 23:40:42 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1432 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.324570 (1.932457 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.141134 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.147\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.472\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.697 | 29.600 | 13.006 |  nan  |  nan  | 14.697 |\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.669 | brec_Cht         | nan    | lam_Sltst  | 3.565 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 16.856 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.161\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.373\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.200 | 33.357 | 16.132 |  nan  |  nan  | 17.200 |\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 28.649 | brec_Cht         | nan    | lam_Sltst  | 4.363 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 18.587 |            |       |\n",
            "\u001b[32m[07/09 23:40:44 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.testing]: \u001b[0mcopypaste: 14.6968,29.6002,13.0056,nan,nan,14.6968\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:40:44 d2.evaluation.testing]: \u001b[0mcopypaste: 17.1999,33.3572,16.1320,nan,nan,17.1999\n",
            "\u001b[32m[07/09 23:40:44 d2.utils.events]: \u001b[0m eta: 0:26:26  iter: 1599  total_loss: 0.709  loss_cls: 0.160  loss_box_reg: 0.242  loss_mask: 0.178  loss_rpn_cls: 0.025  loss_rpn_loc: 0.099  time: 3.9274  data_time: 2.8504  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:42:02 d2.utils.events]: \u001b[0m eta: 0:25:07  iter: 1619  total_loss: 0.701  loss_cls: 0.160  loss_box_reg: 0.233  loss_mask: 0.174  loss_rpn_cls: 0.021  loss_rpn_loc: 0.105  time: 3.9273  data_time: 2.8008  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:43:22 d2.utils.events]: \u001b[0m eta: 0:23:47  iter: 1639  total_loss: 0.710  loss_cls: 0.166  loss_box_reg: 0.234  loss_mask: 0.176  loss_rpn_cls: 0.021  loss_rpn_loc: 0.109  time: 3.9277  data_time: 2.8724  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:44:41 d2.utils.events]: \u001b[0m eta: 0:22:27  iter: 1659  total_loss: 0.688  loss_cls: 0.165  loss_box_reg: 0.224  loss_mask: 0.170  loss_rpn_cls: 0.020  loss_rpn_loc: 0.108  time: 3.9282  data_time: 2.8485  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:46:00 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 1679  total_loss: 0.727  loss_cls: 0.179  loss_box_reg: 0.252  loss_mask: 0.179  loss_rpn_cls: 0.023  loss_rpn_loc: 0.105  time: 3.9283  data_time: 2.8168  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:47:18 d2.utils.events]: \u001b[0m eta: 0:19:49  iter: 1699  total_loss: 0.681  loss_cls: 0.159  loss_box_reg: 0.227  loss_mask: 0.168  loss_rpn_cls: 0.022  loss_rpn_loc: 0.108  time: 3.9283  data_time: 2.8203  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:48:36 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 1719  total_loss: 0.714  loss_cls: 0.156  loss_box_reg: 0.235  loss_mask: 0.175  loss_rpn_cls: 0.020  loss_rpn_loc: 0.102  time: 3.9279  data_time: 2.7794  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:49:54 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 1739  total_loss: 0.703  loss_cls: 0.165  loss_box_reg: 0.228  loss_mask: 0.166  loss_rpn_cls: 0.019  loss_rpn_loc: 0.102  time: 3.9276  data_time: 2.7811  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:51:13 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 1759  total_loss: 0.664  loss_cls: 0.149  loss_box_reg: 0.227  loss_mask: 0.171  loss_rpn_cls: 0.020  loss_rpn_loc: 0.100  time: 3.9275  data_time: 2.8145  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:52:32 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 1779  total_loss: 0.686  loss_cls: 0.158  loss_box_reg: 0.214  loss_mask: 0.168  loss_rpn_cls: 0.021  loss_rpn_loc: 0.105  time: 3.9277  data_time: 2.8203  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:54:05 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:54:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/09 23:54:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/09 23:54:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2191 s / img. ETA=0:02:19\n",
            "\u001b[32m[07/09 23:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.2133 s / img. ETA=0:02:10\n",
            "\u001b[32m[07/09 23:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 16/56. 0.2045 s / img. ETA=0:01:53\n",
            "\u001b[32m[07/09 23:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 21/56. 0.1700 s / img. ETA=0:01:20\n",
            "\u001b[32m[07/09 23:55:04 d2.evaluation.evaluator]: \u001b[0mInference done 26/56. 0.1519 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/09 23:55:09 d2.evaluation.evaluator]: \u001b[0mInference done 31/56. 0.1397 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/09 23:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 34/56. 0.1371 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/09 23:55:21 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1344 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/09 23:55:26 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1338 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/09 23:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 44/56. 0.1300 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/09 23:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.1327 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/09 23:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.1365 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/09 23:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.1419 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/09 23:55:56 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.1446 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 23:56:03 d2.evaluation.evaluator]: \u001b[0mInference done 55/56. 0.1483 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:44.085278 (2.040888 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.149552 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.43s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.719\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.971\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.886\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.756\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 71.940 | 97.082 | 88.619 |  nan  |  nan  | 71.940 |\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:56:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 71.760 | brec_Cht         | 75.953 | lam_Sltst  | 71.359 |\n",
            "| skel_WkstPkst | 65.174 | strless_SltstSst | 75.453 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.62s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.727\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.969\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.866\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.762\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.790\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.790\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 72.685 | 96.895 | 86.632 |  nan  |  nan  | 72.685 |\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 73.831 | brec_Cht         | 80.185 | lam_Sltst  | 69.454 |\n",
            "| skel_WkstPkst | 63.960 | strless_SltstSst | 75.997 |            |        |\n",
            "\u001b[32m[07/09 23:56:07 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: 71.9398,97.0815,88.6192,nan,nan,71.9398\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: 72.6854,96.8947,86.6316,nan,nan,72.6854\n",
            "\u001b[32m[07/09 23:56:11 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 23:56:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/09 23:56:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/09 23:56:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1229 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 23:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1405 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.934705 (1.893470 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.138525 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.368\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.899 | 36.783 | 16.273 |  nan  |  nan  | 17.899 |\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 26.056 | brec_Cht         | nan    | lam_Sltst  | 7.186 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 20.454 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.182\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.193\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.367\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.518\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 19.307 | 37.380 | 18.219 |  nan  |  nan  | 19.307 |\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 23:56:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 28.347 | brec_Cht         | nan    | lam_Sltst  | 8.040 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 21.534 |            |       |\n",
            "\u001b[32m[07/09 23:56:42 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/09 23:56:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 23:56:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:56:42 d2.evaluation.testing]: \u001b[0mcopypaste: 17.8988,36.7828,16.2732,nan,nan,17.8988\n",
            "\u001b[32m[07/09 23:56:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 23:56:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 23:56:42 d2.evaluation.testing]: \u001b[0mcopypaste: 19.3071,37.3802,18.2195,nan,nan,19.3071\n",
            "\u001b[32m[07/09 23:56:42 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 1799  total_loss: 0.702  loss_cls: 0.166  loss_box_reg: 0.239  loss_mask: 0.171  loss_rpn_cls: 0.021  loss_rpn_loc: 0.106  time: 3.9283  data_time: 2.8781  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:57:59 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 1819  total_loss: 0.665  loss_cls: 0.152  loss_box_reg: 0.215  loss_mask: 0.163  loss_rpn_cls: 0.025  loss_rpn_loc: 0.103  time: 3.9277  data_time: 2.7659  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/09 23:59:18 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 1839  total_loss: 0.674  loss_cls: 0.157  loss_box_reg: 0.229  loss_mask: 0.168  loss_rpn_cls: 0.019  loss_rpn_loc: 0.106  time: 3.9278  data_time: 2.8081  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:00:37 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 1859  total_loss: 0.665  loss_cls: 0.147  loss_box_reg: 0.217  loss_mask: 0.169  loss_rpn_cls: 0.019  loss_rpn_loc: 0.094  time: 3.9282  data_time: 2.8567  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:01:56 d2.utils.events]: \u001b[0m eta: 0:07:57  iter: 1879  total_loss: 0.664  loss_cls: 0.144  loss_box_reg: 0.224  loss_mask: 0.171  loss_rpn_cls: 0.018  loss_rpn_loc: 0.106  time: 3.9281  data_time: 2.7993  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:03:14 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 1899  total_loss: 0.684  loss_cls: 0.156  loss_box_reg: 0.231  loss_mask: 0.169  loss_rpn_cls: 0.021  loss_rpn_loc: 0.106  time: 3.9282  data_time: 2.8422  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:04:34 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 1919  total_loss: 0.676  loss_cls: 0.156  loss_box_reg: 0.232  loss_mask: 0.172  loss_rpn_cls: 0.022  loss_rpn_loc: 0.109  time: 3.9288  data_time: 2.9038  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:05:52 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 1939  total_loss: 0.643  loss_cls: 0.140  loss_box_reg: 0.211  loss_mask: 0.157  loss_rpn_cls: 0.018  loss_rpn_loc: 0.108  time: 3.9284  data_time: 2.7905  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:07:11 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 1959  total_loss: 0.649  loss_cls: 0.140  loss_box_reg: 0.221  loss_mask: 0.159  loss_rpn_cls: 0.019  loss_rpn_loc: 0.102  time: 3.9286  data_time: 2.8381  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:08:29 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 1979  total_loss: 0.605  loss_cls: 0.124  loss_box_reg: 0.208  loss_mask: 0.150  loss_rpn_cls: 0.018  loss_rpn_loc: 0.102  time: 3.9285  data_time: 2.8126  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:10:03 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 00:10:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 00:10:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/10 00:10:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1812 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/10 00:10:39 d2.evaluation.evaluator]: \u001b[0mInference done 14/56. 0.1666 s / img. ETA=0:01:40\n",
            "\u001b[32m[07/10 00:10:44 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.1596 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/10 00:10:49 d2.evaluation.evaluator]: \u001b[0mInference done 23/56. 0.1334 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/10 00:10:55 d2.evaluation.evaluator]: \u001b[0mInference done 29/56. 0.1208 s / img. ETA=0:00:41\n",
            "\u001b[32m[07/10 00:11:01 d2.evaluation.evaluator]: \u001b[0mInference done 34/56. 0.1170 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 00:11:06 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1149 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/10 00:11:13 d2.evaluation.evaluator]: \u001b[0mInference done 40/56. 0.1140 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 00:11:20 d2.evaluation.evaluator]: \u001b[0mInference done 45/56. 0.1137 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/10 00:11:27 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.1186 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 00:11:33 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.1238 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 00:11:39 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.1267 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 00:11:45 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.1293 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 00:11:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:27.764160 (1.720866 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:11:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.129291 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:11:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 00:11:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 00:11:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.35s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.765\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.993\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.944\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.779\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800\n",
            "\u001b[32m[07/10 00:11:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 76.459 | 99.259 | 94.362 |  nan  |  nan  | 76.459 |\n",
            "\u001b[32m[07/10 00:11:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:11:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 74.968 | brec_Cht         | 80.009 | lam_Sltst  | 73.356 |\n",
            "| skel_WkstPkst | 77.024 | strless_SltstSst | 76.940 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.51s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.786\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.993\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.940\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.822\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.822\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 78.641 | 99.259 | 94.004 |  nan  |  nan  | 78.641 |\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 78.059 | brec_Cht         | 83.862 | lam_Sltst  | 72.369 |\n",
            "| skel_WkstPkst | 79.370 | strless_SltstSst | 79.543 |            |        |\n",
            "\u001b[32m[07/10 00:11:47 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.testing]: \u001b[0mcopypaste: 76.4592,99.2592,94.3620,nan,nan,76.4592\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 00:11:47 d2.evaluation.testing]: \u001b[0mcopypaste: 78.6407,99.2592,94.0041,nan,nan,78.6407\n",
            "\u001b[32m[07/10 00:11:50 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 00:11:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 00:11:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/10 00:12:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1103 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 00:12:18 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1282 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.574525 (1.757452 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.126288 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.788 | 30.824 | 13.678 |  nan  |  nan  | 14.788 |\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.618 | brec_Cht         | nan    | lam_Sltst  | 2.279 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 17.467 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.449 | 31.240 | 18.594 |  nan  |  nan  | 17.449 |\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 30.700 | brec_Cht         | nan    | lam_Sltst  | 2.334 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 19.314 |            |       |\n",
            "\u001b[32m[07/10 00:12:19 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: 14.7882,30.8240,13.6784,nan,nan,14.7882\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 00:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: 17.4493,31.2403,18.5942,nan,nan,17.4493\n",
            "\u001b[32m[07/10 00:12:19 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 1999  total_loss: 0.617  loss_cls: 0.127  loss_box_reg: 0.226  loss_mask: 0.159  loss_rpn_cls: 0.019  loss_rpn_loc: 0.096  time: 3.9288  data_time: 2.8162  lr: 0.001000  max_mem: 9119M\n",
            "\u001b[32m[07/10 00:12:19 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 2:10:49 (3.9308 s / it)\n",
            "\u001b[32m[07/10 00:12:19 d2.engine.hooks]: \u001b[0mTotal training time: 2:49:07 (0:38:17 on hooks)\n",
            "\n",
            "\n",
            "**Starting train eval**\n",
            "\u001b[32m[07/10 00:12:33 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 00:12:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 00:12:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/10 00:13:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1826 s / img. ETA=0:03:57\n",
            "\u001b[32m[07/10 00:13:36 d2.evaluation.evaluator]: \u001b[0mInference done 12/56. 0.1845 s / img. ETA=0:03:51\n",
            "\u001b[32m[07/10 00:13:45 d2.evaluation.evaluator]: \u001b[0mInference done 15/56. 0.1666 s / img. ETA=0:03:06\n",
            "\u001b[32m[07/10 00:13:50 d2.evaluation.evaluator]: \u001b[0mInference done 16/56. 0.1677 s / img. ETA=0:03:04\n",
            "\u001b[32m[07/10 00:13:55 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.1592 s / img. ETA=0:02:15\n",
            "\u001b[32m[07/10 00:14:01 d2.evaluation.evaluator]: \u001b[0mInference done 25/56. 0.1395 s / img. ETA=0:01:36\n",
            "\u001b[32m[07/10 00:14:08 d2.evaluation.evaluator]: \u001b[0mInference done 30/56. 0.1294 s / img. ETA=0:01:11\n",
            "\u001b[32m[07/10 00:14:14 d2.evaluation.evaluator]: \u001b[0mInference done 33/56. 0.1268 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/10 00:14:20 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.1227 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/10 00:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 40/56. 0.1213 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/10 00:14:33 d2.evaluation.evaluator]: \u001b[0mInference done 44/56. 0.1194 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/10 00:14:42 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.1214 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 00:14:53 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.1246 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 00:15:01 d2.evaluation.evaluator]: \u001b[0mInference done 49/56. 0.1274 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/10 00:15:07 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.1292 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/10 00:15:13 d2.evaluation.evaluator]: \u001b[0mInference done 51/56. 0.1307 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/10 00:15:21 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.1319 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 00:15:27 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.1335 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 00:15:35 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.1343 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 00:15:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:36.070855 (3.060213 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:15:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.134264 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:15:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 00:15:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/10 00:15:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.765\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.993\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.944\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.779\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800\n",
            "\u001b[32m[07/10 00:15:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 76.459 | 99.259 | 94.362 |  nan  |  nan  | 76.459 |\n",
            "\u001b[32m[07/10 00:15:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:15:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 74.968 | brec_Cht         | 80.009 | lam_Sltst  | 73.356 |\n",
            "| skel_WkstPkst | 77.024 | strless_SltstSst | 76.940 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.51s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.786\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.993\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.940\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.822\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.822\n",
            "\u001b[32m[07/10 00:15:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 78.641 | 99.259 | 94.004 |  nan  |  nan  | 78.641 |\n",
            "\u001b[32m[07/10 00:15:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:15:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 78.059 | brec_Cht         | 83.862 | lam_Sltst  | 72.369 |\n",
            "| skel_WkstPkst | 79.370 | strless_SltstSst | 79.543 |            |        |\n",
            "randomly selected cores/Box 8 Depths 10035-45.JPG\n",
            "\n",
            "\n",
            "**Starting val eval**\n",
            "\u001b[32m[07/10 00:16:16 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 00:16:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 00:16:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/10 00:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1113 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 00:16:56 d2.evaluation.evaluator]: \u001b[0mInference done 13/15. 0.1228 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 00:17:02 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1298 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.177241 (2.917724 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.127673 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.788 | 30.824 | 13.678 |  nan  |  nan  | 14.788 |\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.618 | brec_Cht         | nan    | lam_Sltst  | 2.279 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 17.467 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.449 | 31.240 | 18.594 |  nan  |  nan  | 17.449 |\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 00:17:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 30.700 | brec_Cht         | nan    | lam_Sltst  | 2.334 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 19.314 |            |       |\n",
            "randomly selected cores/Boxes 40-42  Depths 7829.5-7838.8 (Dry).JPG\n",
            "Fri Jul 10 00:17:40 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    36W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "CPU times: user 20.8 s, sys: 2.93 s, total: 23.7 s\n",
            "Wall time: 2h 55min 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_hb1WlvLaZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87312ea0-91f3-46ec-ac54-be6db1128f34"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '1' --max_iter 2000\n",
        "# copy results to Google Drive\n",
        "! cp -r output_fold_1 'drive/My Drive/R50-C4'\n",
        "# clean folders if upcoming experiment\n",
        "! rm -r *coco*\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 1\n",
            "\t cores_fold_1_train\n",
            "\t cores_fold_1_val\n",
            "\u001b[32m[07/10 12:33:10 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/10 12:33:22 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 56 images left.\n",
            "\u001b[32m[07/10 12:33:22 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 234          |   brec_Cht    | 4            | lam_Sltst  | 98           |\n",
            "| skel_WkstPkst | 18           | strless_Slt.. | 139          |            |              |\n",
            "|     total     | 493          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/10 12:33:22 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 12:33:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 12:33:22 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/10 12:33:22 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-10 12:33:23.255749: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "model_final_4ce675.pkl: 144MB [00:17, 8.15MB/s]               \n",
            "Unable to load 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (15, 4) in the checkpoint but (3, 4) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (1024, 1024, 3, 3) in the checkpoint but (256, 256, 3, 3) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (256,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (15, 1024, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (15,) in the checkpoint but (3,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (60, 1024, 1, 1) in the checkpoint but (12, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (60,) in the checkpoint but (12,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.deconv.weight' to the model due to incompatible shapes: (2048, 256, 2, 2) in the checkpoint but (256, 256, 2, 2) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/10 12:33:48 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/10 12:34:59 d2.utils.events]: \u001b[0m eta: 1:56:00  iter: 19  total_loss: 44.874  loss_cls: 30.200  loss_box_reg: 0.322  loss_mask: 1.507  loss_rpn_cls: 0.605  loss_rpn_loc: 9.271  time: 3.4944  data_time: 2.7295  lr: 0.000020  max_mem: 6781M\n",
            "\u001b[32m[07/10 12:36:09 d2.utils.events]: \u001b[0m eta: 1:54:40  iter: 39  total_loss: 8.960  loss_cls: 6.726  loss_box_reg: 0.196  loss_mask: 0.583  loss_rpn_cls: 0.272  loss_rpn_loc: 0.984  time: 3.5073  data_time: 2.6801  lr: 0.000040  max_mem: 6782M\n",
            "\u001b[32m[07/10 12:37:19 d2.utils.events]: \u001b[0m eta: 1:53:25  iter: 59  total_loss: 3.233  loss_cls: 1.766  loss_box_reg: 0.308  loss_mask: 0.581  loss_rpn_cls: 0.215  loss_rpn_loc: 0.362  time: 3.4967  data_time: 2.5485  lr: 0.000060  max_mem: 6802M\n",
            "\u001b[32m[07/10 12:38:28 d2.utils.events]: \u001b[0m eta: 1:52:09  iter: 79  total_loss: 1.980  loss_cls: 0.577  loss_box_reg: 0.333  loss_mask: 0.559  loss_rpn_cls: 0.189  loss_rpn_loc: 0.297  time: 3.4907  data_time: 2.5499  lr: 0.000080  max_mem: 7024M\n",
            "\u001b[32m[07/10 12:39:37 d2.utils.events]: \u001b[0m eta: 1:49:34  iter: 99  total_loss: 1.734  loss_cls: 0.378  loss_box_reg: 0.354  loss_mask: 0.545  loss_rpn_cls: 0.190  loss_rpn_loc: 0.273  time: 3.4845  data_time: 2.5441  lr: 0.000100  max_mem: 7057M\n",
            "\u001b[32m[07/10 12:40:46 d2.utils.events]: \u001b[0m eta: 1:48:19  iter: 119  total_loss: 1.649  loss_cls: 0.326  loss_box_reg: 0.374  loss_mask: 0.534  loss_rpn_cls: 0.165  loss_rpn_loc: 0.247  time: 3.4789  data_time: 2.5276  lr: 0.000120  max_mem: 7371M\n",
            "\u001b[32m[07/10 12:41:55 d2.utils.events]: \u001b[0m eta: 1:47:16  iter: 139  total_loss: 1.630  loss_cls: 0.374  loss_box_reg: 0.369  loss_mask: 0.523  loss_rpn_cls: 0.158  loss_rpn_loc: 0.226  time: 3.4716  data_time: 2.4844  lr: 0.000140  max_mem: 7371M\n",
            "\u001b[32m[07/10 12:43:03 d2.utils.events]: \u001b[0m eta: 1:45:48  iter: 159  total_loss: 1.620  loss_cls: 0.350  loss_box_reg: 0.383  loss_mask: 0.509  loss_rpn_cls: 0.158  loss_rpn_loc: 0.214  time: 3.4651  data_time: 2.4682  lr: 0.000160  max_mem: 7569M\n",
            "\u001b[32m[07/10 12:44:12 d2.utils.events]: \u001b[0m eta: 1:44:45  iter: 179  total_loss: 1.611  loss_cls: 0.346  loss_box_reg: 0.406  loss_mask: 0.486  loss_rpn_cls: 0.153  loss_rpn_loc: 0.215  time: 3.4631  data_time: 2.4963  lr: 0.000180  max_mem: 7569M\n",
            "\u001b[32m[07/10 12:45:34 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 12:45:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 12:45:34 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_1_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/10 12:45:34 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_1_train' to COCO format ...)\n",
            "\u001b[32m[07/10 12:45:45 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/10 12:45:45 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 57, #annotations: 493\n",
            "\u001b[32m[07/10 12:45:45 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_1_train_coco_format.json' ...\n",
            "\u001b[32m[07/10 12:45:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0x8f5e4000 @  0x7fba7ceccb6b 0x7fba7ceec379 0x7fba2062104e 0x7fba20622f4a 0x7fba5951167b 0x7fba591606be 0x7fba593c97b5 0x7fba593bb7c1 0x7fba593bad0e 0x7fba593bb7c1 0x7fba5ae1093a 0x7fba593bb7c1 0x7fba5915b457 0x7fba5915c080 0x7fba5947a71a 0x7fba5aef813e 0x7fba593bbc72 0x7fba67455a68 0x7fba67510b04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/10 12:46:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2976 s / img. ETA=0:02:24\n",
            "\u001b[32m[07/10 12:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2888 s / img. ETA=0:02:16\n",
            "\u001b[32m[07/10 12:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2712 s / img. ETA=0:02:14\n",
            "\u001b[32m[07/10 12:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.2595 s / img. ETA=0:02:17\n",
            "\u001b[32m[07/10 12:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2511 s / img. ETA=0:02:17\n",
            "\u001b[32m[07/10 12:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.2453 s / img. ETA=0:02:15\n",
            "\u001b[32m[07/10 12:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2408 s / img. ETA=0:02:11\n",
            "\u001b[32m[07/10 12:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2369 s / img. ETA=0:02:06\n",
            "\u001b[32m[07/10 12:47:32 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.2336 s / img. ETA=0:02:00\n",
            "\u001b[32m[07/10 12:47:41 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.2309 s / img. ETA=0:01:54\n",
            "\u001b[32m[07/10 12:47:50 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2291 s / img. ETA=0:01:47\n",
            "\u001b[32m[07/10 12:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.2257 s / img. ETA=0:01:38\n",
            "\u001b[32m[07/10 12:48:08 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.2240 s / img. ETA=0:01:31\n",
            "\u001b[32m[07/10 12:48:15 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.2226 s / img. ETA=0:01:22\n",
            "\u001b[32m[07/10 12:48:24 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.2212 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/10 12:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.2200 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/10 12:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.2192 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/10 12:48:49 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.2210 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/10 12:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.2226 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/10 12:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.2240 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/10 12:49:07 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.2251 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/10 12:49:13 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.2262 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 12:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.2271 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 12:49:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:17.765396 (3.803181 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 12:49:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.227488 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 12:49:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 12:49:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 12:49:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.61s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.146\n",
            "\u001b[32m[07/10 12:49:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.540 | 9.104  | 0.291  |  nan  |  nan  | 2.540 |\n",
            "\u001b[32m[07/10 12:49:22 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 12:49:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 8.073 | brec_Cht         | 0.000 | lam_Sltst  | 1.275 |\n",
            "| skel_WkstPkst | 0.248 | strless_SltstSst | 3.102 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.19s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.87s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.022\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.022\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.135\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.135\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.193 | 8.777  | 0.220  |  nan  |  nan  | 2.193 |\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 7.217 | brec_Cht         | 0.000 | lam_Sltst  | 1.052 |\n",
            "| skel_WkstPkst | 0.099 | strless_SltstSst | 2.596 |            |       |\n",
            "\u001b[32m[07/10 12:49:23 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.testing]: \u001b[0mcopypaste: 2.5396,9.1036,0.2913,nan,nan,2.5396\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 12:49:23 d2.evaluation.testing]: \u001b[0mcopypaste: 2.1926,8.7774,0.2196,nan,nan,2.1926\n",
            "\u001b[32m[07/10 12:49:27 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 75           |   brec_Cht    | 17           | lam_Sltst  | 29           |\n",
            "| skel_WkstPkst | 8            | strless_Slt.. | 34           |            |              |\n",
            "|     total     | 163          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/10 12:49:27 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 12:49:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 12:49:27 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_1_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/10 12:49:27 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_1_val' to COCO format ...)\n",
            "\u001b[32m[07/10 12:49:30 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/10 12:49:30 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 14, #annotations: 163\n",
            "\u001b[32m[07/10 12:49:30 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_1_val_coco_format.json' ...\n",
            "\u001b[32m[07/10 12:49:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 12:50:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2194 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 12:50:18 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2267 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 12:50:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.248777 (3.694309 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 12:50:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.229143 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 12:50:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 12:50:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 12:50:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.101\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.101\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 1.450 | 5.476  | 0.253  |  nan  |  nan  | 1.450 |\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 4.435 | brec_Cht         | 0.000 | lam_Sltst  | 0.267 |\n",
            "| skel_WkstPkst | 0.000 | strless_SltstSst | 2.548 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.097\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 1.391 | 5.533  | 0.199  |  nan  |  nan  | 1.391 |\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 4.117 | brec_Cht         | 0.000 | lam_Sltst  | 0.284 |\n",
            "| skel_WkstPkst | 0.000 | strless_SltstSst | 2.554 |            |       |\n",
            "\u001b[32m[07/10 12:50:22 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.testing]: \u001b[0mcopypaste: 1.4499,5.4756,0.2531,nan,nan,1.4499\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 12:50:22 d2.evaluation.testing]: \u001b[0mcopypaste: 1.3910,5.5332,0.1988,nan,nan,1.3910\n",
            "\u001b[32m[07/10 12:50:22 d2.utils.events]: \u001b[0m eta: 1:43:26  iter: 199  total_loss: 1.591  loss_cls: 0.355  loss_box_reg: 0.405  loss_mask: 0.471  loss_rpn_cls: 0.142  loss_rpn_loc: 0.221  time: 3.4616  data_time: 2.5002  lr: 0.000200  max_mem: 7786M\n",
            "\u001b[32m[07/10 12:51:30 d2.utils.events]: \u001b[0m eta: 1:42:17  iter: 219  total_loss: 1.585  loss_cls: 0.372  loss_box_reg: 0.425  loss_mask: 0.455  loss_rpn_cls: 0.142  loss_rpn_loc: 0.204  time: 3.4565  data_time: 2.4220  lr: 0.000220  max_mem: 7786M\n",
            "\u001b[32m[07/10 12:52:39 d2.utils.events]: \u001b[0m eta: 1:41:12  iter: 239  total_loss: 1.561  loss_cls: 0.382  loss_box_reg: 0.415  loss_mask: 0.430  loss_rpn_cls: 0.133  loss_rpn_loc: 0.193  time: 3.4566  data_time: 2.4995  lr: 0.000240  max_mem: 7786M\n",
            "\u001b[32m[07/10 12:53:48 d2.utils.events]: \u001b[0m eta: 1:39:55  iter: 259  total_loss: 1.529  loss_cls: 0.377  loss_box_reg: 0.415  loss_mask: 0.410  loss_rpn_cls: 0.125  loss_rpn_loc: 0.185  time: 3.4552  data_time: 2.4523  lr: 0.000260  max_mem: 7928M\n",
            "\u001b[32m[07/10 12:54:57 d2.utils.events]: \u001b[0m eta: 1:38:41  iter: 279  total_loss: 1.531  loss_cls: 0.410  loss_box_reg: 0.419  loss_mask: 0.389  loss_rpn_cls: 0.119  loss_rpn_loc: 0.198  time: 3.4536  data_time: 2.4392  lr: 0.000280  max_mem: 7928M\n",
            "\u001b[32m[07/10 12:56:06 d2.utils.events]: \u001b[0m eta: 1:37:37  iter: 299  total_loss: 1.566  loss_cls: 0.425  loss_box_reg: 0.435  loss_mask: 0.370  loss_rpn_cls: 0.121  loss_rpn_loc: 0.192  time: 3.4536  data_time: 2.4314  lr: 0.000300  max_mem: 8004M\n",
            "\u001b[32m[07/10 12:57:15 d2.utils.events]: \u001b[0m eta: 1:36:32  iter: 319  total_loss: 1.430  loss_cls: 0.362  loss_box_reg: 0.409  loss_mask: 0.346  loss_rpn_cls: 0.108  loss_rpn_loc: 0.181  time: 3.4539  data_time: 2.4736  lr: 0.000320  max_mem: 8267M\n",
            "\u001b[32m[07/10 12:58:25 d2.utils.events]: \u001b[0m eta: 1:35:27  iter: 339  total_loss: 1.466  loss_cls: 0.418  loss_box_reg: 0.438  loss_mask: 0.352  loss_rpn_cls: 0.104  loss_rpn_loc: 0.176  time: 3.4570  data_time: 2.4794  lr: 0.000340  max_mem: 8267M\n",
            "\u001b[32m[07/10 12:59:34 d2.utils.events]: \u001b[0m eta: 1:34:22  iter: 359  total_loss: 1.376  loss_cls: 0.367  loss_box_reg: 0.412  loss_mask: 0.333  loss_rpn_cls: 0.100  loss_rpn_loc: 0.184  time: 3.4553  data_time: 2.4309  lr: 0.000360  max_mem: 8267M\n",
            "\u001b[32m[07/10 13:00:43 d2.utils.events]: \u001b[0m eta: 1:33:19  iter: 379  total_loss: 1.403  loss_cls: 0.391  loss_box_reg: 0.401  loss_mask: 0.320  loss_rpn_cls: 0.100  loss_rpn_loc: 0.181  time: 3.4565  data_time: 2.4705  lr: 0.000380  max_mem: 8267M\n",
            "\u001b[32m[07/10 13:02:04 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:02:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 13:02:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 13:02:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2690 s / img. ETA=0:02:20\n",
            "\u001b[32m[07/10 13:02:46 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2680 s / img. ETA=0:02:12\n",
            "\u001b[32m[07/10 13:02:56 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2548 s / img. ETA=0:02:19\n",
            "\u001b[32m[07/10 13:03:04 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.2436 s / img. ETA=0:02:18\n",
            "\u001b[32m[07/10 13:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2378 s / img. ETA=0:02:18\n",
            "\u001b[32m[07/10 13:03:22 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.2332 s / img. ETA=0:02:15\n",
            "\u001b[32m[07/10 13:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2297 s / img. ETA=0:02:10\n",
            "\u001b[32m[07/10 13:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2269 s / img. ETA=0:02:05\n",
            "\u001b[32m[07/10 13:03:50 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.2244 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/10 13:03:59 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.2225 s / img. ETA=0:01:52\n",
            "\u001b[32m[07/10 13:04:08 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2200 s / img. ETA=0:01:45\n",
            "\u001b[32m[07/10 13:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.2187 s / img. ETA=0:01:37\n",
            "\u001b[32m[07/10 13:04:26 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.2172 s / img. ETA=0:01:30\n",
            "\u001b[32m[07/10 13:04:35 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.2162 s / img. ETA=0:01:22\n",
            "\u001b[32m[07/10 13:04:44 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.2151 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/10 13:04:53 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.2142 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/10 13:05:02 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.2137 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/10 13:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.2114 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/10 13:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.2135 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/10 13:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.2154 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/10 13:05:26 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.2169 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/10 13:05:31 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.2183 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 13:05:37 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.2195 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 13:05:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:17.155810 (3.791458 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:05:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.220058 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:05:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:05:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:05:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.65s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.134\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.322\n",
            "\u001b[32m[07/10 13:05:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.400 | 32.817 | 6.494  |  nan  |  nan  | 13.400 |\n",
            "\u001b[32m[07/10 13:05:40 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:05:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.702 | brec_Cht         | 0.000  | lam_Sltst  | 9.003 |\n",
            "| skel_WkstPkst | 14.410 | strless_SltstSst | 22.888 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.77s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.151\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.103 | 33.270 | 9.606  |  nan  |  nan  | 15.104 |\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 23.410 | brec_Cht         | 0.000  | lam_Sltst  | 10.077 |\n",
            "| skel_WkstPkst | 18.127 | strless_SltstSst | 23.901 |            |        |\n",
            "\u001b[32m[07/10 13:05:41 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.testing]: \u001b[0mcopypaste: 13.4004,32.8171,6.4936,nan,nan,13.4004\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:05:41 d2.evaluation.testing]: \u001b[0mcopypaste: 15.1028,33.2698,9.6058,nan,nan,15.1041\n",
            "\u001b[32m[07/10 13:05:45 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:05:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 13:05:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 13:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2176 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 13:06:31 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2256 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:31.902724 (3.544747 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.228205 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.210\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.318 | 9.672  | 1.627  |  nan  |  nan  | 3.318 |\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 8.976 | brec_Cht         | 0.000 | lam_Sltst  | 0.999 |\n",
            "| skel_WkstPkst | 1.684 | strless_SltstSst | 4.930 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.105\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.158\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 4.171 | 10.480 | 2.889  |  nan  |  nan  | 4.171 |\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 11.152 | brec_Cht         | 0.000 | lam_Sltst  | 1.329 |\n",
            "| skel_WkstPkst | 2.453  | strless_SltstSst | 5.921 |            |       |\n",
            "\u001b[32m[07/10 13:06:34 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: 3.3178,9.6720,1.6274,nan,nan,3.3178\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:06:34 d2.evaluation.testing]: \u001b[0mcopypaste: 4.1711,10.4803,2.8893,nan,nan,4.1711\n",
            "\u001b[32m[07/10 13:06:34 d2.utils.events]: \u001b[0m eta: 1:32:12  iter: 399  total_loss: 1.324  loss_cls: 0.364  loss_box_reg: 0.380  loss_mask: 0.310  loss_rpn_cls: 0.097  loss_rpn_loc: 0.167  time: 3.4547  data_time: 2.4031  lr: 0.000400  max_mem: 8267M\n",
            "\u001b[32m[07/10 13:07:43 d2.utils.events]: \u001b[0m eta: 1:31:03  iter: 419  total_loss: 1.391  loss_cls: 0.397  loss_box_reg: 0.398  loss_mask: 0.307  loss_rpn_cls: 0.097  loss_rpn_loc: 0.198  time: 3.4534  data_time: 2.4386  lr: 0.000420  max_mem: 8267M\n",
            "\u001b[32m[07/10 13:08:52 d2.utils.events]: \u001b[0m eta: 1:29:54  iter: 439  total_loss: 1.375  loss_cls: 0.409  loss_box_reg: 0.409  loss_mask: 0.306  loss_rpn_cls: 0.093  loss_rpn_loc: 0.183  time: 3.4528  data_time: 2.4185  lr: 0.000440  max_mem: 8267M\n",
            "\u001b[32m[07/10 13:10:01 d2.utils.events]: \u001b[0m eta: 1:28:41  iter: 459  total_loss: 1.317  loss_cls: 0.374  loss_box_reg: 0.377  loss_mask: 0.301  loss_rpn_cls: 0.091  loss_rpn_loc: 0.165  time: 3.4536  data_time: 2.4560  lr: 0.000460  max_mem: 8480M\n",
            "\u001b[32m[07/10 13:11:11 d2.utils.events]: \u001b[0m eta: 1:27:31  iter: 479  total_loss: 1.354  loss_cls: 0.355  loss_box_reg: 0.379  loss_mask: 0.293  loss_rpn_cls: 0.088  loss_rpn_loc: 0.171  time: 3.4541  data_time: 2.4440  lr: 0.000480  max_mem: 8480M\n",
            "\u001b[32m[07/10 13:12:20 d2.utils.events]: \u001b[0m eta: 1:26:22  iter: 499  total_loss: 1.309  loss_cls: 0.380  loss_box_reg: 0.382  loss_mask: 0.295  loss_rpn_cls: 0.082  loss_rpn_loc: 0.176  time: 3.4538  data_time: 2.4135  lr: 0.000500  max_mem: 8480M\n",
            "\u001b[32m[07/10 13:13:28 d2.utils.events]: \u001b[0m eta: 1:25:12  iter: 519  total_loss: 1.285  loss_cls: 0.364  loss_box_reg: 0.366  loss_mask: 0.294  loss_rpn_cls: 0.085  loss_rpn_loc: 0.172  time: 3.4528  data_time: 2.4252  lr: 0.000519  max_mem: 8480M\n",
            "\u001b[32m[07/10 13:14:38 d2.utils.events]: \u001b[0m eta: 1:24:05  iter: 539  total_loss: 1.261  loss_cls: 0.359  loss_box_reg: 0.370  loss_mask: 0.281  loss_rpn_cls: 0.083  loss_rpn_loc: 0.168  time: 3.4542  data_time: 2.4584  lr: 0.000539  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:15:47 d2.utils.events]: \u001b[0m eta: 1:22:57  iter: 559  total_loss: 1.241  loss_cls: 0.359  loss_box_reg: 0.377  loss_mask: 0.277  loss_rpn_cls: 0.078  loss_rpn_loc: 0.171  time: 3.4545  data_time: 2.4317  lr: 0.000559  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:16:57 d2.utils.events]: \u001b[0m eta: 1:21:50  iter: 579  total_loss: 1.237  loss_cls: 0.370  loss_box_reg: 0.369  loss_mask: 0.270  loss_rpn_cls: 0.074  loss_rpn_loc: 0.175  time: 3.4552  data_time: 2.4685  lr: 0.000579  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:18:18 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:18:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 13:18:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 13:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2612 s / img. ETA=0:02:16\n",
            "\u001b[32m[07/10 13:18:59 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2526 s / img. ETA=0:02:05\n",
            "\u001b[32m[07/10 13:19:07 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2374 s / img. ETA=0:02:08\n",
            "\u001b[32m[07/10 13:19:13 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.2206 s / img. ETA=0:02:00\n",
            "\u001b[32m[07/10 13:19:21 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2146 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/10 13:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.2083 s / img. ETA=0:01:55\n",
            "\u001b[32m[07/10 13:19:34 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2006 s / img. ETA=0:01:47\n",
            "\u001b[32m[07/10 13:19:41 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.1978 s / img. ETA=0:01:43\n",
            "\u001b[32m[07/10 13:19:49 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.1956 s / img. ETA=0:01:38\n",
            "\u001b[32m[07/10 13:19:57 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.1950 s / img. ETA=0:01:34\n",
            "\u001b[32m[07/10 13:20:03 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1911 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/10 13:20:11 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1844 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/10 13:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.1855 s / img. ETA=0:01:10\n",
            "\u001b[32m[07/10 13:20:29 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1864 s / img. ETA=0:01:04\n",
            "\u001b[32m[07/10 13:20:38 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1867 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/10 13:20:47 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1876 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/10 13:20:53 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1859 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/10 13:21:00 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1881 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/10 13:21:06 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1911 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/10 13:21:12 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1938 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 13:21:17 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1962 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 13:21:23 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1983 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 13:21:28 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.1999 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 13:21:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:51.554732 (3.299129 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:21:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.199925 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:21:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:21:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:21:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.52s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.547\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.254\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.280\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.452\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
            "\u001b[32m[07/10 13:21:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.036 | 54.744 | 25.430 |  nan  |  nan  | 28.036 |\n",
            "\u001b[32m[07/10 13:21:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:21:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 32.969 | brec_Cht         | 20.220 | lam_Sltst  | 17.103 |\n",
            "| skel_WkstPkst | 37.243 | strless_SltstSst | 32.646 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.73s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.547\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 29.543 | 54.665 | 31.315 |  nan  |  nan  | 29.543 |\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 34.650 | brec_Cht         | 21.884 | lam_Sltst  | 19.888 |\n",
            "| skel_WkstPkst | 37.378 | strless_SltstSst | 33.916 |            |        |\n",
            "\u001b[32m[07/10 13:21:30 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: 28.0363,54.7442,25.4300,nan,nan,28.0363\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: 29.5432,54.6653,31.3149,nan,nan,29.5432\n",
            "\u001b[32m[07/10 13:21:33 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:21:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 13:21:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 13:22:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2052 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 13:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2162 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 13:22:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.867206 (3.318578 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:22:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.219825 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:22:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:22:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:22:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.063\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.156\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.041\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 6.254 | 15.648 | 4.072  |  nan  |  nan  | 6.254 |\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 16.444 | brec_Cht         | 1.126 | lam_Sltst  | 5.573 |\n",
            "| skel_WkstPkst | 1.563  | strless_SltstSst | 6.561 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.155\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.070\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.212\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.329\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 6.997 | 15.466 | 5.813  |  nan  |  nan  | 6.997 |\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 17.085 | brec_Cht         | 2.095 | lam_Sltst  | 5.260 |\n",
            "| skel_WkstPkst | 2.433  | strless_SltstSst | 8.112 |            |       |\n",
            "\u001b[32m[07/10 13:22:21 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.testing]: \u001b[0mcopypaste: 6.2535,15.6483,4.0724,nan,nan,6.2535\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:22:21 d2.evaluation.testing]: \u001b[0mcopypaste: 6.9970,15.4658,5.8128,nan,nan,6.9970\n",
            "\u001b[32m[07/10 13:22:21 d2.utils.events]: \u001b[0m eta: 1:20:41  iter: 599  total_loss: 1.258  loss_cls: 0.374  loss_box_reg: 0.390  loss_mask: 0.271  loss_rpn_cls: 0.076  loss_rpn_loc: 0.164  time: 3.4557  data_time: 2.4301  lr: 0.000599  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:23:29 d2.utils.events]: \u001b[0m eta: 1:19:30  iter: 619  total_loss: 1.232  loss_cls: 0.346  loss_box_reg: 0.381  loss_mask: 0.262  loss_rpn_cls: 0.073  loss_rpn_loc: 0.165  time: 3.4541  data_time: 2.3753  lr: 0.000619  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:24:39 d2.utils.events]: \u001b[0m eta: 1:18:21  iter: 639  total_loss: 1.195  loss_cls: 0.346  loss_box_reg: 0.366  loss_mask: 0.267  loss_rpn_cls: 0.073  loss_rpn_loc: 0.148  time: 3.4547  data_time: 2.4271  lr: 0.000639  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:25:49 d2.utils.events]: \u001b[0m eta: 1:17:13  iter: 659  total_loss: 1.236  loss_cls: 0.378  loss_box_reg: 0.388  loss_mask: 0.267  loss_rpn_cls: 0.064  loss_rpn_loc: 0.155  time: 3.4561  data_time: 2.4797  lr: 0.000659  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:26:57 d2.utils.events]: \u001b[0m eta: 1:16:03  iter: 679  total_loss: 1.162  loss_cls: 0.330  loss_box_reg: 0.350  loss_mask: 0.253  loss_rpn_cls: 0.066  loss_rpn_loc: 0.164  time: 3.4550  data_time: 2.4109  lr: 0.000679  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:28:06 d2.utils.events]: \u001b[0m eta: 1:14:54  iter: 699  total_loss: 1.165  loss_cls: 0.328  loss_box_reg: 0.360  loss_mask: 0.258  loss_rpn_cls: 0.063  loss_rpn_loc: 0.157  time: 3.4555  data_time: 2.4409  lr: 0.000699  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:29:16 d2.utils.events]: \u001b[0m eta: 1:13:47  iter: 719  total_loss: 1.185  loss_cls: 0.336  loss_box_reg: 0.361  loss_mask: 0.264  loss_rpn_cls: 0.063  loss_rpn_loc: 0.169  time: 3.4563  data_time: 2.4228  lr: 0.000719  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:30:25 d2.utils.events]: \u001b[0m eta: 1:12:37  iter: 739  total_loss: 1.174  loss_cls: 0.343  loss_box_reg: 0.370  loss_mask: 0.259  loss_rpn_cls: 0.062  loss_rpn_loc: 0.149  time: 3.4559  data_time: 2.4160  lr: 0.000739  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:31:35 d2.utils.events]: \u001b[0m eta: 1:11:31  iter: 759  total_loss: 1.127  loss_cls: 0.320  loss_box_reg: 0.354  loss_mask: 0.253  loss_rpn_cls: 0.056  loss_rpn_loc: 0.157  time: 3.4574  data_time: 2.4644  lr: 0.000759  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:32:44 d2.utils.events]: \u001b[0m eta: 1:10:21  iter: 779  total_loss: 1.109  loss_cls: 0.311  loss_box_reg: 0.348  loss_mask: 0.245  loss_rpn_cls: 0.060  loss_rpn_loc: 0.159  time: 3.4568  data_time: 2.4122  lr: 0.000779  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:34:07 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:34:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 13:34:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 13:34:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2606 s / img. ETA=0:02:32\n",
            "\u001b[32m[07/10 13:34:51 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2540 s / img. ETA=0:02:18\n",
            "\u001b[32m[07/10 13:34:58 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2352 s / img. ETA=0:02:15\n",
            "\u001b[32m[07/10 13:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.2193 s / img. ETA=0:02:06\n",
            "\u001b[32m[07/10 13:35:12 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2127 s / img. ETA=0:02:04\n",
            "\u001b[32m[07/10 13:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.2069 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/10 13:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.1990 s / img. ETA=0:01:51\n",
            "\u001b[32m[07/10 13:35:33 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.1957 s / img. ETA=0:01:46\n",
            "\u001b[32m[07/10 13:35:39 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.1923 s / img. ETA=0:01:39\n",
            "\u001b[32m[07/10 13:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.1907 s / img. ETA=0:01:34\n",
            "\u001b[32m[07/10 13:35:53 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1863 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/10 13:35:59 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.1834 s / img. ETA=0:01:19\n",
            "\u001b[32m[07/10 13:36:06 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1814 s / img. ETA=0:01:12\n",
            "\u001b[32m[07/10 13:36:15 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1826 s / img. ETA=0:01:07\n",
            "\u001b[32m[07/10 13:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1822 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/10 13:36:31 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1831 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/10 13:36:41 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1840 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/10 13:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1829 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/10 13:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1864 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 13:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1894 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/10 13:37:05 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1920 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 13:37:11 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1944 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 13:37:16 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1965 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:52.625024 (3.319712 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.196894 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.52s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.793\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.461\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.562\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.614\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 45.818 | 79.304 | 46.057 |  nan  |  nan  | 45.818 |\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:37:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 43.065 | brec_Cht         | 62.970 | lam_Sltst  | 30.432 |\n",
            "| skel_WkstPkst | 43.246 | strless_SltstSst | 49.378 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.82s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.447\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.605\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 44.241 | 76.963 | 44.740 |  nan  |  nan  | 44.241 |\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 45.560 | brec_Cht         | 53.267 | lam_Sltst  | 29.941 |\n",
            "| skel_WkstPkst | 43.392 | strless_SltstSst | 49.045 |            |        |\n",
            "\u001b[32m[07/10 13:37:21 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.testing]: \u001b[0mcopypaste: 45.8181,79.3041,46.0569,nan,nan,45.8181\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:37:21 d2.evaluation.testing]: \u001b[0mcopypaste: 44.2410,76.9628,44.7404,nan,nan,44.2412\n",
            "\u001b[32m[07/10 13:37:24 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:37:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 13:37:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 13:38:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1991 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 13:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2115 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.752897 (3.305877 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.215650 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.073\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.048\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.192\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.298\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 7.268 | 16.388 | 4.844  |  nan  |  nan  | 7.268 |\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 16.399 | brec_Cht         | 3.416  | lam_Sltst  | 2.748 |\n",
            "| skel_WkstPkst | 2.939  | strless_SltstSst | 10.838 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.173\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.072\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.218\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.366 | 17.341 | 7.159  |  nan  |  nan  | 8.366 |\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 18.152 | brec_Cht         | 4.307  | lam_Sltst  | 2.759 |\n",
            "| skel_WkstPkst | 3.659  | strless_SltstSst | 12.953 |            |       |\n",
            "\u001b[32m[07/10 13:38:12 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: 7.2680,16.3879,4.8442,nan,nan,7.2680\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: 8.3662,17.3409,7.1592,nan,nan,8.3662\n",
            "\u001b[32m[07/10 13:38:12 d2.utils.events]: \u001b[0m eta: 1:09:12  iter: 799  total_loss: 1.101  loss_cls: 0.305  loss_box_reg: 0.343  loss_mask: 0.236  loss_rpn_cls: 0.058  loss_rpn_loc: 0.147  time: 3.4582  data_time: 2.4653  lr: 0.000799  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:39:22 d2.utils.events]: \u001b[0m eta: 1:08:04  iter: 819  total_loss: 1.073  loss_cls: 0.281  loss_box_reg: 0.343  loss_mask: 0.248  loss_rpn_cls: 0.053  loss_rpn_loc: 0.152  time: 3.4585  data_time: 2.4381  lr: 0.000819  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:40:31 d2.utils.events]: \u001b[0m eta: 1:06:55  iter: 839  total_loss: 1.154  loss_cls: 0.335  loss_box_reg: 0.338  loss_mask: 0.242  loss_rpn_cls: 0.049  loss_rpn_loc: 0.172  time: 3.4588  data_time: 2.4235  lr: 0.000839  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:41:40 d2.utils.events]: \u001b[0m eta: 1:05:46  iter: 859  total_loss: 1.149  loss_cls: 0.329  loss_box_reg: 0.346  loss_mask: 0.237  loss_rpn_cls: 0.057  loss_rpn_loc: 0.157  time: 3.4590  data_time: 2.4254  lr: 0.000859  max_mem: 8651M\n",
            "\u001b[32m[07/10 13:42:50 d2.utils.events]: \u001b[0m eta: 1:04:36  iter: 879  total_loss: 1.097  loss_cls: 0.311  loss_box_reg: 0.333  loss_mask: 0.241  loss_rpn_cls: 0.054  loss_rpn_loc: 0.155  time: 3.4595  data_time: 2.4174  lr: 0.000879  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:43:59 d2.utils.events]: \u001b[0m eta: 1:03:27  iter: 899  total_loss: 1.032  loss_cls: 0.292  loss_box_reg: 0.339  loss_mask: 0.230  loss_rpn_cls: 0.046  loss_rpn_loc: 0.138  time: 3.4595  data_time: 2.4379  lr: 0.000899  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:45:09 d2.utils.events]: \u001b[0m eta: 1:02:18  iter: 919  total_loss: 1.003  loss_cls: 0.282  loss_box_reg: 0.320  loss_mask: 0.227  loss_rpn_cls: 0.052  loss_rpn_loc: 0.134  time: 3.4594  data_time: 2.4075  lr: 0.000919  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:46:18 d2.utils.events]: \u001b[0m eta: 1:01:09  iter: 939  total_loss: 0.992  loss_cls: 0.246  loss_box_reg: 0.303  loss_mask: 0.226  loss_rpn_cls: 0.050  loss_rpn_loc: 0.146  time: 3.4595  data_time: 2.4574  lr: 0.000939  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:47:27 d2.utils.events]: \u001b[0m eta: 1:00:00  iter: 959  total_loss: 1.004  loss_cls: 0.284  loss_box_reg: 0.320  loss_mask: 0.223  loss_rpn_cls: 0.045  loss_rpn_loc: 0.145  time: 3.4598  data_time: 2.4245  lr: 0.000959  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:48:37 d2.utils.events]: \u001b[0m eta: 0:58:50  iter: 979  total_loss: 1.003  loss_cls: 0.263  loss_box_reg: 0.314  loss_mask: 0.225  loss_rpn_cls: 0.044  loss_rpn_loc: 0.142  time: 3.4599  data_time: 2.4304  lr: 0.000979  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:49:58 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:49:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 13:49:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 13:50:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2432 s / img. ETA=0:02:09\n",
            "\u001b[32m[07/10 13:50:41 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2253 s / img. ETA=0:01:57\n",
            "\u001b[32m[07/10 13:50:46 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.2078 s / img. ETA=0:01:51\n",
            "\u001b[32m[07/10 13:50:51 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1956 s / img. ETA=0:01:44\n",
            "\u001b[32m[07/10 13:50:57 d2.evaluation.evaluator]: \u001b[0mInference done 20/57. 0.1883 s / img. ETA=0:01:40\n",
            "\u001b[32m[07/10 13:51:03 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1819 s / img. ETA=0:01:35\n",
            "\u001b[32m[07/10 13:51:09 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.1787 s / img. ETA=0:01:32\n",
            "\u001b[32m[07/10 13:51:15 d2.evaluation.evaluator]: \u001b[0mInference done 26/57. 0.1747 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/10 13:51:22 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1730 s / img. ETA=0:01:22\n",
            "\u001b[32m[07/10 13:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 30/57. 0.1702 s / img. ETA=0:01:16\n",
            "\u001b[32m[07/10 13:51:35 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.1651 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/10 13:51:41 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1637 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/10 13:51:49 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1648 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/10 13:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1650 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/10 13:52:04 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1661 s / img. ETA=0:00:47\n",
            "\u001b[32m[07/10 13:52:13 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1675 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/10 13:52:18 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1666 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 13:52:24 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1707 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 13:52:30 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1745 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 13:52:35 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1777 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/10 13:52:41 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1807 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 13:52:46 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1834 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 13:52:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:31.438258 (2.912274 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:52:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.183105 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:52:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:52:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:52:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.49s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.784\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.525\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.597\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 46.184 | 78.380 | 52.548 |  nan  |  nan  | 46.184 |\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 48.004 | brec_Cht         | 48.994 | lam_Sltst  | 39.080 |\n",
            "| skel_WkstPkst | 47.182 | strless_SltstSst | 47.663 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.69s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.780\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.602\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.627\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 50.811 | 78.027 | 60.169 |  nan  |  nan  | 50.811 |\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 53.687 | brec_Cht         | 55.068 | lam_Sltst  | 37.127 |\n",
            "| skel_WkstPkst | 53.448 | strless_SltstSst | 54.726 |            |        |\n",
            "\u001b[32m[07/10 13:52:49 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: 46.1844,78.3797,52.5477,nan,nan,46.1844\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: 50.8113,78.0273,60.1689,nan,nan,50.8113\n",
            "\u001b[32m[07/10 13:52:53 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 13:52:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 13:52:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 13:53:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1918 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 13:53:35 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2060 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.633990 (3.070443 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.210778 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.043\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.215\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 6.542 | 15.847 | 4.309  |  nan  |  nan  | 6.542 |\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:53:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 14.301 | brec_Cht         | 4.921 | lam_Sltst  | 3.717 |\n",
            "| skel_WkstPkst | 1.498  | strless_SltstSst | 8.270 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.22s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.085\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.161\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.083\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.051\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.358\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.508 | 16.112 | 8.287  |  nan  |  nan  | 8.508 |\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 17.992 | brec_Cht         | 7.465  | lam_Sltst  | 4.995 |\n",
            "| skel_WkstPkst | 1.341  | strless_SltstSst | 10.749 |            |       |\n",
            "\u001b[32m[07/10 13:53:39 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.testing]: \u001b[0mcopypaste: 6.5416,15.8469,4.3092,nan,nan,6.5416\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 13:53:39 d2.evaluation.testing]: \u001b[0mcopypaste: 8.5084,16.1123,8.2872,nan,nan,8.5084\n",
            "\u001b[32m[07/10 13:53:39 d2.utils.events]: \u001b[0m eta: 0:57:41  iter: 999  total_loss: 0.987  loss_cls: 0.277  loss_box_reg: 0.326  loss_mask: 0.219  loss_rpn_cls: 0.041  loss_rpn_loc: 0.141  time: 3.4602  data_time: 2.4259  lr: 0.000999  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:54:47 d2.utils.events]: \u001b[0m eta: 0:56:31  iter: 1019  total_loss: 0.974  loss_cls: 0.254  loss_box_reg: 0.332  loss_mask: 0.226  loss_rpn_cls: 0.044  loss_rpn_loc: 0.137  time: 3.4596  data_time: 2.3589  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:55:56 d2.utils.events]: \u001b[0m eta: 0:55:21  iter: 1039  total_loss: 0.935  loss_cls: 0.241  loss_box_reg: 0.307  loss_mask: 0.221  loss_rpn_cls: 0.037  loss_rpn_loc: 0.131  time: 3.4596  data_time: 2.4517  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:57:06 d2.utils.events]: \u001b[0m eta: 0:54:13  iter: 1059  total_loss: 0.952  loss_cls: 0.255  loss_box_reg: 0.302  loss_mask: 0.209  loss_rpn_cls: 0.040  loss_rpn_loc: 0.142  time: 3.4601  data_time: 2.4218  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:58:16 d2.utils.events]: \u001b[0m eta: 0:53:04  iter: 1079  total_loss: 0.895  loss_cls: 0.232  loss_box_reg: 0.292  loss_mask: 0.207  loss_rpn_cls: 0.039  loss_rpn_loc: 0.146  time: 3.4603  data_time: 2.4401  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 13:59:25 d2.utils.events]: \u001b[0m eta: 0:51:56  iter: 1099  total_loss: 0.943  loss_cls: 0.239  loss_box_reg: 0.305  loss_mask: 0.208  loss_rpn_cls: 0.035  loss_rpn_loc: 0.140  time: 3.4609  data_time: 2.4423  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:00:35 d2.utils.events]: \u001b[0m eta: 0:50:46  iter: 1119  total_loss: 0.923  loss_cls: 0.226  loss_box_reg: 0.289  loss_mask: 0.211  loss_rpn_cls: 0.040  loss_rpn_loc: 0.145  time: 3.4609  data_time: 2.4205  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:01:44 d2.utils.events]: \u001b[0m eta: 0:49:38  iter: 1139  total_loss: 0.971  loss_cls: 0.259  loss_box_reg: 0.319  loss_mask: 0.219  loss_rpn_cls: 0.033  loss_rpn_loc: 0.155  time: 3.4614  data_time: 2.4463  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:02:53 d2.utils.events]: \u001b[0m eta: 0:48:32  iter: 1159  total_loss: 0.907  loss_cls: 0.230  loss_box_reg: 0.284  loss_mask: 0.208  loss_rpn_cls: 0.037  loss_rpn_loc: 0.148  time: 3.4612  data_time: 2.3983  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:04:03 d2.utils.events]: \u001b[0m eta: 0:47:22  iter: 1179  total_loss: 0.869  loss_cls: 0.213  loss_box_reg: 0.287  loss_mask: 0.205  loss_rpn_cls: 0.037  loss_rpn_loc: 0.133  time: 3.4612  data_time: 2.4129  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:05:25 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:05:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 14:05:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 14:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2467 s / img. ETA=0:02:10\n",
            "\u001b[32m[07/10 14:06:08 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2243 s / img. ETA=0:01:57\n",
            "\u001b[32m[07/10 14:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.1976 s / img. ETA=0:01:44\n",
            "\u001b[32m[07/10 14:06:20 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1903 s / img. ETA=0:01:41\n",
            "\u001b[32m[07/10 14:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1907 s / img. ETA=0:01:35\n",
            "\u001b[32m[07/10 14:06:33 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.1794 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/10 14:06:38 d2.evaluation.evaluator]: \u001b[0mInference done 26/57. 0.1743 s / img. ETA=0:01:20\n",
            "\u001b[32m[07/10 14:06:44 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1721 s / img. ETA=0:01:16\n",
            "\u001b[32m[07/10 14:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1648 s / img. ETA=0:01:07\n",
            "\u001b[32m[07/10 14:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1585 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/10 14:07:03 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.1589 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/10 14:07:09 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1585 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/10 14:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1586 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/10 14:07:24 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1593 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/10 14:07:30 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.1560 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 14:07:35 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1596 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 14:07:41 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1639 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 14:07:47 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1678 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 14:07:52 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1713 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 14:07:58 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1744 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 14:08:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:19.266574 (2.678203 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:08:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.175551 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:08:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:08:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:08:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.46s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.560\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.880\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.665\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.560\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.648\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682\n",
            "\u001b[32m[07/10 14:08:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 55.993 | 87.994 | 66.522 |  nan  |  nan  | 55.993 |\n",
            "\u001b[32m[07/10 14:08:03 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:08:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 60.761 | brec_Cht         | 54.505 | lam_Sltst  | 51.989 |\n",
            "| skel_WkstPkst | 54.772 | strless_SltstSst | 57.939 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.67s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.569\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.881\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.656\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.569\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.658\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.694\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 56.929 | 88.074 | 65.564 |  nan  |  nan  | 56.929 |\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 65.047 | brec_Cht         | 51.782 | lam_Sltst  | 51.895 |\n",
            "| skel_WkstPkst | 54.596 | strless_SltstSst | 61.323 |            |        |\n",
            "\u001b[32m[07/10 14:08:04 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.testing]: \u001b[0mcopypaste: 55.9932,87.9938,66.5218,nan,nan,55.9932\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:08:04 d2.evaluation.testing]: \u001b[0mcopypaste: 56.9285,88.0740,65.5639,nan,nan,56.9285\n",
            "\u001b[32m[07/10 14:08:07 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:08:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 14:08:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 14:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1784 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 14:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1960 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.801179 (2.866798 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.201926 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.081\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.220\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.062 | 17.400 | 7.373  |  nan  |  nan  | 8.062 |\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.523 | brec_Cht         | 2.680  | lam_Sltst  | 2.266 |\n",
            "| skel_WkstPkst | 1.057  | strless_SltstSst | 13.785 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.096\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.269\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.352\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.610 | 17.853 | 9.667  |  nan  |  nan  | 9.611 |\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.811 | brec_Cht         | 4.244  | lam_Sltst  | 3.078 |\n",
            "| skel_WkstPkst | 1.212  | strless_SltstSst | 15.706 |            |       |\n",
            "\u001b[32m[07/10 14:08:51 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.testing]: \u001b[0mcopypaste: 8.0621,17.3996,7.3725,nan,nan,8.0621\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:08:51 d2.evaluation.testing]: \u001b[0mcopypaste: 9.6101,17.8533,9.6668,nan,nan,9.6110\n",
            "\u001b[32m[07/10 14:08:51 d2.utils.events]: \u001b[0m eta: 0:46:16  iter: 1199  total_loss: 0.938  loss_cls: 0.241  loss_box_reg: 0.308  loss_mask: 0.203  loss_rpn_cls: 0.037  loss_rpn_loc: 0.137  time: 3.4617  data_time: 2.4245  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:10:01 d2.utils.events]: \u001b[0m eta: 0:45:07  iter: 1219  total_loss: 0.879  loss_cls: 0.214  loss_box_reg: 0.297  loss_mask: 0.207  loss_rpn_cls: 0.033  loss_rpn_loc: 0.134  time: 3.4619  data_time: 2.4251  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:11:12 d2.utils.events]: \u001b[0m eta: 0:43:59  iter: 1239  total_loss: 0.931  loss_cls: 0.233  loss_box_reg: 0.313  loss_mask: 0.205  loss_rpn_cls: 0.035  loss_rpn_loc: 0.136  time: 3.4632  data_time: 2.4866  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:12:21 d2.utils.events]: \u001b[0m eta: 0:42:51  iter: 1259  total_loss: 0.836  loss_cls: 0.210  loss_box_reg: 0.271  loss_mask: 0.202  loss_rpn_cls: 0.033  loss_rpn_loc: 0.130  time: 3.4630  data_time: 2.3937  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:13:30 d2.utils.events]: \u001b[0m eta: 0:41:45  iter: 1279  total_loss: 0.834  loss_cls: 0.204  loss_box_reg: 0.261  loss_mask: 0.190  loss_rpn_cls: 0.029  loss_rpn_loc: 0.120  time: 3.4631  data_time: 2.4182  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:14:40 d2.utils.events]: \u001b[0m eta: 0:40:33  iter: 1299  total_loss: 0.801  loss_cls: 0.181  loss_box_reg: 0.258  loss_mask: 0.195  loss_rpn_cls: 0.028  loss_rpn_loc: 0.127  time: 3.4633  data_time: 2.4106  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:15:49 d2.utils.events]: \u001b[0m eta: 0:39:24  iter: 1319  total_loss: 0.805  loss_cls: 0.187  loss_box_reg: 0.270  loss_mask: 0.199  loss_rpn_cls: 0.026  loss_rpn_loc: 0.134  time: 3.4635  data_time: 2.4233  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:16:58 d2.utils.events]: \u001b[0m eta: 0:38:13  iter: 1339  total_loss: 0.779  loss_cls: 0.173  loss_box_reg: 0.259  loss_mask: 0.181  loss_rpn_cls: 0.028  loss_rpn_loc: 0.134  time: 3.4633  data_time: 2.3990  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:18:08 d2.utils.events]: \u001b[0m eta: 0:37:03  iter: 1359  total_loss: 0.791  loss_cls: 0.186  loss_box_reg: 0.257  loss_mask: 0.198  loss_rpn_cls: 0.029  loss_rpn_loc: 0.126  time: 3.4637  data_time: 2.4424  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:19:17 d2.utils.events]: \u001b[0m eta: 0:35:52  iter: 1379  total_loss: 0.808  loss_cls: 0.197  loss_box_reg: 0.255  loss_mask: 0.193  loss_rpn_cls: 0.029  loss_rpn_loc: 0.128  time: 3.4637  data_time: 2.4330  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:20:39 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:20:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 14:20:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 14:21:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1958 s / img. ETA=0:01:52\n",
            "\u001b[32m[07/10 14:21:16 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.1824 s / img. ETA=0:01:38\n",
            "\u001b[32m[07/10 14:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1546 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/10 14:21:28 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1441 s / img. ETA=0:01:12\n",
            "\u001b[32m[07/10 14:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.1349 s / img. ETA=0:01:02\n",
            "\u001b[32m[07/10 14:21:40 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1316 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/10 14:21:46 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.1254 s / img. ETA=0:00:47\n",
            "\u001b[32m[07/10 14:21:52 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1227 s / img. ETA=0:00:41\n",
            "\u001b[32m[07/10 14:21:57 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1231 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/10 14:22:05 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1237 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/10 14:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1247 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 14:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1241 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/10 14:22:25 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1295 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 14:22:31 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1337 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 14:22:36 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1386 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 14:22:41 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1422 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 14:22:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:49.837943 (2.112268 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:22:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.143203 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:22:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:22:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:22:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.38s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.939\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.812\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.660\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.206\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.702\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 66.032 | 93.916 | 81.185 |  nan  |  nan  | 66.032 |\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 68.838 | brec_Cht         | 67.723 | lam_Sltst  | 61.035 |\n",
            "| skel_WkstPkst | 63.298 | strless_SltstSst | 69.267 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.55s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.938\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.772\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.653\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.701\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.732\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 65.300 | 93.806 | 77.158 |  nan  |  nan  | 65.300 |\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 70.691 | brec_Cht         | 65.248 | lam_Sltst  | 57.233 |\n",
            "| skel_WkstPkst | 62.705 | strless_SltstSst | 70.624 |            |        |\n",
            "\u001b[32m[07/10 14:22:46 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.testing]: \u001b[0mcopypaste: 66.0323,93.9156,81.1846,nan,nan,66.0323\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:22:46 d2.evaluation.testing]: \u001b[0mcopypaste: 65.3000,93.8065,77.1576,nan,nan,65.3000\n",
            "\u001b[32m[07/10 14:22:50 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:22:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 14:22:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 14:23:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1588 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 14:23:27 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1812 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 14:23:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.239056 (2.582117 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:23:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.188747 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:23:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:23:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:23:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.079\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.079\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.320\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 7.869 | 16.375 | 6.826  |  nan  |  nan  | 7.869 |\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 21.255 | brec_Cht         | 3.237 | lam_Sltst  | 6.111 |\n",
            "| skel_WkstPkst | 0.683  | strless_SltstSst | 8.057 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.182\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.095\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.388\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.484 | 18.226 | 8.854  |  nan  |  nan  | 9.484 |\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 24.063 | brec_Cht         | 6.210 | lam_Sltst  | 6.848 |\n",
            "| skel_WkstPkst | 0.602  | strless_SltstSst | 9.697 |            |       |\n",
            "\u001b[32m[07/10 14:23:30 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: 7.8685,16.3755,6.8258,nan,nan,7.8685\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: 9.4841,18.2258,8.8544,nan,nan,9.4841\n",
            "\u001b[32m[07/10 14:23:30 d2.utils.events]: \u001b[0m eta: 0:34:43  iter: 1399  total_loss: 0.787  loss_cls: 0.179  loss_box_reg: 0.259  loss_mask: 0.192  loss_rpn_cls: 0.026  loss_rpn_loc: 0.114  time: 3.4639  data_time: 2.4251  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:24:39 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 1419  total_loss: 0.752  loss_cls: 0.168  loss_box_reg: 0.245  loss_mask: 0.184  loss_rpn_cls: 0.026  loss_rpn_loc: 0.120  time: 3.4635  data_time: 2.3730  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:25:49 d2.utils.events]: \u001b[0m eta: 0:32:22  iter: 1439  total_loss: 0.730  loss_cls: 0.162  loss_box_reg: 0.241  loss_mask: 0.185  loss_rpn_cls: 0.023  loss_rpn_loc: 0.121  time: 3.4642  data_time: 2.4485  lr: 0.001000  max_mem: 8848M\n",
            "\u001b[32m[07/10 14:26:58 d2.utils.events]: \u001b[0m eta: 0:31:15  iter: 1459  total_loss: 0.763  loss_cls: 0.167  loss_box_reg: 0.248  loss_mask: 0.179  loss_rpn_cls: 0.027  loss_rpn_loc: 0.133  time: 3.4644  data_time: 2.4491  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:28:09 d2.utils.events]: \u001b[0m eta: 0:30:06  iter: 1479  total_loss: 0.720  loss_cls: 0.154  loss_box_reg: 0.243  loss_mask: 0.178  loss_rpn_cls: 0.029  loss_rpn_loc: 0.113  time: 3.4651  data_time: 2.4459  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:29:20 d2.utils.events]: \u001b[0m eta: 0:28:57  iter: 1499  total_loss: 0.711  loss_cls: 0.152  loss_box_reg: 0.233  loss_mask: 0.177  loss_rpn_cls: 0.024  loss_rpn_loc: 0.115  time: 3.4662  data_time: 2.4902  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:30:33 d2.utils.events]: \u001b[0m eta: 0:27:51  iter: 1519  total_loss: 0.686  loss_cls: 0.142  loss_box_reg: 0.218  loss_mask: 0.174  loss_rpn_cls: 0.026  loss_rpn_loc: 0.112  time: 3.4685  data_time: 2.5697  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:31:43 d2.utils.events]: \u001b[0m eta: 0:26:42  iter: 1539  total_loss: 0.698  loss_cls: 0.154  loss_box_reg: 0.233  loss_mask: 0.177  loss_rpn_cls: 0.022  loss_rpn_loc: 0.110  time: 3.4694  data_time: 2.4618  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:32:54 d2.utils.events]: \u001b[0m eta: 0:25:33  iter: 1559  total_loss: 0.655  loss_cls: 0.135  loss_box_reg: 0.228  loss_mask: 0.167  loss_rpn_cls: 0.028  loss_rpn_loc: 0.119  time: 3.4703  data_time: 2.4796  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:34:07 d2.utils.events]: \u001b[0m eta: 0:24:25  iter: 1579  total_loss: 0.659  loss_cls: 0.150  loss_box_reg: 0.220  loss_mask: 0.172  loss_rpn_cls: 0.022  loss_rpn_loc: 0.112  time: 3.4722  data_time: 2.5460  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:35:32 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:35:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 14:35:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 14:36:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1757 s / img. ETA=0:01:52\n",
            "\u001b[32m[07/10 14:36:10 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.1613 s / img. ETA=0:01:37\n",
            "\u001b[32m[07/10 14:36:16 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1391 s / img. ETA=0:01:19\n",
            "\u001b[32m[07/10 14:36:21 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1313 s / img. ETA=0:01:11\n",
            "\u001b[32m[07/10 14:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.1236 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/10 14:36:34 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1207 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/10 14:36:40 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.1159 s / img. ETA=0:00:46\n",
            "\u001b[32m[07/10 14:36:45 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1142 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/10 14:36:50 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1150 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/10 14:36:58 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1153 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/10 14:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1164 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 14:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.1149 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/10 14:37:16 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1192 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/10 14:37:21 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1229 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/10 14:37:28 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1282 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 14:37:33 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1318 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 14:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1352 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 14:37:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:50.953309 (2.133717 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:37:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.134769 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:37:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:37:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:37:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.38s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.702\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.962\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.882\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.702\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.205\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.766\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.766\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 70.177 | 96.213 | 88.153 |  nan  |  nan  | 70.177 |\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 69.138 | brec_Cht         | 82.574 | lam_Sltst  | 70.327 |\n",
            "| skel_WkstPkst | 55.544 | strless_SltstSst | 73.299 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.54s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.716\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.964\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.865\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.759\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.784\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.784\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 71.552 | 96.369 | 86.511 |  nan  |  nan  | 71.553 |\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 75.441 | brec_Cht         | 77.624 | lam_Sltst  | 67.952 |\n",
            "| skel_WkstPkst | 59.727 | strless_SltstSst | 77.019 |            |        |\n",
            "\u001b[32m[07/10 14:37:41 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.testing]: \u001b[0mcopypaste: 70.1766,96.2134,88.1529,nan,nan,70.1766\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:37:41 d2.evaluation.testing]: \u001b[0mcopypaste: 71.5524,96.3694,86.5107,nan,nan,71.5525\n",
            "\u001b[32m[07/10 14:37:45 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:37:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 14:37:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 14:38:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1592 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 14:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1785 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.035627 (2.781736 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.186314 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.053\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.232\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.818 | 18.928 | 7.021  |  nan  |  nan  | 8.818 |\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:38:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 17.531 | brec_Cht         | 3.859  | lam_Sltst  | 5.886 |\n",
            "| skel_WkstPkst | 1.443  | strless_SltstSst | 15.369 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.201\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.105\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.908 | 20.060 | 10.491 |  nan  |  nan  | 10.908 |\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.875 | brec_Cht         | 5.126  | lam_Sltst  | 8.231 |\n",
            "| skel_WkstPkst | 1.518  | strless_SltstSst | 18.789 |            |       |\n",
            "\u001b[32m[07/10 14:38:29 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: 8.8175,18.9283,7.0210,nan,nan,8.8175\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: 10.9078,20.0599,10.4911,nan,nan,10.9078\n",
            "\u001b[32m[07/10 14:38:29 d2.utils.events]: \u001b[0m eta: 0:23:16  iter: 1599  total_loss: 0.684  loss_cls: 0.146  loss_box_reg: 0.216  loss_mask: 0.166  loss_rpn_cls: 0.025  loss_rpn_loc: 0.108  time: 3.4741  data_time: 2.5397  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:39:40 d2.utils.events]: \u001b[0m eta: 0:22:09  iter: 1619  total_loss: 0.655  loss_cls: 0.127  loss_box_reg: 0.210  loss_mask: 0.168  loss_rpn_cls: 0.024  loss_rpn_loc: 0.109  time: 3.4756  data_time: 2.5222  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:40:54 d2.utils.events]: \u001b[0m eta: 0:21:00  iter: 1639  total_loss: 0.640  loss_cls: 0.132  loss_box_reg: 0.217  loss_mask: 0.168  loss_rpn_cls: 0.021  loss_rpn_loc: 0.108  time: 3.4780  data_time: 2.5971  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:42:08 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 1659  total_loss: 0.662  loss_cls: 0.144  loss_box_reg: 0.219  loss_mask: 0.169  loss_rpn_cls: 0.022  loss_rpn_loc: 0.103  time: 3.4805  data_time: 2.5954  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:43:22 d2.utils.events]: \u001b[0m eta: 0:18:43  iter: 1679  total_loss: 0.644  loss_cls: 0.138  loss_box_reg: 0.219  loss_mask: 0.161  loss_rpn_cls: 0.019  loss_rpn_loc: 0.111  time: 3.4831  data_time: 2.6438  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:44:35 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 1699  total_loss: 0.625  loss_cls: 0.119  loss_box_reg: 0.210  loss_mask: 0.159  loss_rpn_cls: 0.019  loss_rpn_loc: 0.105  time: 3.4854  data_time: 2.5953  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:45:48 d2.utils.events]: \u001b[0m eta: 0:16:25  iter: 1719  total_loss: 0.653  loss_cls: 0.143  loss_box_reg: 0.222  loss_mask: 0.167  loss_rpn_cls: 0.021  loss_rpn_loc: 0.110  time: 3.4873  data_time: 2.5515  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:46:59 d2.utils.events]: \u001b[0m eta: 0:15:16  iter: 1739  total_loss: 0.682  loss_cls: 0.147  loss_box_reg: 0.237  loss_mask: 0.173  loss_rpn_cls: 0.025  loss_rpn_loc: 0.104  time: 3.4876  data_time: 2.4506  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:48:08 d2.utils.events]: \u001b[0m eta: 0:14:05  iter: 1759  total_loss: 0.639  loss_cls: 0.135  loss_box_reg: 0.223  loss_mask: 0.159  loss_rpn_cls: 0.019  loss_rpn_loc: 0.108  time: 3.4874  data_time: 2.4170  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:49:18 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 1779  total_loss: 0.643  loss_cls: 0.139  loss_box_reg: 0.208  loss_mask: 0.166  loss_rpn_cls: 0.024  loss_rpn_loc: 0.111  time: 3.4876  data_time: 2.4479  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:50:39 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:50:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 14:50:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 14:51:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1569 s / img. ETA=0:01:31\n",
            "\u001b[32m[07/10 14:51:11 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.1497 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/10 14:51:16 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1291 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/10 14:51:22 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.1147 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/10 14:51:28 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1078 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/10 14:51:33 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.1022 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/10 14:51:40 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1015 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 14:51:45 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1012 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/10 14:51:51 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1013 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 14:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1019 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/10 14:52:03 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1068 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 14:52:09 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1123 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 14:52:15 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1179 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 14:52:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:24.120118 (1.617695 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:52:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.118447 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:52:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:52:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:52:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.32s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.977\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.906\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.756\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.779\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 73.331 | 97.736 | 90.612 |  nan  |  nan  | 73.331 |\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 72.854 | brec_Cht         | 69.604 | lam_Sltst  | 71.669 |\n",
            "| skel_WkstPkst | 71.970 | strless_SltstSst | 80.557 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.46s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.742\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.974\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.917\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.766\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.790\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.790\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 74.188 | 97.446 | 91.721 |  nan  |  nan  | 74.188 |\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 76.038 | brec_Cht         | 73.069 | lam_Sltst  | 69.339 |\n",
            "| skel_WkstPkst | 70.857 | strless_SltstSst | 81.633 |            |        |\n",
            "\u001b[32m[07/10 14:52:19 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.testing]: \u001b[0mcopypaste: 73.3307,97.7357,90.6124,nan,nan,73.3307\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:52:19 d2.evaluation.testing]: \u001b[0mcopypaste: 74.1875,97.4462,91.7209,nan,nan,74.1875\n",
            "\u001b[32m[07/10 14:52:22 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 14:52:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 14:52:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 14:52:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1354 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 14:52:55 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1598 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.494950 (2.277217 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.169836 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.073\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.050\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.309\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.450 | 18.603 | 7.330  |  nan  |  nan  | 8.450 |\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 18.927 | brec_Cht         | 0.658  | lam_Sltst  | 4.140 |\n",
            "| skel_WkstPkst | 2.843  | strless_SltstSst | 15.681 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.196\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.092\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.272\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.884 | 19.647 | 9.222  |  nan  |  nan  | 9.887 |\n",
            "\u001b[32m[07/10 14:52:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.149 | brec_Cht         | 1.942  | lam_Sltst  | 4.638 |\n",
            "| skel_WkstPkst | 3.250  | strless_SltstSst | 18.443 |            |       |\n",
            "\u001b[32m[07/10 14:52:59 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.testing]: \u001b[0mcopypaste: 8.4496,18.6033,7.3304,nan,nan,8.4496\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 14:52:59 d2.evaluation.testing]: \u001b[0mcopypaste: 9.8845,19.6469,9.2220,nan,nan,9.8871\n",
            "\u001b[32m[07/10 14:52:59 d2.utils.events]: \u001b[0m eta: 0:11:44  iter: 1799  total_loss: 0.637  loss_cls: 0.124  loss_box_reg: 0.211  loss_mask: 0.163  loss_rpn_cls: 0.021  loss_rpn_loc: 0.103  time: 3.4871  data_time: 2.3973  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:54:08 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 1819  total_loss: 0.580  loss_cls: 0.110  loss_box_reg: 0.189  loss_mask: 0.154  loss_rpn_cls: 0.021  loss_rpn_loc: 0.106  time: 3.4870  data_time: 2.4097  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:55:17 d2.utils.events]: \u001b[0m eta: 0:09:24  iter: 1839  total_loss: 0.626  loss_cls: 0.135  loss_box_reg: 0.198  loss_mask: 0.161  loss_rpn_cls: 0.021  loss_rpn_loc: 0.103  time: 3.4867  data_time: 2.4133  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:56:28 d2.utils.events]: \u001b[0m eta: 0:08:14  iter: 1859  total_loss: 0.631  loss_cls: 0.127  loss_box_reg: 0.201  loss_mask: 0.163  loss_rpn_cls: 0.020  loss_rpn_loc: 0.107  time: 3.4871  data_time: 2.4500  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:57:37 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1879  total_loss: 0.634  loss_cls: 0.125  loss_box_reg: 0.221  loss_mask: 0.159  loss_rpn_cls: 0.021  loss_rpn_loc: 0.110  time: 3.4871  data_time: 2.4323  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:58:47 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 1899  total_loss: 0.563  loss_cls: 0.107  loss_box_reg: 0.196  loss_mask: 0.154  loss_rpn_cls: 0.019  loss_rpn_loc: 0.099  time: 3.4867  data_time: 2.3944  lr: 0.001000  max_mem: 8872M\n",
            "\u001b[32m[07/10 14:59:56 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 1919  total_loss: 0.609  loss_cls: 0.122  loss_box_reg: 0.212  loss_mask: 0.161  loss_rpn_cls: 0.023  loss_rpn_loc: 0.104  time: 3.4868  data_time: 2.4070  lr: 0.001000  max_mem: 8945M\n",
            "\u001b[32m[07/10 15:01:06 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 1939  total_loss: 0.603  loss_cls: 0.122  loss_box_reg: 0.205  loss_mask: 0.152  loss_rpn_cls: 0.020  loss_rpn_loc: 0.109  time: 3.4865  data_time: 2.4124  lr: 0.001000  max_mem: 8945M\n",
            "\u001b[32m[07/10 15:02:15 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 1959  total_loss: 0.591  loss_cls: 0.110  loss_box_reg: 0.203  loss_mask: 0.154  loss_rpn_cls: 0.017  loss_rpn_loc: 0.106  time: 3.4865  data_time: 2.4260  lr: 0.001000  max_mem: 8945M\n",
            "\u001b[32m[07/10 15:03:25 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 1979  total_loss: 0.573  loss_cls: 0.104  loss_box_reg: 0.199  loss_mask: 0.156  loss_rpn_cls: 0.014  loss_rpn_loc: 0.101  time: 3.4863  data_time: 2.3864  lr: 0.001000  max_mem: 8945M\n",
            "\u001b[32m[07/10 15:04:48 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:04:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 15:04:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 15:05:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1412 s / img. ETA=0:01:18\n",
            "\u001b[32m[07/10 15:05:16 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.1260 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/10 15:05:22 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1066 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/10 15:05:27 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.0969 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/10 15:05:33 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.0916 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/10 15:05:38 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.0911 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/10 15:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.0907 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/10 15:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.0913 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 15:05:56 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.0962 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 15:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1027 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 15:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1075 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 15:06:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:11.756741 (1.379937 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:06:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.107987 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:06:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:06:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:06:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.771\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.995\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.928\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.785\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.805\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 77.100 | 99.474 | 92.826 |  nan  |  nan  | 77.100 |\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 81.418 | brec_Cht         | 78.861 | lam_Sltst  | 74.657 |\n",
            "| skel_WkstPkst | 74.121 | strless_SltstSst | 76.444 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.39s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.903\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.740\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.781\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 74.047 | 99.001 | 90.327 |  nan  |  nan  | 74.047 |\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 81.030 | brec_Cht         | 77.525 | lam_Sltst  | 67.393 |\n",
            "| skel_WkstPkst | 71.085 | strless_SltstSst | 73.204 |            |        |\n",
            "\u001b[32m[07/10 15:06:13 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.testing]: \u001b[0mcopypaste: 77.1004,99.4742,92.8255,nan,nan,77.1004\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:06:13 d2.evaluation.testing]: \u001b[0mcopypaste: 74.0473,99.0009,90.3266,nan,nan,74.0473\n",
            "\u001b[32m[07/10 15:06:16 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:06:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 15:06:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 15:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1157 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 15:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1446 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.166835 (2.018537 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.153583 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.052\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.082 | 19.229 | 7.363  |  nan  |  nan  | 9.082 |\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.376 | brec_Cht         | 5.051  | lam_Sltst  | 3.410 |\n",
            "| skel_WkstPkst | 2.432  | strless_SltstSst | 14.142 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.382\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.823 | 19.747 | 8.841  |  nan  |  nan  | 9.823 |\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 22.100 | brec_Cht         | 5.788  | lam_Sltst  | 3.899 |\n",
            "| skel_WkstPkst | 3.093  | strless_SltstSst | 14.233 |            |       |\n",
            "\u001b[32m[07/10 15:06:48 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: 9.0822,19.2291,7.3635,nan,nan,9.0822\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: 9.8226,19.7468,8.8411,nan,nan,9.8226\n",
            "\u001b[32m[07/10 15:06:48 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 1999  total_loss: 0.557  loss_cls: 0.111  loss_box_reg: 0.193  loss_mask: 0.152  loss_rpn_cls: 0.016  loss_rpn_loc: 0.100  time: 3.4864  data_time: 2.4498  lr: 0.001000  max_mem: 8945M\n",
            "\u001b[32m[07/10 15:06:48 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 1:56:05 (3.4882 s / it)\n",
            "\u001b[32m[07/10 15:06:48 d2.engine.hooks]: \u001b[0mTotal training time: 2:32:52 (0:36:46 on hooks)\n",
            "\n",
            "\n",
            "**Starting train eval**\n",
            "\u001b[32m[07/10 15:07:01 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:07:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/10 15:07:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 15:07:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1397 s / img. ETA=0:02:34\n",
            "\u001b[32m[07/10 15:07:49 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.1349 s / img. ETA=0:02:18\n",
            "\u001b[32m[07/10 15:07:55 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1147 s / img. ETA=0:01:32\n",
            "\u001b[32m[07/10 15:08:01 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.1011 s / img. ETA=0:01:03\n",
            "\u001b[32m[07/10 15:08:06 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.0956 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/10 15:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.0912 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/10 15:08:18 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.0908 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 15:08:24 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.0912 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/10 15:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.0927 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 15:08:41 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.0962 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 15:08:50 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1002 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 15:08:57 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1027 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 15:09:02 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1049 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 15:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1076 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:51.622252 (2.146582 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.108077 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.771\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.995\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.928\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.785\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.805\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 77.100 | 99.474 | 92.826 |  nan  |  nan  | 77.100 |\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:09:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 81.418 | brec_Cht         | 78.861 | lam_Sltst  | 74.657 |\n",
            "| skel_WkstPkst | 74.121 | strless_SltstSst | 76.444 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.40s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.903\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.740\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.781\n",
            "\u001b[32m[07/10 15:09:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 74.047 | 99.001 | 90.327 |  nan  |  nan  | 74.047 |\n",
            "\u001b[32m[07/10 15:09:17 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:09:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 81.030 | brec_Cht         | 77.525 | lam_Sltst  | 67.393 |\n",
            "| skel_WkstPkst | 71.085 | strless_SltstSst | 73.204 |            |        |\n",
            "randomly selected cores/Box 7 Depths 10025-35.JPG\n",
            "\n",
            "\n",
            "**Starting val eval**\n",
            "\u001b[32m[07/10 15:10:01 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:10:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/10 15:10:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 15:10:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1144 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 15:10:47 d2.evaluation.evaluator]: \u001b[0mInference done 12/14. 0.1335 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.353440 (2.817049 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.152671 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.052\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.082 | 19.229 | 7.363  |  nan  |  nan  | 9.082 |\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.376 | brec_Cht         | 5.051  | lam_Sltst  | 3.410 |\n",
            "| skel_WkstPkst | 2.432  | strless_SltstSst | 14.142 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.382\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.823 | 19.747 | 8.841  |  nan  |  nan  | 9.823 |\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:10:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 22.100 | brec_Cht         | 5.788  | lam_Sltst  | 3.899 |\n",
            "| skel_WkstPkst | 3.093  | strless_SltstSst | 14.233 |            |       |\n",
            "randomly selected cores/Boxes 76-78  Depths 7929.1-7938.7 (Dry).JPG\n",
            "Fri Jul 10 15:12:03 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "CPU times: user 17.8 s, sys: 2.23 s, total: 20 s\n",
            "Wall time: 2h 39min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0chfOFVBLbj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "538106b4-7a38-452a-a423-e0a909e093a8"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '2' --max_iter 2000\n",
        "# copy results to Google Drive\n",
        "! cp -r output_fold_2 'drive/My Drive/R50-C4'\n",
        "# clean folders if upcoming experiment\n",
        "! rm -r *coco*\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 2\n",
            "\t cores_fold_2_train\n",
            "\t cores_fold_2_val\n",
            "\u001b[32m[07/10 15:12:19 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/10 15:12:31 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 57 images left.\n",
            "\u001b[32m[07/10 15:12:31 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 261          |   brec_Cht    | 21           | lam_Sltst  | 103          |\n",
            "| skel_WkstPkst | 24           | strless_Slt.. | 142          |            |              |\n",
            "|     total     | 551          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/10 15:12:31 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:12:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 15:12:31 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/10 15:12:31 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-10 15:12:32.201200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Unable to load 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (15, 4) in the checkpoint but (3, 4) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (1024, 1024, 3, 3) in the checkpoint but (256, 256, 3, 3) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (256,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (15, 1024, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (15,) in the checkpoint but (3,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (60, 1024, 1, 1) in the checkpoint but (12, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (60,) in the checkpoint but (12,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.deconv.weight' to the model due to incompatible shapes: (2048, 256, 2, 2) in the checkpoint but (256, 256, 2, 2) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/10 15:12:34 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/10 15:13:45 d2.utils.events]: \u001b[0m eta: 1:56:07  iter: 19  total_loss: 44.948  loss_cls: 34.629  loss_box_reg: 0.433  loss_mask: 1.501  loss_rpn_cls: 0.819  loss_rpn_loc: 6.910  time: 3.5204  data_time: 2.7661  lr: 0.000020  max_mem: 6785M\n",
            "\u001b[32m[07/10 15:14:54 d2.utils.events]: \u001b[0m eta: 1:54:27  iter: 39  total_loss: 7.703  loss_cls: 5.789  loss_box_reg: 0.229  loss_mask: 0.610  loss_rpn_cls: 0.264  loss_rpn_loc: 0.898  time: 3.5076  data_time: 2.5916  lr: 0.000040  max_mem: 6785M\n",
            "\u001b[32m[07/10 15:16:04 d2.utils.events]: \u001b[0m eta: 1:52:40  iter: 59  total_loss: 2.531  loss_cls: 1.100  loss_box_reg: 0.308  loss_mask: 0.580  loss_rpn_cls: 0.241  loss_rpn_loc: 0.385  time: 3.5006  data_time: 2.5722  lr: 0.000060  max_mem: 6945M\n",
            "\u001b[32m[07/10 15:17:15 d2.utils.events]: \u001b[0m eta: 1:51:42  iter: 79  total_loss: 2.036  loss_cls: 0.678  loss_box_reg: 0.329  loss_mask: 0.570  loss_rpn_cls: 0.178  loss_rpn_loc: 0.300  time: 3.5107  data_time: 2.5956  lr: 0.000080  max_mem: 7032M\n",
            "\u001b[32m[07/10 15:18:25 d2.utils.events]: \u001b[0m eta: 1:50:38  iter: 99  total_loss: 1.843  loss_cls: 0.439  loss_box_reg: 0.381  loss_mask: 0.550  loss_rpn_cls: 0.177  loss_rpn_loc: 0.264  time: 3.5065  data_time: 2.5370  lr: 0.000100  max_mem: 7311M\n",
            "\u001b[32m[07/10 15:19:35 d2.utils.events]: \u001b[0m eta: 1:49:37  iter: 119  total_loss: 1.757  loss_cls: 0.407  loss_box_reg: 0.400  loss_mask: 0.534  loss_rpn_cls: 0.159  loss_rpn_loc: 0.241  time: 3.5085  data_time: 2.5528  lr: 0.000120  max_mem: 7322M\n",
            "\u001b[32m[07/10 15:20:47 d2.utils.events]: \u001b[0m eta: 1:49:05  iter: 139  total_loss: 1.768  loss_cls: 0.416  loss_box_reg: 0.433  loss_mask: 0.519  loss_rpn_cls: 0.166  loss_rpn_loc: 0.225  time: 3.5210  data_time: 2.6293  lr: 0.000140  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:21:58 d2.utils.events]: \u001b[0m eta: 1:47:57  iter: 159  total_loss: 1.668  loss_cls: 0.376  loss_box_reg: 0.419  loss_mask: 0.523  loss_rpn_cls: 0.137  loss_rpn_loc: 0.218  time: 3.5247  data_time: 2.5938  lr: 0.000160  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:23:08 d2.utils.events]: \u001b[0m eta: 1:46:40  iter: 179  total_loss: 1.645  loss_cls: 0.377  loss_box_reg: 0.408  loss_mask: 0.498  loss_rpn_cls: 0.144  loss_rpn_loc: 0.206  time: 3.5226  data_time: 2.5405  lr: 0.000180  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:24:32 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:24:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 15:24:32 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_2_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/10 15:24:32 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_2_train' to COCO format ...)\n",
            "\u001b[32m[07/10 15:24:43 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/10 15:24:44 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 57, #annotations: 551\n",
            "\u001b[32m[07/10 15:24:44 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_2_train_coco_format.json' ...\n",
            "\u001b[32m[07/10 15:24:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0x8f526000 @  0x7fc9ccdf2b6b 0x7fc9cce12379 0x7fc97054704e 0x7fc970548f4a 0x7fc9a943767b 0x7fc9a90866be 0x7fc9a92ef7b5 0x7fc9a92e17c1 0x7fc9a92e0d0e 0x7fc9a92e17c1 0x7fc9aad3693a 0x7fc9a92e17c1 0x7fc9a9081457 0x7fc9a9082080 0x7fc9a93a071a 0x7fc9aae1e13e 0x7fc9a92e1c72 0x7fc9b737ba68 0x7fc9b7436b04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/10 15:26:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2701 s / img. ETA=0:06:18\n",
            "\u001b[32m[07/10 15:26:24 d2.evaluation.evaluator]: \u001b[0mInference done 12/57. 0.2699 s / img. ETA=0:06:09\n",
            "\u001b[32m[07/10 15:26:32 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2697 s / img. ETA=0:06:00\n",
            "\u001b[32m[07/10 15:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2887 s / img. ETA=0:05:52\n",
            "\u001b[32m[07/10 15:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2870 s / img. ETA=0:05:43\n",
            "\u001b[32m[07/10 15:26:58 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.2733 s / img. ETA=0:05:04\n",
            "\u001b[32m[07/10 15:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2629 s / img. ETA=0:04:34\n",
            "\u001b[32m[07/10 15:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.2553 s / img. ETA=0:04:09\n",
            "\u001b[32m[07/10 15:27:27 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2493 s / img. ETA=0:03:47\n",
            "\u001b[32m[07/10 15:27:34 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2449 s / img. ETA=0:03:23\n",
            "\u001b[32m[07/10 15:27:41 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.2393 s / img. ETA=0:02:49\n",
            "\u001b[32m[07/10 15:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2348 s / img. ETA=0:02:21\n",
            "\u001b[32m[07/10 15:27:56 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2313 s / img. ETA=0:01:58\n",
            "\u001b[32m[07/10 15:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.2291 s / img. ETA=0:01:45\n",
            "\u001b[32m[07/10 15:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.2264 s / img. ETA=0:01:25\n",
            "\u001b[32m[07/10 15:28:15 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.2249 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/10 15:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.2253 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/10 15:28:30 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.2267 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/10 15:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.2280 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/10 15:28:41 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.2292 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/10 15:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.2301 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 15:28:53 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.2311 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/10 15:28:58 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.2318 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 15:29:04 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.2324 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 15:29:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:37.013337 (4.173333 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:29:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.232426 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:29:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:29:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:29:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.68s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.027\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.101\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
            "\u001b[32m[07/10 15:29:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.758 | 8.377  | 1.086  |  nan  |  nan  | 2.758 |\n",
            "\u001b[32m[07/10 15:29:05 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:29:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 7.120 | brec_Cht         | 0.051 | lam_Sltst  | 0.216 |\n",
            "| skel_WkstPkst | 2.261 | strless_SltstSst | 4.142 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.94s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.142\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.444 | 8.032  | 0.735  |  nan  |  nan  | 2.444 |\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 7.068 | brec_Cht         | 0.051 | lam_Sltst  | 0.206 |\n",
            "| skel_WkstPkst | 1.201 | strless_SltstSst | 3.696 |            |       |\n",
            "\u001b[32m[07/10 15:29:06 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: 2.7579,8.3770,1.0864,nan,nan,2.7579\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: 2.4443,8.0320,0.7347,nan,nan,2.4443\n",
            "\u001b[32m[07/10 15:29:09 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 48           |   brec_Cht    | 0            | lam_Sltst  | 24           |\n",
            "| skel_WkstPkst | 2            | strless_Slt.. | 31           |            |              |\n",
            "|     total     | 105          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/10 15:29:09 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:29:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 15:29:09 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_2_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/10 15:29:09 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_2_val' to COCO format ...)\n",
            "\u001b[32m[07/10 15:29:11 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/10 15:29:11 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 14, #annotations: 105\n",
            "\u001b[32m[07/10 15:29:11 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_2_val_coco_format.json' ...\n",
            "\u001b[32m[07/10 15:29:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 15:29:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1913 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 15:29:48 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1995 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 15:29:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.594578 (2.288286 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:29:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.199464 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:29:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:29:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:29:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.092\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.161\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.499 | 10.297 | 1.331  |  nan  |  nan  | 3.499 |\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 11.242 | brec_Cht         | nan   | lam_Sltst  | 1.072 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 1.683 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.150\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.070 | 9.920  | 0.838  |  nan  |  nan  | 3.070 |\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 9.897 | brec_Cht         | nan   | lam_Sltst  | 0.817 |\n",
            "| skel_WkstPkst | 0.000 | strless_SltstSst | 1.566 |            |       |\n",
            "\u001b[32m[07/10 15:29:49 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.testing]: \u001b[0mcopypaste: 3.4993,10.2965,1.3305,nan,nan,3.4993\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:29:49 d2.evaluation.testing]: \u001b[0mcopypaste: 3.0700,9.9200,0.8381,nan,nan,3.0700\n",
            "\u001b[32m[07/10 15:29:49 d2.utils.events]: \u001b[0m eta: 1:45:31  iter: 199  total_loss: 1.647  loss_cls: 0.396  loss_box_reg: 0.428  loss_mask: 0.481  loss_rpn_cls: 0.134  loss_rpn_loc: 0.199  time: 3.5247  data_time: 2.5693  lr: 0.000200  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:31:00 d2.utils.events]: \u001b[0m eta: 1:44:26  iter: 219  total_loss: 1.656  loss_cls: 0.416  loss_box_reg: 0.445  loss_mask: 0.451  loss_rpn_cls: 0.129  loss_rpn_loc: 0.193  time: 3.5281  data_time: 2.5776  lr: 0.000220  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:32:12 d2.utils.events]: \u001b[0m eta: 1:43:17  iter: 239  total_loss: 1.611  loss_cls: 0.419  loss_box_reg: 0.442  loss_mask: 0.433  loss_rpn_cls: 0.126  loss_rpn_loc: 0.193  time: 3.5335  data_time: 2.5872  lr: 0.000240  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:33:25 d2.utils.events]: \u001b[0m eta: 1:42:28  iter: 259  total_loss: 1.617  loss_cls: 0.415  loss_box_reg: 0.461  loss_mask: 0.415  loss_rpn_cls: 0.125  loss_rpn_loc: 0.191  time: 3.5411  data_time: 2.6293  lr: 0.000260  max_mem: 7982M\n",
            "\u001b[32m[07/10 15:34:38 d2.utils.events]: \u001b[0m eta: 1:41:46  iter: 279  total_loss: 1.539  loss_cls: 0.421  loss_box_reg: 0.434  loss_mask: 0.390  loss_rpn_cls: 0.111  loss_rpn_loc: 0.181  time: 3.5517  data_time: 2.6628  lr: 0.000280  max_mem: 8489M\n",
            "\u001b[32m[07/10 15:35:51 d2.utils.events]: \u001b[0m eta: 1:40:37  iter: 299  total_loss: 1.598  loss_cls: 0.466  loss_box_reg: 0.470  loss_mask: 0.373  loss_rpn_cls: 0.112  loss_rpn_loc: 0.179  time: 3.5569  data_time: 2.5922  lr: 0.000300  max_mem: 8489M\n",
            "\u001b[32m[07/10 15:37:04 d2.utils.events]: \u001b[0m eta: 1:39:40  iter: 319  total_loss: 1.480  loss_cls: 0.430  loss_box_reg: 0.431  loss_mask: 0.351  loss_rpn_cls: 0.107  loss_rpn_loc: 0.172  time: 3.5637  data_time: 2.6380  lr: 0.000320  max_mem: 8489M\n",
            "\u001b[32m[07/10 15:38:18 d2.utils.events]: \u001b[0m eta: 1:38:48  iter: 339  total_loss: 1.526  loss_cls: 0.469  loss_box_reg: 0.450  loss_mask: 0.346  loss_rpn_cls: 0.104  loss_rpn_loc: 0.181  time: 3.5711  data_time: 2.6361  lr: 0.000340  max_mem: 8747M\n",
            "\u001b[32m[07/10 15:39:31 d2.utils.events]: \u001b[0m eta: 1:37:51  iter: 359  total_loss: 1.450  loss_cls: 0.428  loss_box_reg: 0.413  loss_mask: 0.328  loss_rpn_cls: 0.097  loss_rpn_loc: 0.180  time: 3.5757  data_time: 2.6107  lr: 0.000360  max_mem: 8747M\n",
            "\u001b[32m[07/10 15:40:45 d2.utils.events]: \u001b[0m eta: 1:36:52  iter: 379  total_loss: 1.529  loss_cls: 0.484  loss_box_reg: 0.428  loss_mask: 0.324  loss_rpn_cls: 0.100  loss_rpn_loc: 0.176  time: 3.5806  data_time: 2.6413  lr: 0.000380  max_mem: 8747M\n",
            "\u001b[32m[07/10 15:42:11 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:42:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 15:42:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 15:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2667 s / img. ETA=0:02:40\n",
            "\u001b[32m[07/10 15:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2519 s / img. ETA=0:02:23\n",
            "\u001b[32m[07/10 15:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.2766 s / img. ETA=0:02:05\n",
            "\u001b[32m[07/10 15:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2592 s / img. ETA=0:01:50\n",
            "\u001b[32m[07/10 15:43:18 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.2489 s / img. ETA=0:01:39\n",
            "\u001b[32m[07/10 15:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2417 s / img. ETA=0:01:29\n",
            "\u001b[32m[07/10 15:43:33 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.2364 s / img. ETA=0:01:19\n",
            "\u001b[32m[07/10 15:43:39 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2292 s / img. ETA=0:01:09\n",
            "\u001b[32m[07/10 15:43:47 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2264 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/10 15:43:54 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.2238 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/10 15:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.2217 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/10 15:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.2214 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/10 15:44:16 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.2232 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/10 15:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.2247 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 15:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.2260 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 15:44:34 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.2271 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 15:44:41 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.2283 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 15:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.2291 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 15:44:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:21.467664 (2.720532 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:44:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.228533 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:44:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:44:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:44:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.60s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.135\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.079\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.135\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397\n",
            "\u001b[32m[07/10 15:44:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.495 | 32.340 | 7.896  |  nan  |  nan  | 13.495 |\n",
            "\u001b[32m[07/10 15:44:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:44:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 17.785 | brec_Cht         | 14.366 | lam_Sltst  | 4.923 |\n",
            "| skel_WkstPkst | 13.542 | strless_SltstSst | 16.859 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.93s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.092\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.452\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 16.426 | 32.619 | 13.083 |  nan  |  nan  | 16.426 |\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.607 | brec_Cht         | 21.149 | lam_Sltst  | 5.274 |\n",
            "| skel_WkstPkst | 16.198 | strless_SltstSst | 18.899 |            |       |\n",
            "\u001b[32m[07/10 15:44:54 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: 13.4950,32.3400,7.8962,nan,nan,13.4950\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: 16.4255,32.6191,13.0829,nan,nan,16.4255\n",
            "\u001b[32m[07/10 15:44:56 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:44:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 15:44:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 15:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1879 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1974 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.073986 (2.341554 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.197427 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.239\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.049\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.095\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.271\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.484 | 23.928 | 4.868  |  nan  |  nan  | 9.484 |\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 25.399 | brec_Cht         | nan   | lam_Sltst  | 5.155 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 7.382 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.257\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.072\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.188\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.302\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.836 | 25.702 | 7.174  |  nan  |  nan  | 10.836 |\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 28.432 | brec_Cht         | nan   | lam_Sltst  | 6.610 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 8.302 |            |       |\n",
            "\u001b[32m[07/10 15:45:35 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.testing]: \u001b[0mcopypaste: 9.4838,23.9278,4.8676,nan,nan,9.4838\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 15:45:35 d2.evaluation.testing]: \u001b[0mcopypaste: 10.8359,25.7023,7.1740,nan,nan,10.8359\n",
            "\u001b[32m[07/10 15:45:35 d2.utils.events]: \u001b[0m eta: 1:35:45  iter: 399  total_loss: 1.447  loss_cls: 0.441  loss_box_reg: 0.441  loss_mask: 0.320  loss_rpn_cls: 0.091  loss_rpn_loc: 0.171  time: 3.5831  data_time: 2.5676  lr: 0.000400  max_mem: 8747M\n",
            "\u001b[32m[07/10 15:46:48 d2.utils.events]: \u001b[0m eta: 1:34:44  iter: 419  total_loss: 1.466  loss_cls: 0.441  loss_box_reg: 0.438  loss_mask: 0.310  loss_rpn_cls: 0.096  loss_rpn_loc: 0.165  time: 3.5859  data_time: 2.6163  lr: 0.000420  max_mem: 8747M\n",
            "\u001b[32m[07/10 15:48:02 d2.utils.events]: \u001b[0m eta: 1:33:38  iter: 439  total_loss: 1.426  loss_cls: 0.431  loss_box_reg: 0.414  loss_mask: 0.308  loss_rpn_cls: 0.091  loss_rpn_loc: 0.160  time: 3.5907  data_time: 2.6346  lr: 0.000440  max_mem: 8829M\n",
            "\u001b[32m[07/10 15:49:15 d2.utils.events]: \u001b[0m eta: 1:32:29  iter: 459  total_loss: 1.373  loss_cls: 0.436  loss_box_reg: 0.422  loss_mask: 0.297  loss_rpn_cls: 0.087  loss_rpn_loc: 0.160  time: 3.5939  data_time: 2.5896  lr: 0.000460  max_mem: 8829M\n",
            "\u001b[32m[07/10 15:50:29 d2.utils.events]: \u001b[0m eta: 1:31:21  iter: 479  total_loss: 1.465  loss_cls: 0.486  loss_box_reg: 0.419  loss_mask: 0.290  loss_rpn_cls: 0.088  loss_rpn_loc: 0.162  time: 3.5978  data_time: 2.6460  lr: 0.000480  max_mem: 8829M\n",
            "\u001b[32m[07/10 15:51:43 d2.utils.events]: \u001b[0m eta: 1:30:17  iter: 499  total_loss: 1.339  loss_cls: 0.416  loss_box_reg: 0.394  loss_mask: 0.291  loss_rpn_cls: 0.080  loss_rpn_loc: 0.155  time: 3.6026  data_time: 2.6479  lr: 0.000500  max_mem: 8885M\n",
            "\u001b[32m[07/10 15:52:58 d2.utils.events]: \u001b[0m eta: 1:29:25  iter: 519  total_loss: 1.361  loss_cls: 0.427  loss_box_reg: 0.423  loss_mask: 0.288  loss_rpn_cls: 0.079  loss_rpn_loc: 0.154  time: 3.6081  data_time: 2.6903  lr: 0.000519  max_mem: 8885M\n",
            "\u001b[32m[07/10 15:54:13 d2.utils.events]: \u001b[0m eta: 1:28:15  iter: 539  total_loss: 1.346  loss_cls: 0.427  loss_box_reg: 0.417  loss_mask: 0.282  loss_rpn_cls: 0.071  loss_rpn_loc: 0.148  time: 3.6123  data_time: 2.6639  lr: 0.000539  max_mem: 8885M\n",
            "\u001b[32m[07/10 15:55:27 d2.utils.events]: \u001b[0m eta: 1:27:06  iter: 559  total_loss: 1.306  loss_cls: 0.401  loss_box_reg: 0.389  loss_mask: 0.275  loss_rpn_cls: 0.079  loss_rpn_loc: 0.166  time: 3.6164  data_time: 2.6622  lr: 0.000559  max_mem: 8885M\n",
            "\u001b[32m[07/10 15:56:40 d2.utils.events]: \u001b[0m eta: 1:25:56  iter: 579  total_loss: 1.303  loss_cls: 0.401  loss_box_reg: 0.408  loss_mask: 0.272  loss_rpn_cls: 0.076  loss_rpn_loc: 0.159  time: 3.6175  data_time: 2.5910  lr: 0.000579  max_mem: 8885M\n",
            "\u001b[32m[07/10 15:58:10 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 15:58:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 15:58:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 15:58:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2717 s / img. ETA=0:02:35\n",
            "\u001b[32m[07/10 15:58:55 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2603 s / img. ETA=0:02:21\n",
            "\u001b[32m[07/10 15:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.2444 s / img. ETA=0:02:01\n",
            "\u001b[32m[07/10 15:59:08 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2308 s / img. ETA=0:01:45\n",
            "\u001b[32m[07/10 15:59:15 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.2249 s / img. ETA=0:01:34\n",
            "\u001b[32m[07/10 15:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2206 s / img. ETA=0:01:24\n",
            "\u001b[32m[07/10 15:59:29 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.2171 s / img. ETA=0:01:15\n",
            "\u001b[32m[07/10 15:59:34 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2092 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/10 15:59:41 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2084 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/10 15:59:48 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.2077 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/10 15:59:56 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.2069 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/10 16:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.2078 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/10 16:00:10 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.2105 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 16:00:16 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.2126 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 16:00:22 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.2144 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 16:00:28 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.2160 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 16:00:34 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.2175 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 16:00:40 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.2188 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:15.607190 (2.607831 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.218303 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.62s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.245\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.412\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 24.544 | 50.292 | 17.862 |  nan  |  nan  | 24.544 |\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 31.061 | brec_Cht         | 28.246 | lam_Sltst  | 15.180 |\n",
            "| skel_WkstPkst | 18.929 | strless_SltstSst | 29.303 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.84s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.552\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 27.525 | 50.258 | 28.548 |  nan  |  nan  | 27.525 |\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 34.344 | brec_Cht         | 32.601 | lam_Sltst  | 15.885 |\n",
            "| skel_WkstPkst | 21.050 | strless_SltstSst | 33.744 |            |        |\n",
            "\u001b[32m[07/10 16:00:47 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.testing]: \u001b[0mcopypaste: 24.5437,50.2916,17.8621,nan,nan,24.5437\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:00:47 d2.evaluation.testing]: \u001b[0mcopypaste: 27.5248,50.2576,28.5479,nan,nan,27.5248\n",
            "\u001b[32m[07/10 16:00:50 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:00:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 16:00:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 16:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1847 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1939 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.144749 (2.238305 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.193878 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 7.358 | 19.960 | 2.991  |  nan  |  nan  | 7.358 |\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 17.054 | brec_Cht         | nan   | lam_Sltst  | 4.000 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 8.379 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.060\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.197\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.330\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.736 | 20.819 | 5.963  |  nan  |  nan  | 8.736 |\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 19.822 | brec_Cht         | nan   | lam_Sltst  | 5.412 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 9.711 |            |       |\n",
            "\u001b[32m[07/10 16:01:27 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.testing]: \u001b[0mcopypaste: 7.3582,19.9597,2.9906,nan,nan,7.3582\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:01:27 d2.evaluation.testing]: \u001b[0mcopypaste: 8.7363,20.8189,5.9633,nan,nan,8.7363\n",
            "\u001b[32m[07/10 16:01:27 d2.utils.events]: \u001b[0m eta: 1:24:49  iter: 599  total_loss: 1.302  loss_cls: 0.393  loss_box_reg: 0.400  loss_mask: 0.269  loss_rpn_cls: 0.071  loss_rpn_loc: 0.164  time: 3.6237  data_time: 2.7460  lr: 0.000599  max_mem: 8885M\n",
            "\u001b[32m[07/10 16:02:41 d2.utils.events]: \u001b[0m eta: 1:23:41  iter: 619  total_loss: 1.289  loss_cls: 0.394  loss_box_reg: 0.404  loss_mask: 0.263  loss_rpn_cls: 0.068  loss_rpn_loc: 0.168  time: 3.6260  data_time: 2.6032  lr: 0.000619  max_mem: 8885M\n",
            "\u001b[32m[07/10 16:03:58 d2.utils.events]: \u001b[0m eta: 1:22:36  iter: 639  total_loss: 1.393  loss_cls: 0.449  loss_box_reg: 0.413  loss_mask: 0.264  loss_rpn_cls: 0.067  loss_rpn_loc: 0.171  time: 3.6320  data_time: 2.7656  lr: 0.000639  max_mem: 8885M\n",
            "\u001b[32m[07/10 16:05:12 d2.utils.events]: \u001b[0m eta: 1:21:29  iter: 659  total_loss: 1.278  loss_cls: 0.409  loss_box_reg: 0.391  loss_mask: 0.255  loss_rpn_cls: 0.071  loss_rpn_loc: 0.167  time: 3.6346  data_time: 2.6539  lr: 0.000659  max_mem: 8885M\n",
            "\u001b[32m[07/10 16:06:27 d2.utils.events]: \u001b[0m eta: 1:20:18  iter: 679  total_loss: 1.206  loss_cls: 0.375  loss_box_reg: 0.370  loss_mask: 0.252  loss_rpn_cls: 0.065  loss_rpn_loc: 0.157  time: 3.6374  data_time: 2.6623  lr: 0.000679  max_mem: 8885M\n",
            "\u001b[32m[07/10 16:07:42 d2.utils.events]: \u001b[0m eta: 1:19:08  iter: 699  total_loss: 1.254  loss_cls: 0.404  loss_box_reg: 0.396  loss_mask: 0.259  loss_rpn_cls: 0.061  loss_rpn_loc: 0.152  time: 3.6411  data_time: 2.6790  lr: 0.000699  max_mem: 8885M\n",
            "\u001b[32m[07/10 16:08:58 d2.utils.events]: \u001b[0m eta: 1:17:58  iter: 719  total_loss: 1.216  loss_cls: 0.395  loss_box_reg: 0.380  loss_mask: 0.246  loss_rpn_cls: 0.061  loss_rpn_loc: 0.146  time: 3.6450  data_time: 2.7001  lr: 0.000719  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:10:13 d2.utils.events]: \u001b[0m eta: 1:16:55  iter: 739  total_loss: 1.242  loss_cls: 0.414  loss_box_reg: 0.391  loss_mask: 0.254  loss_rpn_cls: 0.059  loss_rpn_loc: 0.148  time: 3.6482  data_time: 2.6929  lr: 0.000739  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:11:28 d2.utils.events]: \u001b[0m eta: 1:15:42  iter: 759  total_loss: 1.216  loss_cls: 0.372  loss_box_reg: 0.380  loss_mask: 0.246  loss_rpn_cls: 0.054  loss_rpn_loc: 0.147  time: 3.6507  data_time: 2.6560  lr: 0.000759  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:12:42 d2.utils.events]: \u001b[0m eta: 1:14:32  iter: 779  total_loss: 1.196  loss_cls: 0.360  loss_box_reg: 0.375  loss_mask: 0.241  loss_rpn_cls: 0.059  loss_rpn_loc: 0.148  time: 3.6521  data_time: 2.6386  lr: 0.000779  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:14:11 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:14:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 16:14:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 16:14:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2704 s / img. ETA=0:02:31\n",
            "\u001b[32m[07/10 16:14:56 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.2661 s / img. ETA=0:02:21\n",
            "\u001b[32m[07/10 16:15:01 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2580 s / img. ETA=0:02:08\n",
            "\u001b[32m[07/10 16:15:08 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2263 s / img. ETA=0:01:42\n",
            "\u001b[32m[07/10 16:15:13 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2032 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/10 16:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.1915 s / img. ETA=0:01:07\n",
            "\u001b[32m[07/10 16:15:26 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1813 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/10 16:15:32 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1808 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/10 16:15:38 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1795 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/10 16:15:45 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1793 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/10 16:15:51 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1792 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 16:15:57 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1831 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 16:16:03 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1866 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/10 16:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1897 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 16:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1924 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 16:16:20 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1950 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 16:16:26 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1972 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 16:16:31 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1993 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 16:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:03.186278 (2.368967 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.198723 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:16:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:16:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:16:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.57s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.616\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.578\n",
            "\u001b[32m[07/10 16:16:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 35.487 | 61.560 | 39.628 |  nan  |  nan  | 35.487 |\n",
            "\u001b[32m[07/10 16:16:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:16:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 40.755 | brec_Cht         | 47.417 | lam_Sltst  | 21.199 |\n",
            "| skel_WkstPkst | 27.761 | strless_SltstSst | 40.301 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.78s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.369\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.612\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.389\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.369\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.599\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.599\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 36.855 | 61.191 | 38.926 |  nan  |  nan  | 36.855 |\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 44.182 | brec_Cht         | 51.547 | lam_Sltst  | 21.017 |\n",
            "| skel_WkstPkst | 28.314 | strless_SltstSst | 39.213 |            |        |\n",
            "\u001b[32m[07/10 16:16:35 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.testing]: \u001b[0mcopypaste: 35.4866,61.5597,39.6283,nan,nan,35.4866\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:16:35 d2.evaluation.testing]: \u001b[0mcopypaste: 36.8547,61.1911,38.9263,nan,nan,36.8547\n",
            "\u001b[32m[07/10 16:16:38 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:16:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 16:16:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 16:17:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1529 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1714 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.675509 (1.963945 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.171357 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.080\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 7.985 | 19.223 | 5.549  |  nan  |  nan  | 7.985 |\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 19.496 | brec_Cht         | nan   | lam_Sltst  | 2.012 |\n",
            "| skel_WkstPkst | 1.537  | strless_SltstSst | 8.894 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.383\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.383\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.741 | 19.257 | 6.849  |  nan  |  nan  | 8.741 |\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 22.129 | brec_Cht         | nan   | lam_Sltst  | 1.849 |\n",
            "| skel_WkstPkst | 1.537  | strless_SltstSst | 9.448 |            |       |\n",
            "\u001b[32m[07/10 16:17:11 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: 7.9849,19.2229,5.5489,nan,nan,7.9849\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: 8.7406,19.2569,6.8492,nan,nan,8.7406\n",
            "\u001b[32m[07/10 16:17:11 d2.utils.events]: \u001b[0m eta: 1:13:21  iter: 799  total_loss: 1.148  loss_cls: 0.361  loss_box_reg: 0.376  loss_mask: 0.237  loss_rpn_cls: 0.052  loss_rpn_loc: 0.150  time: 3.6550  data_time: 2.6968  lr: 0.000799  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:18:25 d2.utils.events]: \u001b[0m eta: 1:12:11  iter: 819  total_loss: 1.062  loss_cls: 0.324  loss_box_reg: 0.323  loss_mask: 0.225  loss_rpn_cls: 0.050  loss_rpn_loc: 0.141  time: 3.6564  data_time: 2.6122  lr: 0.000819  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:19:41 d2.utils.events]: \u001b[0m eta: 1:11:00  iter: 839  total_loss: 1.125  loss_cls: 0.342  loss_box_reg: 0.340  loss_mask: 0.243  loss_rpn_cls: 0.055  loss_rpn_loc: 0.144  time: 3.6586  data_time: 2.6621  lr: 0.000839  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:20:56 d2.utils.events]: \u001b[0m eta: 1:09:52  iter: 859  total_loss: 1.162  loss_cls: 0.343  loss_box_reg: 0.368  loss_mask: 0.236  loss_rpn_cls: 0.047  loss_rpn_loc: 0.137  time: 3.6608  data_time: 2.6484  lr: 0.000859  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:22:11 d2.utils.events]: \u001b[0m eta: 1:08:43  iter: 879  total_loss: 1.110  loss_cls: 0.330  loss_box_reg: 0.362  loss_mask: 0.231  loss_rpn_cls: 0.046  loss_rpn_loc: 0.138  time: 3.6633  data_time: 2.7048  lr: 0.000879  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:23:25 d2.utils.events]: \u001b[0m eta: 1:07:29  iter: 899  total_loss: 1.089  loss_cls: 0.313  loss_box_reg: 0.344  loss_mask: 0.227  loss_rpn_cls: 0.048  loss_rpn_loc: 0.145  time: 3.6642  data_time: 2.6325  lr: 0.000899  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:24:41 d2.utils.events]: \u001b[0m eta: 1:06:16  iter: 919  total_loss: 1.100  loss_cls: 0.312  loss_box_reg: 0.361  loss_mask: 0.235  loss_rpn_cls: 0.051  loss_rpn_loc: 0.138  time: 3.6665  data_time: 2.6860  lr: 0.000919  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:25:56 d2.utils.events]: \u001b[0m eta: 1:05:05  iter: 939  total_loss: 1.049  loss_cls: 0.294  loss_box_reg: 0.362  loss_mask: 0.228  loss_rpn_cls: 0.043  loss_rpn_loc: 0.136  time: 3.6683  data_time: 2.6742  lr: 0.000939  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:27:11 d2.utils.events]: \u001b[0m eta: 1:03:54  iter: 959  total_loss: 1.061  loss_cls: 0.300  loss_box_reg: 0.347  loss_mask: 0.236  loss_rpn_cls: 0.047  loss_rpn_loc: 0.137  time: 3.6709  data_time: 2.7089  lr: 0.000959  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:28:27 d2.utils.events]: \u001b[0m eta: 1:02:44  iter: 979  total_loss: 1.137  loss_cls: 0.347  loss_box_reg: 0.368  loss_mask: 0.234  loss_rpn_cls: 0.046  loss_rpn_loc: 0.150  time: 3.6730  data_time: 2.6757  lr: 0.000979  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:29:56 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:29:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 16:29:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 16:30:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2396 s / img. ETA=0:02:17\n",
            "\u001b[32m[07/10 16:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2283 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/10 16:30:43 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1932 s / img. ETA=0:01:30\n",
            "\u001b[32m[07/10 16:30:48 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1739 s / img. ETA=0:01:12\n",
            "\u001b[32m[07/10 16:30:54 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.1583 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/10 16:31:00 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.1491 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/10 16:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.1476 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/10 16:31:11 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1471 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/10 16:31:16 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1472 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 16:31:22 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1491 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/10 16:31:30 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1536 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/10 16:31:35 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1574 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 16:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1615 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 16:31:47 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1648 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 16:31:55 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1688 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 16:31:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:43.302247 (1.986582 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:31:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.167907 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:31:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:31:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:31:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.48s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.705\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.482\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.545\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633\n",
            "\u001b[32m[07/10 16:31:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 41.747 | 70.546 | 48.158 |  nan  |  nan  | 41.747 |\n",
            "\u001b[32m[07/10 16:31:57 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:31:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 48.326 | brec_Cht         | 44.741 | lam_Sltst  | 33.231 |\n",
            "| skel_WkstPkst | 31.196 | strless_SltstSst | 51.239 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.11s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.68s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.683\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.495\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.443\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.574\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666\n",
            "\u001b[32m[07/10 16:31:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 44.315 | 68.303 | 49.479 |  nan  |  nan  | 44.315 |\n",
            "\u001b[32m[07/10 16:31:57 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:31:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 53.128 | brec_Cht         | 48.529 | lam_Sltst  | 34.648 |\n",
            "| skel_WkstPkst | 31.916 | strless_SltstSst | 53.354 |            |        |\n",
            "\u001b[32m[07/10 16:31:58 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 16:31:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:31:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:31:58 d2.evaluation.testing]: \u001b[0mcopypaste: 41.7467,70.5462,48.1579,nan,nan,41.7467\n",
            "\u001b[32m[07/10 16:31:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:31:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:31:58 d2.evaluation.testing]: \u001b[0mcopypaste: 44.3152,68.3033,49.4787,nan,nan,44.3152\n",
            "\u001b[32m[07/10 16:32:00 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:32:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 16:32:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 16:32:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1222 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1413 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.072379 (1.563598 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.141276 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.214\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.237\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.327\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.151 | 21.422 | 8.874  |  nan  |  nan  | 10.151 |\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.284 | brec_Cht         | nan    | lam_Sltst  | 4.919 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 15.401 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.114\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.224\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.122\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.114\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.258\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.425 | 22.439 | 12.231 |  nan  |  nan  | 11.425 |\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.909 | brec_Cht         | nan    | lam_Sltst  | 4.918 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 16.874 |            |       |\n",
            "\u001b[32m[07/10 16:32:28 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.testing]: \u001b[0mcopypaste: 10.1510,21.4218,8.8738,nan,nan,10.1510\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:32:28 d2.evaluation.testing]: \u001b[0mcopypaste: 11.4253,22.4390,12.2310,nan,nan,11.4253\n",
            "\u001b[32m[07/10 16:32:28 d2.utils.events]: \u001b[0m eta: 1:01:32  iter: 999  total_loss: 1.019  loss_cls: 0.296  loss_box_reg: 0.325  loss_mask: 0.223  loss_rpn_cls: 0.042  loss_rpn_loc: 0.142  time: 3.6747  data_time: 2.6964  lr: 0.000999  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:33:43 d2.utils.events]: \u001b[0m eta: 1:00:22  iter: 1019  total_loss: 1.061  loss_cls: 0.313  loss_box_reg: 0.336  loss_mask: 0.214  loss_rpn_cls: 0.044  loss_rpn_loc: 0.133  time: 3.6766  data_time: 2.6654  lr: 0.001000  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:34:58 d2.utils.events]: \u001b[0m eta: 0:59:11  iter: 1039  total_loss: 0.993  loss_cls: 0.280  loss_box_reg: 0.326  loss_mask: 0.218  loss_rpn_cls: 0.043  loss_rpn_loc: 0.131  time: 3.6776  data_time: 2.6365  lr: 0.001000  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:36:14 d2.utils.events]: \u001b[0m eta: 0:58:01  iter: 1059  total_loss: 1.044  loss_cls: 0.298  loss_box_reg: 0.347  loss_mask: 0.217  loss_rpn_cls: 0.040  loss_rpn_loc: 0.131  time: 3.6797  data_time: 2.7016  lr: 0.001000  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:37:28 d2.utils.events]: \u001b[0m eta: 0:56:50  iter: 1079  total_loss: 0.976  loss_cls: 0.262  loss_box_reg: 0.327  loss_mask: 0.213  loss_rpn_cls: 0.038  loss_rpn_loc: 0.138  time: 3.6803  data_time: 2.6441  lr: 0.001000  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:38:43 d2.utils.events]: \u001b[0m eta: 0:55:37  iter: 1099  total_loss: 0.979  loss_cls: 0.268  loss_box_reg: 0.327  loss_mask: 0.209  loss_rpn_cls: 0.033  loss_rpn_loc: 0.131  time: 3.6811  data_time: 2.6360  lr: 0.001000  max_mem: 9010M\n",
            "\u001b[32m[07/10 16:39:57 d2.utils.events]: \u001b[0m eta: 0:54:26  iter: 1119  total_loss: 0.976  loss_cls: 0.277  loss_box_reg: 0.328  loss_mask: 0.207  loss_rpn_cls: 0.037  loss_rpn_loc: 0.132  time: 3.6820  data_time: 2.6340  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:41:12 d2.utils.events]: \u001b[0m eta: 0:53:14  iter: 1139  total_loss: 0.957  loss_cls: 0.268  loss_box_reg: 0.315  loss_mask: 0.209  loss_rpn_cls: 0.038  loss_rpn_loc: 0.131  time: 3.6831  data_time: 2.6546  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:42:27 d2.utils.events]: \u001b[0m eta: 0:52:08  iter: 1159  total_loss: 0.935  loss_cls: 0.266  loss_box_reg: 0.305  loss_mask: 0.203  loss_rpn_cls: 0.038  loss_rpn_loc: 0.127  time: 3.6841  data_time: 2.6606  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:43:42 d2.utils.events]: \u001b[0m eta: 0:50:59  iter: 1179  total_loss: 0.964  loss_cls: 0.278  loss_box_reg: 0.309  loss_mask: 0.206  loss_rpn_cls: 0.035  loss_rpn_loc: 0.136  time: 3.6849  data_time: 2.6329  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:45:10 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:45:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 16:45:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 16:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2194 s / img. ETA=0:02:03\n",
            "\u001b[32m[07/10 16:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2145 s / img. ETA=0:01:50\n",
            "\u001b[32m[07/10 16:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1738 s / img. ETA=0:01:17\n",
            "\u001b[32m[07/10 16:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.1530 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/10 16:46:05 d2.evaluation.evaluator]: \u001b[0mInference done 30/57. 0.1386 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/10 16:46:11 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1363 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/10 16:46:17 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1343 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/10 16:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1343 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 16:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1354 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 16:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1398 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 16:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1444 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 16:46:47 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1493 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 16:46:52 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1528 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 16:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1572 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:34.974928 (1.826441 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.156626 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.42s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.840\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.627\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.161\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 52.851 | 83.987 | 62.696 |  nan  |  nan  | 52.851 |\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:47:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 56.832 | brec_Cht         | 55.153 | lam_Sltst  | 50.120 |\n",
            "| skel_WkstPkst | 44.813 | strless_SltstSst | 57.335 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.61s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.823\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.662\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.649\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.704\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.704\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 56.082 | 82.283 | 66.217 |  nan  |  nan  | 56.082 |\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 61.914 | brec_Cht         | 58.071 | lam_Sltst  | 50.523 |\n",
            "| skel_WkstPkst | 46.869 | strless_SltstSst | 63.035 |            |        |\n",
            "\u001b[32m[07/10 16:47:02 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.testing]: \u001b[0mcopypaste: 52.8505,83.9866,62.6963,nan,nan,52.8505\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:47:02 d2.evaluation.testing]: \u001b[0mcopypaste: 56.0824,82.2832,66.2172,nan,nan,56.0824\n",
            "\u001b[32m[07/10 16:47:05 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 16:47:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 16:47:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 16:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1161 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 16:47:31 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1349 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 16:47:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.568770 (1.507641 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:47:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.134926 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 16:47:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 16:47:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 16:47:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.219\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.259\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.194 | 21.915 | 8.426  |  nan  |  nan  | 10.194 |\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.476 | brec_Cht         | nan    | lam_Sltst  | 4.376 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 14.925 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.111\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.062 | 19.983 | 11.978 |  nan  |  nan  | 11.062 |\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 25.173 | brec_Cht         | nan    | lam_Sltst  | 3.310 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 15.764 |            |       |\n",
            "\u001b[32m[07/10 16:47:32 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.testing]: \u001b[0mcopypaste: 10.1944,21.9145,8.4264,nan,nan,10.1944\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 16:47:32 d2.evaluation.testing]: \u001b[0mcopypaste: 11.0619,19.9831,11.9780,nan,nan,11.0619\n",
            "\u001b[32m[07/10 16:47:32 d2.utils.events]: \u001b[0m eta: 0:49:49  iter: 1199  total_loss: 0.916  loss_cls: 0.249  loss_box_reg: 0.314  loss_mask: 0.199  loss_rpn_cls: 0.033  loss_rpn_loc: 0.132  time: 3.6858  data_time: 2.6235  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:48:46 d2.utils.events]: \u001b[0m eta: 0:48:36  iter: 1219  total_loss: 0.935  loss_cls: 0.248  loss_box_reg: 0.322  loss_mask: 0.203  loss_rpn_cls: 0.031  loss_rpn_loc: 0.127  time: 3.6859  data_time: 2.5952  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:50:01 d2.utils.events]: \u001b[0m eta: 0:47:24  iter: 1239  total_loss: 0.910  loss_cls: 0.240  loss_box_reg: 0.301  loss_mask: 0.198  loss_rpn_cls: 0.029  loss_rpn_loc: 0.131  time: 3.6875  data_time: 2.7139  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:51:16 d2.utils.events]: \u001b[0m eta: 0:46:10  iter: 1259  total_loss: 0.902  loss_cls: 0.250  loss_box_reg: 0.308  loss_mask: 0.203  loss_rpn_cls: 0.032  loss_rpn_loc: 0.119  time: 3.6884  data_time: 2.6646  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:52:32 d2.utils.events]: \u001b[0m eta: 0:44:56  iter: 1279  total_loss: 0.873  loss_cls: 0.223  loss_box_reg: 0.316  loss_mask: 0.197  loss_rpn_cls: 0.028  loss_rpn_loc: 0.120  time: 3.6896  data_time: 2.6731  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:53:47 d2.utils.events]: \u001b[0m eta: 0:43:45  iter: 1299  total_loss: 0.855  loss_cls: 0.212  loss_box_reg: 0.281  loss_mask: 0.191  loss_rpn_cls: 0.027  loss_rpn_loc: 0.121  time: 3.6909  data_time: 2.6812  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:55:02 d2.utils.events]: \u001b[0m eta: 0:42:31  iter: 1319  total_loss: 0.844  loss_cls: 0.225  loss_box_reg: 0.294  loss_mask: 0.193  loss_rpn_cls: 0.029  loss_rpn_loc: 0.112  time: 3.6917  data_time: 2.6683  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:56:15 d2.utils.events]: \u001b[0m eta: 0:41:16  iter: 1339  total_loss: 0.783  loss_cls: 0.200  loss_box_reg: 0.268  loss_mask: 0.190  loss_rpn_cls: 0.030  loss_rpn_loc: 0.120  time: 3.6909  data_time: 2.5408  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:57:28 d2.utils.events]: \u001b[0m eta: 0:40:01  iter: 1359  total_loss: 0.860  loss_cls: 0.223  loss_box_reg: 0.283  loss_mask: 0.201  loss_rpn_cls: 0.028  loss_rpn_loc: 0.120  time: 3.6906  data_time: 2.5947  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 16:58:42 d2.utils.events]: \u001b[0m eta: 0:38:46  iter: 1379  total_loss: 0.892  loss_cls: 0.220  loss_box_reg: 0.307  loss_mask: 0.198  loss_rpn_cls: 0.028  loss_rpn_loc: 0.120  time: 3.6903  data_time: 2.5547  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:00:08 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:00:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 17:00:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 17:00:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1896 s / img. ETA=0:01:56\n",
            "\u001b[32m[07/10 17:00:43 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.1828 s / img. ETA=0:01:41\n",
            "\u001b[32m[07/10 17:00:49 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1389 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/10 17:00:55 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1212 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/10 17:01:00 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.1160 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/10 17:01:06 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1146 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 17:01:12 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1146 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 17:01:19 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1171 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 17:01:26 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1215 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 17:01:32 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1270 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 17:01:38 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1305 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 17:01:44 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.1332 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 17:01:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:22.089747 (1.578649 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:01:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.133217 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:01:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:01:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:01:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.39s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.626\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.927\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.767\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.678\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.716\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            "\u001b[32m[07/10 17:01:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 62.646 | 92.653 | 76.678 |  nan  |  nan  | 62.646 |\n",
            "\u001b[32m[07/10 17:01:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:01:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 64.301 | brec_Cht         | 67.615 | lam_Sltst  | 56.204 |\n",
            "| skel_WkstPkst | 56.021 | strless_SltstSst | 69.090 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.53s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.916\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.780\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.701\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.738\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 64.574 | 91.619 | 77.978 |  nan  |  nan  | 64.574 |\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 66.901 | brec_Cht         | 72.909 | lam_Sltst  | 53.097 |\n",
            "| skel_WkstPkst | 59.442 | strless_SltstSst | 70.522 |            |        |\n",
            "\u001b[32m[07/10 17:01:46 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.testing]: \u001b[0mcopypaste: 62.6462,92.6528,76.6779,nan,nan,62.6462\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:01:46 d2.evaluation.testing]: \u001b[0mcopypaste: 64.5741,91.6193,77.9777,nan,nan,64.5741\n",
            "\u001b[32m[07/10 17:01:49 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:01:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 17:01:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 17:02:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.0962 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.824958 (1.202773 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.109601 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.118\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.268\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.077\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.051\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.814 | 26.788 | 7.663  |  nan  |  nan  | 11.814 |\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.791 | brec_Cht         | nan    | lam_Sltst  | 3.950 |\n",
            "| skel_WkstPkst | 1.683  | strless_SltstSst | 16.830 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.130\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.055\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.396\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 12.965 | 26.043 | 10.269 |  nan  |  nan  | 12.965 |\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 28.808 | brec_Cht         | nan    | lam_Sltst  | 3.471 |\n",
            "| skel_WkstPkst | 2.946  | strless_SltstSst | 16.637 |            |       |\n",
            "\u001b[32m[07/10 17:02:09 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.testing]: \u001b[0mcopypaste: 11.8137,26.7882,7.6628,nan,nan,11.8137\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:02:09 d2.evaluation.testing]: \u001b[0mcopypaste: 12.9652,26.0434,10.2685,nan,nan,12.9652\n",
            "\u001b[32m[07/10 17:02:09 d2.utils.events]: \u001b[0m eta: 0:37:32  iter: 1399  total_loss: 0.825  loss_cls: 0.221  loss_box_reg: 0.285  loss_mask: 0.186  loss_rpn_cls: 0.027  loss_rpn_loc: 0.123  time: 3.6899  data_time: 2.5528  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:03:23 d2.utils.events]: \u001b[0m eta: 0:36:17  iter: 1419  total_loss: 0.840  loss_cls: 0.226  loss_box_reg: 0.303  loss_mask: 0.191  loss_rpn_cls: 0.031  loss_rpn_loc: 0.122  time: 3.6899  data_time: 2.5959  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:04:38 d2.utils.events]: \u001b[0m eta: 0:35:03  iter: 1439  total_loss: 0.809  loss_cls: 0.208  loss_box_reg: 0.277  loss_mask: 0.183  loss_rpn_cls: 0.026  loss_rpn_loc: 0.115  time: 3.6906  data_time: 2.6340  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:05:53 d2.utils.events]: \u001b[0m eta: 0:33:50  iter: 1459  total_loss: 0.745  loss_cls: 0.178  loss_box_reg: 0.245  loss_mask: 0.177  loss_rpn_cls: 0.029  loss_rpn_loc: 0.120  time: 3.6910  data_time: 2.6080  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:07:07 d2.utils.events]: \u001b[0m eta: 0:32:38  iter: 1479  total_loss: 0.769  loss_cls: 0.193  loss_box_reg: 0.255  loss_mask: 0.183  loss_rpn_cls: 0.023  loss_rpn_loc: 0.117  time: 3.6913  data_time: 2.6217  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:08:21 d2.utils.events]: \u001b[0m eta: 0:31:23  iter: 1499  total_loss: 0.785  loss_cls: 0.184  loss_box_reg: 0.269  loss_mask: 0.179  loss_rpn_cls: 0.025  loss_rpn_loc: 0.123  time: 3.6913  data_time: 2.6219  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:09:35 d2.utils.events]: \u001b[0m eta: 0:30:07  iter: 1519  total_loss: 0.760  loss_cls: 0.165  loss_box_reg: 0.258  loss_mask: 0.178  loss_rpn_cls: 0.025  loss_rpn_loc: 0.116  time: 3.6919  data_time: 2.6234  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:10:50 d2.utils.events]: \u001b[0m eta: 0:28:50  iter: 1539  total_loss: 0.776  loss_cls: 0.206  loss_box_reg: 0.259  loss_mask: 0.177  loss_rpn_cls: 0.024  loss_rpn_loc: 0.113  time: 3.6924  data_time: 2.6500  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:12:04 d2.utils.events]: \u001b[0m eta: 0:27:35  iter: 1559  total_loss: 0.806  loss_cls: 0.201  loss_box_reg: 0.275  loss_mask: 0.183  loss_rpn_cls: 0.022  loss_rpn_loc: 0.111  time: 3.6927  data_time: 2.6039  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:13:20 d2.utils.events]: \u001b[0m eta: 0:26:20  iter: 1579  total_loss: 0.741  loss_cls: 0.186  loss_box_reg: 0.255  loss_mask: 0.172  loss_rpn_cls: 0.026  loss_rpn_loc: 0.108  time: 3.6937  data_time: 2.6769  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:14:52 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:14:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 17:14:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 17:15:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2188 s / img. ETA=0:02:15\n",
            "\u001b[32m[07/10 17:15:33 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2083 s / img. ETA=0:01:56\n",
            "\u001b[32m[07/10 17:15:39 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1694 s / img. ETA=0:01:20\n",
            "\u001b[32m[07/10 17:15:44 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.1558 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/10 17:15:50 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1441 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/10 17:15:56 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.1373 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/10 17:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1356 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/10 17:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1339 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 17:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1344 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 17:16:19 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1376 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/10 17:16:24 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1405 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 17:16:31 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1455 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 17:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1500 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 17:16:44 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1537 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:38.612141 (1.896387 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.153985 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.42s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.952\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.773\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.698\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.725\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 63.293 | 95.195 | 77.325 |  nan  |  nan  | 63.293 |\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:16:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 66.134 | brec_Cht         | 76.482 | lam_Sltst  | 53.617 |\n",
            "| skel_WkstPkst | 56.671 | strless_SltstSst | 63.561 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.10s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.64s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.946\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.771\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.706\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 64.285 | 94.649 | 77.062 |  nan  |  nan  | 64.285 |\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 68.559 | brec_Cht         | 78.512 | lam_Sltst  | 49.672 |\n",
            "| skel_WkstPkst | 60.185 | strless_SltstSst | 64.498 |            |        |\n",
            "\u001b[32m[07/10 17:16:49 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: 63.2930,95.1953,77.3247,nan,nan,63.2930\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: 64.2854,94.6490,77.0623,nan,nan,64.2854\n",
            "\u001b[32m[07/10 17:16:52 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:16:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 17:16:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 17:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1127 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1324 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.033471 (1.559275 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.132446 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.101\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.222\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.101\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.241\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.066 | 22.228 | 8.238  |  nan  |  nan  | 10.066 |\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.776 | brec_Cht         | nan    | lam_Sltst  | 3.872 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 14.614 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.236\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.324\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.800 | 23.614 | 10.009 |  nan  |  nan  | 10.800 |\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.758 | brec_Cht         | nan    | lam_Sltst  | 4.738 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 13.704 |            |       |\n",
            "\u001b[32m[07/10 17:17:19 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: 10.0656,22.2279,8.2382,nan,nan,10.0656\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: 10.7999,23.6140,10.0095,nan,nan,10.7999\n",
            "\u001b[32m[07/10 17:17:19 d2.utils.events]: \u001b[0m eta: 0:25:05  iter: 1599  total_loss: 0.710  loss_cls: 0.180  loss_box_reg: 0.240  loss_mask: 0.178  loss_rpn_cls: 0.022  loss_rpn_loc: 0.102  time: 3.6961  data_time: 2.8009  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:18:33 d2.utils.events]: \u001b[0m eta: 0:23:49  iter: 1619  total_loss: 0.710  loss_cls: 0.171  loss_box_reg: 0.247  loss_mask: 0.175  loss_rpn_cls: 0.023  loss_rpn_loc: 0.103  time: 3.6962  data_time: 2.5839  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:19:50 d2.utils.events]: \u001b[0m eta: 0:22:34  iter: 1639  total_loss: 0.711  loss_cls: 0.168  loss_box_reg: 0.234  loss_mask: 0.171  loss_rpn_cls: 0.022  loss_rpn_loc: 0.113  time: 3.6977  data_time: 2.7203  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:21:05 d2.utils.events]: \u001b[0m eta: 0:21:20  iter: 1659  total_loss: 0.770  loss_cls: 0.185  loss_box_reg: 0.251  loss_mask: 0.174  loss_rpn_cls: 0.022  loss_rpn_loc: 0.117  time: 3.6987  data_time: 2.6671  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:22:21 d2.utils.events]: \u001b[0m eta: 0:20:06  iter: 1679  total_loss: 0.753  loss_cls: 0.180  loss_box_reg: 0.256  loss_mask: 0.180  loss_rpn_cls: 0.022  loss_rpn_loc: 0.107  time: 3.6996  data_time: 2.6633  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:23:36 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 1699  total_loss: 0.738  loss_cls: 0.157  loss_box_reg: 0.242  loss_mask: 0.174  loss_rpn_cls: 0.023  loss_rpn_loc: 0.118  time: 3.7002  data_time: 2.6773  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:24:52 d2.utils.events]: \u001b[0m eta: 0:17:35  iter: 1719  total_loss: 0.733  loss_cls: 0.178  loss_box_reg: 0.252  loss_mask: 0.171  loss_rpn_cls: 0.022  loss_rpn_loc: 0.121  time: 3.7013  data_time: 2.6940  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:26:07 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 1739  total_loss: 0.753  loss_cls: 0.185  loss_box_reg: 0.256  loss_mask: 0.168  loss_rpn_cls: 0.022  loss_rpn_loc: 0.110  time: 3.7022  data_time: 2.6535  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:27:23 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 1759  total_loss: 0.704  loss_cls: 0.164  loss_box_reg: 0.254  loss_mask: 0.163  loss_rpn_cls: 0.022  loss_rpn_loc: 0.111  time: 3.7031  data_time: 2.6633  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:28:39 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 1779  total_loss: 0.687  loss_cls: 0.160  loss_box_reg: 0.240  loss_mask: 0.163  loss_rpn_cls: 0.021  loss_rpn_loc: 0.104  time: 3.7042  data_time: 2.7006  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:30:08 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:30:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 17:30:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 17:30:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1859 s / img. ETA=0:01:47\n",
            "\u001b[32m[07/10 17:30:41 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.1815 s / img. ETA=0:01:34\n",
            "\u001b[32m[07/10 17:30:47 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1379 s / img. ETA=0:00:56\n",
            "\u001b[32m[07/10 17:30:52 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1211 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/10 17:30:57 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1138 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 17:31:02 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1105 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 17:31:07 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1094 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 17:31:13 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1131 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 17:31:19 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1179 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 17:31:25 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1233 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 17:31:31 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1270 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.1293 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.982140 (1.441964 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.129350 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.34s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.737\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.974\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.888\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.737\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.802\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 73.720 | 97.376 | 88.766 |  nan  |  nan  | 73.720 |\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:31:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 73.661 | brec_Cht         | 72.796 | lam_Sltst  | 73.416 |\n",
            "| skel_WkstPkst | 69.459 | strless_SltstSst | 79.271 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.48s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.971\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.896\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.784\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.805\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 74.317 | 97.065 | 89.610 |  nan  |  nan  | 74.317 |\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 75.937 | brec_Cht         | 78.756 | lam_Sltst  | 68.397 |\n",
            "| skel_WkstPkst | 68.786 | strless_SltstSst | 79.709 |            |        |\n",
            "\u001b[32m[07/10 17:31:38 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: 73.7204,97.3757,88.7660,nan,nan,73.7204\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: 74.3170,97.0654,89.6098,nan,nan,74.3170\n",
            "\u001b[32m[07/10 17:31:41 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:31:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 17:31:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 17:31:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.0925 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.771365 (1.196818 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.111036 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.142\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.055\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.413\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.459\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.118 | 27.872 | 14.245 |  nan  |  nan  | 14.118 |\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 19.842 | brec_Cht         | nan    | lam_Sltst  | 3.225 |\n",
            "| skel_WkstPkst | 16.700 | strless_SltstSst | 16.705 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.145\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.895 | 27.654 | 14.528 |  nan  |  nan  | 15.895 |\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 23.954 | brec_Cht         | nan    | lam_Sltst  | 2.917 |\n",
            "| skel_WkstPkst | 21.262 | strless_SltstSst | 15.446 |            |       |\n",
            "\u001b[32m[07/10 17:32:02 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.testing]: \u001b[0mcopypaste: 14.1178,27.8719,14.2451,nan,nan,14.1178\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:32:02 d2.evaluation.testing]: \u001b[0mcopypaste: 15.8948,27.6536,14.5278,nan,nan,15.8948\n",
            "\u001b[32m[07/10 17:32:02 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 1799  total_loss: 0.684  loss_cls: 0.154  loss_box_reg: 0.231  loss_mask: 0.159  loss_rpn_cls: 0.020  loss_rpn_loc: 0.096  time: 3.7050  data_time: 2.6629  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:33:16 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 1819  total_loss: 0.634  loss_cls: 0.139  loss_box_reg: 0.212  loss_mask: 0.158  loss_rpn_cls: 0.020  loss_rpn_loc: 0.105  time: 3.7050  data_time: 2.5886  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:34:31 d2.utils.events]: \u001b[0m eta: 0:10:04  iter: 1839  total_loss: 0.653  loss_cls: 0.146  loss_box_reg: 0.232  loss_mask: 0.161  loss_rpn_cls: 0.019  loss_rpn_loc: 0.092  time: 3.7053  data_time: 2.6267  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:35:46 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 1859  total_loss: 0.631  loss_cls: 0.142  loss_box_reg: 0.218  loss_mask: 0.157  loss_rpn_cls: 0.017  loss_rpn_loc: 0.105  time: 3.7062  data_time: 2.6943  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:37:02 d2.utils.events]: \u001b[0m eta: 0:07:34  iter: 1879  total_loss: 0.631  loss_cls: 0.141  loss_box_reg: 0.216  loss_mask: 0.160  loss_rpn_cls: 0.021  loss_rpn_loc: 0.097  time: 3.7071  data_time: 2.7001  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:38:18 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 1899  total_loss: 0.645  loss_cls: 0.146  loss_box_reg: 0.217  loss_mask: 0.156  loss_rpn_cls: 0.020  loss_rpn_loc: 0.096  time: 3.7081  data_time: 2.6941  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:39:34 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 1919  total_loss: 0.597  loss_cls: 0.129  loss_box_reg: 0.204  loss_mask: 0.154  loss_rpn_cls: 0.019  loss_rpn_loc: 0.091  time: 3.7086  data_time: 2.6520  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:40:49 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 1939  total_loss: 0.602  loss_cls: 0.128  loss_box_reg: 0.200  loss_mask: 0.148  loss_rpn_cls: 0.018  loss_rpn_loc: 0.099  time: 3.7094  data_time: 2.6719  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:42:05 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 1959  total_loss: 0.614  loss_cls: 0.136  loss_box_reg: 0.211  loss_mask: 0.151  loss_rpn_cls: 0.018  loss_rpn_loc: 0.099  time: 3.7100  data_time: 2.6710  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:43:19 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1979  total_loss: 0.585  loss_cls: 0.120  loss_box_reg: 0.201  loss_mask: 0.153  loss_rpn_cls: 0.017  loss_rpn_loc: 0.098  time: 3.7103  data_time: 2.6468  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:44:51 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:44:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 17:44:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 17:45:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1738 s / img. ETA=0:01:41\n",
            "\u001b[32m[07/10 17:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.1570 s / img. ETA=0:01:19\n",
            "\u001b[32m[07/10 17:45:28 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1257 s / img. ETA=0:00:50\n",
            "\u001b[32m[07/10 17:45:33 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.1117 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/10 17:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1080 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 17:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1055 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 17:45:51 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1066 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 17:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1104 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 17:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1172 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 17:46:10 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1212 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 17:46:16 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1247 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 17:46:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:15.107944 (1.444384 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:46:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.124919 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:46:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:46:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:46:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.34s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.724\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.987\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.895\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.753\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.779\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 72.363 | 98.679 | 89.455 |  nan  |  nan  | 72.363 |\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 76.078 | brec_Cht         | 77.222 | lam_Sltst  | 69.865 |\n",
            "| skel_WkstPkst | 69.567 | strless_SltstSst | 69.084 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.57s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.754\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.986\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.904\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.778\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.804\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.804\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 75.401 | 98.611 | 90.419 |  nan  |  nan  | 75.401 |\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 80.205 | brec_Cht         | 81.026 | lam_Sltst  | 69.724 |\n",
            "| skel_WkstPkst | 66.041 | strless_SltstSst | 80.009 |            |        |\n",
            "\u001b[32m[07/10 17:46:19 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.testing]: \u001b[0mcopypaste: 72.3632,98.6786,89.4548,nan,nan,72.3632\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:46:19 d2.evaluation.testing]: \u001b[0mcopypaste: 75.4008,98.6106,90.4191,nan,nan,75.4008\n",
            "\u001b[32m[07/10 17:46:22 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:46:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 17:46:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 17:46:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.0905 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.456082 (1.161787 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.107765 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.695 | 28.341 | 11.098 |  nan  |  nan  | 13.695 |\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:46:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.221 | brec_Cht         | nan    | lam_Sltst  | 6.764 |\n",
            "| skel_WkstPkst | 12.233 | strless_SltstSst | 14.562 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.931 | 28.019 | 17.477 |  nan  |  nan  | 15.931 |\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.156 | brec_Cht         | nan    | lam_Sltst  | 7.729 |\n",
            "| skel_WkstPkst | 15.556 | strless_SltstSst | 16.282 |            |       |\n",
            "\u001b[32m[07/10 17:46:44 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: 13.6951,28.3412,11.0983,nan,nan,13.6951\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 17:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: 15.9308,28.0195,17.4770,nan,nan,15.9308\n",
            "\u001b[32m[07/10 17:46:44 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 1999  total_loss: 0.649  loss_cls: 0.135  loss_box_reg: 0.223  loss_mask: 0.166  loss_rpn_cls: 0.017  loss_rpn_loc: 0.104  time: 3.7114  data_time: 2.7297  lr: 0.001000  max_mem: 9261M\n",
            "\u001b[32m[07/10 17:46:44 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 2:03:35 (3.7133 s / it)\n",
            "\u001b[32m[07/10 17:46:44 d2.engine.hooks]: \u001b[0mTotal training time: 2:34:02 (0:30:26 on hooks)\n",
            "\n",
            "\n",
            "**Starting train eval**\n",
            "\u001b[32m[07/10 17:46:57 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:46:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 17:46:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 17:47:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1731 s / img. ETA=0:03:14\n",
            "\u001b[32m[07/10 17:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.1634 s / img. ETA=0:02:49\n",
            "\u001b[32m[07/10 17:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.1570 s / img. ETA=0:02:31\n",
            "\u001b[32m[07/10 17:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1249 s / img. ETA=0:01:24\n",
            "\u001b[32m[07/10 17:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.1113 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/10 17:48:11 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1073 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/10 17:48:16 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1049 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/10 17:48:23 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1061 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 17:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1090 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/10 17:48:39 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1119 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 17:48:44 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1145 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 17:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1171 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/10 17:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1192 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 17:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1210 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 17:49:08 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1228 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 17:49:13 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1245 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 17:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.1247 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:59.959707 (2.306917 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.124741 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.32s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.724\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.987\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.895\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.753\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.779\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 72.363 | 98.679 | 89.455 |  nan  |  nan  | 72.363 |\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:49:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 76.078 | brec_Cht         | 77.222 | lam_Sltst  | 69.865 |\n",
            "| skel_WkstPkst | 69.567 | strless_SltstSst | 69.084 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.47s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.754\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.986\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.904\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.778\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.804\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.804\n",
            "\u001b[32m[07/10 17:49:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 75.401 | 98.611 | 90.419 |  nan  |  nan  | 75.401 |\n",
            "\u001b[32m[07/10 17:49:20 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:49:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 80.205 | brec_Cht         | 81.026 | lam_Sltst  | 69.724 |\n",
            "| skel_WkstPkst | 66.041 | strless_SltstSst | 80.009 |            |        |\n",
            "randomly selected cores/Box 7 Depths 10025-35.JPG\n",
            "\n",
            "\n",
            "**Starting val eval**\n",
            "\u001b[32m[07/10 17:50:07 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 17:50:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 17:50:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 17:50:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.0914 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1082 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.485729 (2.053970 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.108231 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.695 | 28.341 | 11.098 |  nan  |  nan  | 13.695 |\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.221 | brec_Cht         | nan    | lam_Sltst  | 6.764 |\n",
            "| skel_WkstPkst | 12.233 | strless_SltstSst | 14.562 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.931 | 28.019 | 17.477 |  nan  |  nan  | 15.931 |\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 17:50:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.156 | brec_Cht         | nan    | lam_Sltst  | 7.729 |\n",
            "| skel_WkstPkst | 15.556 | strless_SltstSst | 16.282 |            |       |\n",
            "randomly selected cores/Boxes 43-45  Depths 7838.8-7847.4 (Dry).JPG\n",
            "  adding: output_fold_1/ (stored 0%)\n",
            "  adding: output_fold_1/training_log.txt (deflated 88%)\n",
            "  adding: output_fold_1/metrics.json (deflated 77%)\n",
            "  adding: output_fold_1/cores_fold_1_val_cores-Boxes 76-78  Depths 7929.1-7938.7 (Dry).JPG.pdf (deflated 0%)\n",
            "  adding: output_fold_1/events.out.tfevents.1594384404.fce45445a1b1.318.0 (deflated 72%)\n",
            "  adding: output_fold_1/model_final.pth (deflated 7%)\n",
            "  adding: output_fold_1/cocoeval_val_1.json (deflated 55%)\n",
            "  adding: output_fold_1/cores_fold_1_train_cores-Box 7 Depths 10025-35.JPG.pdf (deflated 0%)\n",
            "  adding: output_fold_1/last_checkpoint (stored 0%)\n",
            "  adding: output_fold_1/cocoeval_train_1.json (deflated 55%)\n",
            "  adding: output_fold_2/ (stored 0%)\n",
            "  adding: output_fold_2/training_log.txt (deflated 88%)\n",
            "  adding: output_fold_2/metrics.json (deflated 77%)\n",
            "  adding: output_fold_2/events.out.tfevents.1594393953.fce45445a1b1.544.0 (deflated 72%)\n",
            "  adding: output_fold_2/cores_fold_2_val_cores-Boxes 43-45  Depths 7838.8-7847.4 (Dry).JPG.pdf (deflated 0%)\n",
            "  adding: output_fold_2/cores_fold_2_train_cores-Box 7 Depths 10025-35.JPG.pdf (deflated 0%)\n",
            "  adding: output_fold_2/cocoeval_train_2.json (deflated 55%)\n",
            "  adding: output_fold_2/model_final.pth (deflated 7%)\n",
            "  adding: output_fold_2/cocoeval_val_2.json (deflated 56%)\n",
            "  adding: output_fold_2/last_checkpoint (stored 0%)\n",
            "cp: cannot create regular file 'gdrive/My Drive': No such file or directory\n",
            "Fri Jul 10 17:52:04 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "CPU times: user 17.8 s, sys: 2.33 s, total: 20.1 s\n",
            "Wall time: 2h 39min 52s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY-P57y_Lcnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c117030-7061-43b6-fac5-eab02bdecaf9"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '3' --max_iter 2000\n",
        "# copy results to Google Drive\n",
        "! cp -r output_fold_3 'drive/My Drive/R50-C4'\n",
        "# clean folders if upcoming experiment\n",
        "! rm -r *coco*\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 3\n",
            "\t cores_fold_3_train\n",
            "\t cores_fold_3_val\n",
            "\u001b[32m[07/10 20:56:48 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/10 20:57:05 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 56 images left.\n",
            "\u001b[32m[07/10 20:57:05 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 243          |   brec_Cht    | 21           | lam_Sltst  | 102          |\n",
            "| skel_WkstPkst | 20           | strless_Slt.. | 157          |            |              |\n",
            "|     total     | 543          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/10 20:57:05 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 20:57:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 20:57:05 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/10 20:57:05 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-10 20:57:05.614251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "model_final_4ce675.pkl: 144MB [00:13, 10.5MB/s]               \n",
            "Unable to load 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (15, 4) in the checkpoint but (3, 4) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (1024, 1024, 3, 3) in the checkpoint but (256, 256, 3, 3) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (256,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (15, 1024, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (15,) in the checkpoint but (3,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (60, 1024, 1, 1) in the checkpoint but (12, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (60,) in the checkpoint but (12,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.deconv.weight' to the model due to incompatible shapes: (2048, 256, 2, 2) in the checkpoint but (256, 256, 2, 2) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/10 20:57:26 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/10 20:58:58 d2.utils.events]: \u001b[0m eta: 2:26:48  iter: 19  total_loss: 45.704  loss_cls: 34.103  loss_box_reg: 1.277  loss_mask: 1.134  loss_rpn_cls: 0.750  loss_rpn_loc: 6.480  time: 4.5197  data_time: 2.1155  lr: 0.000020  max_mem: 8438M\n",
            "\u001b[32m[07/10 21:00:29 d2.utils.events]: \u001b[0m eta: 2:27:26  iter: 39  total_loss: 8.577  loss_cls: 6.585  loss_box_reg: 0.292  loss_mask: 0.586  loss_rpn_cls: 0.330  loss_rpn_loc: 0.852  time: 4.5498  data_time: 1.9265  lr: 0.000040  max_mem: 8438M\n",
            "\u001b[32m[07/10 21:02:02 d2.utils.events]: \u001b[0m eta: 2:27:27  iter: 59  total_loss: 2.945  loss_cls: 1.411  loss_box_reg: 0.283  loss_mask: 0.563  loss_rpn_cls: 0.236  loss_rpn_loc: 0.415  time: 4.5808  data_time: 1.8990  lr: 0.000060  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:03:36 d2.utils.events]: \u001b[0m eta: 2:27:12  iter: 79  total_loss: 2.140  loss_cls: 0.724  loss_box_reg: 0.321  loss_mask: 0.549  loss_rpn_cls: 0.205  loss_rpn_loc: 0.309  time: 4.6120  data_time: 1.8975  lr: 0.000080  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:05:11 d2.utils.events]: \u001b[0m eta: 2:27:35  iter: 99  total_loss: 1.775  loss_cls: 0.418  loss_box_reg: 0.355  loss_mask: 0.540  loss_rpn_cls: 0.189  loss_rpn_loc: 0.275  time: 4.6393  data_time: 1.9170  lr: 0.000100  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:06:47 d2.utils.events]: \u001b[0m eta: 2:26:33  iter: 119  total_loss: 1.739  loss_cls: 0.377  loss_box_reg: 0.387  loss_mask: 0.520  loss_rpn_cls: 0.172  loss_rpn_loc: 0.248  time: 4.6655  data_time: 1.9367  lr: 0.000120  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:08:23 d2.utils.events]: \u001b[0m eta: 2:25:16  iter: 139  total_loss: 1.671  loss_cls: 0.350  loss_box_reg: 0.394  loss_mask: 0.518  loss_rpn_cls: 0.172  loss_rpn_loc: 0.240  time: 4.6889  data_time: 1.9516  lr: 0.000140  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:10:00 d2.utils.events]: \u001b[0m eta: 2:23:50  iter: 159  total_loss: 1.600  loss_cls: 0.347  loss_box_reg: 0.375  loss_mask: 0.496  loss_rpn_cls: 0.159  loss_rpn_loc: 0.225  time: 4.7081  data_time: 1.9612  lr: 0.000160  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:11:36 d2.utils.events]: \u001b[0m eta: 2:22:28  iter: 179  total_loss: 1.637  loss_cls: 0.382  loss_box_reg: 0.416  loss_mask: 0.491  loss_rpn_cls: 0.154  loss_rpn_loc: 0.209  time: 4.7188  data_time: 1.9272  lr: 0.000180  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:13:29 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 21:13:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 21:13:29 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_3_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/10 21:13:29 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_3_train' to COCO format ...)\n",
            "\u001b[32m[07/10 21:13:45 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/10 21:13:45 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 57, #annotations: 543\n",
            "\u001b[32m[07/10 21:13:45 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_3_train_coco_format.json' ...\n",
            "\u001b[32m[07/10 21:13:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0x67d1a000 @  0x7fa00aabcb6b 0x7fa00aadc379 0x7f9fae21104e 0x7f9fae212f4a 0x7f9fe710167b 0x7f9fe6d506be 0x7f9fe6fb97b5 0x7f9fe6fab7c1 0x7f9fe6faad0e 0x7f9fe6fab7c1 0x7f9fe8a0093a 0x7f9fe6fab7c1 0x7f9fe6d4b457 0x7f9fe6d4c080 0x7f9fe706a71a 0x7f9fe8ae813e 0x7f9fe6fabc72 0x7f9ff5045a68 0x7f9ff5100b04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/10 21:15:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.9352 s / img. ETA=0:05:16\n",
            "\u001b[32m[07/10 21:15:16 d2.evaluation.evaluator]: \u001b[0mInference done 12/57. 0.9330 s / img. ETA=0:05:09\n",
            "\u001b[32m[07/10 21:15:24 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.9318 s / img. ETA=0:05:04\n",
            "\u001b[32m[07/10 21:15:33 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.8804 s / img. ETA=0:04:31\n",
            "\u001b[32m[07/10 21:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.8529 s / img. ETA=0:04:06\n",
            "\u001b[32m[07/10 21:15:51 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.8273 s / img. ETA=0:03:45\n",
            "\u001b[32m[07/10 21:16:00 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.8083 s / img. ETA=0:03:27\n",
            "\u001b[32m[07/10 21:16:10 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.7937 s / img. ETA=0:03:11\n",
            "\u001b[32m[07/10 21:16:19 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.7818 s / img. ETA=0:02:57\n",
            "\u001b[32m[07/10 21:16:28 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.7761 s / img. ETA=0:02:43\n",
            "\u001b[32m[07/10 21:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.7675 s / img. ETA=0:02:30\n",
            "\u001b[32m[07/10 21:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.7605 s / img. ETA=0:02:18\n",
            "\u001b[32m[07/10 21:16:56 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.7540 s / img. ETA=0:02:06\n",
            "\u001b[32m[07/10 21:17:04 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.7482 s / img. ETA=0:01:54\n",
            "\u001b[32m[07/10 21:17:14 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.7474 s / img. ETA=0:01:43\n",
            "\u001b[32m[07/10 21:17:23 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.7428 s / img. ETA=0:01:32\n",
            "\u001b[32m[07/10 21:17:31 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.7389 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/10 21:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.7260 s / img. ETA=0:01:09\n",
            "\u001b[32m[07/10 21:17:43 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.7299 s / img. ETA=0:01:04\n",
            "\u001b[32m[07/10 21:17:49 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.7337 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/10 21:17:55 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.7374 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/10 21:18:00 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.7407 s / img. ETA=0:00:50\n",
            "\u001b[32m[07/10 21:18:06 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.7468 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/10 21:18:12 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.7500 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/10 21:18:17 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.7527 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/10 21:18:22 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.7551 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 21:18:28 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.7574 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 21:18:33 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.7597 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 21:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.7616 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 21:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.7636 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 21:18:50 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.7656 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 21:18:55 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.7683 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 21:18:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:27.005806 (5.134727 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 21:18:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.768277 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 21:18:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 21:18:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 21:18:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.88s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.017\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.054\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.201\n",
            "\u001b[32m[07/10 21:18:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.407 | 17.064 | 1.746  |  nan  |  nan  | 5.407 |\n",
            "\u001b[32m[07/10 21:18:56 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 21:18:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 8.666 | brec_Cht         | 1.258 | lam_Sltst  | 1.088 |\n",
            "| skel_WkstPkst | 9.072 | strless_SltstSst | 6.952 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.24s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.31s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.053\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.027\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.183\n",
            "\u001b[32m[07/10 21:18:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.284 | 16.396 | 1.174  |  nan  |  nan  | 5.284 |\n",
            "\u001b[32m[07/10 21:18:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 21:18:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 8.891 | brec_Cht         | 0.971 | lam_Sltst  | 0.985 |\n",
            "| skel_WkstPkst | 9.194 | strless_SltstSst | 6.378 |            |       |\n",
            "\u001b[32m[07/10 21:18:58 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 21:18:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 21:18:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 21:18:58 d2.evaluation.testing]: \u001b[0mcopypaste: 5.4070,17.0636,1.7455,nan,nan,5.4070\n",
            "\u001b[32m[07/10 21:18:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 21:18:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 21:18:58 d2.evaluation.testing]: \u001b[0mcopypaste: 5.2839,16.3965,1.1743,nan,nan,5.2839\n",
            "\u001b[32m[07/10 21:19:02 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 66           |   brec_Cht    | 0            | lam_Sltst  | 25           |\n",
            "| skel_WkstPkst | 6            | strless_Slt.. | 16           |            |              |\n",
            "|     total     | 113          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/10 21:19:02 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 21:19:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 21:19:02 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_3_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/10 21:19:02 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_3_val' to COCO format ...)\n",
            "\u001b[32m[07/10 21:19:06 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/10 21:19:06 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 14, #annotations: 113\n",
            "\u001b[32m[07/10 21:19:06 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_3_val_coco_format.json' ...\n",
            "\u001b[32m[07/10 21:19:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 21:20:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.6739 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/10 21:20:18 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.7231 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 21:20:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.844967 (4.316107 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 21:20:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.738913 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 21:20:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 21:20:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 21:20:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.177\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.177\n",
            "\u001b[32m[07/10 21:20:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.357 | 10.008 | 0.962  |  nan  |  nan  | 3.357 |\n",
            "\u001b[32m[07/10 21:20:23 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 21:20:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 9.575 | brec_Cht         | nan   | lam_Sltst  | 0.041 |\n",
            "| skel_WkstPkst | 0.337 | strless_SltstSst | 3.477 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.090\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
            "\u001b[32m[07/10 21:20:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.254 | 9.622  | 1.464  |  nan  |  nan  | 3.254 |\n",
            "\u001b[32m[07/10 21:20:23 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 21:20:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 9.528 | brec_Cht         | nan   | lam_Sltst  | 0.011 |\n",
            "| skel_WkstPkst | 0.374 | strless_SltstSst | 3.105 |            |       |\n",
            "\u001b[32m[07/10 21:20:23 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 21:20:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 21:20:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 21:20:23 d2.evaluation.testing]: \u001b[0mcopypaste: 3.3574,10.0083,0.9621,nan,nan,3.3574\n",
            "\u001b[32m[07/10 21:20:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 21:20:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 21:20:23 d2.evaluation.testing]: \u001b[0mcopypaste: 3.2544,9.6220,1.4644,nan,nan,3.2544\n",
            "\u001b[32m[07/10 21:20:23 d2.utils.events]: \u001b[0m eta: 2:21:17  iter: 199  total_loss: 1.621  loss_cls: 0.360  loss_box_reg: 0.425  loss_mask: 0.474  loss_rpn_cls: 0.143  loss_rpn_loc: 0.196  time: 4.7291  data_time: 1.8933  lr: 0.000200  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:22:02 d2.utils.events]: \u001b[0m eta: 2:20:20  iter: 219  total_loss: 1.616  loss_cls: 0.387  loss_box_reg: 0.450  loss_mask: 0.449  loss_rpn_cls: 0.141  loss_rpn_loc: 0.197  time: 4.7491  data_time: 1.9463  lr: 0.000220  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:23:41 d2.utils.events]: \u001b[0m eta: 2:19:56  iter: 239  total_loss: 1.594  loss_cls: 0.411  loss_box_reg: 0.435  loss_mask: 0.430  loss_rpn_cls: 0.132  loss_rpn_loc: 0.186  time: 4.7659  data_time: 1.9506  lr: 0.000240  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:25:20 d2.utils.events]: \u001b[0m eta: 2:19:04  iter: 259  total_loss: 1.644  loss_cls: 0.435  loss_box_reg: 0.463  loss_mask: 0.410  loss_rpn_cls: 0.124  loss_rpn_loc: 0.183  time: 4.7815  data_time: 1.9283  lr: 0.000260  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:27:00 d2.utils.events]: \u001b[0m eta: 2:18:06  iter: 279  total_loss: 1.627  loss_cls: 0.431  loss_box_reg: 0.457  loss_mask: 0.394  loss_rpn_cls: 0.124  loss_rpn_loc: 0.181  time: 4.7960  data_time: 1.8947  lr: 0.000280  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:28:40 d2.utils.events]: \u001b[0m eta: 2:17:13  iter: 299  total_loss: 1.566  loss_cls: 0.449  loss_box_reg: 0.446  loss_mask: 0.367  loss_rpn_cls: 0.116  loss_rpn_loc: 0.182  time: 4.8086  data_time: 1.8995  lr: 0.000300  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:30:19 d2.utils.events]: \u001b[0m eta: 2:15:51  iter: 319  total_loss: 1.536  loss_cls: 0.449  loss_box_reg: 0.447  loss_mask: 0.354  loss_rpn_cls: 0.111  loss_rpn_loc: 0.193  time: 4.8186  data_time: 1.8691  lr: 0.000320  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:32:00 d2.utils.events]: \u001b[0m eta: 2:14:27  iter: 339  total_loss: 1.575  loss_cls: 0.467  loss_box_reg: 0.450  loss_mask: 0.345  loss_rpn_cls: 0.109  loss_rpn_loc: 0.181  time: 4.8315  data_time: 1.8970  lr: 0.000340  max_mem: 8439M\n",
            "\u001b[32m[07/10 21:33:40 d2.utils.events]: \u001b[0m eta: 2:12:57  iter: 359  total_loss: 1.507  loss_cls: 0.446  loss_box_reg: 0.432  loss_mask: 0.334  loss_rpn_cls: 0.104  loss_rpn_loc: 0.182  time: 4.8422  data_time: 1.9030  lr: 0.000360  max_mem: 8521M\n",
            "\u001b[32m[07/10 21:35:22 d2.utils.events]: \u001b[0m eta: 2:11:35  iter: 379  total_loss: 1.544  loss_cls: 0.448  loss_box_reg: 0.468  loss_mask: 0.327  loss_rpn_cls: 0.102  loss_rpn_loc: 0.184  time: 4.8537  data_time: 1.9432  lr: 0.000380  max_mem: 8521M\n",
            "\u001b[32m[07/10 21:37:18 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 21:37:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 21:37:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 21:38:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.9123 s / img. ETA=0:03:31\n",
            "\u001b[32m[07/10 21:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.8743 s / img. ETA=0:03:12\n",
            "\u001b[32m[07/10 21:38:27 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.8344 s / img. ETA=0:03:02\n",
            "\u001b[32m[07/10 21:38:35 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.8081 s / img. ETA=0:02:52\n",
            "\u001b[32m[07/10 21:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.7919 s / img. ETA=0:02:44\n",
            "\u001b[32m[07/10 21:38:52 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.7773 s / img. ETA=0:02:34\n",
            "\u001b[32m[07/10 21:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.7659 s / img. ETA=0:02:25\n",
            "\u001b[32m[07/10 21:39:09 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.7568 s / img. ETA=0:02:17\n",
            "\u001b[32m[07/10 21:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.7492 s / img. ETA=0:02:08\n",
            "\u001b[32m[07/10 21:39:26 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.7428 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/10 21:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.7298 s / img. ETA=0:01:49\n",
            "\u001b[32m[07/10 21:39:41 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.7256 s / img. ETA=0:01:41\n",
            "\u001b[32m[07/10 21:39:50 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.7216 s / img. ETA=0:01:33\n",
            "\u001b[32m[07/10 21:39:59 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.7182 s / img. ETA=0:01:25\n",
            "\u001b[32m[07/10 21:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.7152 s / img. ETA=0:01:16\n",
            "\u001b[32m[07/10 21:40:16 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.7138 s / img. ETA=0:01:08\n",
            "\u001b[32m[07/10 21:40:22 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.7005 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/10 21:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.7092 s / img. ETA=0:00:50\n",
            "\u001b[32m[07/10 21:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.7173 s / img. ETA=0:00:41\n",
            "\u001b[32m[07/10 21:40:47 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.7247 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/10 21:40:56 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.7307 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 21:41:04 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.7367 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 21:41:13 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.7415 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 21:41:20 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.7419 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 21:41:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:36.606200 (4.165504 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 21:41:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.741934 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 21:41:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 21:41:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 21:41:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.87s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.061\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.368\n",
            "\u001b[32m[07/10 21:41:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.251 | 33.347 | 6.193  |  nan  |  nan  | 13.251 |\n",
            "\u001b[32m[07/10 21:41:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 21:41:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.034 | brec_Cht         | 18.374 | lam_Sltst  | 6.489 |\n",
            "| skel_WkstPkst | 5.689  | strless_SltstSst | 15.665 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.21s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.123\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.318\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.421\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.421\n",
            "\u001b[32m[07/10 21:41:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.851 | 33.926 | 12.333 |  nan  |  nan  | 15.851 |\n",
            "\u001b[32m[07/10 21:41:22 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 21:41:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 22.681 | brec_Cht         | 23.297 | lam_Sltst  | 6.981 |\n",
            "| skel_WkstPkst | 9.046  | strless_SltstSst | 17.249 |            |       |\n",
            "\u001b[32m[07/10 21:41:22 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 21:41:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 21:41:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 21:41:22 d2.evaluation.testing]: \u001b[0mcopypaste: 13.2505,33.3472,6.1929,nan,nan,13.2505\n",
            "\u001b[32m[07/10 21:41:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 21:41:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 21:41:22 d2.evaluation.testing]: \u001b[0mcopypaste: 15.8507,33.9264,12.3330,nan,nan,15.8507\n",
            "\u001b[32m[07/10 21:41:26 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 21:41:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 21:41:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 21:42:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.6761 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 21:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.7242 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/10 21:42:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.147044 (4.238560 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 21:42:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.739488 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 21:42:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 21:42:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 21:42:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.199\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.060\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.195\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.302\n",
            "\u001b[32m[07/10 21:42:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.769 | 19.944 | 6.012  |  nan  |  nan  | 8.769 |\n",
            "\u001b[32m[07/10 21:42:27 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 21:42:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 14.030 | brec_Cht         | nan   | lam_Sltst  | 1.047 |\n",
            "| skel_WkstPkst | 15.429 | strless_SltstSst | 4.571 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.207\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.241\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
            "\u001b[32m[07/10 21:42:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.402 | 20.725 | 8.922  |  nan  |  nan  | 10.402 |\n",
            "\u001b[32m[07/10 21:42:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 21:42:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 17.553 | brec_Cht         | nan   | lam_Sltst  | 1.241 |\n",
            "| skel_WkstPkst | 16.411 | strless_SltstSst | 6.404 |            |       |\n",
            "\u001b[32m[07/10 21:42:28 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 21:42:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 21:42:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 21:42:28 d2.evaluation.testing]: \u001b[0mcopypaste: 8.7690,19.9440,6.0119,nan,nan,8.7690\n",
            "\u001b[32m[07/10 21:42:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 21:42:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 21:42:28 d2.evaluation.testing]: \u001b[0mcopypaste: 10.4021,20.7251,8.9217,nan,nan,10.4022\n",
            "\u001b[32m[07/10 21:42:28 d2.utils.events]: \u001b[0m eta: 2:10:15  iter: 399  total_loss: 1.453  loss_cls: 0.475  loss_box_reg: 0.401  loss_mask: 0.310  loss_rpn_cls: 0.101  loss_rpn_loc: 0.183  time: 4.8625  data_time: 1.8971  lr: 0.000400  max_mem: 8831M\n",
            "\u001b[32m[07/10 21:44:09 d2.utils.events]: \u001b[0m eta: 2:08:55  iter: 419  total_loss: 1.432  loss_cls: 0.443  loss_box_reg: 0.418  loss_mask: 0.315  loss_rpn_cls: 0.101  loss_rpn_loc: 0.180  time: 4.8729  data_time: 1.9408  lr: 0.000420  max_mem: 8831M\n",
            "\u001b[32m[07/10 21:45:50 d2.utils.events]: \u001b[0m eta: 2:07:32  iter: 439  total_loss: 1.441  loss_cls: 0.428  loss_box_reg: 0.419  loss_mask: 0.308  loss_rpn_cls: 0.092  loss_rpn_loc: 0.172  time: 4.8805  data_time: 1.8710  lr: 0.000440  max_mem: 8831M\n",
            "\u001b[32m[07/10 21:47:31 d2.utils.events]: \u001b[0m eta: 2:06:04  iter: 459  total_loss: 1.462  loss_cls: 0.460  loss_box_reg: 0.435  loss_mask: 0.305  loss_rpn_cls: 0.096  loss_rpn_loc: 0.158  time: 4.8871  data_time: 1.8307  lr: 0.000460  max_mem: 8831M\n",
            "\u001b[32m[07/10 21:49:13 d2.utils.events]: \u001b[0m eta: 2:04:30  iter: 479  total_loss: 1.385  loss_cls: 0.437  loss_box_reg: 0.405  loss_mask: 0.296  loss_rpn_cls: 0.089  loss_rpn_loc: 0.165  time: 4.8957  data_time: 1.9154  lr: 0.000480  max_mem: 8831M\n",
            "\u001b[32m[07/10 21:50:54 d2.utils.events]: \u001b[0m eta: 2:03:01  iter: 499  total_loss: 1.397  loss_cls: 0.449  loss_box_reg: 0.420  loss_mask: 0.293  loss_rpn_cls: 0.082  loss_rpn_loc: 0.169  time: 4.9034  data_time: 1.8966  lr: 0.000500  max_mem: 8831M\n",
            "\u001b[32m[07/10 21:52:35 d2.utils.events]: \u001b[0m eta: 2:01:35  iter: 519  total_loss: 1.329  loss_cls: 0.411  loss_box_reg: 0.396  loss_mask: 0.288  loss_rpn_cls: 0.084  loss_rpn_loc: 0.160  time: 4.9090  data_time: 1.8834  lr: 0.000519  max_mem: 8831M\n",
            "\u001b[32m[07/10 21:54:18 d2.utils.events]: \u001b[0m eta: 2:00:05  iter: 539  total_loss: 1.382  loss_cls: 0.423  loss_box_reg: 0.410  loss_mask: 0.289  loss_rpn_cls: 0.087  loss_rpn_loc: 0.174  time: 4.9163  data_time: 1.8669  lr: 0.000539  max_mem: 8831M\n",
            "\u001b[32m[07/10 21:55:59 d2.utils.events]: \u001b[0m eta: 1:58:39  iter: 559  total_loss: 1.308  loss_cls: 0.387  loss_box_reg: 0.399  loss_mask: 0.275  loss_rpn_cls: 0.085  loss_rpn_loc: 0.158  time: 4.9220  data_time: 1.8796  lr: 0.000559  max_mem: 8831M\n",
            "\u001b[32m[07/10 21:57:41 d2.utils.events]: \u001b[0m eta: 1:57:09  iter: 579  total_loss: 1.283  loss_cls: 0.384  loss_box_reg: 0.398  loss_mask: 0.286  loss_rpn_cls: 0.076  loss_rpn_loc: 0.154  time: 4.9277  data_time: 1.8891  lr: 0.000579  max_mem: 8831M\n",
            "\u001b[32m[07/10 21:59:38 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 21:59:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 21:59:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 22:00:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.9453 s / img. ETA=0:03:36\n",
            "\u001b[32m[07/10 22:00:43 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.9409 s / img. ETA=0:03:27\n",
            "\u001b[32m[07/10 22:00:49 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.8748 s / img. ETA=0:03:06\n",
            "\u001b[32m[07/10 22:00:56 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.8265 s / img. ETA=0:02:48\n",
            "\u001b[32m[07/10 22:01:02 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.7958 s / img. ETA=0:02:35\n",
            "\u001b[32m[07/10 22:01:09 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.7670 s / img. ETA=0:02:23\n",
            "\u001b[32m[07/10 22:01:15 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.7542 s / img. ETA=0:02:12\n",
            "\u001b[32m[07/10 22:01:21 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.7335 s / img. ETA=0:02:01\n",
            "\u001b[32m[07/10 22:01:28 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.7263 s / img. ETA=0:01:53\n",
            "\u001b[32m[07/10 22:01:35 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.7174 s / img. ETA=0:01:45\n",
            "\u001b[32m[07/10 22:01:41 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.7033 s / img. ETA=0:01:35\n",
            "\u001b[32m[07/10 22:01:48 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.7005 s / img. ETA=0:01:28\n",
            "\u001b[32m[07/10 22:01:57 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.6983 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/10 22:02:05 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.7001 s / img. ETA=0:01:15\n",
            "\u001b[32m[07/10 22:02:14 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.6985 s / img. ETA=0:01:08\n",
            "\u001b[32m[07/10 22:02:22 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.6973 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/10 22:02:27 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.6846 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/10 22:02:35 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.6942 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/10 22:02:44 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.7031 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/10 22:02:52 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.7120 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 22:03:00 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.7189 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/10 22:03:09 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.7249 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 22:03:17 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.7304 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 22:03:24 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.7327 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 22:03:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:19.401426 (3.834643 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 22:03:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.732711 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 22:03:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 22:03:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 22:03:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.74s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.454\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.167\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.205\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.092\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.366\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.441\n",
            "\u001b[32m[07/10 22:03:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 20.509 | 45.429 | 16.732 |  nan  |  nan  | 20.509 |\n",
            "\u001b[32m[07/10 22:03:25 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 22:03:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 26.974 | brec_Cht         | 18.102 | lam_Sltst  | 13.447 |\n",
            "| skel_WkstPkst | 13.644 | strless_SltstSst | 30.376 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.19s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.462\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.255\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.431\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.516\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.516\n",
            "\u001b[32m[07/10 22:03:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.028 | 46.197 | 25.456 |  nan  |  nan  | 25.028 |\n",
            "\u001b[32m[07/10 22:03:27 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 22:03:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 33.063 | brec_Cht         | 26.707 | lam_Sltst  | 14.220 |\n",
            "| skel_WkstPkst | 18.369 | strless_SltstSst | 32.782 |            |        |\n",
            "\u001b[32m[07/10 22:03:27 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 22:03:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 22:03:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 22:03:27 d2.evaluation.testing]: \u001b[0mcopypaste: 20.5087,45.4292,16.7323,nan,nan,20.5087\n",
            "\u001b[32m[07/10 22:03:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 22:03:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 22:03:27 d2.evaluation.testing]: \u001b[0mcopypaste: 25.0281,46.1974,25.4562,nan,nan,25.0281\n",
            "\u001b[32m[07/10 22:03:31 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 22:03:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 22:03:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 22:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.6386 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 22:04:26 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.7123 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 22:04:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.735330 (3.970592 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 22:04:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.729437 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 22:04:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 22:04:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 22:04:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.231\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.045\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.246\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.320\n",
            "\u001b[32m[07/10 22:04:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.109 | 23.077 | 4.451  |  nan  |  nan  | 9.109 |\n",
            "\u001b[32m[07/10 22:04:30 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 22:04:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 14.907 | brec_Cht         | nan   | lam_Sltst  | 1.186 |\n",
            "| skel_WkstPkst | 10.341 | strless_SltstSst | 9.999 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.241\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.112\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.279\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.373\n",
            "\u001b[32m[07/10 22:04:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.223 | 24.052 | 8.866  |  nan  |  nan  | 11.223 |\n",
            "\u001b[32m[07/10 22:04:31 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 22:04:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.230 | brec_Cht         | nan    | lam_Sltst  | 1.183 |\n",
            "| skel_WkstPkst | 11.827 | strless_SltstSst | 11.653 |            |       |\n",
            "\u001b[32m[07/10 22:04:31 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 22:04:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 22:04:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 22:04:31 d2.evaluation.testing]: \u001b[0mcopypaste: 9.1086,23.0766,4.4507,nan,nan,9.1086\n",
            "\u001b[32m[07/10 22:04:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 22:04:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 22:04:31 d2.evaluation.testing]: \u001b[0mcopypaste: 11.2233,24.0519,8.8661,nan,nan,11.2233\n",
            "\u001b[32m[07/10 22:04:31 d2.utils.events]: \u001b[0m eta: 1:55:36  iter: 599  total_loss: 1.324  loss_cls: 0.392  loss_box_reg: 0.403  loss_mask: 0.283  loss_rpn_cls: 0.074  loss_rpn_loc: 0.184  time: 4.9324  data_time: 1.8433  lr: 0.000599  max_mem: 8831M\n",
            "\u001b[32m[07/10 22:06:12 d2.utils.events]: \u001b[0m eta: 1:54:01  iter: 619  total_loss: 1.364  loss_cls: 0.412  loss_box_reg: 0.401  loss_mask: 0.291  loss_rpn_cls: 0.079  loss_rpn_loc: 0.176  time: 4.9364  data_time: 1.8546  lr: 0.000619  max_mem: 8859M\n",
            "\u001b[32m[07/10 22:07:53 d2.utils.events]: \u001b[0m eta: 1:52:30  iter: 639  total_loss: 1.244  loss_cls: 0.361  loss_box_reg: 0.384  loss_mask: 0.267  loss_rpn_cls: 0.066  loss_rpn_loc: 0.149  time: 4.9406  data_time: 1.8728  lr: 0.000639  max_mem: 8859M\n",
            "\u001b[32m[07/10 22:09:37 d2.utils.events]: \u001b[0m eta: 1:50:56  iter: 659  total_loss: 1.290  loss_cls: 0.393  loss_box_reg: 0.409  loss_mask: 0.263  loss_rpn_cls: 0.067  loss_rpn_loc: 0.170  time: 4.9479  data_time: 1.9202  lr: 0.000659  max_mem: 8859M\n",
            "\u001b[32m[07/10 22:11:18 d2.utils.events]: \u001b[0m eta: 1:49:25  iter: 679  total_loss: 1.320  loss_cls: 0.413  loss_box_reg: 0.396  loss_mask: 0.266  loss_rpn_cls: 0.072  loss_rpn_loc: 0.171  time: 4.9518  data_time: 1.8473  lr: 0.000679  max_mem: 8859M\n",
            "\u001b[32m[07/10 22:13:02 d2.utils.events]: \u001b[0m eta: 1:47:56  iter: 699  total_loss: 1.243  loss_cls: 0.384  loss_box_reg: 0.382  loss_mask: 0.257  loss_rpn_cls: 0.064  loss_rpn_loc: 0.151  time: 4.9577  data_time: 1.9087  lr: 0.000699  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:14:44 d2.utils.events]: \u001b[0m eta: 1:46:22  iter: 719  total_loss: 1.279  loss_cls: 0.395  loss_box_reg: 0.383  loss_mask: 0.261  loss_rpn_cls: 0.065  loss_rpn_loc: 0.147  time: 4.9621  data_time: 1.8825  lr: 0.000719  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:16:26 d2.utils.events]: \u001b[0m eta: 1:44:47  iter: 739  total_loss: 1.234  loss_cls: 0.362  loss_box_reg: 0.373  loss_mask: 0.263  loss_rpn_cls: 0.062  loss_rpn_loc: 0.154  time: 4.9661  data_time: 1.8464  lr: 0.000739  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:18:09 d2.utils.events]: \u001b[0m eta: 1:43:17  iter: 759  total_loss: 1.200  loss_cls: 0.372  loss_box_reg: 0.365  loss_mask: 0.250  loss_rpn_cls: 0.058  loss_rpn_loc: 0.164  time: 4.9702  data_time: 1.9261  lr: 0.000759  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:19:51 d2.utils.events]: \u001b[0m eta: 1:41:45  iter: 779  total_loss: 1.178  loss_cls: 0.341  loss_box_reg: 0.352  loss_mask: 0.255  loss_rpn_cls: 0.060  loss_rpn_loc: 0.146  time: 4.9742  data_time: 1.8628  lr: 0.000779  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:21:49 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 22:21:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 22:21:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 22:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.9285 s / img. ETA=0:03:35\n",
            "\u001b[32m[07/10 22:22:54 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.9268 s / img. ETA=0:03:24\n",
            "\u001b[32m[07/10 22:22:59 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.8390 s / img. ETA=0:02:57\n",
            "\u001b[32m[07/10 22:23:06 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.7581 s / img. ETA=0:02:29\n",
            "\u001b[32m[07/10 22:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 20/57. 0.7271 s / img. ETA=0:02:16\n",
            "\u001b[32m[07/10 22:23:18 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.7054 s / img. ETA=0:02:05\n",
            "\u001b[32m[07/10 22:23:23 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.6830 s / img. ETA=0:01:55\n",
            "\u001b[32m[07/10 22:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 26/57. 0.6707 s / img. ETA=0:01:46\n",
            "\u001b[32m[07/10 22:23:34 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.6560 s / img. ETA=0:01:37\n",
            "\u001b[32m[07/10 22:23:42 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.6383 s / img. ETA=0:01:25\n",
            "\u001b[32m[07/10 22:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.6397 s / img. ETA=0:01:18\n",
            "\u001b[32m[07/10 22:23:56 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.6355 s / img. ETA=0:01:12\n",
            "\u001b[32m[07/10 22:24:04 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.6343 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/10 22:24:12 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.6353 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/10 22:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.6321 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/10 22:24:26 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.6223 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/10 22:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.6384 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/10 22:24:43 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.6496 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/10 22:24:51 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.6594 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/10 22:25:00 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.6679 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/10 22:25:08 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.6756 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/10 22:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.6829 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 22:25:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:02.197694 (3.503802 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 22:25:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:35 (0.682522 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 22:25:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 22:25:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 22:25:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.71s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.631\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.130\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.505\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.571\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571\n",
            "\u001b[32m[07/10 22:25:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 35.368 | 63.069 | 36.421 |  nan  |  nan  | 35.368 |\n",
            "\u001b[32m[07/10 22:25:20 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 22:25:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 39.229 | brec_Cht         | 41.139 | lam_Sltst  | 28.307 |\n",
            "| skel_WkstPkst | 26.080 | strless_SltstSst | 42.084 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.621\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.405\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.620\n",
            "\u001b[32m[07/10 22:25:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 37.731 | 62.130 | 40.510 |  nan  |  nan  | 37.731 |\n",
            "\u001b[32m[07/10 22:25:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 22:25:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 44.589 | brec_Cht         | 46.048 | lam_Sltst  | 28.052 |\n",
            "| skel_WkstPkst | 27.827 | strless_SltstSst | 42.143 |            |        |\n",
            "\u001b[32m[07/10 22:25:21 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 22:25:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 22:25:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 22:25:21 d2.evaluation.testing]: \u001b[0mcopypaste: 35.3679,63.0689,36.4214,nan,nan,35.3679\n",
            "\u001b[32m[07/10 22:25:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 22:25:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 22:25:21 d2.evaluation.testing]: \u001b[0mcopypaste: 37.7315,62.1295,40.5100,nan,nan,37.7315\n",
            "\u001b[32m[07/10 22:25:25 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 22:25:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 22:25:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 22:26:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.5452 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 22:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.6258 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:30.533885 (3.392654 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.651866 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.335\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.119\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.318\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.401\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.401\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.972 | 33.475 | 11.880 |  nan  |  nan  | 15.972 |\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.342 | brec_Cht         | nan    | lam_Sltst  | 5.021 |\n",
            "| skel_WkstPkst | 4.040  | strless_SltstSst | 34.483 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.353\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.103\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.460\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.809 | 35.257 | 17.527 |  nan  |  nan  | 17.809 |\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 25.110 | brec_Cht         | nan    | lam_Sltst  | 5.126 |\n",
            "| skel_WkstPkst | 6.775  | strless_SltstSst | 34.227 |            |       |\n",
            "\u001b[32m[07/10 22:26:20 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.testing]: \u001b[0mcopypaste: 15.9715,33.4747,11.8797,nan,nan,15.9715\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 22:26:20 d2.evaluation.testing]: \u001b[0mcopypaste: 17.8095,35.2568,17.5274,nan,nan,17.8095\n",
            "\u001b[32m[07/10 22:26:20 d2.utils.events]: \u001b[0m eta: 1:40:08  iter: 799  total_loss: 1.159  loss_cls: 0.345  loss_box_reg: 0.377  loss_mask: 0.241  loss_rpn_cls: 0.061  loss_rpn_loc: 0.160  time: 4.9778  data_time: 1.9255  lr: 0.000799  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:28:05 d2.utils.events]: \u001b[0m eta: 1:38:31  iter: 819  total_loss: 1.167  loss_cls: 0.354  loss_box_reg: 0.356  loss_mask: 0.245  loss_rpn_cls: 0.059  loss_rpn_loc: 0.144  time: 4.9840  data_time: 1.9701  lr: 0.000819  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:29:49 d2.utils.events]: \u001b[0m eta: 1:36:54  iter: 839  total_loss: 1.149  loss_cls: 0.324  loss_box_reg: 0.365  loss_mask: 0.248  loss_rpn_cls: 0.051  loss_rpn_loc: 0.136  time: 4.9888  data_time: 1.9044  lr: 0.000839  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:31:32 d2.utils.events]: \u001b[0m eta: 1:35:18  iter: 859  total_loss: 1.165  loss_cls: 0.340  loss_box_reg: 0.350  loss_mask: 0.244  loss_rpn_cls: 0.053  loss_rpn_loc: 0.156  time: 4.9929  data_time: 1.8800  lr: 0.000859  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:33:15 d2.utils.events]: \u001b[0m eta: 1:33:41  iter: 879  total_loss: 1.094  loss_cls: 0.308  loss_box_reg: 0.339  loss_mask: 0.233  loss_rpn_cls: 0.057  loss_rpn_loc: 0.159  time: 4.9962  data_time: 1.9134  lr: 0.000879  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:34:58 d2.utils.events]: \u001b[0m eta: 1:32:05  iter: 899  total_loss: 1.092  loss_cls: 0.322  loss_box_reg: 0.348  loss_mask: 0.236  loss_rpn_cls: 0.051  loss_rpn_loc: 0.138  time: 4.9998  data_time: 1.8949  lr: 0.000899  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:36:43 d2.utils.events]: \u001b[0m eta: 1:30:27  iter: 919  total_loss: 1.117  loss_cls: 0.321  loss_box_reg: 0.352  loss_mask: 0.245  loss_rpn_cls: 0.050  loss_rpn_loc: 0.144  time: 5.0052  data_time: 1.9492  lr: 0.000919  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:38:27 d2.utils.events]: \u001b[0m eta: 1:28:54  iter: 939  total_loss: 1.068  loss_cls: 0.314  loss_box_reg: 0.328  loss_mask: 0.235  loss_rpn_cls: 0.048  loss_rpn_loc: 0.136  time: 5.0089  data_time: 1.8832  lr: 0.000939  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:40:11 d2.utils.events]: \u001b[0m eta: 1:27:17  iter: 959  total_loss: 1.121  loss_cls: 0.316  loss_box_reg: 0.356  loss_mask: 0.229  loss_rpn_cls: 0.050  loss_rpn_loc: 0.152  time: 5.0132  data_time: 1.9477  lr: 0.000959  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:41:55 d2.utils.events]: \u001b[0m eta: 1:25:40  iter: 979  total_loss: 1.138  loss_cls: 0.333  loss_box_reg: 0.364  loss_mask: 0.234  loss_rpn_cls: 0.052  loss_rpn_loc: 0.151  time: 5.0175  data_time: 1.9438  lr: 0.000979  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:43:56 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 22:43:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 22:43:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 22:44:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.8988 s / img. ETA=0:03:30\n",
            "\u001b[32m[07/10 22:44:58 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.8809 s / img. ETA=0:03:16\n",
            "\u001b[32m[07/10 22:45:05 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.7591 s / img. ETA=0:02:37\n",
            "\u001b[32m[07/10 22:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.7167 s / img. ETA=0:02:22\n",
            "\u001b[32m[07/10 22:45:16 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.6605 s / img. ETA=0:02:00\n",
            "\u001b[32m[07/10 22:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.6294 s / img. ETA=0:01:45\n",
            "\u001b[32m[07/10 22:45:29 d2.evaluation.evaluator]: \u001b[0mInference done 26/57. 0.6155 s / img. ETA=0:01:37\n",
            "\u001b[32m[07/10 22:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.6056 s / img. ETA=0:01:29\n",
            "\u001b[32m[07/10 22:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.5887 s / img. ETA=0:01:18\n",
            "\u001b[32m[07/10 22:45:47 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.5861 s / img. ETA=0:01:12\n",
            "\u001b[32m[07/10 22:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.5813 s / img. ETA=0:01:06\n",
            "\u001b[32m[07/10 22:46:00 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.5792 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/10 22:46:07 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.5788 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/10 22:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.5768 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/10 22:46:21 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.5677 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/10 22:46:29 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.5818 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/10 22:46:37 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.5951 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 22:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.6044 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/10 22:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.6153 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 22:47:02 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.6252 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 22:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.6359 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 22:47:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:49.806667 (3.265513 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 22:47:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.634527 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 22:47:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 22:47:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 22:47:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.64s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.768\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.481\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.447\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.551\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.625\n",
            "\u001b[32m[07/10 22:47:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 44.716 | 76.846 | 48.118 |  nan  |  nan  | 44.716 |\n",
            "\u001b[32m[07/10 22:47:13 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 22:47:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 46.569 | brec_Cht         | 48.315 | lam_Sltst  | 33.524 |\n",
            "| skel_WkstPkst | 44.137 | strless_SltstSst | 51.035 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.91s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.757\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.545\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.571\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n",
            "\u001b[32m[07/10 22:47:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 46.592 | 75.742 | 54.545 |  nan  |  nan  | 46.592 |\n",
            "\u001b[32m[07/10 22:47:15 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 22:47:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 50.373 | brec_Cht         | 50.505 | lam_Sltst  | 33.551 |\n",
            "| skel_WkstPkst | 43.354 | strless_SltstSst | 55.177 |            |        |\n",
            "\u001b[32m[07/10 22:47:15 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 22:47:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 22:47:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 22:47:15 d2.evaluation.testing]: \u001b[0mcopypaste: 44.7159,76.8457,48.1181,nan,nan,44.7159\n",
            "\u001b[32m[07/10 22:47:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 22:47:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 22:47:15 d2.evaluation.testing]: \u001b[0mcopypaste: 46.5920,75.7422,54.5450,nan,nan,46.5920\n",
            "\u001b[32m[07/10 22:47:19 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 22:47:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 22:47:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 22:47:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.5025 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/10 22:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.6066 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.318187 (3.257576 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.635136 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.147\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.106\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.743 | 34.147 | 10.622 |  nan  |  nan  | 14.743 |\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 22.930 | brec_Cht         | nan    | lam_Sltst  | 3.562 |\n",
            "| skel_WkstPkst | 13.998 | strless_SltstSst | 18.484 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.150\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.343\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 16.664 | 31.498 | 15.019 |  nan  |  nan  | 16.664 |\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 26.648 | brec_Cht         | nan    | lam_Sltst  | 4.223 |\n",
            "| skel_WkstPkst | 12.203 | strless_SltstSst | 23.581 |            |       |\n",
            "\u001b[32m[07/10 22:48:10 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.testing]: \u001b[0mcopypaste: 14.7434,34.1472,10.6225,nan,nan,14.7434\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 22:48:10 d2.evaluation.testing]: \u001b[0mcopypaste: 16.6637,31.4976,15.0192,nan,nan,16.6637\n",
            "\u001b[32m[07/10 22:48:10 d2.utils.events]: \u001b[0m eta: 1:24:03  iter: 999  total_loss: 1.089  loss_cls: 0.320  loss_box_reg: 0.354  loss_mask: 0.225  loss_rpn_cls: 0.046  loss_rpn_loc: 0.161  time: 5.0216  data_time: 1.9215  lr: 0.000999  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:49:56 d2.utils.events]: \u001b[0m eta: 1:22:32  iter: 1019  total_loss: 1.052  loss_cls: 0.296  loss_box_reg: 0.342  loss_mask: 0.226  loss_rpn_cls: 0.048  loss_rpn_loc: 0.138  time: 5.0266  data_time: 1.9592  lr: 0.001000  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:51:38 d2.utils.events]: \u001b[0m eta: 1:20:56  iter: 1039  total_loss: 1.012  loss_cls: 0.280  loss_box_reg: 0.328  loss_mask: 0.230  loss_rpn_cls: 0.042  loss_rpn_loc: 0.144  time: 5.0281  data_time: 1.8399  lr: 0.001000  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:53:23 d2.utils.events]: \u001b[0m eta: 1:19:29  iter: 1059  total_loss: 1.058  loss_cls: 0.304  loss_box_reg: 0.338  loss_mask: 0.224  loss_rpn_cls: 0.044  loss_rpn_loc: 0.136  time: 5.0320  data_time: 1.9122  lr: 0.001000  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:55:06 d2.utils.events]: \u001b[0m eta: 1:17:55  iter: 1079  total_loss: 0.972  loss_cls: 0.257  loss_box_reg: 0.322  loss_mask: 0.223  loss_rpn_cls: 0.041  loss_rpn_loc: 0.139  time: 5.0348  data_time: 1.8967  lr: 0.001000  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:56:50 d2.utils.events]: \u001b[0m eta: 1:16:21  iter: 1099  total_loss: 0.951  loss_cls: 0.263  loss_box_reg: 0.300  loss_mask: 0.209  loss_rpn_cls: 0.041  loss_rpn_loc: 0.135  time: 5.0378  data_time: 1.8993  lr: 0.001000  max_mem: 9029M\n",
            "\u001b[32m[07/10 22:58:35 d2.utils.events]: \u001b[0m eta: 1:14:49  iter: 1119  total_loss: 0.981  loss_cls: 0.263  loss_box_reg: 0.324  loss_mask: 0.214  loss_rpn_cls: 0.039  loss_rpn_loc: 0.130  time: 5.0413  data_time: 1.9193  lr: 0.001000  max_mem: 9029M\n",
            "\u001b[32m[07/10 23:00:20 d2.utils.events]: \u001b[0m eta: 1:13:20  iter: 1139  total_loss: 0.947  loss_cls: 0.261  loss_box_reg: 0.298  loss_mask: 0.214  loss_rpn_cls: 0.035  loss_rpn_loc: 0.131  time: 5.0446  data_time: 1.9572  lr: 0.001000  max_mem: 9029M\n",
            "\u001b[32m[07/10 23:02:04 d2.utils.events]: \u001b[0m eta: 1:11:40  iter: 1159  total_loss: 0.921  loss_cls: 0.233  loss_box_reg: 0.291  loss_mask: 0.210  loss_rpn_cls: 0.039  loss_rpn_loc: 0.151  time: 5.0474  data_time: 1.9358  lr: 0.001000  max_mem: 9029M\n",
            "\u001b[32m[07/10 23:03:48 d2.utils.events]: \u001b[0m eta: 1:10:02  iter: 1179  total_loss: 0.917  loss_cls: 0.229  loss_box_reg: 0.297  loss_mask: 0.205  loss_rpn_cls: 0.035  loss_rpn_loc: 0.133  time: 5.0503  data_time: 1.9267  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:05:50 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 23:05:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 23:05:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 23:06:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.8816 s / img. ETA=0:03:25\n",
            "\u001b[32m[07/10 23:06:48 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.8361 s / img. ETA=0:03:04\n",
            "\u001b[32m[07/10 23:06:53 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.7131 s / img. ETA=0:02:25\n",
            "\u001b[32m[07/10 23:06:59 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.6412 s / img. ETA=0:02:00\n",
            "\u001b[32m[07/10 23:07:04 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.5947 s / img. ETA=0:01:42\n",
            "\u001b[32m[07/10 23:07:09 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.5638 s / img. ETA=0:01:28\n",
            "\u001b[32m[07/10 23:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.5485 s / img. ETA=0:01:18\n",
            "\u001b[32m[07/10 23:07:23 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.5344 s / img. ETA=0:01:08\n",
            "\u001b[32m[07/10 23:07:30 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.5276 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/10 23:07:36 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.5227 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/10 23:07:41 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.5209 s / img. ETA=0:00:50\n",
            "\u001b[32m[07/10 23:07:47 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.5169 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/10 23:07:53 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.5048 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/10 23:07:58 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.5116 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/10 23:08:05 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.5223 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/10 23:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.5355 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/10 23:08:21 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.5497 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 23:08:29 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.5628 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/10 23:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.5745 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 23:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.5784 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/10 23:08:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:29.147650 (2.868224 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 23:08:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:30 (0.578427 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 23:08:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.59s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.893\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.702\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.604\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.675\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.707\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.707\n",
            "\u001b[32m[07/10 23:08:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 60.385 | 89.323 | 70.233 |  nan  |  nan  | 60.385 |\n",
            "\u001b[32m[07/10 23:08:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 23:08:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 59.611 | brec_Cht         | 70.136 | lam_Sltst  | 53.846 |\n",
            "| skel_WkstPkst | 51.376 | strless_SltstSst | 66.956 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.80s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.886\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.718\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.604\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.681\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.714\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714\n",
            "\u001b[32m[07/10 23:08:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 60.393 | 88.630 | 71.835 |  nan  |  nan  | 60.393 |\n",
            "\u001b[32m[07/10 23:08:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 23:08:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 60.504 | brec_Cht         | 69.777 | lam_Sltst  | 49.227 |\n",
            "| skel_WkstPkst | 56.201 | strless_SltstSst | 66.256 |            |        |\n",
            "\u001b[32m[07/10 23:08:45 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 23:08:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 23:08:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 23:08:45 d2.evaluation.testing]: \u001b[0mcopypaste: 60.3850,89.3231,70.2330,nan,nan,60.3850\n",
            "\u001b[32m[07/10 23:08:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 23:08:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 23:08:45 d2.evaluation.testing]: \u001b[0mcopypaste: 60.3931,88.6301,71.8352,nan,nan,60.3931\n",
            "\u001b[32m[07/10 23:08:49 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 23:08:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 23:08:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 23:09:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.4593 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 23:09:33 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.5624 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.208275 (3.023142 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.595073 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.293\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.079\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.123\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.402\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 12.269 | 29.251 | 7.862  |  nan  |  nan  | 12.269 |\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 18.363 | brec_Cht         | nan    | lam_Sltst  | 2.983 |\n",
            "| skel_WkstPkst | 8.684  | strless_SltstSst | 19.045 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.612 | 30.444 | 11.953 |  nan  |  nan  | 14.612 |\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.149 | brec_Cht         | nan    | lam_Sltst  | 3.342 |\n",
            "| skel_WkstPkst | 11.440 | strless_SltstSst | 22.516 |            |       |\n",
            "\u001b[32m[07/10 23:09:37 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.testing]: \u001b[0mcopypaste: 12.2686,29.2505,7.8624,nan,nan,12.2686\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 23:09:37 d2.evaluation.testing]: \u001b[0mcopypaste: 14.6116,30.4444,11.9528,nan,nan,14.6116\n",
            "\u001b[32m[07/10 23:09:37 d2.utils.events]: \u001b[0m eta: 1:08:25  iter: 1199  total_loss: 0.895  loss_cls: 0.242  loss_box_reg: 0.301  loss_mask: 0.202  loss_rpn_cls: 0.034  loss_rpn_loc: 0.130  time: 5.0539  data_time: 1.9237  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:11:21 d2.utils.events]: \u001b[0m eta: 1:06:46  iter: 1219  total_loss: 0.834  loss_cls: 0.214  loss_box_reg: 0.273  loss_mask: 0.198  loss_rpn_cls: 0.030  loss_rpn_loc: 0.124  time: 5.0562  data_time: 1.9109  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:13:06 d2.utils.events]: \u001b[0m eta: 1:05:09  iter: 1239  total_loss: 0.896  loss_cls: 0.230  loss_box_reg: 0.292  loss_mask: 0.211  loss_rpn_cls: 0.033  loss_rpn_loc: 0.131  time: 5.0591  data_time: 1.9293  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:14:51 d2.utils.events]: \u001b[0m eta: 1:03:30  iter: 1259  total_loss: 0.884  loss_cls: 0.233  loss_box_reg: 0.281  loss_mask: 0.200  loss_rpn_cls: 0.036  loss_rpn_loc: 0.129  time: 5.0620  data_time: 1.9382  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:16:35 d2.utils.events]: \u001b[0m eta: 1:01:52  iter: 1279  total_loss: 0.851  loss_cls: 0.220  loss_box_reg: 0.279  loss_mask: 0.190  loss_rpn_cls: 0.032  loss_rpn_loc: 0.121  time: 5.0645  data_time: 1.9016  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:18:20 d2.utils.events]: \u001b[0m eta: 1:00:11  iter: 1299  total_loss: 0.827  loss_cls: 0.192  loss_box_reg: 0.288  loss_mask: 0.195  loss_rpn_cls: 0.029  loss_rpn_loc: 0.126  time: 5.0671  data_time: 1.9143  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:20:04 d2.utils.events]: \u001b[0m eta: 0:58:31  iter: 1319  total_loss: 0.828  loss_cls: 0.212  loss_box_reg: 0.264  loss_mask: 0.187  loss_rpn_cls: 0.026  loss_rpn_loc: 0.125  time: 5.0689  data_time: 1.8918  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:21:47 d2.utils.events]: \u001b[0m eta: 0:56:49  iter: 1339  total_loss: 0.831  loss_cls: 0.197  loss_box_reg: 0.277  loss_mask: 0.190  loss_rpn_cls: 0.028  loss_rpn_loc: 0.126  time: 5.0702  data_time: 1.8653  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:23:31 d2.utils.events]: \u001b[0m eta: 0:55:09  iter: 1359  total_loss: 0.849  loss_cls: 0.215  loss_box_reg: 0.274  loss_mask: 0.202  loss_rpn_cls: 0.029  loss_rpn_loc: 0.126  time: 5.0724  data_time: 1.9213  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:25:15 d2.utils.events]: \u001b[0m eta: 0:53:27  iter: 1379  total_loss: 0.844  loss_cls: 0.220  loss_box_reg: 0.273  loss_mask: 0.204  loss_rpn_cls: 0.027  loss_rpn_loc: 0.122  time: 5.0738  data_time: 1.8851  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:27:15 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 23:27:15 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 23:27:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 23:28:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.8188 s / img. ETA=0:03:09\n",
            "\u001b[32m[07/10 23:28:07 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.7632 s / img. ETA=0:02:47\n",
            "\u001b[32m[07/10 23:28:13 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.6622 s / img. ETA=0:02:14\n",
            "\u001b[32m[07/10 23:28:18 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.6023 s / img. ETA=0:01:52\n",
            "\u001b[32m[07/10 23:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.5442 s / img. ETA=0:01:29\n",
            "\u001b[32m[07/10 23:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 26/57. 0.5195 s / img. ETA=0:01:17\n",
            "\u001b[32m[07/10 23:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.4998 s / img. ETA=0:01:07\n",
            "\u001b[32m[07/10 23:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.4915 s / img. ETA=0:00:59\n",
            "\u001b[32m[07/10 23:28:46 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.4799 s / img. ETA=0:00:50\n",
            "\u001b[32m[07/10 23:28:53 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.4742 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/10 23:28:58 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.4717 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/10 23:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.4614 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/10 23:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.4676 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/10 23:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.4756 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/10 23:29:23 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.4879 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/10 23:29:31 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.5069 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 23:29:39 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.5214 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/10 23:29:46 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.5297 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 23:29:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:11.235252 (2.523755 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 23:29:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:27 (0.528216 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 23:29:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 23:29:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 23:29:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.53s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.596\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.913\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.701\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.596\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.652\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.698\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.698\n",
            "\u001b[32m[07/10 23:29:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 59.632 | 91.260 | 70.126 |  nan  |  nan  | 59.632 |\n",
            "\u001b[32m[07/10 23:29:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 23:29:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 59.625 | brec_Cht         | 56.688 | lam_Sltst  | 53.927 |\n",
            "| skel_WkstPkst | 61.667 | strless_SltstSst | 66.252 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.11s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.73s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.572\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.900\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.679\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.572\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.153\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.630\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681\n",
            "\u001b[32m[07/10 23:29:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 57.226 | 89.975 | 67.921 |  nan  |  nan  | 57.226 |\n",
            "\u001b[32m[07/10 23:29:50 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 23:29:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 56.149 | brec_Cht         | 56.669 | lam_Sltst  | 47.329 |\n",
            "| skel_WkstPkst | 57.313 | strless_SltstSst | 68.672 |            |        |\n",
            "\u001b[32m[07/10 23:29:50 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 23:29:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 23:29:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 23:29:50 d2.evaluation.testing]: \u001b[0mcopypaste: 59.6317,91.2603,70.1264,nan,nan,59.6317\n",
            "\u001b[32m[07/10 23:29:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 23:29:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 23:29:50 d2.evaluation.testing]: \u001b[0mcopypaste: 57.2262,89.9753,67.9210,nan,nan,57.2262\n",
            "\u001b[32m[07/10 23:29:54 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 23:29:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 23:29:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 23:30:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.4313 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/10 23:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.5239 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 23:30:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.263352 (2.807039 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 23:30:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.557247 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 23:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 23:30:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 23:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.147\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.424\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424\n",
            "\u001b[32m[07/10 23:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.735 | 31.090 | 13.025 |  nan  |  nan  | 14.735 |\n",
            "\u001b[32m[07/10 23:30:37 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 23:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 17.988 | brec_Cht         | nan    | lam_Sltst  | 4.701 |\n",
            "| skel_WkstPkst | 11.075 | strless_SltstSst | 25.177 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.384\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.463\n",
            "\u001b[32m[07/10 23:30:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.110 | 31.770 | 15.663 |  nan  |  nan  | 17.110 |\n",
            "\u001b[32m[07/10 23:30:38 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 23:30:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 18.737 | brec_Cht         | nan    | lam_Sltst  | 4.970 |\n",
            "| skel_WkstPkst | 14.656 | strless_SltstSst | 30.078 |            |       |\n",
            "\u001b[32m[07/10 23:30:38 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 23:30:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 23:30:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 23:30:38 d2.evaluation.testing]: \u001b[0mcopypaste: 14.7355,31.0904,13.0245,nan,nan,14.7355\n",
            "\u001b[32m[07/10 23:30:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 23:30:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 23:30:38 d2.evaluation.testing]: \u001b[0mcopypaste: 17.1102,31.7696,15.6627,nan,nan,17.1102\n",
            "\u001b[32m[07/10 23:30:38 d2.utils.events]: \u001b[0m eta: 0:51:47  iter: 1399  total_loss: 0.811  loss_cls: 0.194  loss_box_reg: 0.283  loss_mask: 0.197  loss_rpn_cls: 0.028  loss_rpn_loc: 0.113  time: 5.0755  data_time: 1.9139  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:32:22 d2.utils.events]: \u001b[0m eta: 0:50:05  iter: 1419  total_loss: 0.806  loss_cls: 0.193  loss_box_reg: 0.278  loss_mask: 0.198  loss_rpn_cls: 0.029  loss_rpn_loc: 0.113  time: 5.0775  data_time: 1.9165  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:34:06 d2.utils.events]: \u001b[0m eta: 0:48:23  iter: 1439  total_loss: 0.778  loss_cls: 0.183  loss_box_reg: 0.259  loss_mask: 0.178  loss_rpn_cls: 0.028  loss_rpn_loc: 0.125  time: 5.0795  data_time: 1.9162  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:35:51 d2.utils.events]: \u001b[0m eta: 0:46:42  iter: 1459  total_loss: 0.750  loss_cls: 0.185  loss_box_reg: 0.253  loss_mask: 0.181  loss_rpn_cls: 0.027  loss_rpn_loc: 0.109  time: 5.0812  data_time: 1.9367  lr: 0.001000  max_mem: 9171M\n",
            "\u001b[32m[07/10 23:37:36 d2.utils.events]: \u001b[0m eta: 0:45:01  iter: 1479  total_loss: 0.772  loss_cls: 0.187  loss_box_reg: 0.260  loss_mask: 0.183  loss_rpn_cls: 0.026  loss_rpn_loc: 0.101  time: 5.0837  data_time: 1.9318  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/10 23:39:20 d2.utils.events]: \u001b[0m eta: 0:43:18  iter: 1499  total_loss: 0.746  loss_cls: 0.176  loss_box_reg: 0.245  loss_mask: 0.185  loss_rpn_cls: 0.025  loss_rpn_loc: 0.111  time: 5.0855  data_time: 1.9175  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/10 23:41:05 d2.utils.events]: \u001b[0m eta: 0:41:35  iter: 1519  total_loss: 0.794  loss_cls: 0.186  loss_box_reg: 0.253  loss_mask: 0.184  loss_rpn_cls: 0.029  loss_rpn_loc: 0.116  time: 5.0877  data_time: 1.9311  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/10 23:42:49 d2.utils.events]: \u001b[0m eta: 0:39:52  iter: 1539  total_loss: 0.720  loss_cls: 0.166  loss_box_reg: 0.245  loss_mask: 0.179  loss_rpn_cls: 0.025  loss_rpn_loc: 0.107  time: 5.0889  data_time: 1.8835  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/10 23:44:34 d2.utils.events]: \u001b[0m eta: 0:38:09  iter: 1559  total_loss: 0.700  loss_cls: 0.162  loss_box_reg: 0.239  loss_mask: 0.175  loss_rpn_cls: 0.026  loss_rpn_loc: 0.106  time: 5.0907  data_time: 1.9049  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/10 23:46:17 d2.utils.events]: \u001b[0m eta: 0:36:26  iter: 1579  total_loss: 0.699  loss_cls: 0.157  loss_box_reg: 0.224  loss_mask: 0.181  loss_rpn_cls: 0.026  loss_rpn_loc: 0.107  time: 5.0917  data_time: 1.9122  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/10 23:48:18 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 23:48:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/10 23:48:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/10 23:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.6618 s / img. ETA=0:02:29\n",
            "\u001b[32m[07/10 23:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.5964 s / img. ETA=0:02:01\n",
            "\u001b[32m[07/10 23:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.4843 s / img. ETA=0:01:23\n",
            "\u001b[32m[07/10 23:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.4311 s / img. ETA=0:01:02\n",
            "\u001b[32m[07/10 23:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.4037 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/10 23:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.3943 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/10 23:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.3872 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/10 23:49:35 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.3835 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/10 23:49:41 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.3770 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/10 23:49:49 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.3898 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/10 23:49:55 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.4005 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/10 23:50:02 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.4166 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/10 23:50:09 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.4279 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 23:50:14 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.4342 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/10 23:50:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:39.521341 (1.913872 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 23:50:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.433444 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 23:50:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 23:50:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 23:50:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.40s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.729\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.964\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.874\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.753\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.785\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785\n",
            "\u001b[32m[07/10 23:50:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 72.914 | 96.431 | 87.439 |  nan  |  nan  | 72.914 |\n",
            "\u001b[32m[07/10 23:50:16 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 23:50:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 73.852 | brec_Cht         | 77.583 | lam_Sltst  | 71.710 |\n",
            "| skel_WkstPkst | 66.045 | strless_SltstSst | 75.383 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.57s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.960\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.876\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.769\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.801\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.801\n",
            "\u001b[32m[07/10 23:50:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 74.277 | 96.003 | 87.608 |  nan  |  nan  | 74.278 |\n",
            "\u001b[32m[07/10 23:50:16 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 23:50:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 75.519 | brec_Cht         | 79.409 | lam_Sltst  | 67.059 |\n",
            "| skel_WkstPkst | 72.226 | strless_SltstSst | 77.175 |            |        |\n",
            "\u001b[32m[07/10 23:50:16 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/10 23:50:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 23:50:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 23:50:16 d2.evaluation.testing]: \u001b[0mcopypaste: 72.9144,96.4308,87.4394,nan,nan,72.9144\n",
            "\u001b[32m[07/10 23:50:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 23:50:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 23:50:16 d2.evaluation.testing]: \u001b[0mcopypaste: 74.2775,96.0029,87.6082,nan,nan,74.2778\n",
            "\u001b[32m[07/10 23:50:20 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/10 23:50:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/10 23:50:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/10 23:50:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.3675 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/10 23:50:55 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.4670 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.950421 (2.327825 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.495191 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.437\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.197\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.410\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 19.705 | 43.670 | 11.102 |  nan  |  nan  | 19.705 |\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.723 | brec_Cht         | nan    | lam_Sltst  | 5.012 |\n",
            "| skel_WkstPkst | 21.872 | strless_SltstSst | 27.211 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.442\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.123\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.391\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.472\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 23.397 | 44.152 | 19.200 |  nan  |  nan  | 23.397 |\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 29.349 | brec_Cht         | nan    | lam_Sltst  | 5.340 |\n",
            "| skel_WkstPkst | 27.125 | strless_SltstSst | 31.774 |            |       |\n",
            "\u001b[32m[07/10 23:50:58 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.testing]: \u001b[0mcopypaste: 19.7045,43.6700,11.1019,nan,nan,19.7045\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/10 23:50:58 d2.evaluation.testing]: \u001b[0mcopypaste: 23.3971,44.1519,19.1995,nan,nan,23.3971\n",
            "\u001b[32m[07/10 23:50:58 d2.utils.events]: \u001b[0m eta: 0:34:44  iter: 1599  total_loss: 0.719  loss_cls: 0.160  loss_box_reg: 0.241  loss_mask: 0.176  loss_rpn_cls: 0.024  loss_rpn_loc: 0.113  time: 5.0935  data_time: 1.9016  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/10 23:52:42 d2.utils.events]: \u001b[0m eta: 0:33:01  iter: 1619  total_loss: 0.702  loss_cls: 0.157  loss_box_reg: 0.241  loss_mask: 0.173  loss_rpn_cls: 0.028  loss_rpn_loc: 0.098  time: 5.0948  data_time: 1.9021  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/10 23:54:27 d2.utils.events]: \u001b[0m eta: 0:31:18  iter: 1639  total_loss: 0.755  loss_cls: 0.172  loss_box_reg: 0.252  loss_mask: 0.177  loss_rpn_cls: 0.028  loss_rpn_loc: 0.111  time: 5.0962  data_time: 1.8994  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/10 23:56:12 d2.utils.events]: \u001b[0m eta: 0:29:34  iter: 1659  total_loss: 0.733  loss_cls: 0.161  loss_box_reg: 0.246  loss_mask: 0.179  loss_rpn_cls: 0.023  loss_rpn_loc: 0.107  time: 5.0980  data_time: 1.9282  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/10 23:57:56 d2.utils.events]: \u001b[0m eta: 0:27:51  iter: 1679  total_loss: 0.689  loss_cls: 0.148  loss_box_reg: 0.235  loss_mask: 0.171  loss_rpn_cls: 0.024  loss_rpn_loc: 0.114  time: 5.0992  data_time: 1.8867  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/10 23:59:40 d2.utils.events]: \u001b[0m eta: 0:26:07  iter: 1699  total_loss: 0.669  loss_cls: 0.140  loss_box_reg: 0.229  loss_mask: 0.167  loss_rpn_cls: 0.022  loss_rpn_loc: 0.109  time: 5.1005  data_time: 1.9185  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:01:24 d2.utils.events]: \u001b[0m eta: 0:24:23  iter: 1719  total_loss: 0.702  loss_cls: 0.165  loss_box_reg: 0.232  loss_mask: 0.164  loss_rpn_cls: 0.024  loss_rpn_loc: 0.106  time: 5.1019  data_time: 1.9243  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:03:09 d2.utils.events]: \u001b[0m eta: 0:22:39  iter: 1739  total_loss: 0.677  loss_cls: 0.157  loss_box_reg: 0.230  loss_mask: 0.165  loss_rpn_cls: 0.023  loss_rpn_loc: 0.098  time: 5.1034  data_time: 1.9086  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:04:53 d2.utils.events]: \u001b[0m eta: 0:20:55  iter: 1759  total_loss: 0.670  loss_cls: 0.144  loss_box_reg: 0.237  loss_mask: 0.166  loss_rpn_cls: 0.020  loss_rpn_loc: 0.105  time: 5.1043  data_time: 1.8741  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:06:37 d2.utils.events]: \u001b[0m eta: 0:19:11  iter: 1779  total_loss: 0.684  loss_cls: 0.137  loss_box_reg: 0.226  loss_mask: 0.174  loss_rpn_cls: 0.024  loss_rpn_loc: 0.112  time: 5.1059  data_time: 1.9294  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:08:37 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 00:08:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/11 00:08:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/11 00:09:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.5585 s / img. ETA=0:01:55\n",
            "\u001b[32m[07/11 00:09:13 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.4873 s / img. ETA=0:01:28\n",
            "\u001b[32m[07/11 00:09:18 d2.evaluation.evaluator]: \u001b[0mInference done 20/57. 0.4250 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/11 00:09:24 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.3954 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/11 00:09:30 d2.evaluation.evaluator]: \u001b[0mInference done 30/57. 0.3762 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/11 00:09:35 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.3768 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/11 00:09:41 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.3728 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/11 00:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.3721 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/11 00:09:52 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.3659 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/11 00:09:57 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.3745 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/11 00:10:04 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.3857 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/11 00:10:11 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.4023 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/11 00:10:17 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.4126 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/11 00:10:22 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.4163 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/11 00:10:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:30.037883 (1.731498 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:10:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.416337 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:10:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 00:10:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 00:10:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.38s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.708\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.963\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.872\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.708\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.175\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.773\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773\n",
            "\u001b[32m[07/11 00:10:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 70.810 | 96.304 | 87.163 |  nan  |  nan  | 70.810 |\n",
            "\u001b[32m[07/11 00:10:22 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:10:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 73.345 | brec_Cht         | 66.946 | lam_Sltst  | 66.071 |\n",
            "| skel_WkstPkst | 69.330 | strless_SltstSst | 78.359 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.54s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.963\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.881\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.778\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.798\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.798\n",
            "\u001b[32m[07/11 00:10:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 73.301 | 96.259 | 88.080 |  nan  |  nan  | 73.301 |\n",
            "\u001b[32m[07/11 00:10:23 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:10:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 75.767 | brec_Cht         | 71.907 | lam_Sltst  | 65.735 |\n",
            "| skel_WkstPkst | 76.496 | strless_SltstSst | 76.599 |            |        |\n",
            "\u001b[32m[07/11 00:10:23 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/11 00:10:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 00:10:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 00:10:23 d2.evaluation.testing]: \u001b[0mcopypaste: 70.8099,96.3035,87.1626,nan,nan,70.8099\n",
            "\u001b[32m[07/11 00:10:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 00:10:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 00:10:23 d2.evaluation.testing]: \u001b[0mcopypaste: 73.3007,96.2594,88.0805,nan,nan,73.3007\n",
            "\u001b[32m[07/11 00:10:27 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 00:10:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/11 00:10:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 00:10:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.3698 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/11 00:10:55 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.4395 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.667716 (2.074191 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.474716 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.380\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.182\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 18.227 | 37.987 | 15.077 |  nan  |  nan  | 18.227 |\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 28.072 | brec_Cht         | nan    | lam_Sltst  | 2.579 |\n",
            "| skel_WkstPkst | 17.393 | strless_SltstSst | 24.862 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.229\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.392\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 22.869 | 38.370 | 24.347 |  nan  |  nan  | 22.869 |\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 31.669 | brec_Cht         | nan    | lam_Sltst  | 3.248 |\n",
            "| skel_WkstPkst | 28.333 | strless_SltstSst | 28.227 |            |       |\n",
            "\u001b[32m[07/11 00:10:58 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.testing]: \u001b[0mcopypaste: 18.2266,37.9870,15.0768,nan,nan,18.2266\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 00:10:58 d2.evaluation.testing]: \u001b[0mcopypaste: 22.8691,38.3696,24.3466,nan,nan,22.8691\n",
            "\u001b[32m[07/11 00:10:58 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 1799  total_loss: 0.716  loss_cls: 0.156  loss_box_reg: 0.232  loss_mask: 0.187  loss_rpn_cls: 0.025  loss_rpn_loc: 0.107  time: 5.1068  data_time: 1.8937  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:12:41 d2.utils.events]: \u001b[0m eta: 0:15:43  iter: 1819  total_loss: 0.686  loss_cls: 0.147  loss_box_reg: 0.233  loss_mask: 0.171  loss_rpn_cls: 0.019  loss_rpn_loc: 0.105  time: 5.1070  data_time: 1.8544  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:14:23 d2.utils.events]: \u001b[0m eta: 0:13:58  iter: 1839  total_loss: 0.651  loss_cls: 0.143  loss_box_reg: 0.216  loss_mask: 0.169  loss_rpn_cls: 0.020  loss_rpn_loc: 0.098  time: 5.1071  data_time: 1.8583  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:16:07 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 1859  total_loss: 0.653  loss_cls: 0.146  loss_box_reg: 0.226  loss_mask: 0.168  loss_rpn_cls: 0.021  loss_rpn_loc: 0.101  time: 5.1077  data_time: 1.8872  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:17:49 d2.utils.events]: \u001b[0m eta: 0:10:30  iter: 1879  total_loss: 0.619  loss_cls: 0.128  loss_box_reg: 0.207  loss_mask: 0.155  loss_rpn_cls: 0.023  loss_rpn_loc: 0.101  time: 5.1080  data_time: 1.7911  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:19:32 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 1899  total_loss: 0.623  loss_cls: 0.127  loss_box_reg: 0.201  loss_mask: 0.161  loss_rpn_cls: 0.021  loss_rpn_loc: 0.094  time: 5.1080  data_time: 1.8067  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:21:14 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 1919  total_loss: 0.613  loss_cls: 0.124  loss_box_reg: 0.201  loss_mask: 0.152  loss_rpn_cls: 0.021  loss_rpn_loc: 0.098  time: 5.1079  data_time: 1.7691  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:22:56 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 1939  total_loss: 0.593  loss_cls: 0.117  loss_box_reg: 0.203  loss_mask: 0.151  loss_rpn_cls: 0.019  loss_rpn_loc: 0.093  time: 5.1081  data_time: 1.8458  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:24:39 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 1959  total_loss: 0.596  loss_cls: 0.116  loss_box_reg: 0.200  loss_mask: 0.147  loss_rpn_cls: 0.020  loss_rpn_loc: 0.102  time: 5.1083  data_time: 1.8112  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:26:21 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 1979  total_loss: 0.569  loss_cls: 0.111  loss_box_reg: 0.186  loss_mask: 0.150  loss_rpn_cls: 0.016  loss_rpn_loc: 0.097  time: 5.1082  data_time: 1.8189  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:28:21 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 00:28:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/11 00:28:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/11 00:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.6115 s / img. ETA=0:02:09\n",
            "\u001b[32m[07/11 00:28:58 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.5254 s / img. ETA=0:01:36\n",
            "\u001b[32m[07/11 00:29:04 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.4338 s / img. ETA=0:01:04\n",
            "\u001b[32m[07/11 00:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.3925 s / img. ETA=0:00:46\n",
            "\u001b[32m[07/11 00:29:15 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.3748 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/11 00:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.3687 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/11 00:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.3653 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/11 00:29:34 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.3628 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/11 00:29:40 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.3759 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/11 00:29:46 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.3868 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/11 00:29:53 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.4029 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/11 00:29:59 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.4135 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/11 00:30:04 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.4175 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/11 00:30:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:28.568690 (1.703244 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:30:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.417543 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:30:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 00:30:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 00:30:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.782\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.991\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.946\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.805\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.823\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.823\n",
            "\u001b[32m[07/11 00:30:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 78.230 | 99.057 | 94.637 |  nan  |  nan  | 78.230 |\n",
            "\u001b[32m[07/11 00:30:05 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:30:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 79.101 | brec_Cht         | 80.548 | lam_Sltst  | 74.446 |\n",
            "| skel_WkstPkst | 77.046 | strless_SltstSst | 80.008 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.50s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.784\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.989\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.936\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.784\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.806\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.824\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.824\n",
            "\u001b[32m[07/11 00:30:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 78.438 | 98.905 | 93.615 |  nan  |  nan  | 78.438 |\n",
            "\u001b[32m[07/11 00:30:05 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:30:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 80.111 | brec_Cht         | 82.027 | lam_Sltst  | 71.483 |\n",
            "| skel_WkstPkst | 77.794 | strless_SltstSst | 80.773 |            |        |\n",
            "\u001b[32m[07/11 00:30:05 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/11 00:30:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 00:30:05 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 00:30:05 d2.evaluation.testing]: \u001b[0mcopypaste: 78.2299,99.0575,94.6372,nan,nan,78.2299\n",
            "\u001b[32m[07/11 00:30:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 00:30:05 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 00:30:05 d2.evaluation.testing]: \u001b[0mcopypaste: 78.4378,98.9047,93.6147,nan,nan,78.4378\n",
            "\u001b[32m[07/11 00:30:09 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 00:30:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/11 00:30:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 00:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.3445 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/11 00:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.4474 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.383330 (2.153703 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.488440 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.385\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.132\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.337\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.416\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.859 | 38.535 | 13.233 |  nan  |  nan  | 17.859 |\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 26.312 | brec_Cht         | nan    | lam_Sltst  | 3.340 |\n",
            "| skel_WkstPkst | 15.297 | strless_SltstSst | 26.487 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.392\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.471\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 21.006 | 39.583 | 18.924 |  nan  |  nan  | 21.006 |\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 29.953 | brec_Cht         | nan    | lam_Sltst  | 3.843 |\n",
            "| skel_WkstPkst | 22.202 | strless_SltstSst | 28.026 |            |       |\n",
            "\u001b[32m[07/11 00:30:44 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: 17.8589,38.5347,13.2325,nan,nan,17.8589\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 00:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: 21.0059,39.5829,18.9236,nan,nan,21.0059\n",
            "\u001b[32m[07/11 00:30:44 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 1999  total_loss: 0.583  loss_cls: 0.115  loss_box_reg: 0.195  loss_mask: 0.150  loss_rpn_cls: 0.015  loss_rpn_loc: 0.091  time: 5.1083  data_time: 1.8071  lr: 0.001000  max_mem: 9256M\n",
            "\u001b[32m[07/11 00:30:44 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 2:50:06 (5.1108 s / it)\n",
            "\u001b[32m[07/11 00:30:44 d2.engine.hooks]: \u001b[0mTotal training time: 3:33:07 (0:43:01 on hooks)\n",
            "\n",
            "\n",
            "**Starting train eval**\n",
            "\u001b[32m[07/11 00:31:00 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 00:31:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/11 00:31:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/11 00:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.6296 s / img. ETA=0:03:26\n",
            "\u001b[32m[07/11 00:31:54 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.5936 s / img. ETA=0:03:00\n",
            "\u001b[32m[07/11 00:31:59 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.4778 s / img. ETA=0:01:54\n",
            "\u001b[32m[07/11 00:32:04 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.4232 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/11 00:32:10 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.3924 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/11 00:32:15 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.3761 s / img. ETA=0:00:46\n",
            "\u001b[32m[07/11 00:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.3708 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/11 00:32:27 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.3679 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/11 00:32:34 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.3649 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/11 00:32:39 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.3717 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/11 00:32:47 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.3845 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/11 00:32:52 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.3916 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/11 00:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.4004 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/11 00:33:06 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.4096 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/11 00:33:12 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.4166 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/11 00:33:18 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.4211 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/11 00:33:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:58.165694 (2.272417 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:33:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.420396 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:33:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 00:33:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/11 00:33:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.35s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.782\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.991\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.946\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.805\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.823\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.823\n",
            "\u001b[32m[07/11 00:33:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 78.230 | 99.057 | 94.637 |  nan  |  nan  | 78.230 |\n",
            "\u001b[32m[07/11 00:33:20 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:33:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 79.101 | brec_Cht         | 80.548 | lam_Sltst  | 74.446 |\n",
            "| skel_WkstPkst | 77.046 | strless_SltstSst | 80.008 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.50s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.784\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.989\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.936\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.784\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.806\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.824\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.824\n",
            "\u001b[32m[07/11 00:33:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 78.438 | 98.905 | 93.615 |  nan  |  nan  | 78.438 |\n",
            "\u001b[32m[07/11 00:33:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:33:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 80.111 | brec_Cht         | 82.027 | lam_Sltst  | 71.483 |\n",
            "| skel_WkstPkst | 77.794 | strless_SltstSst | 80.773 |            |        |\n",
            "randomly selected cores/Box 8 Depths 10035-45.JPG\n",
            "\n",
            "\n",
            "**Starting val eval**\n",
            "\u001b[32m[07/11 00:34:02 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 00:34:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/11 00:34:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 00:34:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.3460 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/11 00:34:47 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.4480 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/11 00:34:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.428084 (2.825343 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:34:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.474507 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:34:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 00:34:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/11 00:34:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.385\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.132\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.337\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.416\n",
            "\u001b[32m[07/11 00:34:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.859 | 38.535 | 13.233 |  nan  |  nan  | 17.859 |\n",
            "\u001b[32m[07/11 00:34:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:34:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 26.312 | brec_Cht         | nan    | lam_Sltst  | 3.340 |\n",
            "| skel_WkstPkst | 15.297 | strless_SltstSst | 26.487 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.392\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.471\n",
            "\u001b[32m[07/11 00:34:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 21.006 | 39.583 | 18.924 |  nan  |  nan  | 21.006 |\n",
            "\u001b[32m[07/11 00:34:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:34:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 29.953 | brec_Cht         | nan    | lam_Sltst  | 3.843 |\n",
            "| skel_WkstPkst | 22.202 | strless_SltstSst | 28.026 |            |       |\n",
            "randomly selected cores/Boxes 22-24  Depths 7778.4-7786.5 (Dry).JPG\n",
            "Sat Jul 11 00:35:32 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P0    72W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "CPU times: user 28.7 s, sys: 5.26 s, total: 34 s\n",
            "Wall time: 3h 38min 50s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hUqQJAOLd-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b78a5299-9482-4cd4-82dc-398668e5cc68"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '4' --max_iter 2000\n",
        "# copy results to Google Drive\n",
        "! cp -r output_fold_4 'drive/My Drive/R50-C4'\n",
        "# clean folders if upcoming experiment\n",
        "! rm -r *coco*\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 4\n",
            "\t cores_fold_4_train\n",
            "\t cores_fold_4_val\n",
            "\u001b[32m[07/11 00:35:39 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/11 00:35:54 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 56 images left.\n",
            "\u001b[32m[07/11 00:35:54 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 245          |   brec_Cht    | 17           | lam_Sltst  | 94           |\n",
            "| skel_WkstPkst | 16           | strless_Slt.. | 122          |            |              |\n",
            "|     total     | 494          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/11 00:35:54 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 00:35:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/11 00:35:54 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/11 00:35:54 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-11 00:35:55.290578: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Unable to load 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (15, 4) in the checkpoint but (3, 4) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (1024, 1024, 3, 3) in the checkpoint but (256, 256, 3, 3) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (256,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (15, 1024, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (15,) in the checkpoint but (3,) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (60, 1024, 1, 1) in the checkpoint but (12, 256, 1, 1) in the model!\n",
            "Unable to load 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (60,) in the checkpoint but (12,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.deconv.weight' to the model due to incompatible shapes: (2048, 256, 2, 2) in the checkpoint but (256, 256, 2, 2) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/11 00:35:57 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/11 00:37:27 d2.utils.events]: \u001b[0m eta: 2:27:39  iter: 19  total_loss: 48.935  loss_cls: 37.682  loss_box_reg: 0.815  loss_mask: 1.170  loss_rpn_cls: 0.696  loss_rpn_loc: 9.405  time: 4.4664  data_time: 1.9658  lr: 0.000020  max_mem: 8438M\n",
            "\u001b[32m[07/11 00:38:55 d2.utils.events]: \u001b[0m eta: 2:24:54  iter: 39  total_loss: 8.590  loss_cls: 5.550  loss_box_reg: 0.196  loss_mask: 0.571  loss_rpn_cls: 0.272  loss_rpn_loc: 0.916  time: 4.4397  data_time: 1.8457  lr: 0.000040  max_mem: 8438M\n",
            "\u001b[32m[07/11 00:40:27 d2.utils.events]: \u001b[0m eta: 2:25:08  iter: 59  total_loss: 3.002  loss_cls: 1.592  loss_box_reg: 0.273  loss_mask: 0.567  loss_rpn_cls: 0.221  loss_rpn_loc: 0.362  time: 4.4877  data_time: 1.8654  lr: 0.000060  max_mem: 8438M\n",
            "\u001b[32m[07/11 00:41:59 d2.utils.events]: \u001b[0m eta: 2:24:29  iter: 79  total_loss: 1.957  loss_cls: 0.616  loss_box_reg: 0.306  loss_mask: 0.560  loss_rpn_cls: 0.192  loss_rpn_loc: 0.275  time: 4.5196  data_time: 1.8459  lr: 0.000080  max_mem: 8438M\n",
            "\u001b[32m[07/11 00:43:32 d2.utils.events]: \u001b[0m eta: 2:24:05  iter: 99  total_loss: 1.750  loss_cls: 0.431  loss_box_reg: 0.331  loss_mask: 0.547  loss_rpn_cls: 0.168  loss_rpn_loc: 0.251  time: 4.5416  data_time: 1.8632  lr: 0.000100  max_mem: 8438M\n",
            "\u001b[32m[07/11 00:45:05 d2.utils.events]: \u001b[0m eta: 2:23:07  iter: 119  total_loss: 1.660  loss_cls: 0.354  loss_box_reg: 0.361  loss_mask: 0.535  loss_rpn_cls: 0.167  loss_rpn_loc: 0.229  time: 4.5657  data_time: 1.8492  lr: 0.000120  max_mem: 8438M\n",
            "\u001b[32m[07/11 00:46:40 d2.utils.events]: \u001b[0m eta: 2:22:00  iter: 139  total_loss: 1.612  loss_cls: 0.350  loss_box_reg: 0.369  loss_mask: 0.515  loss_rpn_cls: 0.158  loss_rpn_loc: 0.217  time: 4.5877  data_time: 1.8794  lr: 0.000140  max_mem: 8438M\n",
            "\u001b[32m[07/11 00:48:14 d2.utils.events]: \u001b[0m eta: 2:21:07  iter: 159  total_loss: 1.550  loss_cls: 0.320  loss_box_reg: 0.364  loss_mask: 0.500  loss_rpn_cls: 0.148  loss_rpn_loc: 0.208  time: 4.6029  data_time: 1.8742  lr: 0.000160  max_mem: 8438M\n",
            "\u001b[32m[07/11 00:49:48 d2.utils.events]: \u001b[0m eta: 2:20:08  iter: 179  total_loss: 1.592  loss_cls: 0.369  loss_box_reg: 0.398  loss_mask: 0.490  loss_rpn_cls: 0.145  loss_rpn_loc: 0.195  time: 4.6141  data_time: 1.8382  lr: 0.000180  max_mem: 8438M\n",
            "\u001b[32m[07/11 00:51:38 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 00:51:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/11 00:51:38 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_4_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/11 00:51:38 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_4_train' to COCO format ...)\n",
            "\u001b[32m[07/11 00:51:53 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/11 00:51:53 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 57, #annotations: 494\n",
            "\u001b[32m[07/11 00:51:53 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_4_train_coco_format.json' ...\n",
            "\u001b[32m[07/11 00:51:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0x6802c000 @  0x7fc48571ab6b 0x7fc48573a379 0x7fc428e6f04e 0x7fc428e70f4a 0x7fc461d5f67b 0x7fc4619ae6be 0x7fc461c177b5 0x7fc461c097c1 0x7fc461c08d0e 0x7fc461c097c1 0x7fc46365e93a 0x7fc461c097c1 0x7fc4619a9457 0x7fc4619aa080 0x7fc461cc871a 0x7fc46374613e 0x7fc461c09c72 0x7fc46fca3a68 0x7fc46fd5eb04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/11 00:52:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.9133 s / img. ETA=0:03:20\n",
            "\u001b[32m[07/11 00:52:54 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.9159 s / img. ETA=0:03:11\n",
            "\u001b[32m[07/11 00:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.9016 s / img. ETA=0:03:04\n",
            "\u001b[32m[07/11 00:53:12 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.8639 s / img. ETA=0:02:56\n",
            "\u001b[32m[07/11 00:53:21 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.8368 s / img. ETA=0:02:47\n",
            "\u001b[32m[07/11 00:53:30 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.8165 s / img. ETA=0:02:39\n",
            "\u001b[32m[07/11 00:53:39 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.8006 s / img. ETA=0:02:30\n",
            "\u001b[32m[07/11 00:53:48 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.7882 s / img. ETA=0:02:21\n",
            "\u001b[32m[07/11 00:53:57 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.7830 s / img. ETA=0:02:12\n",
            "\u001b[32m[07/11 00:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.7740 s / img. ETA=0:02:04\n",
            "\u001b[32m[07/11 00:54:14 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.7662 s / img. ETA=0:01:55\n",
            "\u001b[32m[07/11 00:54:23 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.7597 s / img. ETA=0:01:46\n",
            "\u001b[32m[07/11 00:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.7539 s / img. ETA=0:01:37\n",
            "\u001b[32m[07/11 00:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.7511 s / img. ETA=0:01:28\n",
            "\u001b[32m[07/11 00:54:49 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.7463 s / img. ETA=0:01:19\n",
            "\u001b[32m[07/11 00:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.7421 s / img. ETA=0:01:10\n",
            "\u001b[32m[07/11 00:55:05 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.7340 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/11 00:55:12 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.7318 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/11 00:55:20 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.7389 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/11 00:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.7464 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/11 00:55:36 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.7521 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/11 00:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.7566 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/11 00:55:52 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.7608 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/11 00:56:00 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.7629 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/11 00:56:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:40.540447 (4.241162 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:56:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.762915 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:56:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 00:56:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 00:56:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.82s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.043\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.125\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.169\n",
            "\u001b[32m[07/11 00:56:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 4.262 | 12.506 | 1.119  |  nan  |  nan  | 4.262 |\n",
            "\u001b[32m[07/11 00:56:01 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:56:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 9.540 | brec_Cht         | 1.866 | lam_Sltst  | 0.983 |\n",
            "| skel_WkstPkst | 1.396 | strless_SltstSst | 7.527 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.20s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.038\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.122\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
            "\u001b[32m[07/11 00:56:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.841 | 12.151 | 0.566  |  nan  |  nan  | 3.841 |\n",
            "\u001b[32m[07/11 00:56:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:56:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 8.719 | brec_Cht         | 1.244 | lam_Sltst  | 0.928 |\n",
            "| skel_WkstPkst | 1.396 | strless_SltstSst | 6.917 |            |       |\n",
            "\u001b[32m[07/11 00:56:02 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/11 00:56:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 00:56:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 00:56:02 d2.evaluation.testing]: \u001b[0mcopypaste: 4.2624,12.5063,1.1187,nan,nan,4.2624\n",
            "\u001b[32m[07/11 00:56:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 00:56:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 00:56:02 d2.evaluation.testing]: \u001b[0mcopypaste: 3.8408,12.1514,0.5663,nan,nan,3.8408\n",
            "\u001b[32m[07/11 00:56:06 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 64           |   brec_Cht    | 4            | lam_Sltst  | 33           |\n",
            "| skel_WkstPkst | 10           | strless_Slt.. | 51           |            |              |\n",
            "|     total     | 162          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/11 00:56:06 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 00:56:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/11 00:56:06 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_4_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/11 00:56:06 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_4_val' to COCO format ...)\n",
            "\u001b[32m[07/11 00:56:10 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/11 00:56:10 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 14, #annotations: 162\n",
            "\u001b[32m[07/11 00:56:10 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_4_val_coco_format.json' ...\n",
            "\u001b[32m[07/11 00:56:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 00:57:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.7166 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/11 00:57:09 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.7518 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.414377 (4.157153 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.763471 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.092\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 1.824 | 6.629  | 0.370  |  nan  |  nan  | 1.824 |\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 4.426 | brec_Cht         | 0.000 | lam_Sltst  | 0.000 |\n",
            "| skel_WkstPkst | 0.000 | strless_SltstSst | 4.695 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.31s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.091\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 1.639 | 5.787  | 0.267  |  nan  |  nan  | 1.639 |\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP    | category         | AP    | category   | AP    |\n",
            "|:--------------|:------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 3.907 | brec_Cht         | 0.000 | lam_Sltst  | 0.027 |\n",
            "| skel_WkstPkst | 0.000 | strless_SltstSst | 4.263 |            |       |\n",
            "\u001b[32m[07/11 00:57:13 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.testing]: \u001b[0mcopypaste: 1.8241,6.6292,0.3699,nan,nan,1.8241\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 00:57:13 d2.evaluation.testing]: \u001b[0mcopypaste: 1.6394,5.7870,0.2665,nan,nan,1.6394\n",
            "\u001b[32m[07/11 00:57:13 d2.utils.events]: \u001b[0m eta: 2:18:47  iter: 199  total_loss: 1.557  loss_cls: 0.348  loss_box_reg: 0.404  loss_mask: 0.464  loss_rpn_cls: 0.138  loss_rpn_loc: 0.187  time: 4.6265  data_time: 1.8058  lr: 0.000200  max_mem: 8438M\n",
            "\u001b[32m[07/11 00:58:49 d2.utils.events]: \u001b[0m eta: 2:17:33  iter: 219  total_loss: 1.572  loss_cls: 0.392  loss_box_reg: 0.421  loss_mask: 0.444  loss_rpn_cls: 0.140  loss_rpn_loc: 0.184  time: 4.6400  data_time: 1.8422  lr: 0.000220  max_mem: 8438M\n",
            "\u001b[32m[07/11 01:00:26 d2.utils.events]: \u001b[0m eta: 2:16:59  iter: 239  total_loss: 1.560  loss_cls: 0.394  loss_box_reg: 0.431  loss_mask: 0.420  loss_rpn_cls: 0.127  loss_rpn_loc: 0.185  time: 4.6568  data_time: 1.8538  lr: 0.000240  max_mem: 8438M\n",
            "\u001b[32m[07/11 01:02:02 d2.utils.events]: \u001b[0m eta: 2:15:56  iter: 259  total_loss: 1.542  loss_cls: 0.427  loss_box_reg: 0.427  loss_mask: 0.391  loss_rpn_cls: 0.123  loss_rpn_loc: 0.172  time: 4.6707  data_time: 1.8192  lr: 0.000260  max_mem: 8438M\n",
            "\u001b[32m[07/11 01:03:39 d2.utils.events]: \u001b[0m eta: 2:14:52  iter: 279  total_loss: 1.483  loss_cls: 0.406  loss_box_reg: 0.437  loss_mask: 0.379  loss_rpn_cls: 0.122  loss_rpn_loc: 0.178  time: 4.6831  data_time: 1.8110  lr: 0.000280  max_mem: 8438M\n",
            "\u001b[32m[07/11 01:05:16 d2.utils.events]: \u001b[0m eta: 2:13:26  iter: 299  total_loss: 1.574  loss_cls: 0.468  loss_box_reg: 0.416  loss_mask: 0.363  loss_rpn_cls: 0.118  loss_rpn_loc: 0.177  time: 4.6933  data_time: 1.8261  lr: 0.000300  max_mem: 8438M\n",
            "\u001b[32m[07/11 01:06:54 d2.utils.events]: \u001b[0m eta: 2:12:07  iter: 319  total_loss: 1.423  loss_cls: 0.392  loss_box_reg: 0.409  loss_mask: 0.339  loss_rpn_cls: 0.103  loss_rpn_loc: 0.169  time: 4.7055  data_time: 1.8211  lr: 0.000320  max_mem: 8438M\n",
            "\u001b[32m[07/11 01:08:32 d2.utils.events]: \u001b[0m eta: 2:10:42  iter: 339  total_loss: 1.458  loss_cls: 0.408  loss_box_reg: 0.431  loss_mask: 0.333  loss_rpn_cls: 0.112  loss_rpn_loc: 0.172  time: 4.7176  data_time: 1.8172  lr: 0.000340  max_mem: 8561M\n",
            "\u001b[32m[07/11 01:10:09 d2.utils.events]: \u001b[0m eta: 2:09:21  iter: 359  total_loss: 1.448  loss_cls: 0.403  loss_box_reg: 0.419  loss_mask: 0.330  loss_rpn_cls: 0.103  loss_rpn_loc: 0.151  time: 4.7261  data_time: 1.8209  lr: 0.000360  max_mem: 8561M\n",
            "\u001b[32m[07/11 01:11:48 d2.utils.events]: \u001b[0m eta: 2:08:00  iter: 379  total_loss: 1.432  loss_cls: 0.420  loss_box_reg: 0.425  loss_mask: 0.331  loss_rpn_cls: 0.099  loss_rpn_loc: 0.163  time: 4.7371  data_time: 1.8592  lr: 0.000380  max_mem: 8561M\n",
            "\u001b[32m[07/11 01:13:42 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 01:13:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/11 01:13:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/11 01:14:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.9409 s / img. ETA=0:03:25\n",
            "\u001b[32m[07/11 01:14:44 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.9360 s / img. ETA=0:03:13\n",
            "\u001b[32m[07/11 01:14:52 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.9092 s / img. ETA=0:03:03\n",
            "\u001b[32m[07/11 01:15:00 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.8712 s / img. ETA=0:02:53\n",
            "\u001b[32m[07/11 01:15:09 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.8521 s / img. ETA=0:02:44\n",
            "\u001b[32m[07/11 01:15:17 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.8301 s / img. ETA=0:02:34\n",
            "\u001b[32m[07/11 01:15:26 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.8130 s / img. ETA=0:02:25\n",
            "\u001b[32m[07/11 01:15:34 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.7992 s / img. ETA=0:02:16\n",
            "\u001b[32m[07/11 01:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.7881 s / img. ETA=0:02:08\n",
            "\u001b[32m[07/11 01:15:51 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.7788 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/11 01:15:59 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.7724 s / img. ETA=0:01:50\n",
            "\u001b[32m[07/11 01:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.7655 s / img. ETA=0:01:42\n",
            "\u001b[32m[07/11 01:16:16 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.7592 s / img. ETA=0:01:33\n",
            "\u001b[32m[07/11 01:16:24 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.7538 s / img. ETA=0:01:24\n",
            "\u001b[32m[07/11 01:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.7488 s / img. ETA=0:01:16\n",
            "\u001b[32m[07/11 01:16:40 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.7450 s / img. ETA=0:01:07\n",
            "\u001b[32m[07/11 01:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.7367 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/11 01:16:54 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.7345 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/11 01:17:02 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.7415 s / img. ETA=0:00:41\n",
            "\u001b[32m[07/11 01:17:09 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.7480 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/11 01:17:17 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.7533 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/11 01:17:25 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.7604 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/11 01:17:33 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.7642 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/11 01:17:41 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.7681 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/11 01:17:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:32.916979 (4.094557 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 01:17:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.768143 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 01:17:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 01:17:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 01:17:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.74s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.079\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.112\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.244\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.320\n",
            "\u001b[32m[07/11 01:17:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.156 | 27.442 | 7.915  |  nan  |  nan  | 11.156 |\n",
            "\u001b[32m[07/11 01:17:42 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 01:17:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.615 | brec_Cht         | 12.133 | lam_Sltst  | 4.327 |\n",
            "| skel_WkstPkst | 2.181  | strless_SltstSst | 16.527 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.20s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.122\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.122\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.068\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n",
            "\u001b[32m[07/11 01:17:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 12.189 | 27.251 | 7.485  |  nan  |  nan  | 12.189 |\n",
            "\u001b[32m[07/11 01:17:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 01:17:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.502 | brec_Cht         | 16.523 | lam_Sltst  | 4.046 |\n",
            "| skel_WkstPkst | 2.494  | strless_SltstSst | 17.382 |            |       |\n",
            "\u001b[32m[07/11 01:17:44 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/11 01:17:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 01:17:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 01:17:44 d2.evaluation.testing]: \u001b[0mcopypaste: 11.1563,27.4421,7.9155,nan,nan,11.1563\n",
            "\u001b[32m[07/11 01:17:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 01:17:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 01:17:44 d2.evaluation.testing]: \u001b[0mcopypaste: 12.1893,27.2509,7.4855,nan,nan,12.1893\n",
            "\u001b[32m[07/11 01:17:48 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 01:17:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/11 01:17:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 01:18:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.7096 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/11 01:18:46 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.7467 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/11 01:18:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.321453 (4.146828 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 01:18:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.759749 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 01:18:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 01:18:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 01:18:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.043\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.126\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.187\n",
            "\u001b[32m[07/11 01:18:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.758 | 14.088 | 4.336  |  nan  |  nan  | 5.758 |\n",
            "\u001b[32m[07/11 01:18:50 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 01:18:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 11.878 | brec_Cht         | 0.905 | lam_Sltst  | 0.987 |\n",
            "| skel_WkstPkst | 7.624  | strless_SltstSst | 7.399 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.30s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.066\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.231\n",
            "\u001b[32m[07/11 01:18:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 6.559 | 13.742 | 5.454  |  nan  |  nan  | 6.559 |\n",
            "\u001b[32m[07/11 01:18:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 01:18:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 11.977 | brec_Cht         | 2.914 | lam_Sltst  | 1.074 |\n",
            "| skel_WkstPkst | 7.624  | strless_SltstSst | 9.208 |            |       |\n",
            "\u001b[32m[07/11 01:18:51 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/11 01:18:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 01:18:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 01:18:51 d2.evaluation.testing]: \u001b[0mcopypaste: 5.7585,14.0878,4.3355,nan,nan,5.7585\n",
            "\u001b[32m[07/11 01:18:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 01:18:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 01:18:51 d2.evaluation.testing]: \u001b[0mcopypaste: 6.5593,13.7420,5.4537,nan,nan,6.5593\n",
            "\u001b[32m[07/11 01:18:51 d2.utils.events]: \u001b[0m eta: 2:06:43  iter: 399  total_loss: 1.357  loss_cls: 0.403  loss_box_reg: 0.400  loss_mask: 0.311  loss_rpn_cls: 0.095  loss_rpn_loc: 0.157  time: 4.7460  data_time: 1.8122  lr: 0.000400  max_mem: 8561M\n",
            "\u001b[32m[07/11 01:20:30 d2.utils.events]: \u001b[0m eta: 2:05:22  iter: 419  total_loss: 1.393  loss_cls: 0.445  loss_box_reg: 0.400  loss_mask: 0.306  loss_rpn_cls: 0.095  loss_rpn_loc: 0.163  time: 4.7573  data_time: 1.8680  lr: 0.000420  max_mem: 8646M\n",
            "\u001b[32m[07/11 01:22:10 d2.utils.events]: \u001b[0m eta: 2:04:00  iter: 439  total_loss: 1.318  loss_cls: 0.389  loss_box_reg: 0.386  loss_mask: 0.297  loss_rpn_cls: 0.090  loss_rpn_loc: 0.161  time: 4.7671  data_time: 1.8416  lr: 0.000440  max_mem: 8646M\n",
            "\u001b[32m[07/11 01:23:49 d2.utils.events]: \u001b[0m eta: 2:02:31  iter: 459  total_loss: 1.359  loss_cls: 0.400  loss_box_reg: 0.419  loss_mask: 0.302  loss_rpn_cls: 0.088  loss_rpn_loc: 0.166  time: 4.7762  data_time: 1.8188  lr: 0.000460  max_mem: 8646M\n",
            "\u001b[32m[07/11 01:25:30 d2.utils.events]: \u001b[0m eta: 2:01:15  iter: 479  total_loss: 1.352  loss_cls: 0.419  loss_box_reg: 0.377  loss_mask: 0.293  loss_rpn_cls: 0.084  loss_rpn_loc: 0.176  time: 4.7865  data_time: 1.9158  lr: 0.000480  max_mem: 8646M\n",
            "\u001b[32m[07/11 01:27:10 d2.utils.events]: \u001b[0m eta: 1:59:59  iter: 499  total_loss: 1.328  loss_cls: 0.392  loss_box_reg: 0.385  loss_mask: 0.283  loss_rpn_cls: 0.084  loss_rpn_loc: 0.158  time: 4.7959  data_time: 1.8777  lr: 0.000500  max_mem: 8646M\n",
            "\u001b[32m[07/11 01:28:49 d2.utils.events]: \u001b[0m eta: 1:58:32  iter: 519  total_loss: 1.301  loss_cls: 0.393  loss_box_reg: 0.378  loss_mask: 0.283  loss_rpn_cls: 0.081  loss_rpn_loc: 0.164  time: 4.8023  data_time: 1.8510  lr: 0.000519  max_mem: 8646M\n",
            "\u001b[32m[07/11 01:30:29 d2.utils.events]: \u001b[0m eta: 1:57:05  iter: 539  total_loss: 1.268  loss_cls: 0.389  loss_box_reg: 0.369  loss_mask: 0.269  loss_rpn_cls: 0.079  loss_rpn_loc: 0.166  time: 4.8083  data_time: 1.8236  lr: 0.000539  max_mem: 8646M\n",
            "\u001b[32m[07/11 01:32:08 d2.utils.events]: \u001b[0m eta: 1:55:47  iter: 559  total_loss: 1.263  loss_cls: 0.373  loss_box_reg: 0.386  loss_mask: 0.270  loss_rpn_cls: 0.079  loss_rpn_loc: 0.158  time: 4.8139  data_time: 1.8436  lr: 0.000559  max_mem: 8646M\n",
            "\u001b[32m[07/11 01:33:48 d2.utils.events]: \u001b[0m eta: 1:54:32  iter: 579  total_loss: 1.243  loss_cls: 0.369  loss_box_reg: 0.383  loss_mask: 0.266  loss_rpn_cls: 0.069  loss_rpn_loc: 0.142  time: 4.8195  data_time: 1.8597  lr: 0.000579  max_mem: 8646M\n",
            "\u001b[32m[07/11 01:35:42 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 01:35:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/11 01:35:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/11 01:36:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.8903 s / img. ETA=0:03:19\n",
            "\u001b[32m[07/11 01:36:43 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.8986 s / img. ETA=0:03:11\n",
            "\u001b[32m[07/11 01:36:50 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.8474 s / img. ETA=0:02:53\n",
            "\u001b[32m[07/11 01:36:56 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.8035 s / img. ETA=0:02:40\n",
            "\u001b[32m[07/11 01:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.7747 s / img. ETA=0:02:30\n",
            "\u001b[32m[07/11 01:37:11 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.7585 s / img. ETA=0:02:20\n",
            "\u001b[32m[07/11 01:37:18 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.7410 s / img. ETA=0:02:10\n",
            "\u001b[32m[07/11 01:37:25 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.7266 s / img. ETA=0:02:02\n",
            "\u001b[32m[07/11 01:37:32 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.7164 s / img. ETA=0:01:54\n",
            "\u001b[32m[07/11 01:37:38 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.7015 s / img. ETA=0:01:44\n",
            "\u001b[32m[07/11 01:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.6869 s / img. ETA=0:01:35\n",
            "\u001b[32m[07/11 01:37:51 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.6822 s / img. ETA=0:01:28\n",
            "\u001b[32m[07/11 01:38:00 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.6860 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/11 01:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.6823 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/11 01:38:16 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.6808 s / img. ETA=0:01:07\n",
            "\u001b[32m[07/11 01:38:24 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.6795 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/11 01:38:30 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.6716 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/11 01:38:36 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.6705 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/11 01:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.6816 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/11 01:38:51 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.6905 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/11 01:38:59 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.6983 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/11 01:39:07 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.7052 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/11 01:39:15 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.7115 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/11 01:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.7136 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/11 01:39:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:13.785895 (3.726652 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 01:39:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.713561 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 01:39:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 01:39:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 01:39:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.69s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.521\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.167\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.241\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.105\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.404\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n",
            "\u001b[32m[07/11 01:39:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 24.074 | 52.096 | 16.738 |  nan  |  nan  | 24.074 |\n",
            "\u001b[32m[07/11 01:39:23 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 01:39:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 30.121 | brec_Cht         | 28.605 | lam_Sltst  | 17.100 |\n",
            "| skel_WkstPkst | 11.915 | strless_SltstSst | 32.631 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.94s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.522\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.547\n",
            "\u001b[32m[07/11 01:39:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 29.723 | 52.189 | 30.951 |  nan  |  nan  | 29.723 |\n",
            "\u001b[32m[07/11 01:39:24 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 01:39:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 35.559 | brec_Cht         | 38.377 | lam_Sltst  | 19.263 |\n",
            "| skel_WkstPkst | 17.564 | strless_SltstSst | 37.855 |            |        |\n",
            "\u001b[32m[07/11 01:39:24 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/11 01:39:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 01:39:24 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 01:39:24 d2.evaluation.testing]: \u001b[0mcopypaste: 24.0742,52.0956,16.7380,nan,nan,24.0742\n",
            "\u001b[32m[07/11 01:39:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 01:39:24 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 01:39:24 d2.evaluation.testing]: \u001b[0mcopypaste: 29.7234,52.1892,30.9512,nan,nan,29.7234\n",
            "\u001b[32m[07/11 01:39:28 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 01:39:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/11 01:39:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 01:40:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.6834 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/11 01:40:23 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.7286 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.161832 (3.906870 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.742923 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.079\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.217\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.079\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.341\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 7.854 | 21.733 | 3.271  |  nan  |  nan  | 7.854 |\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 12.264 | brec_Cht         | 9.056 | lam_Sltst  | 3.056 |\n",
            "| skel_WkstPkst | 6.620  | strless_SltstSst | 8.276 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.220\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.109\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.106\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.640 | 21.983 | 10.875 |  nan  |  nan  | 10.640 |\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 14.788 | brec_Cht         | 19.626 | lam_Sltst  | 2.872 |\n",
            "| skel_WkstPkst | 6.868  | strless_SltstSst | 9.047  |            |       |\n",
            "\u001b[32m[07/11 01:40:28 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.testing]: \u001b[0mcopypaste: 7.8545,21.7329,3.2715,nan,nan,7.8545\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 01:40:28 d2.evaluation.testing]: \u001b[0mcopypaste: 10.6401,21.9828,10.8754,nan,nan,10.6401\n",
            "\u001b[32m[07/11 01:40:28 d2.utils.events]: \u001b[0m eta: 1:52:57  iter: 599  total_loss: 1.265  loss_cls: 0.391  loss_box_reg: 0.366  loss_mask: 0.269  loss_rpn_cls: 0.078  loss_rpn_loc: 0.155  time: 4.8235  data_time: 1.7857  lr: 0.000599  max_mem: 8646M\n",
            "\u001b[32m[07/11 01:42:08 d2.utils.events]: \u001b[0m eta: 1:51:31  iter: 619  total_loss: 1.211  loss_cls: 0.362  loss_box_reg: 0.381  loss_mask: 0.265  loss_rpn_cls: 0.069  loss_rpn_loc: 0.146  time: 4.8295  data_time: 1.8253  lr: 0.000619  max_mem: 8880M\n",
            "\u001b[32m[07/11 01:43:49 d2.utils.events]: \u001b[0m eta: 1:49:58  iter: 639  total_loss: 1.180  loss_cls: 0.340  loss_box_reg: 0.362  loss_mask: 0.262  loss_rpn_cls: 0.067  loss_rpn_loc: 0.137  time: 4.8358  data_time: 1.8291  lr: 0.000639  max_mem: 8880M\n",
            "\u001b[32m[07/11 01:45:30 d2.utils.events]: \u001b[0m eta: 1:48:32  iter: 659  total_loss: 1.225  loss_cls: 0.377  loss_box_reg: 0.378  loss_mask: 0.260  loss_rpn_cls: 0.068  loss_rpn_loc: 0.152  time: 4.8419  data_time: 1.8405  lr: 0.000659  max_mem: 8880M\n",
            "\u001b[32m[07/11 01:47:09 d2.utils.events]: \u001b[0m eta: 1:46:58  iter: 679  total_loss: 1.234  loss_cls: 0.389  loss_box_reg: 0.384  loss_mask: 0.253  loss_rpn_cls: 0.069  loss_rpn_loc: 0.147  time: 4.8449  data_time: 1.7948  lr: 0.000679  max_mem: 8880M\n",
            "\u001b[32m[07/11 01:48:50 d2.utils.events]: \u001b[0m eta: 1:45:27  iter: 699  total_loss: 1.248  loss_cls: 0.357  loss_box_reg: 0.369  loss_mask: 0.250  loss_rpn_cls: 0.061  loss_rpn_loc: 0.152  time: 4.8508  data_time: 1.8859  lr: 0.000699  max_mem: 8880M\n",
            "\u001b[32m[07/11 01:50:31 d2.utils.events]: \u001b[0m eta: 1:43:57  iter: 719  total_loss: 1.184  loss_cls: 0.332  loss_box_reg: 0.355  loss_mask: 0.247  loss_rpn_cls: 0.062  loss_rpn_loc: 0.154  time: 4.8563  data_time: 1.8534  lr: 0.000719  max_mem: 8896M\n",
            "\u001b[32m[07/11 01:52:11 d2.utils.events]: \u001b[0m eta: 1:42:21  iter: 739  total_loss: 1.149  loss_cls: 0.340  loss_box_reg: 0.350  loss_mask: 0.240  loss_rpn_cls: 0.063  loss_rpn_loc: 0.145  time: 4.8606  data_time: 1.8009  lr: 0.000739  max_mem: 8896M\n",
            "\u001b[32m[07/11 01:53:52 d2.utils.events]: \u001b[0m eta: 1:40:48  iter: 759  total_loss: 1.147  loss_cls: 0.332  loss_box_reg: 0.347  loss_mask: 0.248  loss_rpn_cls: 0.056  loss_rpn_loc: 0.153  time: 4.8652  data_time: 1.8462  lr: 0.000759  max_mem: 8896M\n",
            "\u001b[32m[07/11 01:55:32 d2.utils.events]: \u001b[0m eta: 1:39:16  iter: 779  total_loss: 1.104  loss_cls: 0.310  loss_box_reg: 0.344  loss_mask: 0.237  loss_rpn_cls: 0.059  loss_rpn_loc: 0.143  time: 4.8692  data_time: 1.8133  lr: 0.000779  max_mem: 8896M\n",
            "\u001b[32m[07/11 01:57:29 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 01:57:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/11 01:57:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/11 01:58:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.8423 s / img. ETA=0:02:58\n",
            "\u001b[32m[07/11 01:58:26 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.8435 s / img. ETA=0:02:50\n",
            "\u001b[32m[07/11 01:58:31 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.7802 s / img. ETA=0:02:32\n",
            "\u001b[32m[07/11 01:58:37 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.7404 s / img. ETA=0:02:21\n",
            "\u001b[32m[07/11 01:58:44 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.7144 s / img. ETA=0:02:12\n",
            "\u001b[32m[07/11 01:58:49 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.6825 s / img. ETA=0:02:01\n",
            "\u001b[32m[07/11 01:58:55 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.6643 s / img. ETA=0:01:52\n",
            "\u001b[32m[07/11 01:59:00 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.6473 s / img. ETA=0:01:44\n",
            "\u001b[32m[07/11 01:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.6367 s / img. ETA=0:01:37\n",
            "\u001b[32m[07/11 01:59:15 d2.evaluation.evaluator]: \u001b[0mInference done 30/57. 0.6186 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/11 01:59:21 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.6126 s / img. ETA=0:01:19\n",
            "\u001b[32m[07/11 01:59:28 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.6121 s / img. ETA=0:01:13\n",
            "\u001b[32m[07/11 01:59:35 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.6102 s / img. ETA=0:01:07\n",
            "\u001b[32m[07/11 01:59:42 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.6109 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/11 01:59:50 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.6119 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/11 01:59:57 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.6114 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/11 02:00:05 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.6045 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/11 02:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.6165 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/11 02:00:20 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.6285 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/11 02:00:28 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.6414 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/11 02:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.6509 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/11 02:00:44 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.6593 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/11 02:00:51 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.6613 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/11 02:00:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:55.668242 (3.378235 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 02:00:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:34 (0.661331 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 02:00:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 02:00:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 02:00:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.62s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.647\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.129\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.556\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.556\n",
            "\u001b[32m[07/11 02:00:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.933 | 64.700 | 31.799 |  nan  |  nan  | 33.933 |\n",
            "\u001b[32m[07/11 02:00:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 02:00:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 37.772 | brec_Cht         | 39.836 | lam_Sltst  | 26.594 |\n",
            "| skel_WkstPkst | 22.129 | strless_SltstSst | 43.331 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.15s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.86s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.646\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.399\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.551\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.611\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611\n",
            "\u001b[32m[07/11 02:00:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 37.683 | 64.626 | 39.861 |  nan  |  nan  | 37.683 |\n",
            "\u001b[32m[07/11 02:00:53 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 02:00:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 41.781 | brec_Cht         | 50.655 | lam_Sltst  | 26.584 |\n",
            "| skel_WkstPkst | 25.249 | strless_SltstSst | 44.148 |            |        |\n",
            "\u001b[32m[07/11 02:00:53 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/11 02:00:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 02:00:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 02:00:53 d2.evaluation.testing]: \u001b[0mcopypaste: 33.9326,64.6997,31.7988,nan,nan,33.9326\n",
            "\u001b[32m[07/11 02:00:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 02:00:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 02:00:53 d2.evaluation.testing]: \u001b[0mcopypaste: 37.6833,64.6263,39.8605,nan,nan,37.6833\n",
            "\u001b[32m[07/11 02:00:57 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 02:00:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/11 02:00:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 02:01:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.6094 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/11 02:01:47 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.6716 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.048583 (3.672065 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.692987 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.078\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.078\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.251\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.376\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.376\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 7.778 | 19.315 | 5.048  |  nan  |  nan  | 7.778 |\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 10.208 | brec_Cht         | 6.303 | lam_Sltst  | 1.683 |\n",
            "| skel_WkstPkst | 12.068 | strless_SltstSst | 8.628 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.433\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.410 | 19.430 | 6.715  |  nan  |  nan  | 9.410 |\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 12.006 | brec_Cht         | 6.122  | lam_Sltst  | 2.273 |\n",
            "| skel_WkstPkst | 15.904 | strless_SltstSst | 10.744 |            |       |\n",
            "\u001b[32m[07/11 02:01:52 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.testing]: \u001b[0mcopypaste: 7.7783,19.3151,5.0479,nan,nan,7.7783\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 02:01:52 d2.evaluation.testing]: \u001b[0mcopypaste: 9.4098,19.4299,6.7151,nan,nan,9.4098\n",
            "\u001b[32m[07/11 02:01:52 d2.utils.events]: \u001b[0m eta: 1:37:45  iter: 799  total_loss: 1.140  loss_cls: 0.330  loss_box_reg: 0.370  loss_mask: 0.240  loss_rpn_cls: 0.054  loss_rpn_loc: 0.146  time: 4.8744  data_time: 1.8723  lr: 0.000799  max_mem: 8896M\n",
            "\u001b[32m[07/11 02:03:34 d2.utils.events]: \u001b[0m eta: 1:36:16  iter: 819  total_loss: 1.173  loss_cls: 0.354  loss_box_reg: 0.350  loss_mask: 0.240  loss_rpn_cls: 0.056  loss_rpn_loc: 0.168  time: 4.8795  data_time: 1.8785  lr: 0.000819  max_mem: 8896M\n",
            "\u001b[32m[07/11 02:05:15 d2.utils.events]: \u001b[0m eta: 1:34:44  iter: 839  total_loss: 1.150  loss_cls: 0.345  loss_box_reg: 0.380  loss_mask: 0.235  loss_rpn_cls: 0.053  loss_rpn_loc: 0.140  time: 4.8841  data_time: 1.8618  lr: 0.000839  max_mem: 8896M\n",
            "\u001b[32m[07/11 02:06:57 d2.utils.events]: \u001b[0m eta: 1:33:10  iter: 859  total_loss: 1.078  loss_cls: 0.314  loss_box_reg: 0.333  loss_mask: 0.234  loss_rpn_cls: 0.053  loss_rpn_loc: 0.139  time: 4.8888  data_time: 1.8639  lr: 0.000859  max_mem: 8896M\n",
            "\u001b[32m[07/11 02:08:37 d2.utils.events]: \u001b[0m eta: 1:31:34  iter: 879  total_loss: 1.031  loss_cls: 0.298  loss_box_reg: 0.324  loss_mask: 0.227  loss_rpn_cls: 0.045  loss_rpn_loc: 0.137  time: 4.8915  data_time: 1.8540  lr: 0.000879  max_mem: 8896M\n",
            "\u001b[32m[07/11 02:10:18 d2.utils.events]: \u001b[0m eta: 1:30:00  iter: 899  total_loss: 1.015  loss_cls: 0.292  loss_box_reg: 0.331  loss_mask: 0.225  loss_rpn_cls: 0.052  loss_rpn_loc: 0.144  time: 4.8949  data_time: 1.8453  lr: 0.000899  max_mem: 8896M\n",
            "\u001b[32m[07/11 02:12:01 d2.utils.events]: \u001b[0m eta: 1:28:26  iter: 919  total_loss: 1.047  loss_cls: 0.310  loss_box_reg: 0.349  loss_mask: 0.222  loss_rpn_cls: 0.048  loss_rpn_loc: 0.124  time: 4.9006  data_time: 1.9163  lr: 0.000919  max_mem: 8896M\n",
            "\u001b[32m[07/11 02:13:43 d2.utils.events]: \u001b[0m eta: 1:26:56  iter: 939  total_loss: 1.033  loss_cls: 0.272  loss_box_reg: 0.326  loss_mask: 0.231  loss_rpn_cls: 0.049  loss_rpn_loc: 0.140  time: 4.9050  data_time: 1.8580  lr: 0.000939  max_mem: 8896M\n",
            "\u001b[32m[07/11 02:15:27 d2.utils.events]: \u001b[0m eta: 1:25:20  iter: 959  total_loss: 1.017  loss_cls: 0.274  loss_box_reg: 0.319  loss_mask: 0.212  loss_rpn_cls: 0.044  loss_rpn_loc: 0.145  time: 4.9110  data_time: 1.9356  lr: 0.000959  max_mem: 8896M\n",
            "\u001b[32m[07/11 02:17:11 d2.utils.events]: \u001b[0m eta: 1:23:44  iter: 979  total_loss: 1.007  loss_cls: 0.293  loss_box_reg: 0.325  loss_mask: 0.217  loss_rpn_cls: 0.045  loss_rpn_loc: 0.139  time: 4.9168  data_time: 1.9247  lr: 0.000979  max_mem: 8896M\n",
            "\u001b[32m[07/11 02:19:11 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 02:19:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/11 02:19:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/11 02:20:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.8534 s / img. ETA=0:03:17\n",
            "\u001b[32m[07/11 02:20:11 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.8615 s / img. ETA=0:03:09\n",
            "\u001b[32m[07/11 02:20:18 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.8057 s / img. ETA=0:02:49\n",
            "\u001b[32m[07/11 02:20:24 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.7643 s / img. ETA=0:02:37\n",
            "\u001b[32m[07/11 02:20:31 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.7341 s / img. ETA=0:02:26\n",
            "\u001b[32m[07/11 02:20:37 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.7154 s / img. ETA=0:02:15\n",
            "\u001b[32m[07/11 02:20:44 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.6953 s / img. ETA=0:02:05\n",
            "\u001b[32m[07/11 02:20:50 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.6803 s / img. ETA=0:01:57\n",
            "\u001b[32m[07/11 02:20:58 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.6743 s / img. ETA=0:01:50\n",
            "\u001b[32m[07/11 02:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.6600 s / img. ETA=0:01:41\n",
            "\u001b[32m[07/11 02:21:10 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.6515 s / img. ETA=0:01:33\n",
            "\u001b[32m[07/11 02:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.6522 s / img. ETA=0:01:27\n",
            "\u001b[32m[07/11 02:21:27 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.6583 s / img. ETA=0:01:20\n",
            "\u001b[32m[07/11 02:21:36 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.6574 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/11 02:21:44 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.6567 s / img. ETA=0:01:07\n",
            "\u001b[32m[07/11 02:21:53 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.6575 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/11 02:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.6509 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/11 02:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.6509 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/11 02:22:15 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.6648 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/11 02:22:23 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.6747 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/11 02:22:31 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.6831 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/11 02:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.6904 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/11 02:22:49 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.6971 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/11 02:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.6997 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/11 02:22:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:18.620245 (3.819620 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 02:22:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.699677 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 02:22:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 02:22:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 02:22:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.70s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.686\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.423\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.585\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.585\n",
            "\u001b[32m[07/11 02:22:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 39.278 | 68.614 | 42.282 |  nan  |  nan  | 39.278 |\n",
            "\u001b[32m[07/11 02:22:57 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 02:22:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 45.448 | brec_Cht         | 56.864 | lam_Sltst  | 29.390 |\n",
            "| skel_WkstPkst | 18.202 | strless_SltstSst | 46.487 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.97s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.674\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.494\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.429\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.132\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.561\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643\n",
            "\u001b[32m[07/11 02:22:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 42.853 | 67.386 | 49.409 |  nan  |  nan  | 42.853 |\n",
            "\u001b[32m[07/11 02:22:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 02:22:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 51.931 | brec_Cht         | 64.391 | lam_Sltst  | 30.049 |\n",
            "| skel_WkstPkst | 16.170 | strless_SltstSst | 51.721 |            |        |\n",
            "\u001b[32m[07/11 02:22:58 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/11 02:22:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 02:22:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 02:22:58 d2.evaluation.testing]: \u001b[0mcopypaste: 39.2784,68.6137,42.2820,nan,nan,39.2784\n",
            "\u001b[32m[07/11 02:22:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 02:22:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 02:22:58 d2.evaluation.testing]: \u001b[0mcopypaste: 42.8525,67.3859,49.4092,nan,nan,42.8525\n",
            "\u001b[32m[07/11 02:23:02 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 02:23:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/11 02:23:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 02:23:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.6496 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/11 02:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.7025 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/11 02:24:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.630402 (4.070045 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 02:24:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.719146 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 02:24:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 02:24:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 02:24:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.116\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.252\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.116\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.364\n",
            "\u001b[32m[07/11 02:24:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.633 | 25.207 | 9.433  |  nan  |  nan  | 11.633 |\n",
            "\u001b[32m[07/11 02:24:03 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 02:24:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 13.411 | brec_Cht         | 4.480  | lam_Sltst  | 2.353 |\n",
            "| skel_WkstPkst | 23.850 | strless_SltstSst | 14.070 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.29s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.139\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.258\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.139\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435\n",
            "\u001b[32m[07/11 02:24:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.850 | 25.779 | 16.388 |  nan  |  nan  | 13.850 |\n",
            "\u001b[32m[07/11 02:24:04 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 02:24:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 15.210 | brec_Cht         | 5.536  | lam_Sltst  | 2.951 |\n",
            "| skel_WkstPkst | 28.622 | strless_SltstSst | 16.931 |            |       |\n",
            "\u001b[32m[07/11 02:24:04 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/11 02:24:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 02:24:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 02:24:04 d2.evaluation.testing]: \u001b[0mcopypaste: 11.6327,25.2072,9.4329,nan,nan,11.6327\n",
            "\u001b[32m[07/11 02:24:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 02:24:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 02:24:04 d2.evaluation.testing]: \u001b[0mcopypaste: 13.8501,25.7787,16.3878,nan,nan,13.8501\n",
            "\u001b[32m[07/11 02:24:04 d2.utils.events]: \u001b[0m eta: 1:22:07  iter: 999  total_loss: 1.009  loss_cls: 0.287  loss_box_reg: 0.321  loss_mask: 0.221  loss_rpn_cls: 0.041  loss_rpn_loc: 0.142  time: 4.9221  data_time: 1.9053  lr: 0.000999  max_mem: 8896M\n",
            "\u001b[32m[07/11 02:25:47 d2.utils.events]: \u001b[0m eta: 1:20:42  iter: 1019  total_loss: 1.035  loss_cls: 0.280  loss_box_reg: 0.336  loss_mask: 0.223  loss_rpn_cls: 0.046  loss_rpn_loc: 0.133  time: 4.9265  data_time: 1.8986  lr: 0.001000  max_mem: 8917M\n",
            "\u001b[32m[07/11 02:27:29 d2.utils.events]: \u001b[0m eta: 1:19:11  iter: 1039  total_loss: 0.977  loss_cls: 0.298  loss_box_reg: 0.318  loss_mask: 0.221  loss_rpn_cls: 0.036  loss_rpn_loc: 0.136  time: 4.9300  data_time: 1.8593  lr: 0.001000  max_mem: 8917M\n",
            "\u001b[32m[07/11 02:29:13 d2.utils.events]: \u001b[0m eta: 1:17:48  iter: 1059  total_loss: 0.957  loss_cls: 0.250  loss_box_reg: 0.302  loss_mask: 0.215  loss_rpn_cls: 0.039  loss_rpn_loc: 0.131  time: 4.9352  data_time: 1.9076  lr: 0.001000  max_mem: 8917M\n",
            "\u001b[32m[07/11 02:30:56 d2.utils.events]: \u001b[0m eta: 1:16:17  iter: 1079  total_loss: 0.918  loss_cls: 0.257  loss_box_reg: 0.292  loss_mask: 0.207  loss_rpn_cls: 0.034  loss_rpn_loc: 0.128  time: 4.9396  data_time: 1.8897  lr: 0.001000  max_mem: 8917M\n",
            "\u001b[32m[07/11 02:32:39 d2.utils.events]: \u001b[0m eta: 1:14:52  iter: 1099  total_loss: 0.993  loss_cls: 0.263  loss_box_reg: 0.315  loss_mask: 0.225  loss_rpn_cls: 0.037  loss_rpn_loc: 0.131  time: 4.9432  data_time: 1.9090  lr: 0.001000  max_mem: 8917M\n",
            "\u001b[32m[07/11 02:34:22 d2.utils.events]: \u001b[0m eta: 1:13:21  iter: 1119  total_loss: 0.965  loss_cls: 0.267  loss_box_reg: 0.307  loss_mask: 0.217  loss_rpn_cls: 0.036  loss_rpn_loc: 0.123  time: 4.9468  data_time: 1.8942  lr: 0.001000  max_mem: 8917M\n",
            "\u001b[32m[07/11 02:36:06 d2.utils.events]: \u001b[0m eta: 1:11:49  iter: 1139  total_loss: 0.900  loss_cls: 0.247  loss_box_reg: 0.295  loss_mask: 0.210  loss_rpn_cls: 0.029  loss_rpn_loc: 0.122  time: 4.9514  data_time: 1.9433  lr: 0.001000  max_mem: 8917M\n",
            "\u001b[32m[07/11 02:37:50 d2.utils.events]: \u001b[0m eta: 1:10:17  iter: 1159  total_loss: 0.873  loss_cls: 0.224  loss_box_reg: 0.282  loss_mask: 0.202  loss_rpn_cls: 0.032  loss_rpn_loc: 0.121  time: 4.9554  data_time: 1.9019  lr: 0.001000  max_mem: 8917M\n",
            "\u001b[32m[07/11 02:39:33 d2.utils.events]: \u001b[0m eta: 1:08:42  iter: 1179  total_loss: 0.844  loss_cls: 0.213  loss_box_reg: 0.280  loss_mask: 0.193  loss_rpn_cls: 0.036  loss_rpn_loc: 0.119  time: 4.9591  data_time: 1.9110  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 02:41:34 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 02:41:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/11 02:41:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/11 02:42:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.7069 s / img. ETA=0:02:38\n",
            "\u001b[32m[07/11 02:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.6838 s / img. ETA=0:02:23\n",
            "\u001b[32m[07/11 02:42:29 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.6168 s / img. ETA=0:02:00\n",
            "\u001b[32m[07/11 02:42:36 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.5737 s / img. ETA=0:01:46\n",
            "\u001b[32m[07/11 02:42:42 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.5417 s / img. ETA=0:01:32\n",
            "\u001b[32m[07/11 02:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.5192 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/11 02:42:55 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.5051 s / img. ETA=0:01:12\n",
            "\u001b[32m[07/11 02:43:00 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.4889 s / img. ETA=0:01:03\n",
            "\u001b[32m[07/11 02:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.4893 s / img. ETA=0:00:59\n",
            "\u001b[32m[07/11 02:43:12 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.4945 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/11 02:43:18 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.4940 s / img. ETA=0:00:50\n",
            "\u001b[32m[07/11 02:43:24 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.4945 s / img. ETA=0:00:46\n",
            "\u001b[32m[07/11 02:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.4956 s / img. ETA=0:00:41\n",
            "\u001b[32m[07/11 02:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.4852 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/11 02:43:43 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.4910 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/11 02:43:49 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.4970 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/11 02:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.5094 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/11 02:44:05 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.5246 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/11 02:44:11 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.5318 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/11 02:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.5366 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/11 02:44:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:20.681463 (2.705413 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 02:44:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:27 (0.536592 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 02:44:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 02:44:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 02:44:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.55s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.617\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.897\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.762\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.679\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.721\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.721\n",
            "\u001b[32m[07/11 02:44:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 61.706 | 89.729 | 76.218 |  nan  |  nan  | 61.706 |\n",
            "\u001b[32m[07/11 02:44:18 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 02:44:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 65.700 | brec_Cht         | 66.564 | lam_Sltst  | 53.248 |\n",
            "| skel_WkstPkst | 58.344 | strless_SltstSst | 64.675 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.75s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.890\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.709\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.685\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.729\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729\n",
            "\u001b[32m[07/11 02:44:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 61.262 | 89.026 | 70.901 |  nan  |  nan  | 61.262 |\n",
            "\u001b[32m[07/11 02:44:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 02:44:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 67.209 | brec_Cht         | 74.204 | lam_Sltst  | 51.890 |\n",
            "| skel_WkstPkst | 48.391 | strless_SltstSst | 64.619 |            |        |\n",
            "\u001b[32m[07/11 02:44:19 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/11 02:44:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 02:44:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 02:44:19 d2.evaluation.testing]: \u001b[0mcopypaste: 61.7061,89.7294,76.2176,nan,nan,61.7061\n",
            "\u001b[32m[07/11 02:44:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 02:44:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 02:44:19 d2.evaluation.testing]: \u001b[0mcopypaste: 61.2625,89.0256,70.9007,nan,nan,61.2625\n",
            "\u001b[32m[07/11 02:44:23 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 02:44:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/11 02:44:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 02:44:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.5090 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/11 02:45:06 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.5846 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/11 02:45:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.557817 (3.173091 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 02:45:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.607619 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 02:45:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 02:45:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 02:45:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.248\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.056\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.055\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.381\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.381\n",
            "\u001b[32m[07/11 02:45:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.710 | 24.793 | 5.568  |  nan  |  nan  | 9.710 |\n",
            "\u001b[32m[07/11 02:45:10 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 02:45:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 13.812 | brec_Cht         | 3.366  | lam_Sltst  | 3.551 |\n",
            "| skel_WkstPkst | 13.796 | strless_SltstSst | 14.025 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.242\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.064\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.342\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.431\n",
            "\u001b[32m[07/11 02:45:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.918 | 24.239 | 9.881  |  nan  |  nan  | 10.918 |\n",
            "\u001b[32m[07/11 02:45:11 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 02:45:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 14.756 | brec_Cht         | 3.847  | lam_Sltst  | 3.898 |\n",
            "| skel_WkstPkst | 16.124 | strless_SltstSst | 15.966 |            |       |\n",
            "\u001b[32m[07/11 02:45:11 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/11 02:45:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 02:45:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 02:45:11 d2.evaluation.testing]: \u001b[0mcopypaste: 9.7102,24.7928,5.5678,nan,nan,9.7102\n",
            "\u001b[32m[07/11 02:45:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 02:45:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 02:45:11 d2.evaluation.testing]: \u001b[0mcopypaste: 10.9183,24.2387,9.8807,nan,nan,10.9183\n",
            "\u001b[32m[07/11 02:45:11 d2.utils.events]: \u001b[0m eta: 1:07:10  iter: 1199  total_loss: 0.842  loss_cls: 0.200  loss_box_reg: 0.265  loss_mask: 0.195  loss_rpn_cls: 0.034  loss_rpn_loc: 0.132  time: 4.9638  data_time: 1.9082  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 02:46:55 d2.utils.events]: \u001b[0m eta: 1:05:36  iter: 1219  total_loss: 0.883  loss_cls: 0.213  loss_box_reg: 0.286  loss_mask: 0.201  loss_rpn_cls: 0.031  loss_rpn_loc: 0.141  time: 4.9680  data_time: 1.9188  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 02:48:40 d2.utils.events]: \u001b[0m eta: 1:04:01  iter: 1239  total_loss: 0.828  loss_cls: 0.213  loss_box_reg: 0.272  loss_mask: 0.193  loss_rpn_cls: 0.029  loss_rpn_loc: 0.128  time: 4.9724  data_time: 1.9460  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 02:50:25 d2.utils.events]: \u001b[0m eta: 1:02:27  iter: 1259  total_loss: 0.853  loss_cls: 0.218  loss_box_reg: 0.281  loss_mask: 0.196  loss_rpn_cls: 0.030  loss_rpn_loc: 0.125  time: 4.9771  data_time: 1.9466  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 02:52:09 d2.utils.events]: \u001b[0m eta: 1:00:49  iter: 1279  total_loss: 0.821  loss_cls: 0.206  loss_box_reg: 0.295  loss_mask: 0.193  loss_rpn_cls: 0.031  loss_rpn_loc: 0.132  time: 4.9805  data_time: 1.8879  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 02:53:54 d2.utils.events]: \u001b[0m eta: 0:59:15  iter: 1299  total_loss: 0.822  loss_cls: 0.199  loss_box_reg: 0.275  loss_mask: 0.201  loss_rpn_cls: 0.029  loss_rpn_loc: 0.115  time: 4.9846  data_time: 1.9253  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 02:55:38 d2.utils.events]: \u001b[0m eta: 0:57:36  iter: 1319  total_loss: 0.835  loss_cls: 0.206  loss_box_reg: 0.289  loss_mask: 0.190  loss_rpn_cls: 0.028  loss_rpn_loc: 0.122  time: 4.9875  data_time: 1.9122  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 02:57:21 d2.utils.events]: \u001b[0m eta: 0:55:57  iter: 1339  total_loss: 0.809  loss_cls: 0.191  loss_box_reg: 0.290  loss_mask: 0.186  loss_rpn_cls: 0.026  loss_rpn_loc: 0.118  time: 4.9905  data_time: 1.8790  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 02:59:05 d2.utils.events]: \u001b[0m eta: 0:54:20  iter: 1359  total_loss: 0.830  loss_cls: 0.200  loss_box_reg: 0.264  loss_mask: 0.189  loss_rpn_cls: 0.030  loss_rpn_loc: 0.127  time: 4.9932  data_time: 1.9413  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 03:00:48 d2.utils.events]: \u001b[0m eta: 0:52:43  iter: 1379  total_loss: 0.808  loss_cls: 0.193  loss_box_reg: 0.265  loss_mask: 0.190  loss_rpn_cls: 0.026  loss_rpn_loc: 0.119  time: 4.9957  data_time: 1.9073  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 03:02:48 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 03:02:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/11 03:02:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/11 03:03:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.7175 s / img. ETA=0:02:33\n",
            "\u001b[32m[07/11 03:03:35 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.6961 s / img. ETA=0:02:19\n",
            "\u001b[32m[07/11 03:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.5864 s / img. ETA=0:01:46\n",
            "\u001b[32m[07/11 03:03:47 d2.evaluation.evaluator]: \u001b[0mInference done 20/57. 0.5441 s / img. ETA=0:01:32\n",
            "\u001b[32m[07/11 03:03:52 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.5135 s / img. ETA=0:01:20\n",
            "\u001b[32m[07/11 03:03:57 d2.evaluation.evaluator]: \u001b[0mInference done 26/57. 0.4922 s / img. ETA=0:01:10\n",
            "\u001b[32m[07/11 03:04:03 d2.evaluation.evaluator]: \u001b[0mInference done 30/57. 0.4667 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/11 03:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.4586 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/11 03:04:16 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.4532 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/11 03:04:23 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.4510 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/11 03:04:29 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.4478 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/11 03:04:36 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.4411 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/11 03:04:41 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.4486 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/11 03:04:47 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.4596 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/11 03:04:55 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.4770 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/11 03:05:01 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.4843 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/11 03:05:07 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.4908 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/11 03:05:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:59.264138 (2.293541 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 03:05:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:25 (0.489824 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 03:05:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 03:05:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 03:05:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.46s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.931\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.780\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.645\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.698\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
            "\u001b[32m[07/11 03:05:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 64.493 | 93.062 | 78.011 |  nan  |  nan  | 64.493 |\n",
            "\u001b[32m[07/11 03:05:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 03:05:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 64.485 | brec_Cht         | 66.470 | lam_Sltst  | 61.120 |\n",
            "| skel_WkstPkst | 57.480 | strless_SltstSst | 72.909 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.10s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.75s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.585\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.900\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.692\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.168\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.647\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.690\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.690\n",
            "\u001b[32m[07/11 03:05:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 58.470 | 89.988 | 69.215 |  nan  |  nan  | 59.429 |\n",
            "\u001b[32m[07/11 03:05:10 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 03:05:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 62.017 | brec_Cht         | 68.962 | lam_Sltst  | 52.946 |\n",
            "| skel_WkstPkst | 41.388 | strless_SltstSst | 67.039 |            |        |\n",
            "\u001b[32m[07/11 03:05:10 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/11 03:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 03:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 03:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: 64.4929,93.0617,78.0107,nan,nan,64.4929\n",
            "\u001b[32m[07/11 03:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 03:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 03:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: 58.4703,89.9876,69.2148,nan,nan,59.4290\n",
            "\u001b[32m[07/11 03:05:14 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 03:05:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/11 03:05:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 03:05:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.4495 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/11 03:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.5413 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.389135 (2.821015 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.567576 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.086\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.402\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.917 | 20.831 | 8.553  |  nan  |  nan  | 9.917 |\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 13.164 | brec_Cht         | 5.181  | lam_Sltst  | 3.621 |\n",
            "| skel_WkstPkst | 9.451  | strless_SltstSst | 18.167 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.104\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.264\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.415\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.415\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 9.780 | 19.226 | 10.390 |  nan  |  nan  | 9.780 |\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 13.667 | brec_Cht         | 5.496  | lam_Sltst  | 3.279 |\n",
            "| skel_WkstPkst | 8.129  | strless_SltstSst | 18.329 |            |       |\n",
            "\u001b[32m[07/11 03:05:58 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.testing]: \u001b[0mcopypaste: 9.9167,20.8310,8.5532,nan,nan,9.9167\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 03:05:58 d2.evaluation.testing]: \u001b[0mcopypaste: 9.7797,19.2261,10.3896,nan,nan,9.7797\n",
            "\u001b[32m[07/11 03:05:58 d2.utils.events]: \u001b[0m eta: 0:51:05  iter: 1399  total_loss: 0.764  loss_cls: 0.184  loss_box_reg: 0.279  loss_mask: 0.181  loss_rpn_cls: 0.026  loss_rpn_loc: 0.110  time: 4.9981  data_time: 1.9371  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 03:07:41 d2.utils.events]: \u001b[0m eta: 0:49:24  iter: 1419  total_loss: 0.795  loss_cls: 0.176  loss_box_reg: 0.272  loss_mask: 0.198  loss_rpn_cls: 0.030  loss_rpn_loc: 0.117  time: 5.0001  data_time: 1.9104  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 03:09:25 d2.utils.events]: \u001b[0m eta: 0:47:44  iter: 1439  total_loss: 0.783  loss_cls: 0.178  loss_box_reg: 0.260  loss_mask: 0.195  loss_rpn_cls: 0.029  loss_rpn_loc: 0.125  time: 5.0025  data_time: 1.9268  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 03:11:08 d2.utils.events]: \u001b[0m eta: 0:46:04  iter: 1459  total_loss: 0.747  loss_cls: 0.175  loss_box_reg: 0.240  loss_mask: 0.186  loss_rpn_cls: 0.027  loss_rpn_loc: 0.109  time: 5.0049  data_time: 1.9512  lr: 0.001000  max_mem: 9034M\n",
            "\u001b[32m[07/11 03:12:53 d2.utils.events]: \u001b[0m eta: 0:44:24  iter: 1479  total_loss: 0.765  loss_cls: 0.180  loss_box_reg: 0.264  loss_mask: 0.181  loss_rpn_cls: 0.030  loss_rpn_loc: 0.114  time: 5.0083  data_time: 1.9670  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:14:37 d2.utils.events]: \u001b[0m eta: 0:42:44  iter: 1499  total_loss: 0.697  loss_cls: 0.156  loss_box_reg: 0.237  loss_mask: 0.176  loss_rpn_cls: 0.025  loss_rpn_loc: 0.103  time: 5.0103  data_time: 1.8952  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:16:21 d2.utils.events]: \u001b[0m eta: 0:41:04  iter: 1519  total_loss: 0.687  loss_cls: 0.150  loss_box_reg: 0.229  loss_mask: 0.174  loss_rpn_cls: 0.023  loss_rpn_loc: 0.102  time: 5.0129  data_time: 1.9441  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:18:04 d2.utils.events]: \u001b[0m eta: 0:39:24  iter: 1539  total_loss: 0.707  loss_cls: 0.146  loss_box_reg: 0.243  loss_mask: 0.182  loss_rpn_cls: 0.023  loss_rpn_loc: 0.102  time: 5.0150  data_time: 1.9063  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:19:49 d2.utils.events]: \u001b[0m eta: 0:37:45  iter: 1559  total_loss: 0.754  loss_cls: 0.155  loss_box_reg: 0.258  loss_mask: 0.173  loss_rpn_cls: 0.027  loss_rpn_loc: 0.110  time: 5.0177  data_time: 1.9640  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:21:33 d2.utils.events]: \u001b[0m eta: 0:36:03  iter: 1579  total_loss: 0.678  loss_cls: 0.134  loss_box_reg: 0.231  loss_mask: 0.175  loss_rpn_cls: 0.025  loss_rpn_loc: 0.108  time: 5.0198  data_time: 1.9134  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:23:32 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 03:23:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/11 03:23:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/11 03:24:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.6626 s / img. ETA=0:02:20\n",
            "\u001b[32m[07/11 03:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.6504 s / img. ETA=0:02:09\n",
            "\u001b[32m[07/11 03:24:22 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.5559 s / img. ETA=0:01:39\n",
            "\u001b[32m[07/11 03:24:27 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.4986 s / img. ETA=0:01:19\n",
            "\u001b[32m[07/11 03:24:33 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.4634 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/11 03:24:39 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.4404 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/11 03:24:45 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.4260 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/11 03:24:51 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.4228 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/11 03:24:57 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.4195 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/11 03:25:03 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.4174 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/11 03:25:09 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.4150 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/11 03:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.4240 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/11 03:25:23 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.4383 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/11 03:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.4519 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/11 03:25:36 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.4588 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/11 03:25:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:48.428028 (2.085154 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 03:25:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:24 (0.462594 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 03:25:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 03:25:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 03:25:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.42s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.738\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.972\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.890\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.205\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.777\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.795\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795\n",
            "\u001b[32m[07/11 03:25:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 73.778 | 97.151 | 89.021 |  nan  |  nan  | 73.778 |\n",
            "\u001b[32m[07/11 03:25:41 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 03:25:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 74.508 | brec_Cht         | 75.490 | lam_Sltst  | 70.221 |\n",
            "| skel_WkstPkst | 68.577 | strless_SltstSst | 80.096 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.08s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.61s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.966\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.881\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.775\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.793\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.793\n",
            "\u001b[32m[07/11 03:25:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 73.259 | 96.615 | 88.147 |  nan  |  nan  | 73.259 |\n",
            "\u001b[32m[07/11 03:25:42 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 03:25:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 76.283 | brec_Cht         | 79.565 | lam_Sltst  | 68.694 |\n",
            "| skel_WkstPkst | 63.834 | strless_SltstSst | 77.918 |            |        |\n",
            "\u001b[32m[07/11 03:25:42 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/11 03:25:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 03:25:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 03:25:42 d2.evaluation.testing]: \u001b[0mcopypaste: 73.7783,97.1506,89.0207,nan,nan,73.7783\n",
            "\u001b[32m[07/11 03:25:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 03:25:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 03:25:42 d2.evaluation.testing]: \u001b[0mcopypaste: 73.2589,96.6152,88.1472,nan,nan,73.2589\n",
            "\u001b[32m[07/11 03:25:46 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 03:25:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/11 03:25:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 03:26:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.4258 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/11 03:26:23 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.5236 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/11 03:26:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:24.145373 (2.682819 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 03:26:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.550112 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 03:26:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 03:26:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 03:26:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.253\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.106\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.315\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.387\n",
            "\u001b[32m[07/11 03:26:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.572 | 25.270 | 7.356  |  nan  |  nan  | 10.572 |\n",
            "\u001b[32m[07/11 03:26:27 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 03:26:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 12.492 | brec_Cht         | 8.088  | lam_Sltst  | 2.388 |\n",
            "| skel_WkstPkst | 12.350 | strless_SltstSst | 17.543 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.128\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.246\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.128\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.128\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.373\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.456\n",
            "\u001b[32m[07/11 03:26:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 12.836 | 24.589 | 12.814 |  nan  |  nan  | 12.836 |\n",
            "\u001b[32m[07/11 03:26:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 03:26:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 13.869 | brec_Cht         | 9.203  | lam_Sltst  | 2.760 |\n",
            "| skel_WkstPkst | 18.865 | strless_SltstSst | 19.481 |            |       |\n",
            "\u001b[32m[07/11 03:26:28 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/11 03:26:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 03:26:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 03:26:28 d2.evaluation.testing]: \u001b[0mcopypaste: 10.5722,25.2701,7.3555,nan,nan,10.5722\n",
            "\u001b[32m[07/11 03:26:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 03:26:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 03:26:28 d2.evaluation.testing]: \u001b[0mcopypaste: 12.8356,24.5892,12.8135,nan,nan,12.8356\n",
            "\u001b[32m[07/11 03:26:28 d2.utils.events]: \u001b[0m eta: 0:34:22  iter: 1599  total_loss: 0.665  loss_cls: 0.139  loss_box_reg: 0.224  loss_mask: 0.166  loss_rpn_cls: 0.025  loss_rpn_loc: 0.108  time: 5.0218  data_time: 1.9064  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:28:10 d2.utils.events]: \u001b[0m eta: 0:32:41  iter: 1619  total_loss: 0.639  loss_cls: 0.135  loss_box_reg: 0.209  loss_mask: 0.175  loss_rpn_cls: 0.022  loss_rpn_loc: 0.103  time: 5.0232  data_time: 1.9057  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:29:53 d2.utils.events]: \u001b[0m eta: 0:30:58  iter: 1639  total_loss: 0.648  loss_cls: 0.132  loss_box_reg: 0.229  loss_mask: 0.173  loss_rpn_cls: 0.021  loss_rpn_loc: 0.108  time: 5.0246  data_time: 1.8905  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:31:37 d2.utils.events]: \u001b[0m eta: 0:29:16  iter: 1659  total_loss: 0.638  loss_cls: 0.127  loss_box_reg: 0.212  loss_mask: 0.163  loss_rpn_cls: 0.026  loss_rpn_loc: 0.108  time: 5.0265  data_time: 1.9355  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:33:19 d2.utils.events]: \u001b[0m eta: 0:27:34  iter: 1679  total_loss: 0.655  loss_cls: 0.145  loss_box_reg: 0.216  loss_mask: 0.167  loss_rpn_cls: 0.023  loss_rpn_loc: 0.106  time: 5.0276  data_time: 1.8811  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:35:03 d2.utils.events]: \u001b[0m eta: 0:25:52  iter: 1699  total_loss: 0.606  loss_cls: 0.129  loss_box_reg: 0.210  loss_mask: 0.161  loss_rpn_cls: 0.019  loss_rpn_loc: 0.095  time: 5.0297  data_time: 1.9209  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:36:46 d2.utils.events]: \u001b[0m eta: 0:24:09  iter: 1719  total_loss: 0.686  loss_cls: 0.142  loss_box_reg: 0.235  loss_mask: 0.178  loss_rpn_cls: 0.025  loss_rpn_loc: 0.106  time: 5.0308  data_time: 1.8994  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:38:29 d2.utils.events]: \u001b[0m eta: 0:22:26  iter: 1739  total_loss: 0.674  loss_cls: 0.158  loss_box_reg: 0.229  loss_mask: 0.163  loss_rpn_cls: 0.020  loss_rpn_loc: 0.103  time: 5.0321  data_time: 1.8940  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:40:11 d2.utils.events]: \u001b[0m eta: 0:20:43  iter: 1759  total_loss: 0.632  loss_cls: 0.134  loss_box_reg: 0.216  loss_mask: 0.161  loss_rpn_cls: 0.018  loss_rpn_loc: 0.096  time: 5.0331  data_time: 1.8834  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:41:55 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 1779  total_loss: 0.631  loss_cls: 0.126  loss_box_reg: 0.221  loss_mask: 0.161  loss_rpn_cls: 0.021  loss_rpn_loc: 0.099  time: 5.0347  data_time: 1.9337  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:43:55 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 03:43:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/11 03:43:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/11 03:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.6864 s / img. ETA=0:02:27\n",
            "\u001b[32m[07/11 03:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.6762 s / img. ETA=0:02:16\n",
            "\u001b[32m[07/11 03:44:46 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.5672 s / img. ETA=0:01:42\n",
            "\u001b[32m[07/11 03:44:52 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.5080 s / img. ETA=0:01:22\n",
            "\u001b[32m[07/11 03:44:58 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.4732 s / img. ETA=0:01:08\n",
            "\u001b[32m[07/11 03:45:03 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.4477 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/11 03:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.4315 s / img. ETA=0:00:46\n",
            "\u001b[32m[07/11 03:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.4265 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/11 03:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.4240 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/11 03:45:28 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.4217 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/11 03:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.4165 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/11 03:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.4268 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/11 03:45:48 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.4421 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/11 03:45:55 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.4568 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/11 03:46:00 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.4616 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/11 03:46:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:49.081689 (2.097725 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 03:46:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:24 (0.463791 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 03:46:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 03:46:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 03:46:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.42s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.711\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.985\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.894\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.711\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.757\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.777\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777\n",
            "\u001b[32m[07/11 03:46:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 71.122 | 98.489 | 89.351 |  nan  |  nan  | 71.122 |\n",
            "\u001b[32m[07/11 03:46:05 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 03:46:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 73.724 | brec_Cht         | 70.803 | lam_Sltst  | 74.114 |\n",
            "| skel_WkstPkst | 57.768 | strless_SltstSst | 79.198 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.62s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.689\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.955\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.838\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.738\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.755\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755\n",
            "\u001b[32m[07/11 03:46:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 68.899 | 95.514 | 83.770 |  nan  |  nan  | 68.935 |\n",
            "\u001b[32m[07/11 03:46:06 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 03:46:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 73.705 | brec_Cht         | 74.541 | lam_Sltst  | 68.771 |\n",
            "| skel_WkstPkst | 51.810 | strless_SltstSst | 75.667 |            |        |\n",
            "\u001b[32m[07/11 03:46:06 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/11 03:46:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 03:46:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 03:46:06 d2.evaluation.testing]: \u001b[0mcopypaste: 71.1215,98.4894,89.3509,nan,nan,71.1215\n",
            "\u001b[32m[07/11 03:46:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 03:46:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 03:46:06 d2.evaluation.testing]: \u001b[0mcopypaste: 68.8986,95.5144,83.7701,nan,nan,68.9347\n",
            "\u001b[32m[07/11 03:46:10 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 03:46:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/11 03:46:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 03:46:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.4383 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/11 03:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.5187 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/11 03:46:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:24.241594 (2.693510 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 03:46:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.544738 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 03:46:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 03:46:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 03:46:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.251\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.112\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.279\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.364\n",
            "\u001b[32m[07/11 03:46:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.234 | 25.088 | 7.961  |  nan  |  nan  | 11.234 |\n",
            "\u001b[32m[07/11 03:46:53 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 03:46:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 14.086 | brec_Cht         | 7.372  | lam_Sltst  | 2.965 |\n",
            "| skel_WkstPkst | 15.342 | strless_SltstSst | 16.403 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.118\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.248\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.098\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.405\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.405\n",
            "\u001b[32m[07/11 03:46:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.780 | 24.752 | 9.820  |  nan  |  nan  | 11.780 |\n",
            "\u001b[32m[07/11 03:46:54 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 03:46:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 15.248 | brec_Cht         | 8.166  | lam_Sltst  | 3.523 |\n",
            "| skel_WkstPkst | 14.445 | strless_SltstSst | 17.520 |            |       |\n",
            "\u001b[32m[07/11 03:46:54 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/11 03:46:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 03:46:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 03:46:54 d2.evaluation.testing]: \u001b[0mcopypaste: 11.2335,25.0877,7.9606,nan,nan,11.2335\n",
            "\u001b[32m[07/11 03:46:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 03:46:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 03:46:54 d2.evaluation.testing]: \u001b[0mcopypaste: 11.7801,24.7523,9.8197,nan,nan,11.7801\n",
            "\u001b[32m[07/11 03:46:54 d2.utils.events]: \u001b[0m eta: 0:17:18  iter: 1799  total_loss: 0.627  loss_cls: 0.127  loss_box_reg: 0.214  loss_mask: 0.155  loss_rpn_cls: 0.021  loss_rpn_loc: 0.097  time: 5.0366  data_time: 1.9379  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:48:38 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 1819  total_loss: 0.588  loss_cls: 0.123  loss_box_reg: 0.206  loss_mask: 0.155  loss_rpn_cls: 0.022  loss_rpn_loc: 0.091  time: 5.0388  data_time: 1.9357  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:50:22 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 1839  total_loss: 0.614  loss_cls: 0.134  loss_box_reg: 0.209  loss_mask: 0.164  loss_rpn_cls: 0.018  loss_rpn_loc: 0.094  time: 5.0403  data_time: 1.9191  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:52:07 d2.utils.events]: \u001b[0m eta: 0:12:10  iter: 1859  total_loss: 0.639  loss_cls: 0.142  loss_box_reg: 0.223  loss_mask: 0.166  loss_rpn_cls: 0.022  loss_rpn_loc: 0.097  time: 5.0426  data_time: 1.9715  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:53:50 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 1879  total_loss: 0.625  loss_cls: 0.124  loss_box_reg: 0.221  loss_mask: 0.166  loss_rpn_cls: 0.022  loss_rpn_loc: 0.100  time: 5.0437  data_time: 1.8731  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:55:33 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 1899  total_loss: 0.603  loss_cls: 0.123  loss_box_reg: 0.197  loss_mask: 0.157  loss_rpn_cls: 0.020  loss_rpn_loc: 0.099  time: 5.0449  data_time: 1.8954  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:57:16 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 1919  total_loss: 0.592  loss_cls: 0.110  loss_box_reg: 0.198  loss_mask: 0.150  loss_rpn_cls: 0.020  loss_rpn_loc: 0.101  time: 5.0462  data_time: 1.8750  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 03:59:01 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 1939  total_loss: 0.564  loss_cls: 0.111  loss_box_reg: 0.194  loss_mask: 0.151  loss_rpn_cls: 0.019  loss_rpn_loc: 0.093  time: 5.0480  data_time: 1.9504  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 04:00:46 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 1959  total_loss: 0.554  loss_cls: 0.111  loss_box_reg: 0.204  loss_mask: 0.147  loss_rpn_cls: 0.019  loss_rpn_loc: 0.090  time: 5.0499  data_time: 1.9183  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 04:02:29 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 1979  total_loss: 0.543  loss_cls: 0.100  loss_box_reg: 0.183  loss_mask: 0.152  loss_rpn_cls: 0.015  loss_rpn_loc: 0.095  time: 5.0511  data_time: 1.9324  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 04:04:30 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 04:04:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/11 04:04:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/11 04:05:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.5881 s / img. ETA=0:02:04\n",
            "\u001b[32m[07/11 04:05:09 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.5539 s / img. ETA=0:01:43\n",
            "\u001b[32m[07/11 04:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.4833 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/11 04:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.4289 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/11 04:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.3984 s / img. ETA=0:00:47\n",
            "\u001b[32m[07/11 04:05:31 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.3821 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/11 04:05:37 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.3793 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/11 04:05:42 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.3777 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/11 04:05:47 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.3772 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/11 04:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.3767 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/11 04:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.3860 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/11 04:06:06 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.3984 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/11 04:06:12 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.4101 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/11 04:06:18 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.4167 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/11 04:06:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:32.276642 (1.774551 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 04:06:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.416425 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 04:06:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 04:06:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 04:06:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.761\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.985\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.949\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.792\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.811\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.811\n",
            "\u001b[32m[07/11 04:06:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 76.096 | 98.456 | 94.857 |  nan  |  nan  | 76.096 |\n",
            "\u001b[32m[07/11 04:06:20 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 04:06:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 74.367 | brec_Cht         | 76.836 | lam_Sltst  | 74.899 |\n",
            "| skel_WkstPkst | 74.497 | strless_SltstSst | 79.883 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.52s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.777\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.978\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.922\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.808\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.826\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.826\n",
            "\u001b[32m[07/11 04:06:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 77.668 | 97.814 | 92.172 |  nan  |  nan  | 77.668 |\n",
            "\u001b[32m[07/11 04:06:21 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 04:06:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 80.134 | brec_Cht         | 82.014 | lam_Sltst  | 74.794 |\n",
            "| skel_WkstPkst | 68.495 | strless_SltstSst | 82.903 |            |        |\n",
            "\u001b[32m[07/11 04:06:21 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/11 04:06:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 04:06:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 04:06:21 d2.evaluation.testing]: \u001b[0mcopypaste: 76.0964,98.4562,94.8572,nan,nan,76.0964\n",
            "\u001b[32m[07/11 04:06:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 04:06:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 04:06:21 d2.evaluation.testing]: \u001b[0mcopypaste: 77.6679,97.8140,92.1722,nan,nan,77.6679\n",
            "\u001b[32m[07/11 04:06:25 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 04:06:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/11 04:06:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 04:06:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.3952 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/11 04:06:59 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.4694 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.894148 (2.432683 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.499970 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.254\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.243\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.347\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.678 | 25.356 | 6.859  |  nan  |  nan  | 10.678 |\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 13.164 | brec_Cht         | 4.059  | lam_Sltst  | 2.575 |\n",
            "| skel_WkstPkst | 19.268 | strless_SltstSst | 14.320 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.129\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.130\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.433\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.021 | 26.304 | 12.935 |  nan  |  nan  | 13.021 |\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 15.721 | brec_Cht         | 5.506  | lam_Sltst  | 2.820 |\n",
            "| skel_WkstPkst | 24.421 | strless_SltstSst | 16.637 |            |       |\n",
            "\u001b[32m[07/11 04:07:02 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.testing]: \u001b[0mcopypaste: 10.6775,25.3565,6.8590,nan,nan,10.6775\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/11 04:07:02 d2.evaluation.testing]: \u001b[0mcopypaste: 13.0212,26.3041,12.9347,nan,nan,13.0212\n",
            "\u001b[32m[07/11 04:07:02 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 1999  total_loss: 0.568  loss_cls: 0.103  loss_box_reg: 0.190  loss_mask: 0.155  loss_rpn_cls: 0.017  loss_rpn_loc: 0.089  time: 5.0520  data_time: 1.9124  lr: 0.001000  max_mem: 9058M\n",
            "\u001b[32m[07/11 04:07:02 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 2:48:14 (5.0546 s / it)\n",
            "\u001b[32m[07/11 04:07:02 d2.engine.hooks]: \u001b[0mTotal training time: 3:30:55 (0:42:41 on hooks)\n",
            "\n",
            "\n",
            "**Starting train eval**\n",
            "\u001b[32m[07/11 04:07:19 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 04:07:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/11 04:07:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/11 04:08:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.6075 s / img. ETA=0:03:07\n",
            "\u001b[32m[07/11 04:08:14 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.5945 s / img. ETA=0:02:54\n",
            "\u001b[32m[07/11 04:08:21 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.4897 s / img. ETA=0:01:53\n",
            "\u001b[32m[07/11 04:08:26 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.4331 s / img. ETA=0:01:21\n",
            "\u001b[32m[07/11 04:08:31 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.4014 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/11 04:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.3844 s / img. ETA=0:00:46\n",
            "\u001b[32m[07/11 04:08:44 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.3815 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/11 04:08:50 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.3787 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/11 04:08:57 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.3750 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/11 04:09:02 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.3803 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/11 04:09:08 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.3878 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/11 04:09:18 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.4016 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/11 04:09:23 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.4083 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/11 04:09:29 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.4137 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/11 04:09:35 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.4181 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/11 04:09:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:54.260984 (2.197327 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 04:09:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.417949 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 04:09:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 04:09:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/11 04:09:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.46s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.761\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.985\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.949\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.792\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.811\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.811\n",
            "\u001b[32m[07/11 04:09:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 76.096 | 98.456 | 94.857 |  nan  |  nan  | 76.096 |\n",
            "\u001b[32m[07/11 04:09:38 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 04:09:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 74.367 | brec_Cht         | 76.836 | lam_Sltst  | 74.899 |\n",
            "| skel_WkstPkst | 74.497 | strless_SltstSst | 79.883 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.53s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.777\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.978\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.922\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.808\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.826\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.826\n",
            "\u001b[32m[07/11 04:09:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 77.668 | 97.814 | 92.172 |  nan  |  nan  | 77.668 |\n",
            "\u001b[32m[07/11 04:09:38 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 04:09:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 80.134 | brec_Cht         | 82.014 | lam_Sltst  | 74.794 |\n",
            "| skel_WkstPkst | 68.495 | strless_SltstSst | 82.903 |            |        |\n",
            "randomly selected cores/Box 8 Depths 10035-45.JPG\n",
            "\n",
            "\n",
            "**Starting val eval**\n",
            "\u001b[32m[07/11 04:10:22 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/11 04:10:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/11 04:10:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/11 04:10:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.3978 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/11 04:11:07 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.4708 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/11 04:11:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.296706 (3.032967 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 04:11:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.489935 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/11 04:11:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/11 04:11:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/11 04:11:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.254\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.243\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.347\n",
            "\u001b[32m[07/11 04:11:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.678 | 25.356 | 6.859  |  nan  |  nan  | 10.678 |\n",
            "\u001b[32m[07/11 04:11:12 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 04:11:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 13.164 | brec_Cht         | 4.059  | lam_Sltst  | 2.575 |\n",
            "| skel_WkstPkst | 19.268 | strless_SltstSst | 14.320 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.129\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.130\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.433\n",
            "\u001b[32m[07/11 04:11:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.021 | 26.304 | 12.935 |  nan  |  nan  | 13.021 |\n",
            "\u001b[32m[07/11 04:11:13 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/11 04:11:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 15.721 | brec_Cht         | 5.506  | lam_Sltst  | 2.820 |\n",
            "| skel_WkstPkst | 24.421 | strless_SltstSst | 16.637 |            |       |\n",
            "randomly selected cores/Boxes 19-21  Depths 7770.6-7778.4 (Dry).JPG\n",
            "Sat Jul 11 04:11:55 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    68W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "CPU times: user 27.7 s, sys: 5 s, total: 32.7 s\n",
            "Wall time: 3h 36min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m19G2u9UEw0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output_fold_0"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}