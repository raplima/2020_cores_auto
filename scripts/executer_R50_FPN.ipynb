{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "executer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raplima/2020_cores_auto/blob/master/scripts/executer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_52_mQ1oMPVQ",
        "colab_type": "text"
      },
      "source": [
        "This [`javascript`](https://stackoverflow.com/questions/54057011/google-colab-session-timeout) function might be helpful to avoid Colab identifying the notebook as idle and disconnecting:\n",
        "\n",
        "```javascript\n",
        "function clickedMe(){\n",
        "  console.log('clicked')\n",
        "  document.querySelector(\"paper-button#comments\").click()\n",
        "}\n",
        "setInterval(clickedMe(), 5*60000)\n",
        "```\n",
        "\n",
        "To execute, press `Ctrl+Shift+i`, copy into the console and run it. The code simple searches the `paper-button#comments` and clicks it. Effetively, the `Comment` box is clicked every 5 minutes. Each fold takes ~2.5 h to run, so this can facilitate the experiment (you shouldn't have to watch the entire training)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCps-FC-Nc5y",
        "colab_type": "text"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cneXQmncDd8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "0dac16f4-be94-4574-8b9c-89098ffffb70"
      },
      "source": [
        "# connect to google drive to save results after execution\n",
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHciCqT6BJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f64dc3f2-6b7f-4efc-c24c-57a7b78a3abd"
      },
      "source": [
        "# download, decompress the data\n",
        "!gdown https://drive.google.com/uc?id=1n6w9DJmrcepwIvWsJXLhAxAbHM0f2XjR\n",
        "!unzip cores.zip > /dev/null\n",
        "\n",
        "# clone repository\n",
        "!git clone https://github.com/raplima/2020_cores_auto.git\n",
        "\n",
        "# copy files to facilitate execution:\n",
        "!cp 2020_cores_auto/data/* cores\n",
        "!cp 2020_cores_auto/scripts/* .\n",
        "################################################################################\n",
        "# install libraries\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install pyyaml==5.1 pycocotools>=2.0.1\n",
        "# install detectron2:\n",
        "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1n6w9DJmrcepwIvWsJXLhAxAbHM0f2XjR\n",
            "To: /content/cores.zip\n",
            "296MB [00:02, 104MB/s] \n",
            "Cloning into '2020_cores_auto'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 325 (delta 23), reused 34 (delta 9), pack-reused 271\u001b[K\n",
            "Receiving objects: 100% (325/325), 55.86 MiB | 14.99 MiB/s, done.\n",
            "Resolving deltas: 100% (169/169), done.\n",
            "cp: -r not specified; omitting directory '2020_cores_auto/data/results'\n",
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Collecting torch==1.5\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (703.8MB)\n",
            "\u001b[K     |████████████████████████████████| 703.8MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Successfully installed torch-1.5.0+cu101 torchvision-0.6.0+cu101\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n",
            "Collecting detectron2==0.1.3\n",
            "\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/detectron2-0.1.3%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.2MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2MB 632kB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.8.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (7.0.0)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/81/3b/40e876afde9f5ffa1cfdce10565aba85b0dc2e067ed551dfb566cfee6d4d/yacs-0.1.7-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (3.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.16.0)\n",
            "Collecting fvcore>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/69/f0/dfee20a11c469e43061532e6e1467b9f3614dab10ad5a964e14f78f6631a/fvcore-0.1.1.post20200704.tar.gz\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (4.41.1)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (2.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2==0.1.3) (5.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (2.8.1)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (47.3.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (2.23.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.30.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.17.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.1.3) (1.6.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.1.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.4.8)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.1.post20200704-cp36-none-any.whl size=41894 sha256=b9e9d2e4c860ee90e7470f288e49cf0ddb3eeea1f0ea876ccde856b42ff422ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/d2/8e/b6d0f19811e77dabff1ebed6605ce2b59ee9f487079b434c8c\n",
            "Successfully built fvcore\n",
            "Installing collected packages: mock, yacs, portalocker, fvcore, detectron2\n",
            "Successfully installed detectron2-0.1.3+cu101 fvcore-0.1.1.post20200704 mock-4.0.2 portalocker-1.7.0 yacs-0.1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSLrYG8-NiQC",
        "colab_type": "text"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT7kDUqTCDv_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f173033-dfb7-4310-9465-43c13dc9ca7c"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '0' --max_iter 2000\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 0\n",
            "\t cores_fold_0_train\n",
            "\t cores_fold_0_val\n",
            "\u001b[32m[07/07 14:51:05 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/07 14:51:19 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 55 images left.\n",
            "\u001b[32m[07/07 14:51:19 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 253          |   brec_Cht    | 21           | lam_Sltst  | 111          |\n",
            "| skel_WkstPkst | 26           | strless_Slt.. | 132          |            |              |\n",
            "|     total     | 543          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/07 14:51:19 d2.data.common]: \u001b[0mSerializing 55 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 14:51:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/07 14:51:19 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/07 14:51:19 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-07 14:51:19.475959: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "model_final_f10217.pkl: 178MB [00:18, 9.57MB/s]               \n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/07 14:51:46 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/07 14:53:08 d2.utils.events]: \u001b[0m eta: 2:14:08  iter: 19  total_loss: 3.569  loss_cls: 1.812  loss_box_reg: 0.368  loss_mask: 0.691  loss_rpn_cls: 0.534  loss_rpn_loc: 0.223  time: 4.0486  data_time: 2.6582  lr: 0.000020  max_mem: 7439M\n",
            "\u001b[32m[07/07 14:54:27 d2.utils.events]: \u001b[0m eta: 2:09:59  iter: 39  total_loss: 2.682  loss_cls: 1.263  loss_box_reg: 0.452  loss_mask: 0.672  loss_rpn_cls: 0.188  loss_rpn_loc: 0.164  time: 3.9860  data_time: 2.3584  lr: 0.000040  max_mem: 7904M\n",
            "\u001b[32m[07/07 14:55:47 d2.utils.events]: \u001b[0m eta: 2:09:14  iter: 59  total_loss: 2.080  loss_cls: 0.707  loss_box_reg: 0.515  loss_mask: 0.618  loss_rpn_cls: 0.081  loss_rpn_loc: 0.160  time: 3.9848  data_time: 2.3817  lr: 0.000060  max_mem: 8211M\n",
            "\u001b[32m[07/07 14:57:05 d2.utils.events]: \u001b[0m eta: 2:07:16  iter: 79  total_loss: 1.907  loss_cls: 0.623  loss_box_reg: 0.540  loss_mask: 0.559  loss_rpn_cls: 0.055  loss_rpn_loc: 0.138  time: 3.9627  data_time: 2.2846  lr: 0.000080  max_mem: 8261M\n",
            "\u001b[32m[07/07 14:58:24 d2.utils.events]: \u001b[0m eta: 2:05:45  iter: 99  total_loss: 1.831  loss_cls: 0.600  loss_box_reg: 0.558  loss_mask: 0.490  loss_rpn_cls: 0.043  loss_rpn_loc: 0.141  time: 3.9608  data_time: 2.3643  lr: 0.000100  max_mem: 8340M\n",
            "\u001b[32m[07/07 14:59:42 d2.utils.events]: \u001b[0m eta: 2:04:06  iter: 119  total_loss: 1.753  loss_cls: 0.573  loss_box_reg: 0.570  loss_mask: 0.437  loss_rpn_cls: 0.042  loss_rpn_loc: 0.129  time: 3.9548  data_time: 2.3120  lr: 0.000120  max_mem: 8510M\n",
            "\u001b[32m[07/07 15:01:01 d2.utils.events]: \u001b[0m eta: 2:01:43  iter: 139  total_loss: 1.736  loss_cls: 0.576  loss_box_reg: 0.599  loss_mask: 0.404  loss_rpn_cls: 0.035  loss_rpn_loc: 0.123  time: 3.9488  data_time: 2.2937  lr: 0.000140  max_mem: 8766M\n",
            "\u001b[32m[07/07 15:02:19 d2.utils.events]: \u001b[0m eta: 2:00:24  iter: 159  total_loss: 1.614  loss_cls: 0.530  loss_box_reg: 0.556  loss_mask: 0.383  loss_rpn_cls: 0.033  loss_rpn_loc: 0.125  time: 3.9463  data_time: 2.2193  lr: 0.000160  max_mem: 8766M\n",
            "\u001b[32m[07/07 15:03:38 d2.utils.events]: \u001b[0m eta: 1:59:06  iter: 179  total_loss: 1.593  loss_cls: 0.526  loss_box_reg: 0.550  loss_mask: 0.360  loss_rpn_cls: 0.030  loss_rpn_loc: 0.118  time: 3.9430  data_time: 2.2199  lr: 0.000180  max_mem: 8766M\n",
            "\u001b[32m[07/07 15:05:09 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 15:05:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/07 15:05:09 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_0_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/07 15:05:09 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_0_train' to COCO format ...)\n",
            "\u001b[32m[07/07 15:05:21 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/07 15:05:21 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 56, #annotations: 543\n",
            "\u001b[32m[07/07 15:05:21 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_0_train_coco_format.json' ...\n",
            "\u001b[32m[07/07 15:05:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0xc6c2c000 @  0x7f200fc24b6b 0x7f200fc44379 0x7f1fb337904e 0x7f1fb337af4a 0x7f1fec26967b 0x7f1febeb86be 0x7f1fec1217b5 0x7f1fec1137c1 0x7f1fec112d0e 0x7f1fec1137c1 0x7f1fedb6893a 0x7f1fec1137c1 0x7f1febeb3457 0x7f1febeb4080 0x7f1fec1d271a 0x7f1fedc5013e 0x7f1fec113c72 0x7f1ffa1ada68 0x7f1ffa268b04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/07 15:06:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.4717 s / img. ETA=0:06:26\n",
            "\u001b[32m[07/07 15:07:07 d2.evaluation.evaluator]: \u001b[0mInference done 12/56. 0.4707 s / img. ETA=0:06:17\n",
            "\u001b[32m[07/07 15:07:15 d2.evaluation.evaluator]: \u001b[0mInference done 13/56. 0.4716 s / img. ETA=0:06:09\n",
            "\u001b[32m[07/07 15:07:24 d2.evaluation.evaluator]: \u001b[0mInference done 14/56. 0.4731 s / img. ETA=0:06:00\n",
            "\u001b[32m[07/07 15:07:33 d2.evaluation.evaluator]: \u001b[0mInference done 15/56. 0.4736 s / img. ETA=0:05:52\n",
            "\u001b[32m[07/07 15:07:41 d2.evaluation.evaluator]: \u001b[0mInference done 16/56. 0.4734 s / img. ETA=0:05:43\n",
            "\u001b[32m[07/07 15:07:50 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.4731 s / img. ETA=0:05:34\n",
            "\u001b[32m[07/07 15:07:59 d2.evaluation.evaluator]: \u001b[0mInference done 19/56. 0.4575 s / img. ETA=0:04:57\n",
            "\u001b[32m[07/07 15:08:08 d2.evaluation.evaluator]: \u001b[0mInference done 21/56. 0.4467 s / img. ETA=0:04:26\n",
            "\u001b[32m[07/07 15:08:18 d2.evaluation.evaluator]: \u001b[0mInference done 23/56. 0.4397 s / img. ETA=0:04:00\n",
            "\u001b[32m[07/07 15:08:28 d2.evaluation.evaluator]: \u001b[0mInference done 25/56. 0.4319 s / img. ETA=0:03:38\n",
            "\u001b[32m[07/07 15:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 27/56. 0.4268 s / img. ETA=0:03:18\n",
            "\u001b[32m[07/07 15:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 29/56. 0.4209 s / img. ETA=0:02:59\n",
            "\u001b[32m[07/07 15:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 31/56. 0.4176 s / img. ETA=0:02:42\n",
            "\u001b[32m[07/07 15:09:05 d2.evaluation.evaluator]: \u001b[0mInference done 33/56. 0.4145 s / img. ETA=0:02:26\n",
            "\u001b[32m[07/07 15:09:14 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.4110 s / img. ETA=0:02:11\n",
            "\u001b[32m[07/07 15:09:24 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.4076 s / img. ETA=0:01:56\n",
            "\u001b[32m[07/07 15:09:33 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.4051 s / img. ETA=0:01:43\n",
            "\u001b[32m[07/07 15:09:39 d2.evaluation.evaluator]: \u001b[0mInference done 41/56. 0.4009 s / img. ETA=0:01:28\n",
            "\u001b[32m[07/07 15:09:49 d2.evaluation.evaluator]: \u001b[0mInference done 43/56. 0.4024 s / img. ETA=0:01:16\n",
            "\u001b[32m[07/07 15:09:57 d2.evaluation.evaluator]: \u001b[0mInference done 44/56. 0.4043 s / img. ETA=0:01:10\n",
            "\u001b[32m[07/07 15:10:04 d2.evaluation.evaluator]: \u001b[0mInference done 45/56. 0.4059 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/07 15:10:12 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.4075 s / img. ETA=0:00:59\n",
            "\u001b[32m[07/07 15:10:20 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.4087 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/07 15:10:27 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.4095 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/07 15:10:34 d2.evaluation.evaluator]: \u001b[0mInference done 49/56. 0.4104 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/07 15:10:42 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.4112 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/07 15:10:49 d2.evaluation.evaluator]: \u001b[0mInference done 51/56. 0.4120 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/07 15:10:57 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.4128 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/07 15:11:04 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.4135 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/07 15:11:12 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.4144 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/07 15:11:19 d2.evaluation.evaluator]: \u001b[0mInference done 55/56. 0.4152 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/07 15:11:27 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.4162 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/07 15:11:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:20.342841 (6.281232 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 15:11:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.416219 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 15:11:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 15:11:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 15:11:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.56s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.055\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.176\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.264\n",
            "\u001b[32m[07/07 15:11:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.537 | 11.998 | 4.231  |  nan  |  nan  | 5.537 |\n",
            "\u001b[32m[07/07 15:11:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 15:11:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 15.088 | brec_Cht         | 0.000 | lam_Sltst  | 4.048 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 8.548 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.76s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.116\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.052\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.265\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.265\n",
            "\u001b[32m[07/07 15:11:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.789 | 11.615 | 5.178  |  nan  |  nan  | 5.789 |\n",
            "\u001b[32m[07/07 15:11:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 15:11:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 17.517 | brec_Cht         | 0.000 | lam_Sltst  | 4.055 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 7.373 |            |       |\n",
            "\u001b[32m[07/07 15:11:29 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/07 15:11:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 15:11:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 15:11:29 d2.evaluation.testing]: \u001b[0mcopypaste: 5.5367,11.9977,4.2313,nan,nan,5.5367\n",
            "\u001b[32m[07/07 15:11:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 15:11:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 15:11:29 d2.evaluation.testing]: \u001b[0mcopypaste: 5.7888,11.6154,5.1776,nan,nan,5.7889\n",
            "\u001b[32m[07/07 15:11:32 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 56           |   brec_Cht    | 0            | lam_Sltst  | 16           |\n",
            "| skel_WkstPkst | 0            | strless_Slt.. | 41           |            |              |\n",
            "|     total     | 113          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/07 15:11:32 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 15:11:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/07 15:11:32 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_0_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/07 15:11:32 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_0_val' to COCO format ...)\n",
            "\u001b[32m[07/07 15:11:35 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/07 15:11:35 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 15, #annotations: 113\n",
            "\u001b[32m[07/07 15:11:35 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_0_val_coco_format.json' ...\n",
            "\u001b[32m[07/07 15:11:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/07 15:12:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.3598 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/07 15:12:45 d2.evaluation.evaluator]: \u001b[0mInference done 13/15. 0.3731 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/07 15:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.3815 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/07 15:13:00 d2.evaluation.evaluator]: \u001b[0mInference done 15/15. 0.3876 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/07 15:13:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:55.917995 (5.591799 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 15:13:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.387580 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 15:13:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 15:13:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 15:13:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.081\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.182\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.076\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.259\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.473\n",
            "\u001b[32m[07/07 15:13:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.140 | 18.180 | 7.641  |  nan  |  nan  | 8.140 |\n",
            "\u001b[32m[07/07 15:13:01 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 15:13:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 14.450 | brec_Cht         | nan   | lam_Sltst  | 3.691 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 6.281 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.083\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.170\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.489\n",
            "\u001b[32m[07/07 15:13:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.306 | 17.032 | 7.979  |  nan  |  nan  | 8.306 |\n",
            "\u001b[32m[07/07 15:13:01 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 15:13:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 15.786 | brec_Cht         | nan   | lam_Sltst  | 2.524 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 6.607 |            |       |\n",
            "\u001b[32m[07/07 15:13:01 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/07 15:13:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 15:13:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 15:13:01 d2.evaluation.testing]: \u001b[0mcopypaste: 8.1405,18.1795,7.6413,nan,nan,8.1405\n",
            "\u001b[32m[07/07 15:13:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 15:13:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 15:13:01 d2.evaluation.testing]: \u001b[0mcopypaste: 8.3058,17.0317,7.9790,nan,nan,8.3063\n",
            "\u001b[32m[07/07 15:13:01 d2.utils.events]: \u001b[0m eta: 1:57:37  iter: 199  total_loss: 1.600  loss_cls: 0.533  loss_box_reg: 0.582  loss_mask: 0.338  loss_rpn_cls: 0.024  loss_rpn_loc: 0.116  time: 3.9416  data_time: 2.2125  lr: 0.000200  max_mem: 8850M\n",
            "\u001b[32m[07/07 15:14:17 d2.utils.events]: \u001b[0m eta: 1:56:13  iter: 219  total_loss: 1.504  loss_cls: 0.498  loss_box_reg: 0.539  loss_mask: 0.316  loss_rpn_cls: 0.023  loss_rpn_loc: 0.119  time: 3.9310  data_time: 2.2132  lr: 0.000220  max_mem: 9091M\n",
            "\u001b[32m[07/07 15:15:34 d2.utils.events]: \u001b[0m eta: 1:54:36  iter: 239  total_loss: 1.479  loss_cls: 0.500  loss_box_reg: 0.558  loss_mask: 0.299  loss_rpn_cls: 0.022  loss_rpn_loc: 0.112  time: 3.9240  data_time: 2.1846  lr: 0.000240  max_mem: 9091M\n",
            "\u001b[32m[07/07 15:16:51 d2.utils.events]: \u001b[0m eta: 1:53:30  iter: 259  total_loss: 1.442  loss_cls: 0.501  loss_box_reg: 0.523  loss_mask: 0.282  loss_rpn_cls: 0.020  loss_rpn_loc: 0.110  time: 3.9184  data_time: 2.1159  lr: 0.000260  max_mem: 9091M\n",
            "\u001b[32m[07/07 15:18:09 d2.utils.events]: \u001b[0m eta: 1:52:18  iter: 279  total_loss: 1.325  loss_cls: 0.471  loss_box_reg: 0.469  loss_mask: 0.264  loss_rpn_cls: 0.019  loss_rpn_loc: 0.107  time: 3.9163  data_time: 2.1683  lr: 0.000280  max_mem: 9091M\n",
            "\u001b[32m[07/07 15:19:26 d2.utils.events]: \u001b[0m eta: 1:50:32  iter: 299  total_loss: 1.297  loss_cls: 0.482  loss_box_reg: 0.444  loss_mask: 0.246  loss_rpn_cls: 0.016  loss_rpn_loc: 0.106  time: 3.9118  data_time: 2.1217  lr: 0.000300  max_mem: 9091M\n",
            "\u001b[32m[07/07 15:20:43 d2.utils.events]: \u001b[0m eta: 1:48:58  iter: 319  total_loss: 1.185  loss_cls: 0.443  loss_box_reg: 0.403  loss_mask: 0.226  loss_rpn_cls: 0.015  loss_rpn_loc: 0.102  time: 3.9061  data_time: 2.1061  lr: 0.000320  max_mem: 9091M\n",
            "\u001b[32m[07/07 15:22:01 d2.utils.events]: \u001b[0m eta: 1:47:51  iter: 339  total_loss: 1.179  loss_cls: 0.449  loss_box_reg: 0.395  loss_mask: 0.214  loss_rpn_cls: 0.013  loss_rpn_loc: 0.103  time: 3.9073  data_time: 2.1835  lr: 0.000340  max_mem: 9091M\n",
            "\u001b[32m[07/07 15:23:20 d2.utils.events]: \u001b[0m eta: 1:46:40  iter: 359  total_loss: 1.137  loss_cls: 0.433  loss_box_reg: 0.367  loss_mask: 0.210  loss_rpn_cls: 0.014  loss_rpn_loc: 0.101  time: 3.9102  data_time: 2.2362  lr: 0.000360  max_mem: 9091M\n",
            "\u001b[32m[07/07 15:24:39 d2.utils.events]: \u001b[0m eta: 1:45:22  iter: 379  total_loss: 1.058  loss_cls: 0.399  loss_box_reg: 0.321  loss_mask: 0.194  loss_rpn_cls: 0.014  loss_rpn_loc: 0.105  time: 3.9099  data_time: 2.1911  lr: 0.000380  max_mem: 9091M\n",
            "\u001b[32m[07/07 15:26:09 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 15:26:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/07 15:26:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/07 15:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.3835 s / img. ETA=0:04:41\n",
            "\u001b[32m[07/07 15:27:29 d2.evaluation.evaluator]: \u001b[0mInference done 12/56. 0.3861 s / img. ETA=0:04:37\n",
            "\u001b[32m[07/07 15:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 14/56. 0.3716 s / img. ETA=0:04:05\n",
            "\u001b[32m[07/07 15:27:47 d2.evaluation.evaluator]: \u001b[0mInference done 16/56. 0.3646 s / img. ETA=0:03:46\n",
            "\u001b[32m[07/07 15:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 18/56. 0.3493 s / img. ETA=0:03:19\n",
            "\u001b[32m[07/07 15:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.3375 s / img. ETA=0:02:56\n",
            "\u001b[32m[07/07 15:28:05 d2.evaluation.evaluator]: \u001b[0mInference done 22/56. 0.3265 s / img. ETA=0:02:39\n",
            "\u001b[32m[07/07 15:28:11 d2.evaluation.evaluator]: \u001b[0mInference done 24/56. 0.3218 s / img. ETA=0:02:24\n",
            "\u001b[32m[07/07 15:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 26/56. 0.3179 s / img. ETA=0:02:11\n",
            "\u001b[32m[07/07 15:28:23 d2.evaluation.evaluator]: \u001b[0mInference done 29/56. 0.2998 s / img. ETA=0:01:49\n",
            "\u001b[32m[07/07 15:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 31/56. 0.2940 s / img. ETA=0:01:39\n",
            "\u001b[32m[07/07 15:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 33/56. 0.2969 s / img. ETA=0:01:31\n",
            "\u001b[32m[07/07 15:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 35/56. 0.2996 s / img. ETA=0:01:24\n",
            "\u001b[32m[07/07 15:28:53 d2.evaluation.evaluator]: \u001b[0mInference done 37/56. 0.3016 s / img. ETA=0:01:16\n",
            "\u001b[32m[07/07 15:29:02 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.3047 s / img. ETA=0:01:08\n",
            "\u001b[32m[07/07 15:29:07 d2.evaluation.evaluator]: \u001b[0mInference done 41/56. 0.3015 s / img. ETA=0:00:59\n",
            "\u001b[32m[07/07 15:29:15 d2.evaluation.evaluator]: \u001b[0mInference done 44/56. 0.2950 s / img. ETA=0:00:46\n",
            "\u001b[32m[07/07 15:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 45/56. 0.2973 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/07 15:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.2999 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/07 15:29:34 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.3026 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/07 15:29:41 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.3057 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/07 15:29:49 d2.evaluation.evaluator]: \u001b[0mInference done 49/56. 0.3088 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/07 15:29:56 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.3117 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/07 15:30:03 d2.evaluation.evaluator]: \u001b[0mInference done 51/56. 0.3147 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/07 15:30:09 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.3195 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/07 15:30:14 d2.evaluation.evaluator]: \u001b[0mInference done 55/56. 0.3229 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/07 15:30:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:32.294317 (4.162634 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 15:30:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.325525 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 15:30:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 15:30:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 15:30:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.46s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.472\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.353\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.539\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.663\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.663\n",
            "\u001b[32m[07/07 15:30:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 30.833 | 47.185 | 35.302 |  nan  |  nan  | 30.833 |\n",
            "\u001b[32m[07/07 15:30:18 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 15:30:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 48.626 | brec_Cht         | 21.901 | lam_Sltst  | 16.759 |\n",
            "| skel_WkstPkst | 30.049 | strless_SltstSst | 36.830 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.63s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.470\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.128\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.586\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.711\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.711\n",
            "\u001b[32m[07/07 15:30:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.159 | 47.029 | 37.697 |  nan  |  nan  | 33.159 |\n",
            "\u001b[32m[07/07 15:30:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 15:30:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 50.284 | brec_Cht         | 25.147 | lam_Sltst  | 15.808 |\n",
            "| skel_WkstPkst | 38.771 | strless_SltstSst | 35.784 |            |        |\n",
            "\u001b[32m[07/07 15:30:19 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/07 15:30:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 15:30:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 15:30:19 d2.evaluation.testing]: \u001b[0mcopypaste: 30.8330,47.1851,35.3021,nan,nan,30.8330\n",
            "\u001b[32m[07/07 15:30:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 15:30:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 15:30:19 d2.evaluation.testing]: \u001b[0mcopypaste: 33.1588,47.0293,37.6966,nan,nan,33.1589\n",
            "\u001b[32m[07/07 15:30:22 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 15:30:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/07 15:30:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/07 15:30:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.2397 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/07 15:30:52 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.2811 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 15:30:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.236796 (2.023680 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 15:30:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.280575 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 15:30:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 15:30:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 15:30:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.628\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.628\n",
            "\u001b[32m[07/07 15:30:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 19.868 | 34.686 | 19.729 |  nan  |  nan  | 19.868 |\n",
            "\u001b[32m[07/07 15:30:54 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 15:30:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 38.027 | brec_Cht         | nan    | lam_Sltst  | 6.454 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 15.122 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.221\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.419\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.645\n",
            "\u001b[32m[07/07 15:30:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 20.789 | 33.298 | 22.062 |  nan  |  nan  | 20.789 |\n",
            "\u001b[32m[07/07 15:30:54 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 15:30:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 38.599 | brec_Cht         | nan    | lam_Sltst  | 8.263 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 15.505 |            |       |\n",
            "\u001b[32m[07/07 15:30:54 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/07 15:30:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 15:30:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 15:30:54 d2.evaluation.testing]: \u001b[0mcopypaste: 19.8677,34.6861,19.7287,nan,nan,19.8677\n",
            "\u001b[32m[07/07 15:30:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 15:30:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 15:30:54 d2.evaluation.testing]: \u001b[0mcopypaste: 20.7889,33.2977,22.0616,nan,nan,20.7889\n",
            "\u001b[32m[07/07 15:30:54 d2.utils.events]: \u001b[0m eta: 1:44:04  iter: 399  total_loss: 1.027  loss_cls: 0.389  loss_box_reg: 0.321  loss_mask: 0.192  loss_rpn_cls: 0.011  loss_rpn_loc: 0.101  time: 3.9097  data_time: 2.2000  lr: 0.000400  max_mem: 9120M\n",
            "\u001b[32m[07/07 15:32:10 d2.utils.events]: \u001b[0m eta: 1:42:46  iter: 419  total_loss: 0.943  loss_cls: 0.372  loss_box_reg: 0.296  loss_mask: 0.182  loss_rpn_cls: 0.010  loss_rpn_loc: 0.102  time: 3.9054  data_time: 2.2212  lr: 0.000420  max_mem: 9120M\n",
            "\u001b[32m[07/07 15:33:29 d2.utils.events]: \u001b[0m eta: 1:41:26  iter: 439  total_loss: 0.932  loss_cls: 0.365  loss_box_reg: 0.302  loss_mask: 0.180  loss_rpn_cls: 0.011  loss_rpn_loc: 0.091  time: 3.9064  data_time: 2.2520  lr: 0.000440  max_mem: 9120M\n",
            "\u001b[32m[07/07 15:34:47 d2.utils.events]: \u001b[0m eta: 1:39:54  iter: 459  total_loss: 0.853  loss_cls: 0.320  loss_box_reg: 0.262  loss_mask: 0.173  loss_rpn_cls: 0.009  loss_rpn_loc: 0.090  time: 3.9057  data_time: 2.2287  lr: 0.000460  max_mem: 9120M\n",
            "\u001b[32m[07/07 15:36:05 d2.utils.events]: \u001b[0m eta: 1:38:50  iter: 479  total_loss: 0.847  loss_cls: 0.318  loss_box_reg: 0.255  loss_mask: 0.163  loss_rpn_cls: 0.008  loss_rpn_loc: 0.092  time: 3.9069  data_time: 2.1703  lr: 0.000480  max_mem: 9120M\n",
            "\u001b[32m[07/07 15:37:23 d2.utils.events]: \u001b[0m eta: 1:37:32  iter: 499  total_loss: 0.780  loss_cls: 0.280  loss_box_reg: 0.243  loss_mask: 0.157  loss_rpn_cls: 0.007  loss_rpn_loc: 0.090  time: 3.9056  data_time: 2.1715  lr: 0.000500  max_mem: 9120M\n",
            "\u001b[32m[07/07 15:38:40 d2.utils.events]: \u001b[0m eta: 1:36:10  iter: 519  total_loss: 0.754  loss_cls: 0.261  loss_box_reg: 0.239  loss_mask: 0.156  loss_rpn_cls: 0.006  loss_rpn_loc: 0.089  time: 3.9038  data_time: 2.1622  lr: 0.000519  max_mem: 9120M\n",
            "\u001b[32m[07/07 15:39:57 d2.utils.events]: \u001b[0m eta: 1:34:33  iter: 539  total_loss: 0.725  loss_cls: 0.258  loss_box_reg: 0.221  loss_mask: 0.152  loss_rpn_cls: 0.007  loss_rpn_loc: 0.089  time: 3.9012  data_time: 2.1435  lr: 0.000539  max_mem: 9120M\n",
            "\u001b[32m[07/07 15:41:14 d2.utils.events]: \u001b[0m eta: 1:33:13  iter: 559  total_loss: 0.668  loss_cls: 0.231  loss_box_reg: 0.204  loss_mask: 0.138  loss_rpn_cls: 0.005  loss_rpn_loc: 0.090  time: 3.8997  data_time: 2.1723  lr: 0.000559  max_mem: 9120M\n",
            "\u001b[32m[07/07 15:42:31 d2.utils.events]: \u001b[0m eta: 1:31:54  iter: 579  total_loss: 0.632  loss_cls: 0.221  loss_box_reg: 0.196  loss_mask: 0.138  loss_rpn_cls: 0.006  loss_rpn_loc: 0.088  time: 3.8976  data_time: 2.1353  lr: 0.000579  max_mem: 9172M\n",
            "\u001b[32m[07/07 15:44:01 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 15:44:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/07 15:44:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/07 15:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.2395 s / img. ETA=0:01:15\n",
            "\u001b[32m[07/07 15:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 16/56. 0.2095 s / img. ETA=0:00:56\n",
            "\u001b[32m[07/07 15:44:33 d2.evaluation.evaluator]: \u001b[0mInference done 22/56. 0.1813 s / img. ETA=0:00:41\n",
            "\u001b[32m[07/07 15:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 29/56. 0.1631 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/07 15:44:44 d2.evaluation.evaluator]: \u001b[0mInference done 34/56. 0.1604 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/07 15:44:50 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1621 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/07 15:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 45/56. 0.1587 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/07 15:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 48/56. 0.1644 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/07 15:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.1728 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/07 15:45:13 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.1795 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/07 15:45:19 d2.evaluation.evaluator]: \u001b[0mInference done 56/56. 0.1858 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/07 15:45:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:06.205847 (1.298154 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 15:45:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.185782 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 15:45:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 15:45:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 15:45:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.31s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.716\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.875\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.836\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.842\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.842\n",
            "\u001b[32m[07/07 15:45:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 71.587 | 87.452 | 83.569 |  nan  |  nan  | 71.587 |\n",
            "\u001b[32m[07/07 15:45:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 15:45:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 78.008 | brec_Cht         | 76.501 | lam_Sltst  | 55.274 |\n",
            "| skel_WkstPkst | 70.611 | strless_SltstSst | 77.540 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.47s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.719\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.877\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.832\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.782\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.844\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.844\n",
            "\u001b[32m[07/07 15:45:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 71.867 | 87.697 | 83.159 |  nan  |  nan  | 71.868 |\n",
            "\u001b[32m[07/07 15:45:20 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 15:45:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 78.344 | brec_Cht         | 80.056 | lam_Sltst  | 51.201 |\n",
            "| skel_WkstPkst | 72.651 | strless_SltstSst | 77.083 |            |        |\n",
            "\u001b[32m[07/07 15:45:20 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/07 15:45:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 15:45:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 15:45:20 d2.evaluation.testing]: \u001b[0mcopypaste: 71.5869,87.4515,83.5691,nan,nan,71.5869\n",
            "\u001b[32m[07/07 15:45:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 15:45:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 15:45:20 d2.evaluation.testing]: \u001b[0mcopypaste: 71.8669,87.6969,83.1594,nan,nan,71.8676\n",
            "\u001b[32m[07/07 15:45:23 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 15:45:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/07 15:45:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/07 15:45:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1431 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/07 15:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1837 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.752236 (1.275224 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.186433 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.478\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.568\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 30.324 | 47.825 | 31.506 |  nan  |  nan  | 30.324 |\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 42.043 | brec_Cht         | nan    | lam_Sltst  | 10.467 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 38.463 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.488\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.309\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.578\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 30.915 | 48.790 | 32.526 |  nan  |  nan  | 30.915 |\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 44.203 | brec_Cht         | nan    | lam_Sltst  | 10.017 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 38.525 |            |        |\n",
            "\u001b[32m[07/07 15:45:43 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.testing]: \u001b[0mcopypaste: 30.3240,47.8254,31.5058,nan,nan,30.3240\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 15:45:43 d2.evaluation.testing]: \u001b[0mcopypaste: 30.9150,48.7901,32.5256,nan,nan,30.9150\n",
            "\u001b[32m[07/07 15:45:43 d2.utils.events]: \u001b[0m eta: 1:30:37  iter: 599  total_loss: 0.599  loss_cls: 0.193  loss_box_reg: 0.180  loss_mask: 0.131  loss_rpn_cls: 0.005  loss_rpn_loc: 0.085  time: 3.8974  data_time: 2.1986  lr: 0.000599  max_mem: 9172M\n",
            "\u001b[32m[07/07 15:47:04 d2.utils.events]: \u001b[0m eta: 1:29:27  iter: 619  total_loss: 0.567  loss_cls: 0.180  loss_box_reg: 0.171  loss_mask: 0.123  loss_rpn_cls: 0.006  loss_rpn_loc: 0.079  time: 3.9028  data_time: 2.2684  lr: 0.000619  max_mem: 9172M\n",
            "\u001b[32m[07/07 15:48:28 d2.utils.events]: \u001b[0m eta: 1:28:26  iter: 639  total_loss: 0.539  loss_cls: 0.161  loss_box_reg: 0.161  loss_mask: 0.117  loss_rpn_cls: 0.004  loss_rpn_loc: 0.076  time: 3.9118  data_time: 2.3984  lr: 0.000639  max_mem: 9232M\n",
            "\u001b[32m[07/07 15:49:51 d2.utils.events]: \u001b[0m eta: 1:27:18  iter: 659  total_loss: 0.523  loss_cls: 0.162  loss_box_reg: 0.161  loss_mask: 0.119  loss_rpn_cls: 0.003  loss_rpn_loc: 0.076  time: 3.9186  data_time: 2.3132  lr: 0.000659  max_mem: 9232M\n",
            "\u001b[32m[07/07 15:51:12 d2.utils.events]: \u001b[0m eta: 1:26:09  iter: 679  total_loss: 0.484  loss_cls: 0.142  loss_box_reg: 0.153  loss_mask: 0.113  loss_rpn_cls: 0.003  loss_rpn_loc: 0.076  time: 3.9228  data_time: 2.2992  lr: 0.000679  max_mem: 9273M\n",
            "\u001b[32m[07/07 15:52:33 d2.utils.events]: \u001b[0m eta: 1:24:55  iter: 699  total_loss: 0.460  loss_cls: 0.134  loss_box_reg: 0.147  loss_mask: 0.109  loss_rpn_cls: 0.003  loss_rpn_loc: 0.073  time: 3.9260  data_time: 2.2481  lr: 0.000699  max_mem: 9273M\n",
            "\u001b[32m[07/07 15:53:53 d2.utils.events]: \u001b[0m eta: 1:23:38  iter: 719  total_loss: 0.443  loss_cls: 0.117  loss_box_reg: 0.133  loss_mask: 0.107  loss_rpn_cls: 0.003  loss_rpn_loc: 0.069  time: 3.9286  data_time: 2.2235  lr: 0.000719  max_mem: 9273M\n",
            "\u001b[32m[07/07 15:55:13 d2.utils.events]: \u001b[0m eta: 1:22:22  iter: 739  total_loss: 0.446  loss_cls: 0.119  loss_box_reg: 0.146  loss_mask: 0.107  loss_rpn_cls: 0.003  loss_rpn_loc: 0.074  time: 3.9297  data_time: 2.1870  lr: 0.000739  max_mem: 9273M\n",
            "\u001b[32m[07/07 15:56:32 d2.utils.events]: \u001b[0m eta: 1:21:07  iter: 759  total_loss: 0.430  loss_cls: 0.110  loss_box_reg: 0.140  loss_mask: 0.105  loss_rpn_cls: 0.002  loss_rpn_loc: 0.071  time: 3.9307  data_time: 2.1792  lr: 0.000759  max_mem: 9273M\n",
            "\u001b[32m[07/07 15:57:52 d2.utils.events]: \u001b[0m eta: 1:19:53  iter: 779  total_loss: 0.417  loss_cls: 0.107  loss_box_reg: 0.133  loss_mask: 0.100  loss_rpn_cls: 0.003  loss_rpn_loc: 0.067  time: 3.9328  data_time: 2.2397  lr: 0.000779  max_mem: 9273M\n",
            "\u001b[32m[07/07 15:59:26 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 15:59:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/07 15:59:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/07 15:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1939 s / img. ETA=0:01:03\n",
            "\u001b[32m[07/07 15:59:49 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.1720 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/07 15:59:55 d2.evaluation.evaluator]: \u001b[0mInference done 26/56. 0.1491 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/07 16:00:01 d2.evaluation.evaluator]: \u001b[0mInference done 34/56. 0.1400 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/07 16:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 40/56. 0.1384 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/07 16:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.1384 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/07 16:00:18 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.1473 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/07 16:00:23 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.1527 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/07 16:00:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.289210 (0.966455 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:00:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.153605 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:00:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 16:00:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 16:00:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.857\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.986\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.981\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.857\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.870\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.900\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.900\n",
            "\u001b[32m[07/07 16:00:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 85.677 | 98.621 | 98.061 |  nan  |  nan  | 85.677 |\n",
            "\u001b[32m[07/07 16:00:25 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:00:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 86.510 | brec_Cht         | 86.247 | lam_Sltst  | 81.153 |\n",
            "| skel_WkstPkst | 87.014 | strless_SltstSst | 87.461 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.36s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.845\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.986\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.967\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.845\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.861\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.889\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.889\n",
            "\u001b[32m[07/07 16:00:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 84.538 | 98.621 | 96.727 |  nan  |  nan  | 84.538 |\n",
            "\u001b[32m[07/07 16:00:26 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:00:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 86.147 | brec_Cht         | 86.829 | lam_Sltst  | 77.320 |\n",
            "| skel_WkstPkst | 85.468 | strless_SltstSst | 86.925 |            |        |\n",
            "\u001b[32m[07/07 16:00:26 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/07 16:00:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 16:00:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:00:26 d2.evaluation.testing]: \u001b[0mcopypaste: 85.6768,98.6210,98.0613,nan,nan,85.6768\n",
            "\u001b[32m[07/07 16:00:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 16:00:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:00:26 d2.evaluation.testing]: \u001b[0mcopypaste: 84.5380,98.6210,96.7271,nan,nan,84.5380\n",
            "\u001b[32m[07/07 16:00:29 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 16:00:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/07 16:00:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/07 16:00:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1217 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/07 16:00:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.335814 (0.933581 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:00:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.143451 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:00:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 16:00:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 16:00:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.469\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.294\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.504\n",
            "\u001b[32m[07/07 16:00:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.685 | 46.905 | 29.433 |  nan  |  nan  | 28.685 |\n",
            "\u001b[32m[07/07 16:00:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:00:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 39.344 | brec_Cht         | nan    | lam_Sltst  | 12.522 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 34.189 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.473\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.298\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.507\n",
            "\u001b[32m[07/07 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 29.843 | 47.320 | 30.731 |  nan  |  nan  | 29.843 |\n",
            "\u001b[32m[07/07 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 41.468 | brec_Cht         | nan    | lam_Sltst  | 11.815 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 36.246 |            |        |\n",
            "\u001b[32m[07/07 16:00:45 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/07 16:00:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 16:00:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:00:45 d2.evaluation.testing]: \u001b[0mcopypaste: 28.6851,46.9049,29.4328,nan,nan,28.6851\n",
            "\u001b[32m[07/07 16:00:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 16:00:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:00:45 d2.evaluation.testing]: \u001b[0mcopypaste: 29.8429,47.3198,30.7311,nan,nan,29.8429\n",
            "\u001b[32m[07/07 16:00:45 d2.utils.events]: \u001b[0m eta: 1:18:40  iter: 799  total_loss: 0.397  loss_cls: 0.096  loss_box_reg: 0.126  loss_mask: 0.099  loss_rpn_cls: 0.003  loss_rpn_loc: 0.066  time: 3.9357  data_time: 2.2334  lr: 0.000799  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:02:03 d2.utils.events]: \u001b[0m eta: 1:17:23  iter: 819  total_loss: 0.378  loss_cls: 0.093  loss_box_reg: 0.123  loss_mask: 0.099  loss_rpn_cls: 0.002  loss_rpn_loc: 0.065  time: 3.9357  data_time: 2.2109  lr: 0.000819  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:03:23 d2.utils.events]: \u001b[0m eta: 1:16:05  iter: 839  total_loss: 0.376  loss_cls: 0.083  loss_box_reg: 0.125  loss_mask: 0.096  loss_rpn_cls: 0.004  loss_rpn_loc: 0.061  time: 3.9368  data_time: 2.2497  lr: 0.000839  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:04:41 d2.utils.events]: \u001b[0m eta: 1:14:46  iter: 859  total_loss: 0.358  loss_cls: 0.077  loss_box_reg: 0.118  loss_mask: 0.093  loss_rpn_cls: 0.002  loss_rpn_loc: 0.060  time: 3.9359  data_time: 2.1308  lr: 0.000859  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:05:58 d2.utils.events]: \u001b[0m eta: 1:13:26  iter: 879  total_loss: 0.342  loss_cls: 0.073  loss_box_reg: 0.118  loss_mask: 0.091  loss_rpn_cls: 0.002  loss_rpn_loc: 0.059  time: 3.9343  data_time: 2.0929  lr: 0.000879  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:07:15 d2.utils.events]: \u001b[0m eta: 1:12:02  iter: 899  total_loss: 0.340  loss_cls: 0.076  loss_box_reg: 0.111  loss_mask: 0.093  loss_rpn_cls: 0.002  loss_rpn_loc: 0.061  time: 3.9327  data_time: 2.0780  lr: 0.000899  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:08:32 d2.utils.events]: \u001b[0m eta: 1:10:38  iter: 919  total_loss: 0.331  loss_cls: 0.071  loss_box_reg: 0.111  loss_mask: 0.090  loss_rpn_cls: 0.002  loss_rpn_loc: 0.061  time: 3.9308  data_time: 2.0532  lr: 0.000919  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:09:50 d2.utils.events]: \u001b[0m eta: 1:09:20  iter: 939  total_loss: 0.335  loss_cls: 0.068  loss_box_reg: 0.117  loss_mask: 0.088  loss_rpn_cls: 0.001  loss_rpn_loc: 0.054  time: 3.9292  data_time: 2.0941  lr: 0.000939  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:11:06 d2.utils.events]: \u001b[0m eta: 1:08:00  iter: 959  total_loss: 0.324  loss_cls: 0.067  loss_box_reg: 0.110  loss_mask: 0.086  loss_rpn_cls: 0.001  loss_rpn_loc: 0.058  time: 3.9275  data_time: 2.0403  lr: 0.000959  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:12:23 d2.utils.events]: \u001b[0m eta: 1:06:38  iter: 979  total_loss: 0.309  loss_cls: 0.057  loss_box_reg: 0.104  loss_mask: 0.088  loss_rpn_cls: 0.002  loss_rpn_loc: 0.056  time: 3.9250  data_time: 2.0640  lr: 0.000979  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:13:51 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 16:13:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/07 16:13:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/07 16:14:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1684 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/07 16:14:11 d2.evaluation.evaluator]: \u001b[0mInference done 19/56. 0.1452 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/07 16:14:16 d2.evaluation.evaluator]: \u001b[0mInference done 30/56. 0.1231 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/07 16:14:22 d2.evaluation.evaluator]: \u001b[0mInference done 38/56. 0.1223 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/07 16:14:28 d2.evaluation.evaluator]: \u001b[0mInference done 46/56. 0.1223 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/07 16:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 51/56. 0.1290 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.704183 (0.758906 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.131179 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.892\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.892\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.889\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.915\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.915\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 89.229 | 99.898 | 99.898 |  nan  |  nan  | 89.229 |\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 90.953 | brec_Cht         | 86.813 | lam_Sltst  | 87.176 |\n",
            "| skel_WkstPkst | 92.271 | strless_SltstSst | 88.931 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.32s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.891\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.891\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.892\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.918\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.918\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 89.130 | 99.898 | 99.898 |  nan  |  nan  | 89.130 |\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 90.034 | brec_Cht         | 89.603 | lam_Sltst  | 88.327 |\n",
            "| skel_WkstPkst | 89.295 | strless_SltstSst | 88.390 |            |        |\n",
            "\u001b[32m[07/07 16:14:38 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.testing]: \u001b[0mcopypaste: 89.2288,99.8983,99.8983,nan,nan,89.2288\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:14:38 d2.evaluation.testing]: \u001b[0mcopypaste: 89.1298,99.8983,99.8983,nan,nan,89.1298\n",
            "\u001b[32m[07/07 16:14:41 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 16:14:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/07 16:14:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/07 16:14:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1270 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.727919 (0.772792 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.138209 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.284\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.474\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.501\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.356 | 47.363 | 30.959 |  nan  |  nan  | 28.356 |\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 34.792 | brec_Cht         | nan    | lam_Sltst  | 14.789 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 35.488 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.475\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.090\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.502\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.859 | 47.453 | 28.817 |  nan  |  nan  | 28.859 |\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 37.559 | brec_Cht         | nan    | lam_Sltst  | 14.043 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 34.975 |            |        |\n",
            "\u001b[32m[07/07 16:14:54 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.testing]: \u001b[0mcopypaste: 28.3561,47.3632,30.9593,nan,nan,28.3561\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:14:54 d2.evaluation.testing]: \u001b[0mcopypaste: 28.8589,47.4527,28.8175,nan,nan,28.8589\n",
            "\u001b[32m[07/07 16:14:54 d2.utils.events]: \u001b[0m eta: 1:05:19  iter: 999  total_loss: 0.304  loss_cls: 0.057  loss_box_reg: 0.103  loss_mask: 0.083  loss_rpn_cls: 0.002  loss_rpn_loc: 0.056  time: 3.9233  data_time: 2.0873  lr: 0.000999  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:16:10 d2.utils.events]: \u001b[0m eta: 1:03:53  iter: 1019  total_loss: 0.304  loss_cls: 0.060  loss_box_reg: 0.104  loss_mask: 0.083  loss_rpn_cls: 0.003  loss_rpn_loc: 0.050  time: 3.9206  data_time: 2.0537  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:17:27 d2.utils.events]: \u001b[0m eta: 1:02:36  iter: 1039  total_loss: 0.295  loss_cls: 0.056  loss_box_reg: 0.107  loss_mask: 0.083  loss_rpn_cls: 0.001  loss_rpn_loc: 0.047  time: 3.9190  data_time: 2.0785  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:18:43 d2.utils.events]: \u001b[0m eta: 1:01:14  iter: 1059  total_loss: 0.291  loss_cls: 0.053  loss_box_reg: 0.100  loss_mask: 0.081  loss_rpn_cls: 0.002  loss_rpn_loc: 0.051  time: 3.9176  data_time: 2.0927  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:20:00 d2.utils.events]: \u001b[0m eta: 0:59:56  iter: 1079  total_loss: 0.267  loss_cls: 0.051  loss_box_reg: 0.092  loss_mask: 0.081  loss_rpn_cls: 0.001  loss_rpn_loc: 0.047  time: 3.9157  data_time: 2.1204  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:21:16 d2.utils.events]: \u001b[0m eta: 0:58:38  iter: 1099  total_loss: 0.269  loss_cls: 0.047  loss_box_reg: 0.092  loss_mask: 0.081  loss_rpn_cls: 0.001  loss_rpn_loc: 0.047  time: 3.9142  data_time: 2.0962  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:22:33 d2.utils.events]: \u001b[0m eta: 0:57:19  iter: 1119  total_loss: 0.262  loss_cls: 0.047  loss_box_reg: 0.089  loss_mask: 0.080  loss_rpn_cls: 0.001  loss_rpn_loc: 0.047  time: 3.9128  data_time: 2.0710  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:23:50 d2.utils.events]: \u001b[0m eta: 0:55:59  iter: 1139  total_loss: 0.266  loss_cls: 0.046  loss_box_reg: 0.088  loss_mask: 0.078  loss_rpn_cls: 0.001  loss_rpn_loc: 0.045  time: 3.9117  data_time: 2.0707  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:25:07 d2.utils.events]: \u001b[0m eta: 0:54:39  iter: 1159  total_loss: 0.278  loss_cls: 0.046  loss_box_reg: 0.094  loss_mask: 0.081  loss_rpn_cls: 0.001  loss_rpn_loc: 0.049  time: 3.9105  data_time: 2.0918  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:26:24 d2.utils.events]: \u001b[0m eta: 0:53:20  iter: 1179  total_loss: 0.262  loss_cls: 0.046  loss_box_reg: 0.092  loss_mask: 0.078  loss_rpn_cls: 0.002  loss_rpn_loc: 0.042  time: 3.9097  data_time: 2.1526  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:27:53 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 16:27:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/07 16:27:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/07 16:28:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1554 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/07 16:28:11 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.1331 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/07 16:28:16 d2.evaluation.evaluator]: \u001b[0mInference done 31/56. 0.1186 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/07 16:28:22 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1201 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/07 16:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.1208 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/07 16:28:33 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.1259 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.014822 (0.706173 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.127568 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.920\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.920\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.917\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.942\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.942\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 91.998 | 99.908 | 99.908 |  nan  |  nan  | 91.998 |\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 91.685 | brec_Cht         | 93.495 | lam_Sltst  | 89.434 |\n",
            "| skel_WkstPkst | 92.832 | strless_SltstSst | 92.543 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.29s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.908\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.908\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.223\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.904\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.929\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.929\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 90.794 | 99.908 | 99.908 |  nan  |  nan  | 90.794 |\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 91.703 | brec_Cht         | 91.526 | lam_Sltst  | 88.617 |\n",
            "| skel_WkstPkst | 92.469 | strless_SltstSst | 89.657 |            |        |\n",
            "\u001b[32m[07/07 16:28:36 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.testing]: \u001b[0mcopypaste: 91.9976,99.9085,99.9085,nan,nan,91.9976\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:28:36 d2.evaluation.testing]: \u001b[0mcopypaste: 90.7943,99.9085,99.9085,nan,nan,90.7943\n",
            "\u001b[32m[07/07 16:28:39 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 16:28:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/07 16:28:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/07 16:28:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1056 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/07 16:28:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.062907 (0.806291 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:28:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.126381 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:28:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 16:28:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 16:28:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.443\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n",
            "\u001b[32m[07/07 16:28:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 26.349 | 44.291 | 26.944 |  nan  |  nan  | 26.349 |\n",
            "\u001b[32m[07/07 16:28:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:28:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 36.415 | brec_Cht         | nan    | lam_Sltst  | 7.669 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 34.964 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.268\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.433\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n",
            "\u001b[32m[07/07 16:28:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 26.770 | 43.309 | 26.023 |  nan  |  nan  | 26.770 |\n",
            "\u001b[32m[07/07 16:28:53 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:28:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 38.404 | brec_Cht         | nan    | lam_Sltst  | 7.626 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 34.282 |            |       |\n",
            "\u001b[32m[07/07 16:28:53 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/07 16:28:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 16:28:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:28:53 d2.evaluation.testing]: \u001b[0mcopypaste: 26.3493,44.2913,26.9439,nan,nan,26.3493\n",
            "\u001b[32m[07/07 16:28:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 16:28:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:28:53 d2.evaluation.testing]: \u001b[0mcopypaste: 26.7703,43.3093,26.0233,nan,nan,26.7703\n",
            "\u001b[32m[07/07 16:28:53 d2.utils.events]: \u001b[0m eta: 0:52:02  iter: 1199  total_loss: 0.246  loss_cls: 0.043  loss_box_reg: 0.083  loss_mask: 0.077  loss_rpn_cls: 0.002  loss_rpn_loc: 0.038  time: 3.9082  data_time: 2.1259  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:30:09 d2.utils.events]: \u001b[0m eta: 0:50:42  iter: 1219  total_loss: 0.230  loss_cls: 0.039  loss_box_reg: 0.077  loss_mask: 0.074  loss_rpn_cls: 0.001  loss_rpn_loc: 0.040  time: 3.9065  data_time: 2.1092  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:31:24 d2.utils.events]: \u001b[0m eta: 0:49:23  iter: 1239  total_loss: 0.238  loss_cls: 0.039  loss_box_reg: 0.079  loss_mask: 0.077  loss_rpn_cls: 0.001  loss_rpn_loc: 0.041  time: 3.9045  data_time: 2.0976  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:32:41 d2.utils.events]: \u001b[0m eta: 0:48:04  iter: 1259  total_loss: 0.246  loss_cls: 0.039  loss_box_reg: 0.087  loss_mask: 0.075  loss_rpn_cls: 0.002  loss_rpn_loc: 0.043  time: 3.9031  data_time: 2.0365  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:33:57 d2.utils.events]: \u001b[0m eta: 0:46:46  iter: 1279  total_loss: 0.229  loss_cls: 0.037  loss_box_reg: 0.077  loss_mask: 0.075  loss_rpn_cls: 0.002  loss_rpn_loc: 0.041  time: 3.9021  data_time: 2.0848  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:35:15 d2.utils.events]: \u001b[0m eta: 0:45:28  iter: 1299  total_loss: 0.235  loss_cls: 0.039  loss_box_reg: 0.078  loss_mask: 0.075  loss_rpn_cls: 0.002  loss_rpn_loc: 0.039  time: 3.9016  data_time: 2.0889  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:36:32 d2.utils.events]: \u001b[0m eta: 0:44:11  iter: 1319  total_loss: 0.236  loss_cls: 0.040  loss_box_reg: 0.078  loss_mask: 0.074  loss_rpn_cls: 0.001  loss_rpn_loc: 0.041  time: 3.9012  data_time: 2.1150  lr: 0.001000  max_mem: 9273M\n",
            "\u001b[32m[07/07 16:37:50 d2.utils.events]: \u001b[0m eta: 0:42:53  iter: 1339  total_loss: 0.233  loss_cls: 0.035  loss_box_reg: 0.080  loss_mask: 0.073  loss_rpn_cls: 0.001  loss_rpn_loc: 0.040  time: 3.9008  data_time: 2.1504  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:39:07 d2.utils.events]: \u001b[0m eta: 0:41:35  iter: 1359  total_loss: 0.228  loss_cls: 0.034  loss_box_reg: 0.077  loss_mask: 0.072  loss_rpn_cls: 0.002  loss_rpn_loc: 0.042  time: 3.8999  data_time: 2.1142  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:40:24 d2.utils.events]: \u001b[0m eta: 0:40:16  iter: 1379  total_loss: 0.221  loss_cls: 0.035  loss_box_reg: 0.076  loss_mask: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.037  time: 3.8993  data_time: 2.0939  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:41:52 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 16:41:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/07 16:41:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/07 16:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1494 s / img. ETA=0:00:41\n",
            "\u001b[32m[07/07 16:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.1311 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/07 16:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 31/56. 0.1217 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/07 16:42:20 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1191 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/07 16:42:26 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.1190 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/07 16:42:31 d2.evaluation.evaluator]: \u001b[0mInference done 53/56. 0.1242 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 16:42:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.193977 (0.670470 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:42:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.125963 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:42:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 16:42:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 16:42:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.952\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.952\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.944\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.970\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.970\n",
            "\u001b[32m[07/07 16:42:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 95.222 | 99.915 | 99.915 |  nan  |  nan  | 95.222 |\n",
            "\u001b[32m[07/07 16:42:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:42:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 94.788 | brec_Cht         | 95.809 | lam_Sltst  | 94.722 |\n",
            "| skel_WkstPkst | 94.722 | strless_SltstSst | 96.071 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.921\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.921\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.919\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.945\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.945\n",
            "\u001b[32m[07/07 16:42:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 92.109 | 99.915 | 99.915 |  nan  |  nan  | 92.109 |\n",
            "\u001b[32m[07/07 16:42:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:42:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 92.293 | brec_Cht         | 92.370 | lam_Sltst  | 91.637 |\n",
            "| skel_WkstPkst | 93.189 | strless_SltstSst | 91.054 |            |        |\n",
            "\u001b[32m[07/07 16:42:34 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/07 16:42:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 16:42:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:42:34 d2.evaluation.testing]: \u001b[0mcopypaste: 95.2223,99.9152,99.9152,nan,nan,95.2223\n",
            "\u001b[32m[07/07 16:42:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 16:42:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:42:34 d2.evaluation.testing]: \u001b[0mcopypaste: 92.1085,99.9152,99.9152,nan,nan,92.1085\n",
            "\u001b[32m[07/07 16:42:37 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 16:42:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/07 16:42:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/07 16:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1208 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.625047 (0.762505 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.137308 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.276\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.443\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 27.554 | 44.318 | 27.051 |  nan  |  nan  | 27.554 |\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 39.369 | brec_Cht         | nan    | lam_Sltst  | 9.016 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 34.278 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.282\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.448\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.079\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.205 | 44.767 | 27.865 |  nan  |  nan  | 28.205 |\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 41.346 | brec_Cht         | nan    | lam_Sltst  | 9.083 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 34.187 |            |       |\n",
            "\u001b[32m[07/07 16:42:49 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.testing]: \u001b[0mcopypaste: 27.5541,44.3185,27.0506,nan,nan,27.5541\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:42:49 d2.evaluation.testing]: \u001b[0mcopypaste: 28.2053,44.7671,27.8650,nan,nan,28.2053\n",
            "\u001b[32m[07/07 16:42:49 d2.utils.events]: \u001b[0m eta: 0:38:57  iter: 1399  total_loss: 0.224  loss_cls: 0.036  loss_box_reg: 0.075  loss_mask: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.8985  data_time: 2.0576  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:44:06 d2.utils.events]: \u001b[0m eta: 0:37:39  iter: 1419  total_loss: 0.223  loss_cls: 0.033  loss_box_reg: 0.073  loss_mask: 0.071  loss_rpn_cls: 0.001  loss_rpn_loc: 0.041  time: 3.8972  data_time: 2.0396  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:45:22 d2.utils.events]: \u001b[0m eta: 0:36:22  iter: 1439  total_loss: 0.234  loss_cls: 0.036  loss_box_reg: 0.072  loss_mask: 0.071  loss_rpn_cls: 0.002  loss_rpn_loc: 0.044  time: 3.8960  data_time: 2.0505  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:46:39 d2.utils.events]: \u001b[0m eta: 0:35:04  iter: 1459  total_loss: 0.214  loss_cls: 0.035  loss_box_reg: 0.069  loss_mask: 0.070  loss_rpn_cls: 0.001  loss_rpn_loc: 0.037  time: 3.8957  data_time: 2.1185  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:47:55 d2.utils.events]: \u001b[0m eta: 0:33:44  iter: 1479  total_loss: 0.199  loss_cls: 0.031  loss_box_reg: 0.063  loss_mask: 0.070  loss_rpn_cls: 0.001  loss_rpn_loc: 0.034  time: 3.8943  data_time: 2.0271  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:49:12 d2.utils.events]: \u001b[0m eta: 0:32:26  iter: 1499  total_loss: 0.216  loss_cls: 0.034  loss_box_reg: 0.071  loss_mask: 0.069  loss_rpn_cls: 0.001  loss_rpn_loc: 0.040  time: 3.8938  data_time: 2.0976  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:50:29 d2.utils.events]: \u001b[0m eta: 0:31:08  iter: 1519  total_loss: 0.203  loss_cls: 0.029  loss_box_reg: 0.066  loss_mask: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.034  time: 3.8928  data_time: 2.0614  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:51:45 d2.utils.events]: \u001b[0m eta: 0:29:50  iter: 1539  total_loss: 0.196  loss_cls: 0.029  loss_box_reg: 0.065  loss_mask: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.031  time: 3.8918  data_time: 2.0628  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:53:02 d2.utils.events]: \u001b[0m eta: 0:28:32  iter: 1559  total_loss: 0.196  loss_cls: 0.031  loss_box_reg: 0.065  loss_mask: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 3.8911  data_time: 2.0740  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:54:18 d2.utils.events]: \u001b[0m eta: 0:27:14  iter: 1579  total_loss: 0.198  loss_cls: 0.028  loss_box_reg: 0.063  loss_mask: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.035  time: 3.8903  data_time: 2.0515  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:55:47 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 16:55:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/07 16:55:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/07 16:55:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1514 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/07 16:56:04 d2.evaluation.evaluator]: \u001b[0mInference done 20/56. 0.1327 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/07 16:56:10 d2.evaluation.evaluator]: \u001b[0mInference done 31/56. 0.1179 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/07 16:56:15 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1186 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/07 16:56:20 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.1190 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/07 16:56:25 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.1230 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 16:56:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.352385 (0.673576 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:56:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.124345 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:56:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 16:56:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 16:56:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.953\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.953\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.942\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.968\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.968\n",
            "\u001b[32m[07/07 16:56:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 95.309 | 99.916 | 99.916 |  nan  |  nan  | 95.309 |\n",
            "\u001b[32m[07/07 16:56:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:56:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 95.774 | brec_Cht         | 99.213 | lam_Sltst  | 92.137 |\n",
            "| skel_WkstPkst | 97.774 | strless_SltstSst | 91.647 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.926\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.926\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.923\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.949\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.949\n",
            "\u001b[32m[07/07 16:56:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 92.587 | 99.916 | 99.916 |  nan  |  nan  | 92.587 |\n",
            "\u001b[32m[07/07 16:56:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:56:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 93.315 | brec_Cht         | 92.458 | lam_Sltst  | 93.085 |\n",
            "| skel_WkstPkst | 92.454 | strless_SltstSst | 91.623 |            |        |\n",
            "\u001b[32m[07/07 16:56:29 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/07 16:56:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 16:56:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:56:29 d2.evaluation.testing]: \u001b[0mcopypaste: 95.3089,99.9164,99.9164,nan,nan,95.3089\n",
            "\u001b[32m[07/07 16:56:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 16:56:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:56:29 d2.evaluation.testing]: \u001b[0mcopypaste: 92.5868,99.9164,99.9164,nan,nan,92.5868\n",
            "\u001b[32m[07/07 16:56:32 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 16:56:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/07 16:56:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/07 16:56:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1114 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.145481 (0.814548 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.129660 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.463\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 29.291 | 46.316 | 31.581 |  nan  |  nan  | 29.291 |\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 39.583 | brec_Cht         | nan    | lam_Sltst  | 14.865 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 33.424 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.480\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 29.289 | 47.955 | 29.528 |  nan  |  nan  | 29.289 |\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 40.634 | brec_Cht         | nan    | lam_Sltst  | 14.331 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 32.901 |            |        |\n",
            "\u001b[32m[07/07 16:56:45 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.testing]: \u001b[0mcopypaste: 29.2906,46.3165,31.5809,nan,nan,29.2906\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 16:56:45 d2.evaluation.testing]: \u001b[0mcopypaste: 29.2885,47.9545,29.5280,nan,nan,29.2885\n",
            "\u001b[32m[07/07 16:56:45 d2.utils.events]: \u001b[0m eta: 0:25:56  iter: 1599  total_loss: 0.196  loss_cls: 0.028  loss_box_reg: 0.062  loss_mask: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 3.8895  data_time: 2.0975  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:58:01 d2.utils.events]: \u001b[0m eta: 0:24:37  iter: 1619  total_loss: 0.204  loss_cls: 0.028  loss_box_reg: 0.067  loss_mask: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.034  time: 3.8883  data_time: 2.0672  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 16:59:17 d2.utils.events]: \u001b[0m eta: 0:23:16  iter: 1639  total_loss: 0.188  loss_cls: 0.027  loss_box_reg: 0.062  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.031  time: 3.8873  data_time: 2.0361  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:00:35 d2.utils.events]: \u001b[0m eta: 0:21:57  iter: 1659  total_loss: 0.186  loss_cls: 0.027  loss_box_reg: 0.060  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.033  time: 3.8871  data_time: 2.1015  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:01:52 d2.utils.events]: \u001b[0m eta: 0:20:40  iter: 1679  total_loss: 0.203  loss_cls: 0.028  loss_box_reg: 0.069  loss_mask: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.8869  data_time: 2.0833  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:03:08 d2.utils.events]: \u001b[0m eta: 0:19:21  iter: 1699  total_loss: 0.186  loss_cls: 0.027  loss_box_reg: 0.060  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.031  time: 3.8860  data_time: 2.0401  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:04:25 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 1719  total_loss: 0.184  loss_cls: 0.027  loss_box_reg: 0.058  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.029  time: 3.8853  data_time: 2.0596  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:05:41 d2.utils.events]: \u001b[0m eta: 0:16:44  iter: 1739  total_loss: 0.185  loss_cls: 0.026  loss_box_reg: 0.063  loss_mask: 0.066  loss_rpn_cls: 0.002  loss_rpn_loc: 0.030  time: 3.8846  data_time: 2.0611  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:06:59 d2.utils.events]: \u001b[0m eta: 0:15:27  iter: 1759  total_loss: 0.182  loss_cls: 0.026  loss_box_reg: 0.061  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.029  time: 3.8843  data_time: 2.0695  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:08:15 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 1779  total_loss: 0.181  loss_cls: 0.026  loss_box_reg: 0.058  loss_mask: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.029  time: 3.8837  data_time: 2.0785  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:09:44 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 17:09:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/07 17:09:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/07 17:09:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1467 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/07 17:10:05 d2.evaluation.evaluator]: \u001b[0mInference done 19/56. 0.1315 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/07 17:10:10 d2.evaluation.evaluator]: \u001b[0mInference done 30/56. 0.1211 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/07 17:10:16 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1183 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/07 17:10:21 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.1182 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/07 17:10:26 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.1227 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.265235 (0.711083 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.124362 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.961\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.961\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.948\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.975\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.975\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 96.111 | 99.932 | 99.932 |  nan  |  nan  | 96.111 |\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 95.620 | brec_Cht         | 94.372 | lam_Sltst  | 96.369 |\n",
            "| skel_WkstPkst | 98.092 | strless_SltstSst | 96.102 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.933\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.933\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.929\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.955\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.955\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 93.297 | 99.932 | 99.932 |  nan  |  nan  | 93.297 |\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 93.845 | brec_Cht         | 92.410 | lam_Sltst  | 94.303 |\n",
            "| skel_WkstPkst | 93.048 | strless_SltstSst | 92.877 |            |        |\n",
            "\u001b[32m[07/07 17:10:29 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.testing]: \u001b[0mcopypaste: 96.1111,99.9317,99.9317,nan,nan,96.1111\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 17:10:29 d2.evaluation.testing]: \u001b[0mcopypaste: 93.2966,99.9317,99.9317,nan,nan,93.2966\n",
            "\u001b[32m[07/07 17:10:32 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 17:10:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/07 17:10:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/07 17:10:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1249 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.748580 (0.774858 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.137055 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.432\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.269\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.490\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 26.889 | 43.239 | 28.288 |  nan  |  nan  | 26.889 |\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 38.805 | brec_Cht         | nan    | lam_Sltst  | 7.858 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 34.004 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.427\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.269\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.491\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 26.924 | 42.745 | 28.278 |  nan  |  nan  | 26.924 |\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 40.588 | brec_Cht         | nan    | lam_Sltst  | 7.662 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 32.521 |            |       |\n",
            "\u001b[32m[07/07 17:10:45 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.testing]: \u001b[0mcopypaste: 26.8888,43.2385,28.2885,nan,nan,26.8888\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 17:10:45 d2.evaluation.testing]: \u001b[0mcopypaste: 26.9236,42.7450,28.2778,nan,nan,26.9236\n",
            "\u001b[32m[07/07 17:10:45 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 1799  total_loss: 0.190  loss_cls: 0.028  loss_box_reg: 0.060  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.034  time: 3.8833  data_time: 2.0698  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:12:01 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 1819  total_loss: 0.182  loss_cls: 0.026  loss_box_reg: 0.061  loss_mask: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.033  time: 3.8825  data_time: 2.0426  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:13:18 d2.utils.events]: \u001b[0m eta: 0:10:17  iter: 1839  total_loss: 0.181  loss_cls: 0.025  loss_box_reg: 0.059  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 3.8822  data_time: 2.1054  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:14:36 d2.utils.events]: \u001b[0m eta: 0:09:00  iter: 1859  total_loss: 0.179  loss_cls: 0.025  loss_box_reg: 0.059  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.031  time: 3.8819  data_time: 2.1038  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:15:52 d2.utils.events]: \u001b[0m eta: 0:07:43  iter: 1879  total_loss: 0.175  loss_cls: 0.024  loss_box_reg: 0.054  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.034  time: 3.8811  data_time: 2.0828  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:17:11 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 1899  total_loss: 0.177  loss_cls: 0.025  loss_box_reg: 0.059  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 3.8819  data_time: 2.2091  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:18:28 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 1919  total_loss: 0.178  loss_cls: 0.026  loss_box_reg: 0.055  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 3.8818  data_time: 2.1990  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:19:45 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 1939  total_loss: 0.174  loss_cls: 0.025  loss_box_reg: 0.055  loss_mask: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.031  time: 3.8812  data_time: 2.1307  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:21:01 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 1959  total_loss: 0.167  loss_cls: 0.025  loss_box_reg: 0.056  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.025  time: 3.8807  data_time: 2.0749  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:22:18 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 1979  total_loss: 0.169  loss_cls: 0.024  loss_box_reg: 0.053  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.028  time: 3.8803  data_time: 2.0896  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:23:48 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 17:23:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/07 17:23:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/07 17:24:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1411 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/07 17:24:08 d2.evaluation.evaluator]: \u001b[0mInference done 19/56. 0.1298 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/07 17:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 30/56. 0.1190 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/07 17:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 39/56. 0.1175 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/07 17:24:25 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.1178 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/07 17:24:30 d2.evaluation.evaluator]: \u001b[0mInference done 52/56. 0.1215 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 17:24:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.135218 (0.708534 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:24:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.122452 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:24:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 17:24:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 17:24:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.953\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.953\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.231\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.943\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.970\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.970\n",
            "\u001b[32m[07/07 17:24:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 95.342 | 99.922 | 99.922 |  nan  |  nan  | 95.342 |\n",
            "\u001b[32m[07/07 17:24:32 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:24:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 97.582 | brec_Cht         | 96.280 | lam_Sltst  | 95.461 |\n",
            "| skel_WkstPkst | 94.102 | strless_SltstSst | 93.283 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.936\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.936\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.930\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.957\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.957\n",
            "\u001b[32m[07/07 17:24:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 93.560 | 99.922 | 99.922 |  nan  |  nan  | 93.560 |\n",
            "\u001b[32m[07/07 17:24:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:24:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 94.892 | brec_Cht         | 93.704 | lam_Sltst  | 93.502 |\n",
            "| skel_WkstPkst | 93.072 | strless_SltstSst | 92.628 |            |        |\n",
            "\u001b[32m[07/07 17:24:33 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_train in csv format:\n",
            "\u001b[32m[07/07 17:24:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 17:24:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 17:24:33 d2.evaluation.testing]: \u001b[0mcopypaste: 95.3417,99.9220,99.9220,nan,nan,95.3417\n",
            "\u001b[32m[07/07 17:24:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 17:24:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 17:24:33 d2.evaluation.testing]: \u001b[0mcopypaste: 93.5597,99.9220,99.9220,nan,nan,93.5597\n",
            "\u001b[32m[07/07 17:24:35 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 17:24:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/07 17:24:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/07 17:24:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1259 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.083294 (0.808329 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.138056 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.254\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.411\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.054\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.445 | 41.137 | 26.886 |  nan  |  nan  | 25.445 |\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 37.380 | brec_Cht         | nan    | lam_Sltst  | 8.981 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 29.975 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.411\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.262\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.484\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.676 | 41.119 | 26.202 |  nan  |  nan  | 25.676 |\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 39.489 | brec_Cht         | nan    | lam_Sltst  | 7.760 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 29.779 |            |       |\n",
            "\u001b[32m[07/07 17:24:49 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_0_val in csv format:\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.testing]: \u001b[0mcopypaste: 25.4451,41.1371,26.8857,nan,nan,25.4451\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 17:24:49 d2.evaluation.testing]: \u001b[0mcopypaste: 25.6758,41.1191,26.2015,nan,nan,25.6758\n",
            "\u001b[32m[07/07 17:24:49 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 1999  total_loss: 0.179  loss_cls: 0.027  loss_box_reg: 0.060  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.028  time: 3.8797  data_time: 2.0817  lr: 0.001000  max_mem: 9357M\n",
            "\u001b[32m[07/07 17:24:49 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 2:09:11 (3.8817 s / it)\n",
            "\u001b[32m[07/07 17:24:49 d2.engine.hooks]: \u001b[0mTotal training time: 2:32:53 (0:23:41 on hooks)\n",
            "\n",
            "\n",
            "**Starting train eval**\n",
            "\u001b[32m[07/07 17:25:02 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 17:25:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/07 17:25:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 56 images\n",
            "\u001b[32m[07/07 17:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/56. 0.1550 s / img. ETA=0:01:04\n",
            "\u001b[32m[07/07 17:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 17/56. 0.1361 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/07 17:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 26/56. 0.1220 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/07 17:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 34/56. 0.1155 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/07 17:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 40/56. 0.1133 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/07 17:25:46 d2.evaluation.evaluator]: \u001b[0mInference done 47/56. 0.1146 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/07 17:25:52 d2.evaluation.evaluator]: \u001b[0mInference done 50/56. 0.1204 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/07 17:25:58 d2.evaluation.evaluator]: \u001b[0mInference done 54/56. 0.1221 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/07 17:26:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.416263 (0.968946 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:26:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.123320 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:26:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 17:26:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/07 17:26:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.953\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.953\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.231\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.943\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.970\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.970\n",
            "\u001b[32m[07/07 17:26:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 95.342 | 99.922 | 99.922 |  nan  |  nan  | 95.342 |\n",
            "\u001b[32m[07/07 17:26:00 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:26:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 97.582 | brec_Cht         | 96.280 | lam_Sltst  | 95.461 |\n",
            "| skel_WkstPkst | 94.102 | strless_SltstSst | 93.283 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.936\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.936\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.930\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.957\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.957\n",
            "\u001b[32m[07/07 17:26:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 93.560 | 99.922 | 99.922 |  nan  |  nan  | 93.560 |\n",
            "\u001b[32m[07/07 17:26:00 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:26:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 94.892 | brec_Cht         | 93.704 | lam_Sltst  | 93.502 |\n",
            "| skel_WkstPkst | 93.072 | strless_SltstSst | 92.628 |            |        |\n",
            "randomly selected cores/Box 8 Depths 10035-45.JPG\n",
            "\n",
            "\n",
            "**Starting val eval**\n",
            "\u001b[32m[07/07 17:26:37 d2.data.common]: \u001b[0mSerializing 15 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 17:26:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/07 17:26:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 15 images\n",
            "\u001b[32m[07/07 17:26:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/15. 0.1206 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/07 17:26:57 d2.evaluation.evaluator]: \u001b[0mInference done 14/15. 0.1431 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/07 17:26:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.471974 (1.447197 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:26:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.147418 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:26:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 17:26:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/07 17:26:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.254\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.411\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.054\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494\n",
            "\u001b[32m[07/07 17:26:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.445 | 41.137 | 26.886 |  nan  |  nan  | 25.445 |\n",
            "\u001b[32m[07/07 17:26:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:26:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 37.380 | brec_Cht         | nan    | lam_Sltst  | 8.981 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 29.975 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.411\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.262\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.484\n",
            "\u001b[32m[07/07 17:26:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.676 | 41.119 | 26.202 |  nan  |  nan  | 25.676 |\n",
            "\u001b[32m[07/07 17:26:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:26:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 39.489 | brec_Cht         | nan    | lam_Sltst  | 7.760 |\n",
            "| skel_WkstPkst | nan    | strless_SltstSst | 29.779 |            |       |\n",
            "randomly selected cores/Boxes 40-42  Depths 7829.5-7838.8 (Dry).JPG\n",
            "Tue Jul  7 17:27:30 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    39W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "CPU times: user 16.6 s, sys: 2.24 s, total: 18.8 s\n",
            "Wall time: 2h 36min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_hb1WlvLaZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c726c03e-ff00-4e4d-a43d-208f33dd9475"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '1' --max_iter 2000\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 1\n",
            "\t cores_fold_1_train\n",
            "\t cores_fold_1_val\n",
            "\u001b[32m[07/07 17:27:38 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/07 17:27:50 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 56 images left.\n",
            "\u001b[32m[07/07 17:27:50 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 234          |   brec_Cht    | 4            | lam_Sltst  | 98           |\n",
            "| skel_WkstPkst | 18           | strless_Slt.. | 139          |            |              |\n",
            "|     total     | 493          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/07 17:27:50 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 17:27:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/07 17:27:50 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/07 17:27:50 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-07 17:27:50.613040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/07 17:27:52 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/07 17:29:07 d2.utils.events]: \u001b[0m eta: 2:01:49  iter: 19  total_loss: 3.529  loss_cls: 1.828  loss_box_reg: 0.313  loss_mask: 0.691  loss_rpn_cls: 0.450  loss_rpn_loc: 0.228  time: 3.6938  data_time: 2.4004  lr: 0.000020  max_mem: 7199M\n",
            "\u001b[32m[07/07 17:30:21 d2.utils.events]: \u001b[0m eta: 2:00:35  iter: 39  total_loss: 2.675  loss_cls: 1.232  loss_box_reg: 0.418  loss_mask: 0.668  loss_rpn_cls: 0.175  loss_rpn_loc: 0.182  time: 3.6949  data_time: 2.2372  lr: 0.000040  max_mem: 7717M\n",
            "\u001b[32m[07/07 17:31:34 d2.utils.events]: \u001b[0m eta: 1:58:50  iter: 59  total_loss: 2.001  loss_cls: 0.652  loss_box_reg: 0.444  loss_mask: 0.612  loss_rpn_cls: 0.083  loss_rpn_loc: 0.162  time: 3.6765  data_time: 2.1730  lr: 0.000060  max_mem: 7954M\n",
            "\u001b[32m[07/07 17:32:48 d2.utils.events]: \u001b[0m eta: 1:57:53  iter: 79  total_loss: 1.805  loss_cls: 0.570  loss_box_reg: 0.490  loss_mask: 0.544  loss_rpn_cls: 0.056  loss_rpn_loc: 0.160  time: 3.6771  data_time: 2.1577  lr: 0.000080  max_mem: 7954M\n",
            "\u001b[32m[07/07 17:34:01 d2.utils.events]: \u001b[0m eta: 1:56:40  iter: 99  total_loss: 1.715  loss_cls: 0.551  loss_box_reg: 0.530  loss_mask: 0.471  loss_rpn_cls: 0.040  loss_rpn_loc: 0.147  time: 3.6761  data_time: 2.1396  lr: 0.000100  max_mem: 8357M\n",
            "\u001b[32m[07/07 17:35:15 d2.utils.events]: \u001b[0m eta: 1:54:57  iter: 119  total_loss: 1.609  loss_cls: 0.517  loss_box_reg: 0.513  loss_mask: 0.415  loss_rpn_cls: 0.034  loss_rpn_loc: 0.143  time: 3.6778  data_time: 2.1420  lr: 0.000120  max_mem: 8357M\n",
            "\u001b[32m[07/07 17:36:28 d2.utils.events]: \u001b[0m eta: 1:53:38  iter: 139  total_loss: 1.626  loss_cls: 0.520  loss_box_reg: 0.534  loss_mask: 0.402  loss_rpn_cls: 0.032  loss_rpn_loc: 0.133  time: 3.6722  data_time: 2.0784  lr: 0.000140  max_mem: 8357M\n",
            "\u001b[32m[07/07 17:37:41 d2.utils.events]: \u001b[0m eta: 1:52:31  iter: 159  total_loss: 1.578  loss_cls: 0.505  loss_box_reg: 0.533  loss_mask: 0.365  loss_rpn_cls: 0.026  loss_rpn_loc: 0.130  time: 3.6723  data_time: 2.0937  lr: 0.000160  max_mem: 8725M\n",
            "\u001b[32m[07/07 17:38:55 d2.utils.events]: \u001b[0m eta: 1:51:27  iter: 179  total_loss: 1.515  loss_cls: 0.479  loss_box_reg: 0.539  loss_mask: 0.353  loss_rpn_cls: 0.028  loss_rpn_loc: 0.125  time: 3.6716  data_time: 2.1013  lr: 0.000180  max_mem: 8725M\n",
            "\u001b[32m[07/07 17:40:20 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 17:40:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/07 17:40:20 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_1_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/07 17:40:20 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_1_train' to COCO format ...)\n",
            "\u001b[32m[07/07 17:40:31 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/07 17:40:31 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 57, #annotations: 493\n",
            "\u001b[32m[07/07 17:40:31 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_1_train_coco_format.json' ...\n",
            "\u001b[32m[07/07 17:40:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0xc7b6c000 @  0x7fd1afbeab6b 0x7fd1afc0a379 0x7fd15333f04e 0x7fd153340f4a 0x7fd18c22f67b 0x7fd18be7e6be 0x7fd18c0e77b5 0x7fd18c0d97c1 0x7fd18c0d8d0e 0x7fd18c0d97c1 0x7fd18db2e93a 0x7fd18c0d97c1 0x7fd18be79457 0x7fd18be7a080 0x7fd18c19871a 0x7fd18dc1613e 0x7fd18c0d9c72 0x7fd19a173a68 0x7fd19a22eb04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/07 17:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.4767 s / img. ETA=0:06:32\n",
            "\u001b[32m[07/07 17:42:16 d2.evaluation.evaluator]: \u001b[0mInference done 12/57. 0.4754 s / img. ETA=0:06:25\n",
            "\u001b[32m[07/07 17:42:25 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.4769 s / img. ETA=0:06:17\n",
            "\u001b[32m[07/07 17:42:34 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.4519 s / img. ETA=0:05:26\n",
            "\u001b[32m[07/07 17:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.4361 s / img. ETA=0:04:49\n",
            "\u001b[32m[07/07 17:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.4259 s / img. ETA=0:04:21\n",
            "\u001b[32m[07/07 17:43:02 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.4182 s / img. ETA=0:03:58\n",
            "\u001b[32m[07/07 17:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.4070 s / img. ETA=0:03:34\n",
            "\u001b[32m[07/07 17:43:19 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.4026 s / img. ETA=0:03:16\n",
            "\u001b[32m[07/07 17:43:29 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.3995 s / img. ETA=0:03:00\n",
            "\u001b[32m[07/07 17:43:38 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.3973 s / img. ETA=0:02:45\n",
            "\u001b[32m[07/07 17:43:47 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.3928 s / img. ETA=0:02:30\n",
            "\u001b[32m[07/07 17:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.3894 s / img. ETA=0:02:16\n",
            "\u001b[32m[07/07 17:44:05 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.3868 s / img. ETA=0:02:03\n",
            "\u001b[32m[07/07 17:44:14 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.3858 s / img. ETA=0:01:51\n",
            "\u001b[32m[07/07 17:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.3853 s / img. ETA=0:01:38\n",
            "\u001b[32m[07/07 17:44:33 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.3840 s / img. ETA=0:01:27\n",
            "\u001b[32m[07/07 17:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.3828 s / img. ETA=0:01:15\n",
            "\u001b[32m[07/07 17:44:53 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.3765 s / img. ETA=0:00:58\n",
            "\u001b[32m[07/07 17:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.3784 s / img. ETA=0:00:53\n",
            "\u001b[32m[07/07 17:45:08 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.3802 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/07 17:45:16 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.3817 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/07 17:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.3831 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/07 17:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.3844 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/07 17:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.3856 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/07 17:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.3867 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/07 17:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.3878 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/07 17:46:01 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.3888 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/07 17:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.3899 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/07 17:46:16 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.3911 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/07 17:46:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:59.220473 (5.754240 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:46:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.391052 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:46:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 17:46:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 17:46:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.51s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.110\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.044\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.053\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.185\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.275\n",
            "\u001b[32m[07/07 17:46:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.300 | 10.967 | 4.388  |  nan  |  nan  | 5.300 |\n",
            "\u001b[32m[07/07 17:46:16 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:46:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 16.058 | brec_Cht         | 0.000 | lam_Sltst  | 2.735 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 7.705 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.71s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.055\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.278\n",
            "\u001b[32m[07/07 17:46:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.536 | 10.832 | 5.286  |  nan  |  nan  | 5.536 |\n",
            "\u001b[32m[07/07 17:46:17 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:46:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 17.982 | brec_Cht         | 0.000 | lam_Sltst  | 2.506 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 7.191 |            |       |\n",
            "\u001b[32m[07/07 17:46:17 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/07 17:46:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 17:46:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 17:46:17 d2.evaluation.testing]: \u001b[0mcopypaste: 5.2997,10.9675,4.3877,nan,nan,5.2998\n",
            "\u001b[32m[07/07 17:46:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 17:46:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 17:46:17 d2.evaluation.testing]: \u001b[0mcopypaste: 5.5358,10.8323,5.2860,nan,nan,5.5359\n",
            "\u001b[32m[07/07 17:46:20 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 75           |   brec_Cht    | 17           | lam_Sltst  | 29           |\n",
            "| skel_WkstPkst | 8            | strless_Slt.. | 34           |            |              |\n",
            "|     total     | 163          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/07 17:46:20 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 17:46:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/07 17:46:20 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_1_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/07 17:46:20 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_1_val' to COCO format ...)\n",
            "\u001b[32m[07/07 17:46:23 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/07 17:46:23 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 14, #annotations: 163\n",
            "\u001b[32m[07/07 17:46:23 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_1_val_coco_format.json' ...\n",
            "\u001b[32m[07/07 17:46:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/07 17:47:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.3916 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/07 17:47:50 d2.evaluation.evaluator]: \u001b[0mInference done 12/14. 0.3977 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/07 17:47:57 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.4043 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/07 17:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.4086 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/07 17:48:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:56.458628 (6.273181 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:48:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.408569 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 17:48:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 17:48:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 17:48:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.040\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.054\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.177\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.260\n",
            "\u001b[32m[07/07 17:48:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.376 | 11.123 | 3.988  |  nan  |  nan  | 5.376 |\n",
            "\u001b[32m[07/07 17:48:05 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:48:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 10.621 | brec_Cht         | 0.000  | lam_Sltst  | 2.668 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 13.588 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.109\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.050\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.023\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.256\n",
            "\u001b[32m[07/07 17:48:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 4.980 | 10.880 | 3.286  |  nan  |  nan  | 4.980 |\n",
            "\u001b[32m[07/07 17:48:06 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 17:48:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 11.510 | brec_Cht         | 0.000  | lam_Sltst  | 2.510 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 10.879 |            |       |\n",
            "\u001b[32m[07/07 17:48:06 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/07 17:48:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 17:48:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 17:48:06 d2.evaluation.testing]: \u001b[0mcopypaste: 5.3755,11.1234,3.9878,nan,nan,5.3756\n",
            "\u001b[32m[07/07 17:48:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 17:48:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 17:48:06 d2.evaluation.testing]: \u001b[0mcopypaste: 4.9798,10.8798,3.2856,nan,nan,4.9798\n",
            "\u001b[32m[07/07 17:48:06 d2.utils.events]: \u001b[0m eta: 1:50:05  iter: 199  total_loss: 1.450  loss_cls: 0.465  loss_box_reg: 0.531  loss_mask: 0.334  loss_rpn_cls: 0.022  loss_rpn_loc: 0.121  time: 3.6697  data_time: 2.0526  lr: 0.000200  max_mem: 8725M\n",
            "\u001b[32m[07/07 17:49:18 d2.utils.events]: \u001b[0m eta: 1:48:49  iter: 219  total_loss: 1.443  loss_cls: 0.461  loss_box_reg: 0.498  loss_mask: 0.313  loss_rpn_cls: 0.023  loss_rpn_loc: 0.122  time: 3.6648  data_time: 2.0678  lr: 0.000220  max_mem: 8818M\n",
            "\u001b[32m[07/07 17:50:31 d2.utils.events]: \u001b[0m eta: 1:47:36  iter: 239  total_loss: 1.373  loss_cls: 0.449  loss_box_reg: 0.502  loss_mask: 0.284  loss_rpn_cls: 0.020  loss_rpn_loc: 0.118  time: 3.6636  data_time: 2.0727  lr: 0.000240  max_mem: 8818M\n",
            "\u001b[32m[07/07 17:51:45 d2.utils.events]: \u001b[0m eta: 1:46:24  iter: 259  total_loss: 1.257  loss_cls: 0.415  loss_box_reg: 0.456  loss_mask: 0.268  loss_rpn_cls: 0.018  loss_rpn_loc: 0.112  time: 3.6655  data_time: 2.0224  lr: 0.000260  max_mem: 8944M\n",
            "\u001b[32m[07/07 17:52:58 d2.utils.events]: \u001b[0m eta: 1:45:13  iter: 279  total_loss: 1.255  loss_cls: 0.443  loss_box_reg: 0.442  loss_mask: 0.245  loss_rpn_cls: 0.019  loss_rpn_loc: 0.114  time: 3.6666  data_time: 1.9766  lr: 0.000280  max_mem: 8944M\n",
            "\u001b[32m[07/07 17:54:12 d2.utils.events]: \u001b[0m eta: 1:44:02  iter: 299  total_loss: 1.155  loss_cls: 0.425  loss_box_reg: 0.392  loss_mask: 0.229  loss_rpn_cls: 0.016  loss_rpn_loc: 0.114  time: 3.6687  data_time: 2.0088  lr: 0.000300  max_mem: 8944M\n",
            "\u001b[32m[07/07 17:55:26 d2.utils.events]: \u001b[0m eta: 1:42:52  iter: 319  total_loss: 1.058  loss_cls: 0.399  loss_box_reg: 0.344  loss_mask: 0.216  loss_rpn_cls: 0.014  loss_rpn_loc: 0.107  time: 3.6700  data_time: 2.0148  lr: 0.000320  max_mem: 8944M\n",
            "\u001b[32m[07/07 17:56:41 d2.utils.events]: \u001b[0m eta: 1:41:52  iter: 339  total_loss: 1.140  loss_cls: 0.435  loss_box_reg: 0.345  loss_mask: 0.209  loss_rpn_cls: 0.015  loss_rpn_loc: 0.109  time: 3.6743  data_time: 2.0456  lr: 0.000340  max_mem: 8944M\n",
            "\u001b[32m[07/07 17:57:54 d2.utils.events]: \u001b[0m eta: 1:40:39  iter: 359  total_loss: 0.973  loss_cls: 0.376  loss_box_reg: 0.295  loss_mask: 0.193  loss_rpn_cls: 0.011  loss_rpn_loc: 0.110  time: 3.6736  data_time: 1.9718  lr: 0.000360  max_mem: 8944M\n",
            "\u001b[32m[07/07 17:59:08 d2.utils.events]: \u001b[0m eta: 1:39:27  iter: 379  total_loss: 1.013  loss_cls: 0.383  loss_box_reg: 0.305  loss_mask: 0.191  loss_rpn_cls: 0.014  loss_rpn_loc: 0.107  time: 3.6752  data_time: 1.9925  lr: 0.000380  max_mem: 8944M\n",
            "\u001b[32m[07/07 18:00:34 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 18:00:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/07 18:00:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/07 18:01:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.3238 s / img. ETA=0:03:35\n",
            "\u001b[32m[07/07 18:01:41 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.3130 s / img. ETA=0:03:11\n",
            "\u001b[32m[07/07 18:01:47 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.2893 s / img. ETA=0:02:34\n",
            "\u001b[32m[07/07 18:01:54 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.2732 s / img. ETA=0:02:11\n",
            "\u001b[32m[07/07 18:02:00 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.2622 s / img. ETA=0:01:52\n",
            "\u001b[32m[07/07 18:02:07 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2520 s / img. ETA=0:01:37\n",
            "\u001b[32m[07/07 18:02:14 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.2511 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/07 18:02:19 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2411 s / img. ETA=0:01:13\n",
            "\u001b[32m[07/07 18:02:25 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2309 s / img. ETA=0:01:02\n",
            "\u001b[32m[07/07 18:02:31 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.2313 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/07 18:02:37 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.2343 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/07 18:02:45 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.2387 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/07 18:02:52 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.2427 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/07 18:02:57 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.2392 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/07 18:03:04 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.2416 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/07 18:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.2455 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/07 18:03:20 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.2504 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/07 18:03:27 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.2538 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/07 18:03:34 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.2573 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/07 18:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.2615 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/07 18:03:49 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.2658 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/07 18:03:54 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.2719 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/07 18:03:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:52.048737 (3.308630 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:03:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.272237 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:03:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 18:03:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 18:03:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.454\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.106\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            "\u001b[32m[07/07 18:03:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 29.211 | 45.409 | 30.208 |  nan  |  nan  | 29.211 |\n",
            "\u001b[32m[07/07 18:03:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:03:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 50.887 | brec_Cht         | 0.000  | lam_Sltst  | 17.659 |\n",
            "| skel_WkstPkst | 32.277 | strless_SltstSst | 45.233 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.08s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.53s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.451\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.329\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561\n",
            "\u001b[32m[07/07 18:03:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 32.863 | 45.116 | 37.665 |  nan  |  nan  | 32.863 |\n",
            "\u001b[32m[07/07 18:03:59 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:03:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 52.813 | brec_Cht         | 0.000  | lam_Sltst  | 18.824 |\n",
            "| skel_WkstPkst | 47.291 | strless_SltstSst | 45.388 |            |        |\n",
            "\u001b[32m[07/07 18:03:59 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/07 18:03:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 18:03:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:03:59 d2.evaluation.testing]: \u001b[0mcopypaste: 29.2112,45.4085,30.2084,nan,nan,29.2112\n",
            "\u001b[32m[07/07 18:03:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 18:03:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:03:59 d2.evaluation.testing]: \u001b[0mcopypaste: 32.8632,45.1159,37.6655,nan,nan,32.8633\n",
            "\u001b[32m[07/07 18:04:02 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 18:04:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/07 18:04:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/07 18:04:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2545 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/07 18:04:33 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2888 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/07 18:04:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.081212 (2.120135 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:04:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.306898 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:04:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 18:04:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 18:04:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.248\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.153\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
            "\u001b[32m[07/07 18:04:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 14.831 | 24.754 | 15.303 |  nan  |  nan  | 14.831 |\n",
            "\u001b[32m[07/07 18:04:37 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:04:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 24.650 | brec_Cht         | 0.000  | lam_Sltst  | 14.655 |\n",
            "| skel_WkstPkst | 8.567  | strless_SltstSst | 26.281 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.170\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.156\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
            "\u001b[32m[07/07 18:04:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.556 | 24.311 | 16.964 |  nan  |  nan  | 15.556 |\n",
            "\u001b[32m[07/07 18:04:37 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:04:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 25.894 | brec_Cht         | 0.000  | lam_Sltst  | 17.875 |\n",
            "| skel_WkstPkst | 9.148  | strless_SltstSst | 24.861 |            |        |\n",
            "\u001b[32m[07/07 18:04:37 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/07 18:04:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 18:04:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:04:37 d2.evaluation.testing]: \u001b[0mcopypaste: 14.8305,24.7540,15.3031,nan,nan,14.8305\n",
            "\u001b[32m[07/07 18:04:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 18:04:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:04:37 d2.evaluation.testing]: \u001b[0mcopypaste: 15.5557,24.3108,16.9643,nan,nan,15.5557\n",
            "\u001b[32m[07/07 18:04:37 d2.utils.events]: \u001b[0m eta: 1:38:16  iter: 399  total_loss: 0.917  loss_cls: 0.342  loss_box_reg: 0.278  loss_mask: 0.180  loss_rpn_cls: 0.011  loss_rpn_loc: 0.102  time: 3.6767  data_time: 1.9982  lr: 0.000400  max_mem: 8944M\n",
            "\u001b[32m[07/07 18:05:53 d2.utils.events]: \u001b[0m eta: 1:37:05  iter: 419  total_loss: 0.886  loss_cls: 0.342  loss_box_reg: 0.266  loss_mask: 0.172  loss_rpn_cls: 0.009  loss_rpn_loc: 0.106  time: 3.6823  data_time: 2.0857  lr: 0.000420  max_mem: 8944M\n",
            "\u001b[32m[07/07 18:07:08 d2.utils.events]: \u001b[0m eta: 1:35:52  iter: 439  total_loss: 0.841  loss_cls: 0.326  loss_box_reg: 0.250  loss_mask: 0.167  loss_rpn_cls: 0.011  loss_rpn_loc: 0.103  time: 3.6854  data_time: 2.0540  lr: 0.000440  max_mem: 8944M\n",
            "\u001b[32m[07/07 18:08:23 d2.utils.events]: \u001b[0m eta: 1:34:39  iter: 459  total_loss: 0.806  loss_cls: 0.296  loss_box_reg: 0.254  loss_mask: 0.162  loss_rpn_cls: 0.008  loss_rpn_loc: 0.096  time: 3.6893  data_time: 2.0819  lr: 0.000460  max_mem: 9132M\n",
            "\u001b[32m[07/07 18:09:37 d2.utils.events]: \u001b[0m eta: 1:33:24  iter: 479  total_loss: 0.777  loss_cls: 0.283  loss_box_reg: 0.231  loss_mask: 0.163  loss_rpn_cls: 0.008  loss_rpn_loc: 0.098  time: 3.6900  data_time: 2.0512  lr: 0.000480  max_mem: 9132M\n",
            "\u001b[32m[07/07 18:10:52 d2.utils.events]: \u001b[0m eta: 1:32:12  iter: 499  total_loss: 0.716  loss_cls: 0.246  loss_box_reg: 0.214  loss_mask: 0.149  loss_rpn_cls: 0.009  loss_rpn_loc: 0.097  time: 3.6917  data_time: 2.0653  lr: 0.000500  max_mem: 9132M\n",
            "\u001b[32m[07/07 18:12:05 d2.utils.events]: \u001b[0m eta: 1:30:58  iter: 519  total_loss: 0.673  loss_cls: 0.228  loss_box_reg: 0.189  loss_mask: 0.144  loss_rpn_cls: 0.007  loss_rpn_loc: 0.093  time: 3.6906  data_time: 2.0323  lr: 0.000519  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:13:22 d2.utils.events]: \u001b[0m eta: 1:29:53  iter: 539  total_loss: 0.664  loss_cls: 0.215  loss_box_reg: 0.202  loss_mask: 0.146  loss_rpn_cls: 0.007  loss_rpn_loc: 0.092  time: 3.6960  data_time: 2.1095  lr: 0.000539  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:14:40 d2.utils.events]: \u001b[0m eta: 1:28:46  iter: 559  total_loss: 0.641  loss_cls: 0.203  loss_box_reg: 0.200  loss_mask: 0.135  loss_rpn_cls: 0.006  loss_rpn_loc: 0.092  time: 3.7034  data_time: 2.1753  lr: 0.000559  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:16:00 d2.utils.events]: \u001b[0m eta: 1:27:37  iter: 579  total_loss: 0.575  loss_cls: 0.168  loss_box_reg: 0.178  loss_mask: 0.129  loss_rpn_cls: 0.006  loss_rpn_loc: 0.093  time: 3.7131  data_time: 2.2558  lr: 0.000579  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:17:33 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 18:17:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/07 18:17:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/07 18:17:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1814 s / img. ETA=0:00:56\n",
            "\u001b[32m[07/07 18:17:56 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1505 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/07 18:18:01 d2.evaluation.evaluator]: \u001b[0mInference done 26/57. 0.1343 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/07 18:18:07 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1291 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/07 18:18:12 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1329 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/07 18:18:18 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1352 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/07 18:18:23 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1388 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/07 18:18:28 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1452 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/07 18:18:34 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1542 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:55.645778 (1.070111 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.158996 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.829\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.660\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.622\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.674\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.718\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.718\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 62.164 | 82.931 | 65.996 |  nan  |  nan  | 62.164 |\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 77.263 | brec_Cht         | 26.485 | lam_Sltst  | 53.601 |\n",
            "| skel_WkstPkst | 74.537 | strless_SltstSst | 78.936 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.41s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.829\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.743\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.709\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.754\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 64.808 | 82.931 | 74.260 |  nan  |  nan  | 64.808 |\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 79.231 | brec_Cht         | 36.304 | lam_Sltst  | 49.470 |\n",
            "| skel_WkstPkst | 78.688 | strless_SltstSst | 80.345 |            |        |\n",
            "\u001b[32m[07/07 18:18:39 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.testing]: \u001b[0mcopypaste: 62.1643,82.9307,65.9962,nan,nan,62.1644\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:18:39 d2.evaluation.testing]: \u001b[0mcopypaste: 64.8076,82.9307,74.2603,nan,nan,64.8076\n",
            "\u001b[32m[07/07 18:18:43 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 18:18:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/07 18:18:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/07 18:19:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1653 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.2151 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.718823 (1.524314 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.215117 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.166\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.401\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.401\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 16.954 | 32.040 | 16.558 |  nan  |  nan  | 16.954 |\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 28.290 | brec_Cht         | 4.188  | lam_Sltst  | 12.941 |\n",
            "| skel_WkstPkst | 9.201  | strless_SltstSst | 30.150 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.305\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.182\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.078\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.373\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.422\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 18.224 | 30.515 | 17.729 |  nan  |  nan  | 18.224 |\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 28.785 | brec_Cht         | 6.446  | lam_Sltst  | 12.784 |\n",
            "| skel_WkstPkst | 10.266 | strless_SltstSst | 32.840 |            |        |\n",
            "\u001b[32m[07/07 18:19:07 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.testing]: \u001b[0mcopypaste: 16.9539,32.0402,16.5576,nan,nan,16.9539\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:19:07 d2.evaluation.testing]: \u001b[0mcopypaste: 18.2241,30.5153,17.7291,nan,nan,18.2241\n",
            "\u001b[32m[07/07 18:19:07 d2.utils.events]: \u001b[0m eta: 1:26:38  iter: 599  total_loss: 0.579  loss_cls: 0.175  loss_box_reg: 0.185  loss_mask: 0.130  loss_rpn_cls: 0.005  loss_rpn_loc: 0.087  time: 3.7233  data_time: 2.2475  lr: 0.000599  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:20:28 d2.utils.events]: \u001b[0m eta: 1:25:27  iter: 619  total_loss: 0.555  loss_cls: 0.162  loss_box_reg: 0.172  loss_mask: 0.125  loss_rpn_cls: 0.005  loss_rpn_loc: 0.085  time: 3.7331  data_time: 2.2568  lr: 0.000619  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:21:48 d2.utils.events]: \u001b[0m eta: 1:24:22  iter: 639  total_loss: 0.518  loss_cls: 0.159  loss_box_reg: 0.160  loss_mask: 0.119  loss_rpn_cls: 0.004  loss_rpn_loc: 0.078  time: 3.7412  data_time: 2.2153  lr: 0.000639  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:23:05 d2.utils.events]: \u001b[0m eta: 1:23:15  iter: 659  total_loss: 0.485  loss_cls: 0.139  loss_box_reg: 0.153  loss_mask: 0.118  loss_rpn_cls: 0.005  loss_rpn_loc: 0.079  time: 3.7458  data_time: 2.1622  lr: 0.000659  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:24:23 d2.utils.events]: \u001b[0m eta: 1:22:10  iter: 679  total_loss: 0.468  loss_cls: 0.127  loss_box_reg: 0.144  loss_mask: 0.113  loss_rpn_cls: 0.004  loss_rpn_loc: 0.076  time: 3.7496  data_time: 2.1038  lr: 0.000679  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:25:43 d2.utils.events]: \u001b[0m eta: 1:21:01  iter: 699  total_loss: 0.468  loss_cls: 0.127  loss_box_reg: 0.145  loss_mask: 0.109  loss_rpn_cls: 0.004  loss_rpn_loc: 0.075  time: 3.7571  data_time: 2.2497  lr: 0.000699  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:27:04 d2.utils.events]: \u001b[0m eta: 1:19:52  iter: 719  total_loss: 0.429  loss_cls: 0.109  loss_box_reg: 0.135  loss_mask: 0.103  loss_rpn_cls: 0.004  loss_rpn_loc: 0.071  time: 3.7656  data_time: 2.3053  lr: 0.000719  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:28:25 d2.utils.events]: \u001b[0m eta: 1:18:44  iter: 739  total_loss: 0.414  loss_cls: 0.101  loss_box_reg: 0.133  loss_mask: 0.101  loss_rpn_cls: 0.003  loss_rpn_loc: 0.073  time: 3.7724  data_time: 2.2408  lr: 0.000739  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:29:43 d2.utils.events]: \u001b[0m eta: 1:17:34  iter: 759  total_loss: 0.420  loss_cls: 0.102  loss_box_reg: 0.135  loss_mask: 0.103  loss_rpn_cls: 0.003  loss_rpn_loc: 0.078  time: 3.7767  data_time: 2.2132  lr: 0.000759  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:31:00 d2.utils.events]: \u001b[0m eta: 1:16:19  iter: 779  total_loss: 0.401  loss_cls: 0.098  loss_box_reg: 0.126  loss_mask: 0.102  loss_rpn_cls: 0.004  loss_rpn_loc: 0.075  time: 3.7784  data_time: 2.1030  lr: 0.000779  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:32:33 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 18:32:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/07 18:32:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/07 18:32:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1545 s / img. ETA=0:00:46\n",
            "\u001b[32m[07/07 18:32:53 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1369 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/07 18:32:59 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1262 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/07 18:33:04 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1242 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/07 18:33:10 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1251 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/07 18:33:15 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1277 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/07 18:33:21 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1334 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.146408 (0.829739 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.136692 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.801\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.955\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.901\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.801\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.828\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.859\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.859\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 80.126 | 95.514 | 90.103 |  nan  |  nan  | 80.126 |\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 86.428 | brec_Cht         | 52.871 | lam_Sltst  | 82.196 |\n",
            "| skel_WkstPkst | 92.203 | strless_SltstSst | 86.933 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.32s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.803\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.954\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.936\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.830\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.862\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.862\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 80.290 | 95.394 | 93.612 |  nan  |  nan  | 80.290 |\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 88.315 | brec_Cht         | 58.492 | lam_Sltst  | 78.005 |\n",
            "| skel_WkstPkst | 88.287 | strless_SltstSst | 88.350 |            |        |\n",
            "\u001b[32m[07/07 18:33:25 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.testing]: \u001b[0mcopypaste: 80.1263,95.5138,90.1031,nan,nan,80.1263\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:33:25 d2.evaluation.testing]: \u001b[0mcopypaste: 80.2899,95.3941,93.6122,nan,nan,80.2899\n",
            "\u001b[32m[07/07 18:33:29 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 18:33:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/07 18:33:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/07 18:33:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1468 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 18:33:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.913804 (1.212645 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:33:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.179754 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:33:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 18:33:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 18:33:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.386\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
            "\u001b[32m[07/07 18:33:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 19.033 | 34.093 | 17.448 |  nan  |  nan  | 19.033 |\n",
            "\u001b[32m[07/07 18:33:50 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:33:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 26.441 | brec_Cht         | 20.219 | lam_Sltst  | 9.430 |\n",
            "| skel_WkstPkst | 9.597  | strless_SltstSst | 29.479 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.327\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.219\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.421\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.448\n",
            "\u001b[32m[07/07 18:33:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 21.596 | 32.702 | 21.855 |  nan  |  nan  | 21.596 |\n",
            "\u001b[32m[07/07 18:33:50 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:33:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 27.290 | brec_Cht         | 28.075 | lam_Sltst  | 8.737 |\n",
            "| skel_WkstPkst | 10.255 | strless_SltstSst | 33.624 |            |       |\n",
            "\u001b[32m[07/07 18:33:50 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/07 18:33:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 18:33:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:33:50 d2.evaluation.testing]: \u001b[0mcopypaste: 19.0330,34.0925,17.4475,nan,nan,19.0330\n",
            "\u001b[32m[07/07 18:33:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 18:33:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:33:50 d2.evaluation.testing]: \u001b[0mcopypaste: 21.5963,32.7024,21.8551,nan,nan,21.5963\n",
            "\u001b[32m[07/07 18:33:50 d2.utils.events]: \u001b[0m eta: 1:15:11  iter: 799  total_loss: 0.398  loss_cls: 0.097  loss_box_reg: 0.125  loss_mask: 0.095  loss_rpn_cls: 0.002  loss_rpn_loc: 0.066  time: 3.7840  data_time: 2.2469  lr: 0.000799  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:35:12 d2.utils.events]: \u001b[0m eta: 1:14:00  iter: 819  total_loss: 0.350  loss_cls: 0.077  loss_box_reg: 0.124  loss_mask: 0.092  loss_rpn_cls: 0.003  loss_rpn_loc: 0.068  time: 3.7917  data_time: 2.3145  lr: 0.000819  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:36:32 d2.utils.events]: \u001b[0m eta: 1:12:53  iter: 839  total_loss: 0.349  loss_cls: 0.078  loss_box_reg: 0.120  loss_mask: 0.092  loss_rpn_cls: 0.004  loss_rpn_loc: 0.068  time: 3.7976  data_time: 2.2959  lr: 0.000839  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:37:51 d2.utils.events]: \u001b[0m eta: 1:11:39  iter: 859  total_loss: 0.372  loss_cls: 0.081  loss_box_reg: 0.123  loss_mask: 0.091  loss_rpn_cls: 0.002  loss_rpn_loc: 0.072  time: 3.8002  data_time: 2.1690  lr: 0.000859  max_mem: 9285M\n",
            "\u001b[32m[07/07 18:39:08 d2.utils.events]: \u001b[0m eta: 1:10:25  iter: 879  total_loss: 0.341  loss_cls: 0.072  loss_box_reg: 0.105  loss_mask: 0.090  loss_rpn_cls: 0.003  loss_rpn_loc: 0.067  time: 3.8017  data_time: 2.1046  lr: 0.000879  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:40:27 d2.utils.events]: \u001b[0m eta: 1:09:19  iter: 899  total_loss: 0.338  loss_cls: 0.069  loss_box_reg: 0.105  loss_mask: 0.089  loss_rpn_cls: 0.002  loss_rpn_loc: 0.066  time: 3.8044  data_time: 2.1929  lr: 0.000899  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:41:47 d2.utils.events]: \u001b[0m eta: 1:08:11  iter: 919  total_loss: 0.306  loss_cls: 0.063  loss_box_reg: 0.106  loss_mask: 0.087  loss_rpn_cls: 0.002  loss_rpn_loc: 0.058  time: 3.8088  data_time: 2.2296  lr: 0.000919  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:43:07 d2.utils.events]: \u001b[0m eta: 1:07:06  iter: 939  total_loss: 0.291  loss_cls: 0.059  loss_box_reg: 0.096  loss_mask: 0.083  loss_rpn_cls: 0.002  loss_rpn_loc: 0.056  time: 3.8127  data_time: 2.2495  lr: 0.000939  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:44:27 d2.utils.events]: \u001b[0m eta: 1:05:56  iter: 959  total_loss: 0.311  loss_cls: 0.058  loss_box_reg: 0.099  loss_mask: 0.085  loss_rpn_cls: 0.003  loss_rpn_loc: 0.060  time: 3.8175  data_time: 2.2726  lr: 0.000959  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:45:48 d2.utils.events]: \u001b[0m eta: 1:04:51  iter: 979  total_loss: 0.304  loss_cls: 0.057  loss_box_reg: 0.099  loss_mask: 0.082  loss_rpn_cls: 0.002  loss_rpn_loc: 0.060  time: 3.8218  data_time: 2.2731  lr: 0.000979  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:47:23 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 18:47:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/07 18:47:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/07 18:47:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1484 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/07 18:47:42 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1313 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/07 18:47:47 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1197 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/07 18:47:53 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1172 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/07 18:47:58 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1181 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/07 18:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1224 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/07 18:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1281 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:41.716887 (0.802248 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.131496 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.867\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.867\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.859\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.886\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.886\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 86.700 | 99.910 | 99.910 |  nan  |  nan  | 86.700 |\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 88.709 | brec_Cht         | 70.099 | lam_Sltst  | 89.467 |\n",
            "| skel_WkstPkst | 95.669 | strless_SltstSst | 89.556 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.33s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.859\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.859\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.854\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.881\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.881\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 85.893 | 99.910 | 99.910 |  nan  |  nan  | 85.893 |\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 88.864 | brec_Cht         | 74.224 | lam_Sltst  | 86.464 |\n",
            "| skel_WkstPkst | 89.888 | strless_SltstSst | 90.025 |            |        |\n",
            "\u001b[32m[07/07 18:48:13 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.testing]: \u001b[0mcopypaste: 86.7000,99.9104,99.9104,nan,nan,86.7000\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:48:13 d2.evaluation.testing]: \u001b[0mcopypaste: 85.8932,99.9104,99.9104,nan,nan,85.8932\n",
            "\u001b[32m[07/07 18:48:17 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 18:48:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/07 18:48:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/07 18:48:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1382 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 18:48:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.791539 (1.199060 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:48:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.173952 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 18:48:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 18:48:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 18:48:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.413\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.223\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.480\n",
            "\u001b[32m[07/07 18:48:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 23.388 | 41.296 | 22.255 |  nan  |  nan  | 23.388 |\n",
            "\u001b[32m[07/07 18:48:38 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:48:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 24.857 | brec_Cht         | 43.981 | lam_Sltst  | 11.231 |\n",
            "| skel_WkstPkst | 10.489 | strless_SltstSst | 26.383 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.401\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.266\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.261\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.513\n",
            "\u001b[32m[07/07 18:48:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 26.073 | 40.120 | 26.572 |  nan  |  nan  | 26.073 |\n",
            "\u001b[32m[07/07 18:48:38 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 18:48:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 25.140 | brec_Cht         | 52.762 | lam_Sltst  | 11.573 |\n",
            "| skel_WkstPkst | 11.084 | strless_SltstSst | 29.806 |            |        |\n",
            "\u001b[32m[07/07 18:48:38 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/07 18:48:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 18:48:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:48:38 d2.evaluation.testing]: \u001b[0mcopypaste: 23.3883,41.2963,22.2554,nan,nan,23.3883\n",
            "\u001b[32m[07/07 18:48:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 18:48:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 18:48:38 d2.evaluation.testing]: \u001b[0mcopypaste: 26.0732,40.1198,26.5724,nan,nan,26.0732\n",
            "\u001b[32m[07/07 18:48:38 d2.utils.events]: \u001b[0m eta: 1:03:41  iter: 999  total_loss: 0.294  loss_cls: 0.054  loss_box_reg: 0.096  loss_mask: 0.081  loss_rpn_cls: 0.002  loss_rpn_loc: 0.057  time: 3.8274  data_time: 2.3422  lr: 0.000999  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:50:00 d2.utils.events]: \u001b[0m eta: 1:02:30  iter: 1019  total_loss: 0.282  loss_cls: 0.056  loss_box_reg: 0.095  loss_mask: 0.080  loss_rpn_cls: 0.003  loss_rpn_loc: 0.056  time: 3.8332  data_time: 2.3388  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:51:22 d2.utils.events]: \u001b[0m eta: 1:01:19  iter: 1039  total_loss: 0.281  loss_cls: 0.048  loss_box_reg: 0.090  loss_mask: 0.081  loss_rpn_cls: 0.002  loss_rpn_loc: 0.057  time: 3.8385  data_time: 2.3373  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:52:45 d2.utils.events]: \u001b[0m eta: 1:00:16  iter: 1059  total_loss: 0.289  loss_cls: 0.050  loss_box_reg: 0.096  loss_mask: 0.078  loss_rpn_cls: 0.002  loss_rpn_loc: 0.055  time: 3.8444  data_time: 2.3613  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:54:08 d2.utils.events]: \u001b[0m eta: 0:59:08  iter: 1079  total_loss: 0.268  loss_cls: 0.047  loss_box_reg: 0.089  loss_mask: 0.078  loss_rpn_cls: 0.002  loss_rpn_loc: 0.052  time: 3.8497  data_time: 2.3666  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:55:29 d2.utils.events]: \u001b[0m eta: 0:57:58  iter: 1099  total_loss: 0.278  loss_cls: 0.047  loss_box_reg: 0.089  loss_mask: 0.079  loss_rpn_cls: 0.001  loss_rpn_loc: 0.050  time: 3.8536  data_time: 2.2910  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:56:48 d2.utils.events]: \u001b[0m eta: 0:56:45  iter: 1119  total_loss: 0.260  loss_cls: 0.043  loss_box_reg: 0.079  loss_mask: 0.077  loss_rpn_cls: 0.002  loss_rpn_loc: 0.053  time: 3.8554  data_time: 2.1934  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:58:05 d2.utils.events]: \u001b[0m eta: 0:55:30  iter: 1139  total_loss: 0.272  loss_cls: 0.046  loss_box_reg: 0.092  loss_mask: 0.077  loss_rpn_cls: 0.001  loss_rpn_loc: 0.056  time: 3.8549  data_time: 2.1338  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 18:59:21 d2.utils.events]: \u001b[0m eta: 0:54:16  iter: 1159  total_loss: 0.252  loss_cls: 0.042  loss_box_reg: 0.078  loss_mask: 0.076  loss_rpn_cls: 0.003  loss_rpn_loc: 0.055  time: 3.8538  data_time: 2.1070  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:00:37 d2.utils.events]: \u001b[0m eta: 0:53:00  iter: 1179  total_loss: 0.267  loss_cls: 0.040  loss_box_reg: 0.088  loss_mask: 0.074  loss_rpn_cls: 0.001  loss_rpn_loc: 0.055  time: 3.8534  data_time: 2.1339  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:02:07 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 19:02:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/07 19:02:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/07 19:02:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1440 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/07 19:02:25 d2.evaluation.evaluator]: \u001b[0mInference done 20/57. 0.1218 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/07 19:02:30 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.1133 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/07 19:02:35 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1119 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/07 19:02:41 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1108 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/07 19:02:46 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1165 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/07 19:02:51 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.1214 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/07 19:02:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.801508 (0.707721 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:02:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.121377 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:02:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 19:02:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 19:02:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.905\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.905\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.253\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.901\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.929\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.929\n",
            "\u001b[32m[07/07 19:02:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 90.496 | 99.958 | 99.958 |  nan  |  nan  | 90.496 |\n",
            "\u001b[32m[07/07 19:02:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:02:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 92.984 | brec_Cht         | 87.624 | lam_Sltst  | 92.608 |\n",
            "| skel_WkstPkst | 93.885 | strless_SltstSst | 85.379 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.901\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.901\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.892\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.919\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.919\n",
            "\u001b[32m[07/07 19:02:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 90.083 | 99.958 | 99.958 |  nan  |  nan  | 90.083 |\n",
            "\u001b[32m[07/07 19:02:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:02:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 91.832 | brec_Cht         | 86.906 | lam_Sltst  | 90.244 |\n",
            "| skel_WkstPkst | 92.169 | strless_SltstSst | 89.265 |            |        |\n",
            "\u001b[32m[07/07 19:02:52 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/07 19:02:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 19:02:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:02:52 d2.evaluation.testing]: \u001b[0mcopypaste: 90.4958,99.9578,99.9578,nan,nan,90.4958\n",
            "\u001b[32m[07/07 19:02:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 19:02:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:02:52 d2.evaluation.testing]: \u001b[0mcopypaste: 90.0830,99.9578,99.9578,nan,nan,90.0830\n",
            "\u001b[32m[07/07 19:02:55 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 19:02:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/07 19:02:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/07 19:03:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1311 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.550307 (1.061145 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.164780 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.240\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.490\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 23.969 | 39.964 | 24.798 |  nan  |  nan  | 23.969 |\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 24.070 | brec_Cht         | 50.773 | lam_Sltst  | 11.647 |\n",
            "| skel_WkstPkst | 9.861  | strless_SltstSst | 23.492 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.394\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.492\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.514\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.504 | 39.445 | 25.152 |  nan  |  nan  | 25.504 |\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 23.685 | brec_Cht         | 55.362 | lam_Sltst  | 11.348 |\n",
            "| skel_WkstPkst | 10.388 | strless_SltstSst | 26.739 |            |        |\n",
            "\u001b[32m[07/07 19:03:14 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.testing]: \u001b[0mcopypaste: 23.9688,39.9645,24.7979,nan,nan,23.9688\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:03:14 d2.evaluation.testing]: \u001b[0mcopypaste: 25.5044,39.4449,25.1523,nan,nan,25.5044\n",
            "\u001b[32m[07/07 19:03:14 d2.utils.events]: \u001b[0m eta: 0:51:45  iter: 1199  total_loss: 0.259  loss_cls: 0.043  loss_box_reg: 0.085  loss_mask: 0.074  loss_rpn_cls: 0.002  loss_rpn_loc: 0.052  time: 3.8535  data_time: 2.1109  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:04:34 d2.utils.events]: \u001b[0m eta: 0:50:28  iter: 1219  total_loss: 0.257  loss_cls: 0.045  loss_box_reg: 0.083  loss_mask: 0.075  loss_rpn_cls: 0.002  loss_rpn_loc: 0.050  time: 3.8557  data_time: 2.2288  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:05:55 d2.utils.events]: \u001b[0m eta: 0:49:16  iter: 1239  total_loss: 0.252  loss_cls: 0.042  loss_box_reg: 0.080  loss_mask: 0.075  loss_rpn_cls: 0.002  loss_rpn_loc: 0.050  time: 3.8590  data_time: 2.3049  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:07:16 d2.utils.events]: \u001b[0m eta: 0:48:03  iter: 1259  total_loss: 0.233  loss_cls: 0.037  loss_box_reg: 0.076  loss_mask: 0.073  loss_rpn_cls: 0.002  loss_rpn_loc: 0.046  time: 3.8618  data_time: 2.2625  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:08:36 d2.utils.events]: \u001b[0m eta: 0:46:51  iter: 1279  total_loss: 0.229  loss_cls: 0.038  loss_box_reg: 0.075  loss_mask: 0.073  loss_rpn_cls: 0.001  loss_rpn_loc: 0.040  time: 3.8644  data_time: 2.2836  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:09:55 d2.utils.events]: \u001b[0m eta: 0:45:38  iter: 1299  total_loss: 0.220  loss_cls: 0.035  loss_box_reg: 0.069  loss_mask: 0.071  loss_rpn_cls: 0.002  loss_rpn_loc: 0.043  time: 3.8652  data_time: 2.1890  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:11:13 d2.utils.events]: \u001b[0m eta: 0:44:22  iter: 1319  total_loss: 0.224  loss_cls: 0.036  loss_box_reg: 0.070  loss_mask: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.042  time: 3.8658  data_time: 2.1556  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:12:30 d2.utils.events]: \u001b[0m eta: 0:43:04  iter: 1339  total_loss: 0.212  loss_cls: 0.032  loss_box_reg: 0.067  loss_mask: 0.070  loss_rpn_cls: 0.002  loss_rpn_loc: 0.042  time: 3.8654  data_time: 2.0851  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:13:48 d2.utils.events]: \u001b[0m eta: 0:41:50  iter: 1359  total_loss: 0.214  loss_cls: 0.032  loss_box_reg: 0.066  loss_mask: 0.072  loss_rpn_cls: 0.002  loss_rpn_loc: 0.040  time: 3.8660  data_time: 2.1454  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:15:05 d2.utils.events]: \u001b[0m eta: 0:40:34  iter: 1379  total_loss: 0.213  loss_cls: 0.032  loss_box_reg: 0.063  loss_mask: 0.070  loss_rpn_cls: 0.001  loss_rpn_loc: 0.039  time: 3.8659  data_time: 2.1340  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:16:34 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 19:16:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/07 19:16:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/07 19:16:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1420 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/07 19:16:51 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1226 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/07 19:16:57 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1203 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/07 19:17:02 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1186 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/07 19:17:07 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1187 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/07 19:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1234 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.725367 (0.648565 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.125070 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.949\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.949\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.259\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.938\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.966\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.966\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 94.911 | 99.947 | 99.947 |  nan  |  nan  | 94.911 |\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP      | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:--------|:-----------|:-------|\n",
            "| bio_Sltst     | 94.111 | brec_Cht         | 100.000 | lam_Sltst  | 93.758 |\n",
            "| skel_WkstPkst | 92.687 | strless_SltstSst | 94.001  |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.910\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.910\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.251\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.902\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.929\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.929\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 90.978 | 99.947 | 99.947 |  nan  |  nan  | 90.978 |\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 91.864 | brec_Cht         | 90.000 | lam_Sltst  | 89.458 |\n",
            "| skel_WkstPkst | 92.342 | strless_SltstSst | 91.225 |            |        |\n",
            "\u001b[32m[07/07 19:17:15 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.testing]: \u001b[0mcopypaste: 94.9113,99.9466,99.9466,nan,nan,94.9113\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:17:15 d2.evaluation.testing]: \u001b[0mcopypaste: 90.9779,99.9466,99.9466,nan,nan,90.9779\n",
            "\u001b[32m[07/07 19:17:18 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 19:17:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/07 19:17:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/07 19:17:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1230 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 19:17:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.467439 (0.940827 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:17:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.154930 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:17:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 19:17:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 19:17:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.434\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n",
            "\u001b[32m[07/07 19:17:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 27.046 | 43.409 | 28.593 |  nan  |  nan  | 27.046 |\n",
            "\u001b[32m[07/07 19:17:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:17:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 25.188 | brec_Cht         | 56.395 | lam_Sltst  | 12.423 |\n",
            "| skel_WkstPkst | 15.754 | strless_SltstSst | 25.468 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.432\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.503\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.521\n",
            "\u001b[32m[07/07 19:17:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.580 | 43.154 | 30.153 |  nan  |  nan  | 28.580 |\n",
            "\u001b[32m[07/07 19:17:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:17:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 25.470 | brec_Cht         | 59.709 | lam_Sltst  | 12.147 |\n",
            "| skel_WkstPkst | 17.827 | strless_SltstSst | 27.750 |            |        |\n",
            "\u001b[32m[07/07 19:17:36 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/07 19:17:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 19:17:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:17:36 d2.evaluation.testing]: \u001b[0mcopypaste: 27.0455,43.4092,28.5930,nan,nan,27.0455\n",
            "\u001b[32m[07/07 19:17:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 19:17:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:17:36 d2.evaluation.testing]: \u001b[0mcopypaste: 28.5805,43.1545,30.1527,nan,nan,28.5805\n",
            "\u001b[32m[07/07 19:17:36 d2.utils.events]: \u001b[0m eta: 0:39:20  iter: 1399  total_loss: 0.219  loss_cls: 0.032  loss_box_reg: 0.066  loss_mask: 0.070  loss_rpn_cls: 0.001  loss_rpn_loc: 0.037  time: 3.8659  data_time: 2.1881  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:18:51 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 1419  total_loss: 0.213  loss_cls: 0.032  loss_box_reg: 0.069  loss_mask: 0.069  loss_rpn_cls: 0.002  loss_rpn_loc: 0.039  time: 3.8643  data_time: 2.0120  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:20:06 d2.utils.events]: \u001b[0m eta: 0:36:43  iter: 1439  total_loss: 0.219  loss_cls: 0.033  loss_box_reg: 0.070  loss_mask: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.041  time: 3.8627  data_time: 2.0026  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:21:20 d2.utils.events]: \u001b[0m eta: 0:35:21  iter: 1459  total_loss: 0.221  loss_cls: 0.033  loss_box_reg: 0.066  loss_mask: 0.071  loss_rpn_cls: 0.001  loss_rpn_loc: 0.043  time: 3.8608  data_time: 1.9980  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:22:35 d2.utils.events]: \u001b[0m eta: 0:34:05  iter: 1479  total_loss: 0.203  loss_cls: 0.031  loss_box_reg: 0.065  loss_mask: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.039  time: 3.8593  data_time: 1.9863  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:23:50 d2.utils.events]: \u001b[0m eta: 0:32:47  iter: 1499  total_loss: 0.197  loss_cls: 0.028  loss_box_reg: 0.063  loss_mask: 0.069  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.8574  data_time: 1.9956  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:25:05 d2.utils.events]: \u001b[0m eta: 0:31:30  iter: 1519  total_loss: 0.194  loss_cls: 0.029  loss_box_reg: 0.063  loss_mask: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.036  time: 3.8561  data_time: 2.0316  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:26:19 d2.utils.events]: \u001b[0m eta: 0:30:08  iter: 1539  total_loss: 0.198  loss_cls: 0.029  loss_box_reg: 0.068  loss_mask: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.8539  data_time: 1.9942  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:27:33 d2.utils.events]: \u001b[0m eta: 0:28:48  iter: 1559  total_loss: 0.208  loss_cls: 0.029  loss_box_reg: 0.073  loss_mask: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.8524  data_time: 1.9887  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:28:48 d2.utils.events]: \u001b[0m eta: 0:27:27  iter: 1579  total_loss: 0.203  loss_cls: 0.031  loss_box_reg: 0.066  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.8507  data_time: 1.9905  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:30:13 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 19:30:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/07 19:30:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/07 19:30:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1340 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/07 19:30:29 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1170 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/07 19:30:35 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.1145 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/07 19:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.1132 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/07 19:30:46 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1147 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/07 19:30:51 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1199 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/07 19:30:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:31.747554 (0.610530 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:30:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.119758 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:30:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 19:30:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 19:30:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.959\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.959\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.944\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.973\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.973\n",
            "\u001b[32m[07/07 19:30:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 95.942 | 99.974 | 99.974 |  nan  |  nan  | 95.942 |\n",
            "\u001b[32m[07/07 19:30:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:30:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 96.333 | brec_Cht         | 96.287 | lam_Sltst  | 97.119 |\n",
            "| skel_WkstPkst | 98.394 | strless_SltstSst | 91.574 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.923\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.923\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.252\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.912\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.940\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.940\n",
            "\u001b[32m[07/07 19:30:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 92.260 | 99.974 | 99.974 |  nan  |  nan  | 92.260 |\n",
            "\u001b[32m[07/07 19:30:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:30:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 93.464 | brec_Cht         | 90.000 | lam_Sltst  | 92.359 |\n",
            "| skel_WkstPkst | 93.687 | strless_SltstSst | 91.789 |            |        |\n",
            "\u001b[32m[07/07 19:30:52 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/07 19:30:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 19:30:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:30:52 d2.evaluation.testing]: \u001b[0mcopypaste: 95.9416,99.9739,99.9739,nan,nan,95.9416\n",
            "\u001b[32m[07/07 19:30:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 19:30:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:30:52 d2.evaluation.testing]: \u001b[0mcopypaste: 92.2598,99.9739,99.9739,nan,nan,92.2598\n",
            "\u001b[32m[07/07 19:30:55 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 19:30:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/07 19:30:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/07 19:31:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1228 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.055754 (0.895084 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.149876 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.419\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.079\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.484\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.988 | 41.931 | 26.288 |  nan  |  nan  | 25.988 |\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 24.878 | brec_Cht         | 53.328 | lam_Sltst  | 12.706 |\n",
            "| skel_WkstPkst | 14.768 | strless_SltstSst | 24.262 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.276\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.427\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.503\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.503\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 27.551 | 42.674 | 27.234 |  nan  |  nan  | 27.551 |\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 24.713 | brec_Cht         | 56.644 | lam_Sltst  | 12.759 |\n",
            "| skel_WkstPkst | 15.704 | strless_SltstSst | 27.937 |            |        |\n",
            "\u001b[32m[07/07 19:31:11 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.testing]: \u001b[0mcopypaste: 25.9884,41.9313,26.2883,nan,nan,25.9884\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:31:11 d2.evaluation.testing]: \u001b[0mcopypaste: 27.5515,42.6739,27.2337,nan,nan,27.5515\n",
            "\u001b[32m[07/07 19:31:11 d2.utils.events]: \u001b[0m eta: 0:26:07  iter: 1599  total_loss: 0.197  loss_cls: 0.029  loss_box_reg: 0.063  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.8488  data_time: 1.9534  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:32:26 d2.utils.events]: \u001b[0m eta: 0:24:47  iter: 1619  total_loss: 0.186  loss_cls: 0.026  loss_box_reg: 0.056  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.037  time: 3.8471  data_time: 2.0016  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:33:40 d2.utils.events]: \u001b[0m eta: 0:23:28  iter: 1639  total_loss: 0.185  loss_cls: 0.029  loss_box_reg: 0.061  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 3.8458  data_time: 2.0297  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:34:55 d2.utils.events]: \u001b[0m eta: 0:22:08  iter: 1659  total_loss: 0.201  loss_cls: 0.030  loss_box_reg: 0.068  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.039  time: 3.8444  data_time: 2.0067  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:36:09 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 1679  total_loss: 0.212  loss_cls: 0.029  loss_box_reg: 0.069  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.043  time: 3.8429  data_time: 1.9899  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:37:24 d2.utils.events]: \u001b[0m eta: 0:19:30  iter: 1699  total_loss: 0.192  loss_cls: 0.028  loss_box_reg: 0.063  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.036  time: 3.8414  data_time: 1.9912  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:38:39 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 1719  total_loss: 0.201  loss_cls: 0.029  loss_box_reg: 0.064  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.039  time: 3.8402  data_time: 2.0024  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:39:54 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 1739  total_loss: 0.192  loss_cls: 0.027  loss_box_reg: 0.062  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.033  time: 3.8392  data_time: 2.0360  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:41:08 d2.utils.events]: \u001b[0m eta: 0:15:33  iter: 1759  total_loss: 0.193  loss_cls: 0.027  loss_box_reg: 0.061  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.036  time: 3.8378  data_time: 1.9755  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:42:22 d2.utils.events]: \u001b[0m eta: 0:14:16  iter: 1779  total_loss: 0.204  loss_cls: 0.028  loss_box_reg: 0.067  loss_mask: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.036  time: 3.8365  data_time: 1.9929  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:43:48 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 19:43:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/07 19:43:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/07 19:43:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1355 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/07 19:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1174 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/07 19:44:10 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.1111 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/07 19:44:15 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1094 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/07 19:44:20 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1117 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/07 19:44:26 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1180 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/07 19:44:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.285718 (0.620879 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:44:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.117929 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:44:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 19:44:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 19:44:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.952\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.952\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.940\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.969\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.969\n",
            "\u001b[32m[07/07 19:44:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 95.241 | 99.990 | 99.990 |  nan  |  nan  | 95.241 |\n",
            "\u001b[32m[07/07 19:44:27 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:44:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 94.260 | brec_Cht         | 95.644 | lam_Sltst  | 91.237 |\n",
            "| skel_WkstPkst | 98.350 | strless_SltstSst | 96.715 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.929\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.929\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.916\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.944\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.944\n",
            "\u001b[32m[07/07 19:44:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 92.892 | 99.990 | 99.990 |  nan  |  nan  | 92.892 |\n",
            "\u001b[32m[07/07 19:44:27 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:44:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 94.169 | brec_Cht         | 90.000 | lam_Sltst  | 91.206 |\n",
            "| skel_WkstPkst | 96.022 | strless_SltstSst | 93.064 |            |        |\n",
            "\u001b[32m[07/07 19:44:27 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/07 19:44:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 19:44:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:44:27 d2.evaluation.testing]: \u001b[0mcopypaste: 95.2411,99.9898,99.9898,nan,nan,95.2411\n",
            "\u001b[32m[07/07 19:44:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 19:44:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:44:27 d2.evaluation.testing]: \u001b[0mcopypaste: 92.8922,99.9898,99.9898,nan,nan,92.8922\n",
            "\u001b[32m[07/07 19:44:30 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 19:44:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/07 19:44:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/07 19:44:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1278 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.332185 (0.925798 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.154055 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.254\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.408\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.250\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.404 | 40.800 | 24.965 |  nan  |  nan  | 25.404 |\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 26.716 | brec_Cht         | 50.265 | lam_Sltst  | 13.210 |\n",
            "| skel_WkstPkst | 12.782 | strless_SltstSst | 24.045 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.413\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 26.996 | 41.336 | 26.939 |  nan  |  nan  | 26.996 |\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 26.814 | brec_Cht         | 53.862 | lam_Sltst  | 14.195 |\n",
            "| skel_WkstPkst | 13.653 | strless_SltstSst | 26.458 |            |        |\n",
            "\u001b[32m[07/07 19:44:47 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.testing]: \u001b[0mcopypaste: 25.4037,40.8003,24.9654,nan,nan,25.4037\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:44:47 d2.evaluation.testing]: \u001b[0mcopypaste: 26.9962,41.3361,26.9393,nan,nan,26.9962\n",
            "\u001b[32m[07/07 19:44:47 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 1799  total_loss: 0.183  loss_cls: 0.027  loss_box_reg: 0.055  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.033  time: 3.8351  data_time: 2.0075  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:46:01 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 1819  total_loss: 0.176  loss_cls: 0.025  loss_box_reg: 0.054  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.035  time: 3.8338  data_time: 2.0162  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:47:16 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 1839  total_loss: 0.180  loss_cls: 0.024  loss_box_reg: 0.056  loss_mask: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.032  time: 3.8324  data_time: 1.9970  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:48:31 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 1859  total_loss: 0.185  loss_cls: 0.025  loss_box_reg: 0.053  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.039  time: 3.8315  data_time: 1.9735  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:49:45 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 1879  total_loss: 0.182  loss_cls: 0.027  loss_box_reg: 0.058  loss_mask: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.037  time: 3.8305  data_time: 2.0180  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:51:00 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 1899  total_loss: 0.168  loss_cls: 0.024  loss_box_reg: 0.050  loss_mask: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.029  time: 3.8292  data_time: 1.9855  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:52:14 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 1919  total_loss: 0.168  loss_cls: 0.024  loss_box_reg: 0.054  loss_mask: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 3.8281  data_time: 2.0067  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:53:29 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 1939  total_loss: 0.176  loss_cls: 0.024  loss_box_reg: 0.055  loss_mask: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 3.8270  data_time: 1.9822  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:54:45 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 1959  total_loss: 0.175  loss_cls: 0.022  loss_box_reg: 0.051  loss_mask: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.033  time: 3.8270  data_time: 2.0786  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:56:01 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 1979  total_loss: 0.164  loss_cls: 0.021  loss_box_reg: 0.050  loss_mask: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 3.8267  data_time: 2.0581  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:57:31 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 19:57:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/07 19:57:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/07 19:57:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1366 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/07 19:57:47 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1142 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/07 19:57:52 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.1104 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/07 19:57:57 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1107 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/07 19:58:03 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1115 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/07 19:58:08 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1168 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.061612 (0.616569 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.116920 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.974\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.974\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.264\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.954\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.984\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.984\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 97.425 | 99.983 | 99.983 |  nan  |  nan  | 97.425 |\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP      | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:--------|:-----------|:-------|\n",
            "| bio_Sltst     | 96.750 | brec_Cht         | 100.000 | lam_Sltst  | 96.816 |\n",
            "| skel_WkstPkst | 96.518 | strless_SltstSst | 97.042  |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.939\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.939\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.929\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.957\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.957\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 93.872 | 99.983 | 99.983 |  nan  |  nan  | 93.872 |\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 94.863 | brec_Cht         | 90.644 | lam_Sltst  | 93.995 |\n",
            "| skel_WkstPkst | 96.116 | strless_SltstSst | 93.743 |            |        |\n",
            "\u001b[32m[07/07 19:58:09 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_train in csv format:\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.testing]: \u001b[0mcopypaste: 97.4254,99.9830,99.9830,nan,nan,97.4254\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:58:09 d2.evaluation.testing]: \u001b[0mcopypaste: 93.8721,99.9830,99.9830,nan,nan,93.8721\n",
            "\u001b[32m[07/07 19:58:13 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 19:58:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/07 19:58:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/07 19:58:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1243 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.127381 (0.903042 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.151516 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.447\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.259\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 26.332 | 44.703 | 25.877 |  nan  |  nan  | 26.332 |\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 23.812 | brec_Cht         | 48.213 | lam_Sltst  | 18.264 |\n",
            "| skel_WkstPkst | 14.608 | strless_SltstSst | 26.760 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.282\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.445\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.174 | 44.462 | 28.345 |  nan  |  nan  | 28.174 |\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 24.480 | brec_Cht         | 52.264 | lam_Sltst  | 18.192 |\n",
            "| skel_WkstPkst | 16.018 | strless_SltstSst | 29.917 |            |        |\n",
            "\u001b[32m[07/07 19:58:29 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_1_val in csv format:\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.testing]: \u001b[0mcopypaste: 26.3318,44.7033,25.8768,nan,nan,26.3318\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/07 19:58:29 d2.evaluation.testing]: \u001b[0mcopypaste: 28.1741,44.4622,28.3450,nan,nan,28.1741\n",
            "\u001b[32m[07/07 19:58:29 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 1999  total_loss: 0.168  loss_cls: 0.023  loss_box_reg: 0.054  loss_mask: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.033  time: 3.8267  data_time: 2.0949  lr: 0.001000  max_mem: 9382M\n",
            "\u001b[32m[07/07 19:58:29 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 2:07:25 (3.8287 s / it)\n",
            "\u001b[32m[07/07 19:58:29 d2.engine.hooks]: \u001b[0mTotal training time: 2:30:28 (0:23:02 on hooks)\n",
            "\n",
            "\n",
            "**Starting train eval**\n",
            "\u001b[32m[07/07 19:58:42 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 19:58:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/07 19:58:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/07 19:58:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1433 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/07 19:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1235 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/07 19:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1138 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/07 19:59:13 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1109 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/07 19:59:18 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.1081 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/07 19:59:23 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1105 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/07 19:59:29 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1138 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/07 19:59:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.539179 (0.856523 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:59:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.116587 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 19:59:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 19:59:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/07 19:59:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.974\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.974\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.264\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.954\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.984\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.984\n",
            "\u001b[32m[07/07 19:59:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 97.425 | 99.983 | 99.983 |  nan  |  nan  | 97.425 |\n",
            "\u001b[32m[07/07 19:59:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:59:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP      | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:--------|:-----------|:-------|\n",
            "| bio_Sltst     | 96.750 | brec_Cht         | 100.000 | lam_Sltst  | 96.816 |\n",
            "| skel_WkstPkst | 96.518 | strless_SltstSst | 97.042  |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.939\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.939\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.929\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.957\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.957\n",
            "\u001b[32m[07/07 19:59:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 93.872 | 99.983 | 99.983 |  nan  |  nan  | 93.872 |\n",
            "\u001b[32m[07/07 19:59:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 19:59:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 94.863 | brec_Cht         | 90.644 | lam_Sltst  | 93.995 |\n",
            "| skel_WkstPkst | 96.116 | strless_SltstSst | 93.743 |            |        |\n",
            "randomly selected cores/Box 7 Depths 10025-35.JPG\n",
            "\n",
            "\n",
            "**Starting val eval**\n",
            "\u001b[32m[07/07 20:00:19 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/07 20:00:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/07 20:00:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/07 20:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1324 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/07 20:00:48 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1596 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/07 20:00:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.916573 (1.768508 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 20:00:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.168764 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/07 20:00:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/07 20:00:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/07 20:00:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.447\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.259\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n",
            "\u001b[32m[07/07 20:00:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 26.332 | 44.703 | 25.877 |  nan  |  nan  | 26.332 |\n",
            "\u001b[32m[07/07 20:00:50 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 20:00:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 23.812 | brec_Cht         | 48.213 | lam_Sltst  | 18.264 |\n",
            "| skel_WkstPkst | 14.608 | strless_SltstSst | 26.760 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.282\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.445\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            "\u001b[32m[07/07 20:00:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.174 | 44.462 | 28.345 |  nan  |  nan  | 28.174 |\n",
            "\u001b[32m[07/07 20:00:50 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/07 20:00:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 24.480 | brec_Cht         | 52.264 | lam_Sltst  | 18.192 |\n",
            "| skel_WkstPkst | 16.018 | strless_SltstSst | 29.917 |            |        |\n",
            "randomly selected cores/Boxes 76-78  Depths 7929.1-7938.7 (Dry).JPG\n",
            "Tue Jul  7 20:01:21 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    39W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "CPU times: user 16.5 s, sys: 1.97 s, total: 18.5 s\n",
            "Wall time: 2h 33min 52s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0chfOFVBLbj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75d24761-680b-4600-c15e-3975d626bca6"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '2' --max_iter 2000\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 2\n",
            "\t cores_fold_2_train\n",
            "\t cores_fold_2_val\n",
            "\u001b[32m[07/08 11:49:27 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/08 11:49:43 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 57 images left.\n",
            "\u001b[32m[07/08 11:49:43 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 261          |   brec_Cht    | 21           | lam_Sltst  | 103          |\n",
            "| skel_WkstPkst | 24           | strless_Slt.. | 142          |            |              |\n",
            "|     total     | 551          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/08 11:49:43 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 11:49:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 11:49:43 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/08 11:49:43 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-08 11:49:44.193156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "model_final_f10217.pkl: 178MB [00:16, 10.5MB/s]               \n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/08 11:50:08 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/08 11:51:46 d2.utils.events]: \u001b[0m eta: 2:39:07  iter: 19  total_loss: 3.516  loss_cls: 1.818  loss_box_reg: 0.355  loss_mask: 0.691  loss_rpn_cls: 0.470  loss_rpn_loc: 0.223  time: 4.8154  data_time: 2.0741  lr: 0.000020  max_mem: 8437M\n",
            "\u001b[32m[07/08 11:53:23 d2.utils.events]: \u001b[0m eta: 2:37:30  iter: 39  total_loss: 2.652  loss_cls: 1.232  loss_box_reg: 0.421  loss_mask: 0.668  loss_rpn_cls: 0.189  loss_rpn_loc: 0.175  time: 4.8375  data_time: 1.9234  lr: 0.000040  max_mem: 8437M\n",
            "\u001b[32m[07/08 11:55:01 d2.utils.events]: \u001b[0m eta: 2:37:07  iter: 59  total_loss: 2.124  loss_cls: 0.714  loss_box_reg: 0.492  loss_mask: 0.616  loss_rpn_cls: 0.093  loss_rpn_loc: 0.147  time: 4.8493  data_time: 1.8925  lr: 0.000060  max_mem: 8516M\n",
            "\u001b[32m[07/08 11:56:40 d2.utils.events]: \u001b[0m eta: 2:36:26  iter: 79  total_loss: 1.928  loss_cls: 0.618  loss_box_reg: 0.554  loss_mask: 0.546  loss_rpn_cls: 0.048  loss_rpn_loc: 0.146  time: 4.8869  data_time: 1.9766  lr: 0.000080  max_mem: 8516M\n",
            "\u001b[32m[07/08 11:58:20 d2.utils.events]: \u001b[0m eta: 2:35:43  iter: 99  total_loss: 1.825  loss_cls: 0.595  loss_box_reg: 0.556  loss_mask: 0.477  loss_rpn_cls: 0.041  loss_rpn_loc: 0.132  time: 4.9029  data_time: 1.8766  lr: 0.000100  max_mem: 8516M\n",
            "\u001b[32m[07/08 11:59:59 d2.utils.events]: \u001b[0m eta: 2:34:22  iter: 119  total_loss: 1.738  loss_cls: 0.573  loss_box_reg: 0.557  loss_mask: 0.428  loss_rpn_cls: 0.032  loss_rpn_loc: 0.131  time: 4.9138  data_time: 1.8753  lr: 0.000120  max_mem: 8516M\n",
            "\u001b[32m[07/08 12:01:40 d2.utils.events]: \u001b[0m eta: 2:33:07  iter: 139  total_loss: 1.705  loss_cls: 0.568  loss_box_reg: 0.581  loss_mask: 0.392  loss_rpn_cls: 0.031  loss_rpn_loc: 0.123  time: 4.9353  data_time: 1.8883  lr: 0.000140  max_mem: 8591M\n",
            "\u001b[32m[07/08 12:03:21 d2.utils.events]: \u001b[0m eta: 2:31:34  iter: 159  total_loss: 1.650  loss_cls: 0.540  loss_box_reg: 0.569  loss_mask: 0.376  loss_rpn_cls: 0.029  loss_rpn_loc: 0.126  time: 4.9454  data_time: 1.8369  lr: 0.000160  max_mem: 8761M\n",
            "\u001b[32m[07/08 12:05:02 d2.utils.events]: \u001b[0m eta: 2:30:18  iter: 179  total_loss: 1.602  loss_cls: 0.523  loss_box_reg: 0.579  loss_mask: 0.352  loss_rpn_cls: 0.029  loss_rpn_loc: 0.120  time: 4.9596  data_time: 1.8686  lr: 0.000180  max_mem: 8761M\n",
            "\u001b[32m[07/08 12:07:01 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 12:07:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/08 12:07:01 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_2_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/08 12:07:01 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_2_train' to COCO format ...)\n",
            "\u001b[32m[07/08 12:07:17 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/08 12:07:17 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 57, #annotations: 551\n",
            "\u001b[32m[07/08 12:07:17 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_2_train_coco_format.json' ...\n",
            "\u001b[32m[07/08 12:07:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0x6e6ec000 @  0x7fe846184b6b 0x7fe8461a4379 0x7fe7e98d904e 0x7fe7e98daf4a 0x7fe8227c967b 0x7fe8224186be 0x7fe8226817b5 0x7fe8226737c1 0x7fe822672d0e 0x7fe8226737c1 0x7fe8240c893a 0x7fe8226737c1 0x7fe822413457 0x7fe822414080 0x7fe82273271a 0x7fe8241b013e 0x7fe822673c72 0x7fe83070da68 0x7fe8307c8b04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/08 12:09:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.9264 s / img. ETA=0:07:07\n",
            "\u001b[32m[07/08 12:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 12/57. 0.9230 s / img. ETA=0:06:58\n",
            "\u001b[32m[07/08 12:09:21 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.9391 s / img. ETA=0:06:50\n",
            "\u001b[32m[07/08 12:09:31 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.9358 s / img. ETA=0:06:41\n",
            "\u001b[32m[07/08 12:09:40 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.9342 s / img. ETA=0:06:33\n",
            "\u001b[32m[07/08 12:09:49 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.8858 s / img. ETA=0:05:41\n",
            "\u001b[32m[07/08 12:09:58 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.8547 s / img. ETA=0:05:02\n",
            "\u001b[32m[07/08 12:10:07 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.8352 s / img. ETA=0:04:30\n",
            "\u001b[32m[07/08 12:10:15 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.8075 s / img. ETA=0:04:01\n",
            "\u001b[32m[07/08 12:10:23 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.7939 s / img. ETA=0:03:38\n",
            "\u001b[32m[07/08 12:10:32 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.7823 s / img. ETA=0:03:18\n",
            "\u001b[32m[07/08 12:10:41 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.7695 s / img. ETA=0:02:59\n",
            "\u001b[32m[07/08 12:10:50 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.7659 s / img. ETA=0:02:43\n",
            "\u001b[32m[07/08 12:10:59 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.7587 s / img. ETA=0:02:27\n",
            "\u001b[32m[07/08 12:11:07 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.7521 s / img. ETA=0:02:12\n",
            "\u001b[32m[07/08 12:11:16 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.7464 s / img. ETA=0:01:58\n",
            "\u001b[32m[07/08 12:11:25 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.7411 s / img. ETA=0:01:45\n",
            "\u001b[32m[07/08 12:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.7383 s / img. ETA=0:01:32\n",
            "\u001b[32m[07/08 12:11:46 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.7399 s / img. ETA=0:01:20\n",
            "\u001b[32m[07/08 12:11:54 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.7432 s / img. ETA=0:01:15\n",
            "\u001b[32m[07/08 12:12:02 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.7466 s / img. ETA=0:01:10\n",
            "\u001b[32m[07/08 12:12:09 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.7498 s / img. ETA=0:01:05\n",
            "\u001b[32m[07/08 12:12:17 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.7527 s / img. ETA=0:00:59\n",
            "\u001b[32m[07/08 12:12:25 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.7582 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/08 12:12:32 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.7603 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/08 12:12:40 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.7623 s / img. ETA=0:00:42\n",
            "\u001b[32m[07/08 12:12:47 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.7642 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/08 12:12:55 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.7659 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/08 12:13:02 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.7677 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/08 12:13:10 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.7721 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/08 12:13:18 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.7736 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/08 12:13:25 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.7750 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/08 12:13:32 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.7766 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/08 12:13:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:25.863034 (6.266597 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 12:13:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.776565 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 12:13:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 12:13:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 12:13:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.71s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.056\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.047\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.188\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.276\n",
            "\u001b[32m[07/08 12:13:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.641 | 11.498 | 4.681  |  nan  |  nan  | 5.641 |\n",
            "\u001b[32m[07/08 12:13:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 12:13:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 15.496 | brec_Cht         | 0.000 | lam_Sltst  | 3.020 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 9.690 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.93s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.059\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.056\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.191\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.280\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.280\n",
            "\u001b[32m[07/08 12:13:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.894 | 11.196 | 5.631  |  nan  |  nan  | 5.894 |\n",
            "\u001b[32m[07/08 12:13:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 12:13:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 17.643 | brec_Cht         | 0.000 | lam_Sltst  | 2.789 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 9.037 |            |       |\n",
            "\u001b[32m[07/08 12:13:35 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/08 12:13:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 12:13:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 12:13:35 d2.evaluation.testing]: \u001b[0mcopypaste: 5.6413,11.4975,4.6806,nan,nan,5.6413\n",
            "\u001b[32m[07/08 12:13:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 12:13:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 12:13:35 d2.evaluation.testing]: \u001b[0mcopypaste: 5.8938,11.1958,5.6313,nan,nan,5.8938\n",
            "\u001b[32m[07/08 12:13:39 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 48           |   brec_Cht    | 0            | lam_Sltst  | 24           |\n",
            "| skel_WkstPkst | 2            | strless_Slt.. | 31           |            |              |\n",
            "|     total     | 105          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/08 12:13:39 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 12:13:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/08 12:13:39 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_2_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/08 12:13:39 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_2_val' to COCO format ...)\n",
            "\u001b[32m[07/08 12:13:42 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/08 12:13:42 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 14, #annotations: 105\n",
            "\u001b[32m[07/08 12:13:42 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_2_val_coco_format.json' ...\n",
            "\u001b[32m[07/08 12:13:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 12:14:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.6454 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/08 12:14:56 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.6528 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.6742 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.585132 (4.731681 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.674225 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.113\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.050\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.195\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.332\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 4.955 | 11.286 | 2.357  |  nan  |  nan  | 4.955 |\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 11.246 | brec_Cht         | nan   | lam_Sltst  | 3.569 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 5.003 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.22s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.113\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.041\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.054\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.199\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.389 | 11.253 | 4.103  |  nan  |  nan  | 5.389 |\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 13.613 | brec_Cht         | nan   | lam_Sltst  | 3.556 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 4.388 |            |       |\n",
            "\u001b[32m[07/08 12:15:04 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.testing]: \u001b[0mcopypaste: 4.9546,11.2856,2.3569,nan,nan,4.9547\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 12:15:04 d2.evaluation.testing]: \u001b[0mcopypaste: 5.3894,11.2532,4.1033,nan,nan,5.3894\n",
            "\u001b[32m[07/08 12:15:04 d2.utils.events]: \u001b[0m eta: 2:29:09  iter: 199  total_loss: 1.551  loss_cls: 0.505  loss_box_reg: 0.565  loss_mask: 0.335  loss_rpn_cls: 0.027  loss_rpn_loc: 0.115  time: 4.9767  data_time: 1.9024  lr: 0.000200  max_mem: 8988M\n",
            "\u001b[32m[07/08 12:16:46 d2.utils.events]: \u001b[0m eta: 2:27:51  iter: 219  total_loss: 1.514  loss_cls: 0.503  loss_box_reg: 0.552  loss_mask: 0.307  loss_rpn_cls: 0.020  loss_rpn_loc: 0.114  time: 4.9866  data_time: 1.8656  lr: 0.000220  max_mem: 8988M\n",
            "\u001b[32m[07/08 12:18:29 d2.utils.events]: \u001b[0m eta: 2:26:29  iter: 239  total_loss: 1.449  loss_cls: 0.496  loss_box_reg: 0.526  loss_mask: 0.286  loss_rpn_cls: 0.025  loss_rpn_loc: 0.111  time: 5.0014  data_time: 1.9031  lr: 0.000240  max_mem: 8988M\n",
            "\u001b[32m[07/08 12:20:14 d2.utils.events]: \u001b[0m eta: 2:25:25  iter: 259  total_loss: 1.387  loss_cls: 0.480  loss_box_reg: 0.499  loss_mask: 0.263  loss_rpn_cls: 0.021  loss_rpn_loc: 0.107  time: 5.0183  data_time: 1.9453  lr: 0.000260  max_mem: 8988M\n",
            "\u001b[32m[07/08 12:21:57 d2.utils.events]: \u001b[0m eta: 2:24:15  iter: 279  total_loss: 1.268  loss_cls: 0.453  loss_box_reg: 0.436  loss_mask: 0.254  loss_rpn_cls: 0.019  loss_rpn_loc: 0.106  time: 5.0297  data_time: 1.9025  lr: 0.000280  max_mem: 9185M\n",
            "\u001b[32m[07/08 12:23:42 d2.utils.events]: \u001b[0m eta: 2:23:04  iter: 299  total_loss: 1.244  loss_cls: 0.481  loss_box_reg: 0.419  loss_mask: 0.231  loss_rpn_cls: 0.018  loss_rpn_loc: 0.101  time: 5.0433  data_time: 1.8680  lr: 0.000300  max_mem: 9185M\n",
            "\u001b[32m[07/08 12:25:26 d2.utils.events]: \u001b[0m eta: 2:21:40  iter: 319  total_loss: 1.136  loss_cls: 0.442  loss_box_reg: 0.363  loss_mask: 0.211  loss_rpn_cls: 0.012  loss_rpn_loc: 0.101  time: 5.0542  data_time: 1.8936  lr: 0.000320  max_mem: 9185M\n",
            "\u001b[32m[07/08 12:27:10 d2.utils.events]: \u001b[0m eta: 2:20:21  iter: 339  total_loss: 1.134  loss_cls: 0.448  loss_box_reg: 0.362  loss_mask: 0.205  loss_rpn_cls: 0.015  loss_rpn_loc: 0.104  time: 5.0632  data_time: 1.8608  lr: 0.000340  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:28:54 d2.utils.events]: \u001b[0m eta: 2:18:52  iter: 359  total_loss: 1.033  loss_cls: 0.402  loss_box_reg: 0.324  loss_mask: 0.196  loss_rpn_cls: 0.012  loss_rpn_loc: 0.104  time: 5.0694  data_time: 1.8590  lr: 0.000360  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:30:39 d2.utils.events]: \u001b[0m eta: 2:17:22  iter: 379  total_loss: 1.036  loss_cls: 0.412  loss_box_reg: 0.328  loss_mask: 0.191  loss_rpn_cls: 0.016  loss_rpn_loc: 0.094  time: 5.0787  data_time: 1.8807  lr: 0.000380  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:32:40 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 12:32:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 12:32:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 12:33:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.7165 s / img. ETA=0:04:52\n",
            "\u001b[32m[07/08 12:34:03 d2.evaluation.evaluator]: \u001b[0mInference done 12/57. 0.7227 s / img. ETA=0:04:51\n",
            "\u001b[32m[07/08 12:34:12 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.7008 s / img. ETA=0:04:20\n",
            "\u001b[32m[07/08 12:34:17 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.6523 s / img. ETA=0:03:43\n",
            "\u001b[32m[07/08 12:34:23 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.5961 s / img. ETA=0:02:59\n",
            "\u001b[32m[07/08 12:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.5557 s / img. ETA=0:02:27\n",
            "\u001b[32m[07/08 12:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.5339 s / img. ETA=0:02:05\n",
            "\u001b[32m[07/08 12:34:41 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.5121 s / img. ETA=0:01:46\n",
            "\u001b[32m[07/08 12:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.4905 s / img. ETA=0:01:24\n",
            "\u001b[32m[07/08 12:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.4910 s / img. ETA=0:01:17\n",
            "\u001b[32m[07/08 12:35:02 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.4970 s / img. ETA=0:01:10\n",
            "\u001b[32m[07/08 12:35:07 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.4953 s / img. ETA=0:01:03\n",
            "\u001b[32m[07/08 12:35:15 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.4995 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/08 12:35:21 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.5001 s / img. ETA=0:00:50\n",
            "\u001b[32m[07/08 12:35:28 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.5017 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/08 12:35:35 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.5093 s / img. ETA=0:00:41\n",
            "\u001b[32m[07/08 12:35:41 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.5141 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/08 12:35:49 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.5218 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/08 12:35:55 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.5299 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/08 12:36:02 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.5362 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/08 12:36:10 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.5439 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/08 12:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.5511 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/08 12:36:25 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.5573 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/08 12:36:32 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.5615 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/08 12:36:40 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.5726 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/08 12:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.5769 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/08 12:36:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:29.865448 (4.035874 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 12:36:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:29 (0.576886 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 12:36:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 12:36:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 12:36:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.55s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.475\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.315\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.560\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.663\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.663\n",
            "\u001b[32m[07/08 12:36:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 31.500 | 47.499 | 34.750 |  nan  |  nan  | 31.500 |\n",
            "\u001b[32m[07/08 12:36:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 12:36:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 49.830 | brec_Cht         | 22.507 | lam_Sltst  | 19.448 |\n",
            "| skel_WkstPkst | 21.344 | strless_SltstSst | 44.372 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.11s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.76s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.476\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.379\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.608\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.713\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            "\u001b[32m[07/08 12:36:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.627 | 47.552 | 37.858 |  nan  |  nan  | 33.627 |\n",
            "\u001b[32m[07/08 12:36:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 12:36:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 51.810 | brec_Cht         | 25.802 | lam_Sltst  | 18.940 |\n",
            "| skel_WkstPkst | 27.694 | strless_SltstSst | 43.888 |            |        |\n",
            "\u001b[32m[07/08 12:36:49 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/08 12:36:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 12:36:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 12:36:49 d2.evaluation.testing]: \u001b[0mcopypaste: 31.5001,47.4990,34.7498,nan,nan,31.5001\n",
            "\u001b[32m[07/08 12:36:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 12:36:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 12:36:49 d2.evaluation.testing]: \u001b[0mcopypaste: 33.6268,47.5516,37.8580,nan,nan,33.6269\n",
            "\u001b[32m[07/08 12:36:53 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 12:36:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 12:36:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 12:37:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.4318 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/08 12:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.4902 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/08 12:37:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.993203 (2.332578 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 12:37:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.490177 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 12:37:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 12:37:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 12:37:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.239\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.472\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.239\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.116\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
            "\u001b[32m[07/08 12:37:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 23.893 | 47.245 | 14.099 |  nan  |  nan  | 23.893 |\n",
            "\u001b[32m[07/08 12:37:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 12:37:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 31.644 | brec_Cht         | nan    | lam_Sltst  | 10.292 |\n",
            "| skel_WkstPkst | 35.149 | strless_SltstSst | 18.487 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.458\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566\n",
            "\u001b[32m[07/08 12:37:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.086 | 45.803 | 27.111 |  nan  |  nan  | 28.086 |\n",
            "\u001b[32m[07/08 12:37:30 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 12:37:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 31.604 | brec_Cht         | nan    | lam_Sltst  | 13.010 |\n",
            "| skel_WkstPkst | 50.297 | strless_SltstSst | 17.434 |            |        |\n",
            "\u001b[32m[07/08 12:37:30 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/08 12:37:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 12:37:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 12:37:30 d2.evaluation.testing]: \u001b[0mcopypaste: 23.8931,47.2451,14.0994,nan,nan,23.8931\n",
            "\u001b[32m[07/08 12:37:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 12:37:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 12:37:30 d2.evaluation.testing]: \u001b[0mcopypaste: 28.0862,45.8025,27.1107,nan,nan,28.0862\n",
            "\u001b[32m[07/08 12:37:30 d2.utils.events]: \u001b[0m eta: 2:15:53  iter: 399  total_loss: 0.936  loss_cls: 0.342  loss_box_reg: 0.275  loss_mask: 0.183  loss_rpn_cls: 0.010  loss_rpn_loc: 0.096  time: 5.0861  data_time: 1.8873  lr: 0.000400  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:39:15 d2.utils.events]: \u001b[0m eta: 2:14:27  iter: 419  total_loss: 0.939  loss_cls: 0.364  loss_box_reg: 0.286  loss_mask: 0.173  loss_rpn_cls: 0.010  loss_rpn_loc: 0.096  time: 5.0937  data_time: 1.9424  lr: 0.000420  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:41:00 d2.utils.events]: \u001b[0m eta: 2:12:57  iter: 439  total_loss: 0.912  loss_cls: 0.332  loss_box_reg: 0.280  loss_mask: 0.171  loss_rpn_cls: 0.009  loss_rpn_loc: 0.095  time: 5.1014  data_time: 1.9172  lr: 0.000440  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:42:45 d2.utils.events]: \u001b[0m eta: 2:11:36  iter: 459  total_loss: 0.823  loss_cls: 0.301  loss_box_reg: 0.254  loss_mask: 0.166  loss_rpn_cls: 0.008  loss_rpn_loc: 0.097  time: 5.1075  data_time: 1.8774  lr: 0.000460  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:44:31 d2.utils.events]: \u001b[0m eta: 2:10:19  iter: 479  total_loss: 0.817  loss_cls: 0.302  loss_box_reg: 0.263  loss_mask: 0.164  loss_rpn_cls: 0.007  loss_rpn_loc: 0.092  time: 5.1164  data_time: 1.9605  lr: 0.000480  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:46:16 d2.utils.events]: \u001b[0m eta: 2:08:39  iter: 499  total_loss: 0.713  loss_cls: 0.239  loss_box_reg: 0.221  loss_mask: 0.151  loss_rpn_cls: 0.008  loss_rpn_loc: 0.091  time: 5.1207  data_time: 1.8649  lr: 0.000500  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:48:01 d2.utils.events]: \u001b[0m eta: 2:07:02  iter: 519  total_loss: 0.703  loss_cls: 0.252  loss_box_reg: 0.224  loss_mask: 0.143  loss_rpn_cls: 0.007  loss_rpn_loc: 0.087  time: 5.1268  data_time: 1.8848  lr: 0.000519  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:49:47 d2.utils.events]: \u001b[0m eta: 2:05:27  iter: 539  total_loss: 0.671  loss_cls: 0.238  loss_box_reg: 0.209  loss_mask: 0.139  loss_rpn_cls: 0.006  loss_rpn_loc: 0.084  time: 5.1334  data_time: 1.9391  lr: 0.000539  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:51:32 d2.utils.events]: \u001b[0m eta: 2:03:48  iter: 559  total_loss: 0.649  loss_cls: 0.218  loss_box_reg: 0.200  loss_mask: 0.133  loss_rpn_cls: 0.004  loss_rpn_loc: 0.088  time: 5.1365  data_time: 1.8305  lr: 0.000559  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:53:17 d2.utils.events]: \u001b[0m eta: 2:02:10  iter: 579  total_loss: 0.584  loss_cls: 0.192  loss_box_reg: 0.181  loss_mask: 0.131  loss_rpn_cls: 0.005  loss_rpn_loc: 0.078  time: 5.1402  data_time: 1.9000  lr: 0.000579  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:55:19 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 12:55:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 12:55:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 12:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.5140 s / img. ETA=0:01:36\n",
            "\u001b[32m[07/08 12:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.4805 s / img. ETA=0:01:17\n",
            "\u001b[32m[07/08 12:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.4018 s / img. ETA=0:00:53\n",
            "\u001b[32m[07/08 12:56:01 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.3674 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/08 12:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.3514 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/08 12:56:13 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.3525 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/08 12:56:19 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.3546 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/08 12:56:25 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.3598 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/08 12:56:31 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.3708 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/08 12:56:37 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.3835 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/08 12:56:43 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.3978 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/08 12:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.4078 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/08 12:56:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:21.208966 (1.561711 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 12:56:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.410454 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 12:56:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 12:56:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 12:56:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.698\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.869\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.821\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.698\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.777\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.829\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.829\n",
            "\u001b[32m[07/08 12:56:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 69.830 | 86.897 | 82.148 |  nan  |  nan  | 69.830 |\n",
            "\u001b[32m[07/08 12:56:53 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 12:56:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 76.788 | brec_Cht         | 73.266 | lam_Sltst  | 57.877 |\n",
            "| skel_WkstPkst | 61.247 | strless_SltstSst | 79.970 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.54s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.710\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.870\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.819\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.787\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.840\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.840\n",
            "\u001b[32m[07/08 12:56:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 70.954 | 86.976 | 81.926 |  nan  |  nan  | 70.954 |\n",
            "\u001b[32m[07/08 12:56:54 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 12:56:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 79.861 | brec_Cht         | 76.645 | lam_Sltst  | 54.991 |\n",
            "| skel_WkstPkst | 63.539 | strless_SltstSst | 79.735 |            |        |\n",
            "\u001b[32m[07/08 12:56:54 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/08 12:56:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 12:56:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 12:56:54 d2.evaluation.testing]: \u001b[0mcopypaste: 69.8297,86.8968,82.1478,nan,nan,69.8297\n",
            "\u001b[32m[07/08 12:56:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 12:56:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 12:56:54 d2.evaluation.testing]: \u001b[0mcopypaste: 70.9540,86.9756,81.9260,nan,nan,70.9542\n",
            "\u001b[32m[07/08 12:56:58 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 12:56:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 12:56:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 12:57:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.3194 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/08 12:57:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.714338 (1.301593 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 12:57:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.350210 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 12:57:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 12:57:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 12:57:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.574\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.407\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.499\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.538\n",
            "\u001b[32m[07/08 12:57:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 34.642 | 57.380 | 40.747 |  nan  |  nan  | 34.642 |\n",
            "\u001b[32m[07/08 12:57:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 12:57:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 25.403 | brec_Cht         | nan    | lam_Sltst  | 18.620 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 19.398 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.547\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.399\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.503\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.548\n",
            "\u001b[32m[07/08 12:57:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 34.415 | 54.732 | 39.866 |  nan  |  nan  | 34.415 |\n",
            "\u001b[32m[07/08 12:57:20 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 12:57:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 26.934 | brec_Cht         | nan    | lam_Sltst  | 17.977 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 17.602 |            |        |\n",
            "\u001b[32m[07/08 12:57:20 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/08 12:57:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 12:57:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 12:57:20 d2.evaluation.testing]: \u001b[0mcopypaste: 34.6421,57.3804,40.7467,nan,nan,34.6421\n",
            "\u001b[32m[07/08 12:57:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 12:57:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 12:57:20 d2.evaluation.testing]: \u001b[0mcopypaste: 34.4154,54.7320,39.8658,nan,nan,34.4154\n",
            "\u001b[32m[07/08 12:57:20 d2.utils.events]: \u001b[0m eta: 2:00:31  iter: 599  total_loss: 0.583  loss_cls: 0.184  loss_box_reg: 0.183  loss_mask: 0.120  loss_rpn_cls: 0.007  loss_rpn_loc: 0.076  time: 5.1452  data_time: 1.9188  lr: 0.000599  max_mem: 9326M\n",
            "\u001b[32m[07/08 12:59:05 d2.utils.events]: \u001b[0m eta: 1:58:49  iter: 619  total_loss: 0.531  loss_cls: 0.168  loss_box_reg: 0.171  loss_mask: 0.120  loss_rpn_cls: 0.005  loss_rpn_loc: 0.080  time: 5.1490  data_time: 1.8516  lr: 0.000619  max_mem: 9326M\n",
            "\u001b[32m[07/08 13:00:50 d2.utils.events]: \u001b[0m eta: 1:57:11  iter: 639  total_loss: 0.551  loss_cls: 0.178  loss_box_reg: 0.171  loss_mask: 0.122  loss_rpn_cls: 0.004  loss_rpn_loc: 0.081  time: 5.1530  data_time: 1.8796  lr: 0.000639  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:02:35 d2.utils.events]: \u001b[0m eta: 1:55:31  iter: 659  total_loss: 0.518  loss_cls: 0.148  loss_box_reg: 0.161  loss_mask: 0.114  loss_rpn_cls: 0.004  loss_rpn_loc: 0.077  time: 5.1547  data_time: 1.8538  lr: 0.000659  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:04:20 d2.utils.events]: \u001b[0m eta: 1:53:56  iter: 679  total_loss: 0.502  loss_cls: 0.141  loss_box_reg: 0.162  loss_mask: 0.112  loss_rpn_cls: 0.004  loss_rpn_loc: 0.075  time: 5.1584  data_time: 1.9283  lr: 0.000679  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:06:05 d2.utils.events]: \u001b[0m eta: 1:52:13  iter: 699  total_loss: 0.468  loss_cls: 0.125  loss_box_reg: 0.147  loss_mask: 0.108  loss_rpn_cls: 0.004  loss_rpn_loc: 0.075  time: 5.1607  data_time: 1.8523  lr: 0.000699  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:07:51 d2.utils.events]: \u001b[0m eta: 1:50:33  iter: 719  total_loss: 0.454  loss_cls: 0.110  loss_box_reg: 0.143  loss_mask: 0.103  loss_rpn_cls: 0.003  loss_rpn_loc: 0.072  time: 5.1649  data_time: 1.8825  lr: 0.000719  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:09:37 d2.utils.events]: \u001b[0m eta: 1:48:53  iter: 739  total_loss: 0.449  loss_cls: 0.120  loss_box_reg: 0.138  loss_mask: 0.104  loss_rpn_cls: 0.003  loss_rpn_loc: 0.074  time: 5.1682  data_time: 1.8984  lr: 0.000739  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:11:23 d2.utils.events]: \u001b[0m eta: 1:47:12  iter: 759  total_loss: 0.410  loss_cls: 0.100  loss_box_reg: 0.135  loss_mask: 0.102  loss_rpn_cls: 0.003  loss_rpn_loc: 0.069  time: 5.1719  data_time: 1.8806  lr: 0.000759  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:13:08 d2.utils.events]: \u001b[0m eta: 1:45:29  iter: 779  total_loss: 0.399  loss_cls: 0.095  loss_box_reg: 0.129  loss_mask: 0.099  loss_rpn_cls: 0.004  loss_rpn_loc: 0.069  time: 5.1734  data_time: 1.8628  lr: 0.000779  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:15:12 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 13:15:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 13:15:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 13:15:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.4577 s / img. ETA=0:01:23\n",
            "\u001b[32m[07/08 13:15:39 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.4130 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/08 13:15:45 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.3446 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/08 13:15:51 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.3184 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/08 13:15:56 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.3176 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/08 13:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.3188 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/08 13:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.3237 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/08 13:16:15 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.3382 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/08 13:16:20 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.3468 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/08 13:16:26 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.3536 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/08 13:16:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:02.981704 (1.211187 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 13:16:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.353556 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 13:16:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 13:16:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 13:16:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.41s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.873\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.989\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.873\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.881\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.906\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.906\n",
            "\u001b[32m[07/08 13:16:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 87.276 | 99.046 | 98.855 |  nan  |  nan  | 87.276 |\n",
            "\u001b[32m[07/08 13:16:26 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 13:16:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 86.212 | brec_Cht         | 89.350 | lam_Sltst  | 83.552 |\n",
            "| skel_WkstPkst | 89.402 | strless_SltstSst | 87.861 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.42s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.852\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.972\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.852\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.866\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.890\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.890\n",
            "\u001b[32m[07/08 13:16:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 85.151 | 99.046 | 97.243 |  nan  |  nan  | 85.151 |\n",
            "\u001b[32m[07/08 13:16:27 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 13:16:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 87.319 | brec_Cht         | 87.401 | lam_Sltst  | 79.782 |\n",
            "| skel_WkstPkst | 84.766 | strless_SltstSst | 86.487 |            |        |\n",
            "\u001b[32m[07/08 13:16:27 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/08 13:16:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 13:16:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 13:16:27 d2.evaluation.testing]: \u001b[0mcopypaste: 87.2755,99.0463,98.8550,nan,nan,87.2755\n",
            "\u001b[32m[07/08 13:16:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 13:16:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 13:16:27 d2.evaluation.testing]: \u001b[0mcopypaste: 85.1509,99.0463,97.2428,nan,nan,85.1509\n",
            "\u001b[32m[07/08 13:16:30 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 13:16:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 13:16:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 13:16:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2882 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.388361 (1.043151 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.314041 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.520\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.413\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.469\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.373 | 51.961 | 41.347 |  nan  |  nan  | 33.373 |\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 21.876 | brec_Cht         | nan    | lam_Sltst  | 16.578 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 19.891 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.387\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.443\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.475\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.252 | 50.309 | 38.748 |  nan  |  nan  | 33.252 |\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 22.560 | brec_Cht         | nan    | lam_Sltst  | 16.363 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 18.936 |            |        |\n",
            "\u001b[32m[07/08 13:16:48 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.testing]: \u001b[0mcopypaste: 33.3735,51.9611,41.3466,nan,nan,33.3735\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 13:16:48 d2.evaluation.testing]: \u001b[0mcopypaste: 33.2518,50.3088,38.7479,nan,nan,33.2518\n",
            "\u001b[32m[07/08 13:16:48 d2.utils.events]: \u001b[0m eta: 1:43:47  iter: 799  total_loss: 0.402  loss_cls: 0.095  loss_box_reg: 0.130  loss_mask: 0.098  loss_rpn_cls: 0.004  loss_rpn_loc: 0.071  time: 5.1785  data_time: 1.9281  lr: 0.000799  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:18:35 d2.utils.events]: \u001b[0m eta: 1:42:10  iter: 819  total_loss: 0.360  loss_cls: 0.083  loss_box_reg: 0.112  loss_mask: 0.096  loss_rpn_cls: 0.003  loss_rpn_loc: 0.064  time: 5.1816  data_time: 1.8957  lr: 0.000819  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:20:22 d2.utils.events]: \u001b[0m eta: 1:40:35  iter: 839  total_loss: 0.348  loss_cls: 0.085  loss_box_reg: 0.115  loss_mask: 0.095  loss_rpn_cls: 0.003  loss_rpn_loc: 0.059  time: 5.1856  data_time: 1.9527  lr: 0.000839  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:22:08 d2.utils.events]: \u001b[0m eta: 1:38:53  iter: 859  total_loss: 0.373  loss_cls: 0.081  loss_box_reg: 0.122  loss_mask: 0.099  loss_rpn_cls: 0.003  loss_rpn_loc: 0.065  time: 5.1892  data_time: 1.8967  lr: 0.000859  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:23:54 d2.utils.events]: \u001b[0m eta: 1:37:16  iter: 879  total_loss: 0.393  loss_cls: 0.093  loss_box_reg: 0.132  loss_mask: 0.095  loss_rpn_cls: 0.003  loss_rpn_loc: 0.069  time: 5.1912  data_time: 1.8790  lr: 0.000879  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:25:40 d2.utils.events]: \u001b[0m eta: 1:35:33  iter: 899  total_loss: 0.349  loss_cls: 0.075  loss_box_reg: 0.112  loss_mask: 0.090  loss_rpn_cls: 0.003  loss_rpn_loc: 0.054  time: 5.1941  data_time: 1.9133  lr: 0.000899  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:27:26 d2.utils.events]: \u001b[0m eta: 1:33:52  iter: 919  total_loss: 0.326  loss_cls: 0.067  loss_box_reg: 0.107  loss_mask: 0.090  loss_rpn_cls: 0.003  loss_rpn_loc: 0.056  time: 5.1962  data_time: 1.8678  lr: 0.000919  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:29:13 d2.utils.events]: \u001b[0m eta: 1:32:11  iter: 939  total_loss: 0.317  loss_cls: 0.066  loss_box_reg: 0.109  loss_mask: 0.086  loss_rpn_cls: 0.002  loss_rpn_loc: 0.057  time: 5.1991  data_time: 1.9392  lr: 0.000939  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:30:59 d2.utils.events]: \u001b[0m eta: 1:30:30  iter: 959  total_loss: 0.312  loss_cls: 0.062  loss_box_reg: 0.109  loss_mask: 0.084  loss_rpn_cls: 0.002  loss_rpn_loc: 0.057  time: 5.2016  data_time: 1.9128  lr: 0.000959  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:32:47 d2.utils.events]: \u001b[0m eta: 1:28:51  iter: 979  total_loss: 0.328  loss_cls: 0.067  loss_box_reg: 0.112  loss_mask: 0.087  loss_rpn_cls: 0.002  loss_rpn_loc: 0.055  time: 5.2050  data_time: 1.9410  lr: 0.000979  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:34:49 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 13:34:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 13:34:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 13:35:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.4127 s / img. ETA=0:01:08\n",
            "\u001b[32m[07/08 13:35:13 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.3634 s / img. ETA=0:00:46\n",
            "\u001b[32m[07/08 13:35:18 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.3148 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/08 13:35:24 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.2994 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/08 13:35:29 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.2991 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/08 13:35:35 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.2996 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/08 13:35:40 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.3075 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/08 13:35:46 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.3188 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/08 13:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.3274 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 13:35:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:54.317101 (1.044560 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 13:35:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.328544 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 13:35:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 13:35:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 13:35:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.909\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.909\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.908\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.931\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.931\n",
            "\u001b[32m[07/08 13:35:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 90.855 | 99.997 | 99.997 |  nan  |  nan  | 90.855 |\n",
            "\u001b[32m[07/08 13:35:54 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 13:35:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 91.075 | brec_Cht         | 94.106 | lam_Sltst  | 89.821 |\n",
            "| skel_WkstPkst | 88.925 | strless_SltstSst | 90.348 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.894\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.998\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.894\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.898\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.921\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.921\n",
            "\u001b[32m[07/08 13:35:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 89.390 | 99.997 | 99.799 |  nan  |  nan  | 89.390 |\n",
            "\u001b[32m[07/08 13:35:54 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 13:35:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 89.931 | brec_Cht         | 91.481 | lam_Sltst  | 86.752 |\n",
            "| skel_WkstPkst | 89.643 | strless_SltstSst | 89.142 |            |        |\n",
            "\u001b[32m[07/08 13:35:54 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/08 13:35:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 13:35:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 13:35:54 d2.evaluation.testing]: \u001b[0mcopypaste: 90.8548,99.9970,99.9970,nan,nan,90.8548\n",
            "\u001b[32m[07/08 13:35:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 13:35:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 13:35:54 d2.evaluation.testing]: \u001b[0mcopypaste: 89.3898,99.9970,99.7990,nan,nan,89.3898\n",
            "\u001b[32m[07/08 13:35:58 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 13:35:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 13:35:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 13:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2802 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.731962 (0.970218 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.302101 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.536\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.232 | 53.571 | 38.449 |  nan  |  nan  | 33.232 |\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 21.349 | brec_Cht         | nan    | lam_Sltst  | 14.064 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 22.367 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.528\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.386\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.503\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.503\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.532 | 52.816 | 38.557 |  nan  |  nan  | 33.532 |\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 21.409 | brec_Cht         | nan    | lam_Sltst  | 15.847 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 21.725 |            |        |\n",
            "\u001b[32m[07/08 13:36:15 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.testing]: \u001b[0mcopypaste: 33.2323,53.5711,38.4491,nan,nan,33.2323\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 13:36:15 d2.evaluation.testing]: \u001b[0mcopypaste: 33.5324,52.8155,38.5573,nan,nan,33.5324\n",
            "\u001b[32m[07/08 13:36:15 d2.utils.events]: \u001b[0m eta: 1:27:10  iter: 999  total_loss: 0.294  loss_cls: 0.058  loss_box_reg: 0.097  loss_mask: 0.085  loss_rpn_cls: 0.002  loss_rpn_loc: 0.052  time: 5.2064  data_time: 1.9223  lr: 0.000999  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:38:03 d2.utils.events]: \u001b[0m eta: 1:25:35  iter: 1019  total_loss: 0.290  loss_cls: 0.055  loss_box_reg: 0.095  loss_mask: 0.082  loss_rpn_cls: 0.002  loss_rpn_loc: 0.050  time: 5.2099  data_time: 1.9665  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:39:49 d2.utils.events]: \u001b[0m eta: 1:23:55  iter: 1039  total_loss: 0.287  loss_cls: 0.053  loss_box_reg: 0.095  loss_mask: 0.084  loss_rpn_cls: 0.002  loss_rpn_loc: 0.051  time: 5.2122  data_time: 1.9030  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:41:36 d2.utils.events]: \u001b[0m eta: 1:22:17  iter: 1059  total_loss: 0.288  loss_cls: 0.054  loss_box_reg: 0.101  loss_mask: 0.083  loss_rpn_cls: 0.002  loss_rpn_loc: 0.048  time: 5.2146  data_time: 1.9173  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:43:23 d2.utils.events]: \u001b[0m eta: 1:20:38  iter: 1079  total_loss: 0.284  loss_cls: 0.051  loss_box_reg: 0.096  loss_mask: 0.081  loss_rpn_cls: 0.001  loss_rpn_loc: 0.045  time: 5.2167  data_time: 1.9126  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:45:08 d2.utils.events]: \u001b[0m eta: 1:18:56  iter: 1099  total_loss: 0.268  loss_cls: 0.048  loss_box_reg: 0.092  loss_mask: 0.083  loss_rpn_cls: 0.002  loss_rpn_loc: 0.051  time: 5.2174  data_time: 1.8798  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:46:55 d2.utils.events]: \u001b[0m eta: 1:17:17  iter: 1119  total_loss: 0.278  loss_cls: 0.047  loss_box_reg: 0.086  loss_mask: 0.079  loss_rpn_cls: 0.002  loss_rpn_loc: 0.051  time: 5.2198  data_time: 1.9108  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:48:43 d2.utils.events]: \u001b[0m eta: 1:15:39  iter: 1139  total_loss: 0.278  loss_cls: 0.047  loss_box_reg: 0.091  loss_mask: 0.080  loss_rpn_cls: 0.001  loss_rpn_loc: 0.059  time: 5.2229  data_time: 1.9738  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:50:29 d2.utils.events]: \u001b[0m eta: 1:13:56  iter: 1159  total_loss: 0.270  loss_cls: 0.046  loss_box_reg: 0.089  loss_mask: 0.077  loss_rpn_cls: 0.001  loss_rpn_loc: 0.047  time: 5.2246  data_time: 1.9073  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:52:17 d2.utils.events]: \u001b[0m eta: 1:12:15  iter: 1179  total_loss: 0.262  loss_cls: 0.044  loss_box_reg: 0.085  loss_mask: 0.076  loss_rpn_cls: 0.002  loss_rpn_loc: 0.046  time: 5.2271  data_time: 1.9443  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:54:20 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 13:54:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 13:54:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 13:54:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.3933 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/08 13:54:43 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.3435 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/08 13:54:48 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.3059 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/08 13:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2961 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/08 13:54:59 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.2933 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/08 13:55:05 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.2996 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/08 13:55:11 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.3096 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/08 13:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.3195 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/08 13:55:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.432683 (0.950629 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 13:55:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.319951 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 13:55:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 13:55:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 13:55:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.916\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.916\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.915\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.938\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.938\n",
            "\u001b[32m[07/08 13:55:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50   |  AP75   |  APs  |  APm  |  APl   |\n",
            "|:------:|:-------:|:-------:|:-----:|:-----:|:------:|\n",
            "| 91.594 | 100.000 | 100.000 |  nan  |  nan  | 91.594 |\n",
            "\u001b[32m[07/08 13:55:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 13:55:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 93.067 | brec_Cht         | 84.999 | lam_Sltst  | 92.651 |\n",
            "| skel_WkstPkst | 94.180 | strless_SltstSst | 93.074 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.36s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.909\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.909\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.221\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.910\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.932\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.932\n",
            "\u001b[32m[07/08 13:55:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50   |  AP75   |  APs  |  APm  |  APl   |\n",
            "|:------:|:-------:|:-------:|:-----:|:-----:|:------:|\n",
            "| 90.938 | 100.000 | 100.000 |  nan  |  nan  | 90.938 |\n",
            "\u001b[32m[07/08 13:55:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 13:55:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 91.620 | brec_Cht         | 90.469 | lam_Sltst  | 90.029 |\n",
            "| skel_WkstPkst | 92.269 | strless_SltstSst | 90.305 |            |        |\n",
            "\u001b[32m[07/08 13:55:20 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/08 13:55:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 13:55:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 13:55:20 d2.evaluation.testing]: \u001b[0mcopypaste: 91.5941,100.0000,100.0000,nan,nan,91.5941\n",
            "\u001b[32m[07/08 13:55:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 13:55:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 13:55:20 d2.evaluation.testing]: \u001b[0mcopypaste: 90.9383,100.0000,100.0000,nan,nan,90.9383\n",
            "\u001b[32m[07/08 13:55:23 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 13:55:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 13:55:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 13:55:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2748 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.256051 (0.917339 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.298493 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.534\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.408\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.943 | 53.370 | 40.788 |  nan  |  nan  | 33.943 |\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 20.584 | brec_Cht         | nan    | lam_Sltst  | 19.776 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 20.265 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.518\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.413\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 34.049 | 51.761 | 41.345 |  nan  |  nan  | 34.049 |\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 21.078 | brec_Cht         | nan    | lam_Sltst  | 20.863 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 19.107 |            |        |\n",
            "\u001b[32m[07/08 13:55:39 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.testing]: \u001b[0mcopypaste: 33.9433,53.3700,40.7879,nan,nan,33.9433\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 13:55:39 d2.evaluation.testing]: \u001b[0mcopypaste: 34.0490,51.7614,41.3450,nan,nan,34.0490\n",
            "\u001b[32m[07/08 13:55:39 d2.utils.events]: \u001b[0m eta: 1:10:33  iter: 1199  total_loss: 0.238  loss_cls: 0.041  loss_box_reg: 0.077  loss_mask: 0.076  loss_rpn_cls: 0.001  loss_rpn_loc: 0.043  time: 5.2291  data_time: 1.9376  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:57:26 d2.utils.events]: \u001b[0m eta: 1:08:53  iter: 1219  total_loss: 0.237  loss_cls: 0.040  loss_box_reg: 0.080  loss_mask: 0.077  loss_rpn_cls: 0.002  loss_rpn_loc: 0.041  time: 5.2310  data_time: 1.9348  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 13:59:13 d2.utils.events]: \u001b[0m eta: 1:07:11  iter: 1239  total_loss: 0.248  loss_cls: 0.041  loss_box_reg: 0.083  loss_mask: 0.075  loss_rpn_cls: 0.001  loss_rpn_loc: 0.042  time: 5.2331  data_time: 1.9230  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:01:00 d2.utils.events]: \u001b[0m eta: 1:05:30  iter: 1259  total_loss: 0.238  loss_cls: 0.041  loss_box_reg: 0.081  loss_mask: 0.076  loss_rpn_cls: 0.001  loss_rpn_loc: 0.040  time: 5.2348  data_time: 1.9312  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:02:48 d2.utils.events]: \u001b[0m eta: 1:03:47  iter: 1279  total_loss: 0.233  loss_cls: 0.038  loss_box_reg: 0.078  loss_mask: 0.074  loss_rpn_cls: 0.002  loss_rpn_loc: 0.039  time: 5.2369  data_time: 1.9469  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:04:36 d2.utils.events]: \u001b[0m eta: 1:02:06  iter: 1299  total_loss: 0.232  loss_cls: 0.036  loss_box_reg: 0.076  loss_mask: 0.075  loss_rpn_cls: 0.002  loss_rpn_loc: 0.041  time: 5.2395  data_time: 1.9557  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:06:23 d2.utils.events]: \u001b[0m eta: 1:00:21  iter: 1319  total_loss: 0.229  loss_cls: 0.040  loss_box_reg: 0.080  loss_mask: 0.072  loss_rpn_cls: 0.002  loss_rpn_loc: 0.039  time: 5.2416  data_time: 1.9643  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:08:10 d2.utils.events]: \u001b[0m eta: 0:58:35  iter: 1339  total_loss: 0.230  loss_cls: 0.036  loss_box_reg: 0.076  loss_mask: 0.073  loss_rpn_cls: 0.002  loss_rpn_loc: 0.039  time: 5.2428  data_time: 1.9315  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:09:56 d2.utils.events]: \u001b[0m eta: 0:56:54  iter: 1359  total_loss: 0.232  loss_cls: 0.037  loss_box_reg: 0.078  loss_mask: 0.071  loss_rpn_cls: 0.002  loss_rpn_loc: 0.041  time: 5.2439  data_time: 1.9233  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:11:43 d2.utils.events]: \u001b[0m eta: 0:55:07  iter: 1379  total_loss: 0.232  loss_cls: 0.035  loss_box_reg: 0.080  loss_mask: 0.071  loss_rpn_cls: 0.002  loss_rpn_loc: 0.039  time: 5.2454  data_time: 1.9049  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:13:47 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 14:13:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 14:13:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 14:14:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.3898 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/08 14:14:09 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.3425 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/08 14:14:15 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.3032 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/08 14:14:20 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2920 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/08 14:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.2896 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/08 14:14:31 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.2957 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/08 14:14:37 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.3056 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/08 14:14:43 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.3151 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.854356 (0.939507 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.315691 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.919\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.919\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.911\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.935\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.935\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50   |  AP75   |  APs  |  APm  |  APl   |\n",
            "|:------:|:-------:|:-------:|:-----:|:-----:|:------:|\n",
            "| 91.854 | 100.000 | 100.000 |  nan  |  nan  | 91.854 |\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 95.155 | brec_Cht         | 83.281 | lam_Sltst  | 96.266 |\n",
            "| skel_WkstPkst | 89.457 | strless_SltstSst | 95.112 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.36s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.906\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.906\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.904\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.927\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.927\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50   |  AP75   |  APs  |  APm  |  APl   |\n",
            "|:------:|:-------:|:-------:|:-----:|:-----:|:------:|\n",
            "| 90.553 | 100.000 | 100.000 |  nan  |  nan  | 90.553 |\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 92.850 | brec_Cht         | 85.834 | lam_Sltst  | 90.591 |\n",
            "| skel_WkstPkst | 92.221 | strless_SltstSst | 91.270 |            |        |\n",
            "\u001b[32m[07/08 14:14:45 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.testing]: \u001b[0mcopypaste: 91.8543,100.0000,100.0000,nan,nan,91.8543\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 14:14:45 d2.evaluation.testing]: \u001b[0mcopypaste: 90.5534,100.0000,100.0000,nan,nan,90.5534\n",
            "\u001b[32m[07/08 14:14:49 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 14:14:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 14:14:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 14:15:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2758 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.727751 (0.969750 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.301222 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.531\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.381\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 34.376 | 53.097 | 38.132 |  nan  |  nan  | 34.376 |\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 20.421 | brec_Cht         | nan    | lam_Sltst  | 16.848 |\n",
            "| skel_WkstPkst | 80.099 | strless_SltstSst | 20.136 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.529\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.369\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.467\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.489\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 34.441 | 52.855 | 36.888 |  nan  |  nan  | 34.441 |\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 20.876 | brec_Cht         | nan    | lam_Sltst  | 16.644 |\n",
            "| skel_WkstPkst | 80.198 | strless_SltstSst | 20.045 |            |        |\n",
            "\u001b[32m[07/08 14:15:06 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.testing]: \u001b[0mcopypaste: 34.3761,53.0971,38.1316,nan,nan,34.3761\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 14:15:06 d2.evaluation.testing]: \u001b[0mcopypaste: 34.4406,52.8548,36.8876,nan,nan,34.4406\n",
            "\u001b[32m[07/08 14:15:06 d2.utils.events]: \u001b[0m eta: 0:53:24  iter: 1399  total_loss: 0.220  loss_cls: 0.034  loss_box_reg: 0.073  loss_mask: 0.071  loss_rpn_cls: 0.001  loss_rpn_loc: 0.040  time: 5.2468  data_time: 1.9501  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:16:53 d2.utils.events]: \u001b[0m eta: 0:51:39  iter: 1419  total_loss: 0.218  loss_cls: 0.034  loss_box_reg: 0.072  loss_mask: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.040  time: 5.2483  data_time: 1.9313  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:18:38 d2.utils.events]: \u001b[0m eta: 0:49:53  iter: 1439  total_loss: 0.213  loss_cls: 0.033  loss_box_reg: 0.073  loss_mask: 0.069  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 5.2486  data_time: 1.8975  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:20:25 d2.utils.events]: \u001b[0m eta: 0:48:07  iter: 1459  total_loss: 0.213  loss_cls: 0.034  loss_box_reg: 0.071  loss_mask: 0.070  loss_rpn_cls: 0.001  loss_rpn_loc: 0.036  time: 5.2496  data_time: 1.9108  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:22:11 d2.utils.events]: \u001b[0m eta: 0:46:19  iter: 1479  total_loss: 0.205  loss_cls: 0.033  loss_box_reg: 0.068  loss_mask: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.035  time: 5.2502  data_time: 1.9296  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:23:56 d2.utils.events]: \u001b[0m eta: 0:44:32  iter: 1499  total_loss: 0.209  loss_cls: 0.028  loss_box_reg: 0.069  loss_mask: 0.069  loss_rpn_cls: 0.002  loss_rpn_loc: 0.034  time: 5.2503  data_time: 1.8850  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:25:42 d2.utils.events]: \u001b[0m eta: 0:42:45  iter: 1519  total_loss: 0.204  loss_cls: 0.031  loss_box_reg: 0.068  loss_mask: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.033  time: 5.2512  data_time: 1.9103  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:27:28 d2.utils.events]: \u001b[0m eta: 0:40:59  iter: 1539  total_loss: 0.198  loss_cls: 0.031  loss_box_reg: 0.068  loss_mask: 0.067  loss_rpn_cls: 0.002  loss_rpn_loc: 0.032  time: 5.2516  data_time: 1.9149  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:29:15 d2.utils.events]: \u001b[0m eta: 0:39:13  iter: 1559  total_loss: 0.203  loss_cls: 0.031  loss_box_reg: 0.071  loss_mask: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.034  time: 5.2526  data_time: 1.9332  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:31:01 d2.utils.events]: \u001b[0m eta: 0:37:27  iter: 1579  total_loss: 0.205  loss_cls: 0.031  loss_box_reg: 0.070  loss_mask: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.035  time: 5.2533  data_time: 1.9382  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:33:02 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 14:33:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 14:33:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 14:33:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.3735 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/08 14:33:23 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.3301 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/08 14:33:29 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.2941 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/08 14:33:34 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2850 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/08 14:33:39 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.2833 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/08 14:33:45 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.2897 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/08 14:33:50 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.2991 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/08 14:33:56 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.3080 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/08 14:33:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.936241 (0.902620 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 14:33:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.308737 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 14:33:57 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 14:33:57 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 14:33:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.958\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.958\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.230\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.948\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.971\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.971\n",
            "\u001b[32m[07/08 14:33:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50   |  AP75   |  APs  |  APm  |  APl   |\n",
            "|:------:|:-------:|:-------:|:-----:|:-----:|:------:|\n",
            "| 95.834 | 100.000 | 100.000 |  nan  |  nan  | 95.834 |\n",
            "\u001b[32m[07/08 14:33:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 14:33:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 96.172 | brec_Cht         | 96.231 | lam_Sltst  | 94.309 |\n",
            "| skel_WkstPkst | 95.611 | strless_SltstSst | 96.849 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.34s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.925\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.925\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.223\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.922\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.945\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.945\n",
            "\u001b[32m[07/08 14:33:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50   |  AP75   |  APs  |  APm  |  APl   |\n",
            "|:------:|:-------:|:-------:|:-----:|:-----:|:------:|\n",
            "| 92.487 | 100.000 | 100.000 |  nan  |  nan  | 92.487 |\n",
            "\u001b[32m[07/08 14:33:58 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 14:33:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 93.457 | brec_Cht         | 91.176 | lam_Sltst  | 92.020 |\n",
            "| skel_WkstPkst | 93.380 | strless_SltstSst | 92.400 |            |        |\n",
            "\u001b[32m[07/08 14:33:58 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/08 14:33:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 14:33:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 14:33:58 d2.evaluation.testing]: \u001b[0mcopypaste: 95.8344,100.0000,100.0000,nan,nan,95.8344\n",
            "\u001b[32m[07/08 14:33:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 14:33:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 14:33:58 d2.evaluation.testing]: \u001b[0mcopypaste: 92.4867,100.0000,100.0000,nan,nan,92.4867\n",
            "\u001b[32m[07/08 14:34:02 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 14:34:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 14:34:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 14:34:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2723 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.276364 (0.919596 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.292114 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.527\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.395\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.275 | 52.708 | 39.519 |  nan  |  nan  | 33.275 |\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 19.742 | brec_Cht         | nan    | lam_Sltst  | 17.983 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 20.226 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.521\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.378\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.447\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.469\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.633 | 52.124 | 37.783 |  nan  |  nan  | 33.633 |\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 21.294 | brec_Cht         | nan    | lam_Sltst  | 19.189 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 18.899 |            |        |\n",
            "\u001b[32m[07/08 14:34:18 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.testing]: \u001b[0mcopypaste: 33.2751,52.7076,39.5193,nan,nan,33.2751\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 14:34:18 d2.evaluation.testing]: \u001b[0mcopypaste: 33.6328,52.1238,37.7827,nan,nan,33.6328\n",
            "\u001b[32m[07/08 14:34:18 d2.utils.events]: \u001b[0m eta: 0:35:39  iter: 1599  total_loss: 0.204  loss_cls: 0.031  loss_box_reg: 0.065  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.036  time: 5.2530  data_time: 1.8714  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:36:03 d2.utils.events]: \u001b[0m eta: 0:33:52  iter: 1619  total_loss: 0.195  loss_cls: 0.030  loss_box_reg: 0.061  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.039  time: 5.2526  data_time: 1.8387  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:37:48 d2.utils.events]: \u001b[0m eta: 0:32:06  iter: 1639  total_loss: 0.214  loss_cls: 0.031  loss_box_reg: 0.067  loss_mask: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.045  time: 5.2530  data_time: 1.9008  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:39:34 d2.utils.events]: \u001b[0m eta: 0:30:19  iter: 1659  total_loss: 0.210  loss_cls: 0.031  loss_box_reg: 0.069  loss_mask: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.043  time: 5.2532  data_time: 1.8897  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:41:19 d2.utils.events]: \u001b[0m eta: 0:28:31  iter: 1679  total_loss: 0.199  loss_cls: 0.032  loss_box_reg: 0.066  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.036  time: 5.2532  data_time: 1.8531  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:43:04 d2.utils.events]: \u001b[0m eta: 0:26:45  iter: 1699  total_loss: 0.187  loss_cls: 0.029  loss_box_reg: 0.058  loss_mask: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.031  time: 5.2532  data_time: 1.9246  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:44:49 d2.utils.events]: \u001b[0m eta: 0:24:58  iter: 1719  total_loss: 0.197  loss_cls: 0.029  loss_box_reg: 0.066  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.033  time: 5.2533  data_time: 1.8693  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:46:33 d2.utils.events]: \u001b[0m eta: 0:23:11  iter: 1739  total_loss: 0.201  loss_cls: 0.029  loss_box_reg: 0.068  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.037  time: 5.2528  data_time: 1.8721  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:48:20 d2.utils.events]: \u001b[0m eta: 0:21:24  iter: 1759  total_loss: 0.187  loss_cls: 0.029  loss_box_reg: 0.061  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 5.2535  data_time: 1.9375  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:50:06 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 1779  total_loss: 0.191  loss_cls: 0.028  loss_box_reg: 0.060  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 5.2539  data_time: 1.9000  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:52:08 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 14:52:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 14:52:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 14:52:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.3660 s / img. ETA=0:00:53\n",
            "\u001b[32m[07/08 14:52:29 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.3262 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/08 14:52:34 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.2956 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/08 14:52:39 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2851 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/08 14:52:44 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.2817 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/08 14:52:50 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.2881 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/08 14:52:55 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.2973 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/08 14:53:01 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.3051 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/08 14:53:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.949670 (0.883648 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 14:53:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.305904 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 14:53:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 14:53:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 14:53:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.949\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.949\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.944\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.967\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.967\n",
            "\u001b[32m[07/08 14:53:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50   |  AP75   |  APs  |  APm  |  APl   |\n",
            "|:------:|:-------:|:-------:|:-----:|:-----:|:------:|\n",
            "| 94.945 | 100.000 | 100.000 |  nan  |  nan  | 94.945 |\n",
            "\u001b[32m[07/08 14:53:03 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 14:53:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 95.383 | brec_Cht         | 97.156 | lam_Sltst  | 93.805 |\n",
            "| skel_WkstPkst | 92.915 | strless_SltstSst | 95.468 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.33s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.929\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.929\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.928\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.950\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.950\n",
            "\u001b[32m[07/08 14:53:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50   |  AP75   |  APs  |  APm  |  APl   |\n",
            "|:------:|:-------:|:-------:|:-----:|:-----:|:------:|\n",
            "| 92.865 | 100.000 | 100.000 |  nan  |  nan  | 92.865 |\n",
            "\u001b[32m[07/08 14:53:03 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 14:53:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 93.925 | brec_Cht         | 92.394 | lam_Sltst  | 92.272 |\n",
            "| skel_WkstPkst | 92.778 | strless_SltstSst | 92.954 |            |        |\n",
            "\u001b[32m[07/08 14:53:03 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/08 14:53:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 14:53:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 14:53:03 d2.evaluation.testing]: \u001b[0mcopypaste: 94.9455,100.0000,100.0000,nan,nan,94.9455\n",
            "\u001b[32m[07/08 14:53:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 14:53:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 14:53:03 d2.evaluation.testing]: \u001b[0mcopypaste: 92.8648,100.0000,100.0000,nan,nan,92.8648\n",
            "\u001b[32m[07/08 14:53:07 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 14:53:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 14:53:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 14:53:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2769 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.366630 (0.929626 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.297877 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.522\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.388\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.343\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.485\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 34.303 | 52.210 | 38.846 |  nan  |  nan  | 34.303 |\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 18.024 | brec_Cht         | nan    | lam_Sltst  | 17.345 |\n",
            "| skel_WkstPkst | 80.099 | strless_SltstSst | 21.744 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.523\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 34.926 | 52.261 | 37.722 |  nan  |  nan  | 34.926 |\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 19.029 | brec_Cht         | nan    | lam_Sltst  | 20.025 |\n",
            "| skel_WkstPkst | 80.198 | strless_SltstSst | 20.451 |            |        |\n",
            "\u001b[32m[07/08 14:53:23 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.testing]: \u001b[0mcopypaste: 34.3030,52.2097,38.8465,nan,nan,34.3030\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 14:53:23 d2.evaluation.testing]: \u001b[0mcopypaste: 34.9258,52.2609,37.7220,nan,nan,34.9258\n",
            "\u001b[32m[07/08 14:53:23 d2.utils.events]: \u001b[0m eta: 0:17:50  iter: 1799  total_loss: 0.189  loss_cls: 0.028  loss_box_reg: 0.062  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 5.2542  data_time: 1.9003  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:55:09 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 1819  total_loss: 0.183  loss_cls: 0.027  loss_box_reg: 0.058  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 5.2546  data_time: 1.9591  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:56:56 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 1839  total_loss: 0.187  loss_cls: 0.029  loss_box_reg: 0.063  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.033  time: 5.2553  data_time: 1.9137  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 14:58:42 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 1859  total_loss: 0.186  loss_cls: 0.027  loss_box_reg: 0.062  loss_mask: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 5.2562  data_time: 1.9457  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 15:00:29 d2.utils.events]: \u001b[0m eta: 0:10:44  iter: 1879  total_loss: 0.185  loss_cls: 0.028  loss_box_reg: 0.062  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 5.2570  data_time: 1.9283  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 15:02:16 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 1899  total_loss: 0.179  loss_cls: 0.028  loss_box_reg: 0.056  loss_mask: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 5.2579  data_time: 1.9474  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 15:04:01 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 1919  total_loss: 0.173  loss_cls: 0.025  loss_box_reg: 0.056  loss_mask: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.027  time: 5.2581  data_time: 1.9232  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 15:05:47 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 1939  total_loss: 0.188  loss_cls: 0.026  loss_box_reg: 0.065  loss_mask: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.031  time: 5.2585  data_time: 1.8962  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 15:07:33 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 1959  total_loss: 0.191  loss_cls: 0.028  loss_box_reg: 0.066  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 5.2586  data_time: 1.8906  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 15:09:18 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 1979  total_loss: 0.185  loss_cls: 0.027  loss_box_reg: 0.064  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.033  time: 5.2589  data_time: 1.9308  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 15:11:23 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 15:11:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 15:11:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 15:11:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.3722 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/08 15:11:44 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.3299 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/08 15:11:49 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.2926 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/08 15:11:55 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.2831 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/08 15:12:01 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.2818 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/08 15:12:06 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.2894 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/08 15:12:12 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.2991 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/08 15:12:17 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.3069 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/08 15:12:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.464615 (0.893550 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 15:12:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.306876 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 15:12:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 15:12:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 15:12:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.963\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.963\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.230\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.953\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.977\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.977\n",
            "\u001b[32m[07/08 15:12:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50   |  AP75   |  APs  |  APm  |  APl   |\n",
            "|:------:|:-------:|:-------:|:-----:|:-----:|:------:|\n",
            "| 96.272 | 100.000 | 100.000 |  nan  |  nan  | 96.272 |\n",
            "\u001b[32m[07/08 15:12:18 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 15:12:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 96.107 | brec_Cht         | 94.796 | lam_Sltst  | 97.729 |\n",
            "| skel_WkstPkst | 98.511 | strless_SltstSst | 94.217 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.34s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.937\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.937\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.935\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.958\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.958\n",
            "\u001b[32m[07/08 15:12:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50   |  AP75   |  APs  |  APm  |  APl   |\n",
            "|:------:|:-------:|:-------:|:-----:|:-----:|:------:|\n",
            "| 93.662 | 100.000 | 100.000 |  nan  |  nan  | 93.662 |\n",
            "\u001b[32m[07/08 15:12:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 15:12:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 94.661 | brec_Cht         | 93.507 | lam_Sltst  | 93.672 |\n",
            "| skel_WkstPkst | 93.230 | strless_SltstSst | 93.240 |            |        |\n",
            "\u001b[32m[07/08 15:12:19 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_train in csv format:\n",
            "\u001b[32m[07/08 15:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 15:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 15:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: 96.2720,100.0000,100.0000,nan,nan,96.2720\n",
            "\u001b[32m[07/08 15:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 15:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 15:12:19 d2.evaluation.testing]: \u001b[0mcopypaste: 93.6620,100.0000,100.0000,nan,nan,93.6620\n",
            "\u001b[32m[07/08 15:12:22 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 15:12:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 15:12:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 15:12:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2712 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.234502 (0.914945 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.292784 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.533\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.337\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.472\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.705 | 53.341 | 39.595 |  nan  |  nan  | 33.705 |\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 20.105 | brec_Cht         | nan    | lam_Sltst  | 19.004 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 20.563 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.513\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.452\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.474\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.876 | 51.269 | 39.638 |  nan  |  nan  | 33.876 |\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 21.022 | brec_Cht         | nan    | lam_Sltst  | 20.265 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 19.068 |            |        |\n",
            "\u001b[32m[07/08 15:12:38 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_2_val in csv format:\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.testing]: \u001b[0mcopypaste: 33.7052,53.3408,39.5954,nan,nan,33.7052\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 15:12:38 d2.evaluation.testing]: \u001b[0mcopypaste: 33.8757,51.2688,39.6375,nan,nan,33.8757\n",
            "\u001b[32m[07/08 15:12:38 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 1999  total_loss: 0.183  loss_cls: 0.027  loss_box_reg: 0.064  loss_mask: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 5.2592  data_time: 1.9099  lr: 0.001000  max_mem: 9378M\n",
            "\u001b[32m[07/08 15:12:39 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 2:55:07 (5.2619 s / it)\n",
            "\u001b[32m[07/08 15:12:39 d2.engine.hooks]: \u001b[0mTotal training time: 3:22:19 (0:27:11 on hooks)\n",
            "\n",
            "\n",
            "**Starting train eval**\n",
            "\u001b[32m[07/08 15:12:56 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 15:12:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 15:12:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 15:13:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.3664 s / img. ETA=0:01:12\n",
            "\u001b[32m[07/08 15:13:21 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.3321 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/08 15:13:26 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2972 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/08 15:13:32 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.2828 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/08 15:13:38 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.2801 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/08 15:13:43 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.2827 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/08 15:13:49 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.2919 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/08 15:13:54 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.2995 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/08 15:14:00 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.3049 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/08 15:14:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:54.395554 (1.046068 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 15:14:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.305012 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 15:14:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 15:14:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/08 15:14:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.963\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.963\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.230\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.953\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.977\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.977\n",
            "\u001b[32m[07/08 15:14:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50   |  AP75   |  APs  |  APm  |  APl   |\n",
            "|:------:|:-------:|:-------:|:-----:|:-----:|:------:|\n",
            "| 96.272 | 100.000 | 100.000 |  nan  |  nan  | 96.272 |\n",
            "\u001b[32m[07/08 15:14:01 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 15:14:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 96.107 | brec_Cht         | 94.796 | lam_Sltst  | 97.729 |\n",
            "| skel_WkstPkst | 98.511 | strless_SltstSst | 94.217 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.35s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.937\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.937\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.935\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.958\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.958\n",
            "\u001b[32m[07/08 15:14:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50   |  AP75   |  APs  |  APm  |  APl   |\n",
            "|:------:|:-------:|:-------:|:-----:|:-----:|:------:|\n",
            "| 93.662 | 100.000 | 100.000 |  nan  |  nan  | 93.662 |\n",
            "\u001b[32m[07/08 15:14:01 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 15:14:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 94.661 | brec_Cht         | 93.507 | lam_Sltst  | 93.672 |\n",
            "| skel_WkstPkst | 93.230 | strless_SltstSst | 93.240 |            |        |\n",
            "randomly selected cores/Box 7 Depths 10025-35.JPG\n",
            "\n",
            "\n",
            "**Starting val eval**\n",
            "\u001b[32m[07/08 15:14:55 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 15:14:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 15:14:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 15:15:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2718 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 15:15:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.059489 (1.117721 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 15:15:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.292385 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 15:15:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 15:15:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/08 15:15:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.533\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.337\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.472\n",
            "\u001b[32m[07/08 15:15:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.705 | 53.341 | 39.595 |  nan  |  nan  | 33.705 |\n",
            "\u001b[32m[07/08 15:15:15 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 15:15:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 20.105 | brec_Cht         | nan    | lam_Sltst  | 19.004 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 20.563 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.513\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.452\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.474\n",
            "\u001b[32m[07/08 15:15:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.876 | 51.269 | 39.638 |  nan  |  nan  | 33.876 |\n",
            "\u001b[32m[07/08 15:15:15 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 15:15:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 21.022 | brec_Cht         | nan    | lam_Sltst  | 20.265 |\n",
            "| skel_WkstPkst | 75.149 | strless_SltstSst | 19.068 |            |        |\n",
            "randomly selected cores/Boxes 43-45  Depths 7838.8-7847.4 (Dry).JPG\n",
            "Wed Jul  8 15:15:50 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    70W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "CPU times: user 27.2 s, sys: 4.92 s, total: 32.2 s\n",
            "Wall time: 3h 26min 30s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY-P57y_Lcnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "85991337-9a52-4165-d54f-93d9596447c7"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '3' --max_iter 2000\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 3\n",
            "\t cores_fold_3_train\n",
            "\t cores_fold_3_val\n",
            "\u001b[32m[07/08 18:38:37 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/08 18:38:49 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 56 images left.\n",
            "\u001b[32m[07/08 18:38:49 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 243          |   brec_Cht    | 21           | lam_Sltst  | 102          |\n",
            "| skel_WkstPkst | 20           | strless_Slt.. | 157          |            |              |\n",
            "|     total     | 543          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/08 18:38:49 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 18:38:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 18:38:49 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/08 18:38:49 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-08 18:38:49.976615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "model_final_f10217.pkl: 178MB [00:18, 9.54MB/s]               \n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/08 18:39:16 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/08 18:40:32 d2.utils.events]: \u001b[0m eta: 2:02:18  iter: 19  total_loss: 3.621  loss_cls: 1.820  loss_box_reg: 0.344  loss_mask: 0.691  loss_rpn_cls: 0.522  loss_rpn_loc: 0.237  time: 3.7169  data_time: 2.3926  lr: 0.000020  max_mem: 7324M\n",
            "\u001b[32m[07/08 18:41:47 d2.utils.events]: \u001b[0m eta: 2:01:04  iter: 39  total_loss: 2.714  loss_cls: 1.250  loss_box_reg: 0.419  loss_mask: 0.671  loss_rpn_cls: 0.184  loss_rpn_loc: 0.177  time: 3.7370  data_time: 2.2348  lr: 0.000040  max_mem: 7740M\n",
            "\u001b[32m[07/08 18:43:02 d2.utils.events]: \u001b[0m eta: 1:59:50  iter: 59  total_loss: 2.068  loss_cls: 0.697  loss_box_reg: 0.470  loss_mask: 0.621  loss_rpn_cls: 0.077  loss_rpn_loc: 0.162  time: 3.7326  data_time: 2.1668  lr: 0.000060  max_mem: 7938M\n",
            "\u001b[32m[07/08 18:44:18 d2.utils.events]: \u001b[0m eta: 1:59:45  iter: 79  total_loss: 1.943  loss_cls: 0.628  loss_box_reg: 0.511  loss_mask: 0.556  loss_rpn_cls: 0.057  loss_rpn_loc: 0.143  time: 3.7533  data_time: 2.1863  lr: 0.000080  max_mem: 8655M\n",
            "\u001b[32m[07/08 18:45:34 d2.utils.events]: \u001b[0m eta: 1:58:51  iter: 99  total_loss: 1.838  loss_cls: 0.611  loss_box_reg: 0.570  loss_mask: 0.475  loss_rpn_cls: 0.037  loss_rpn_loc: 0.141  time: 3.7632  data_time: 2.1921  lr: 0.000100  max_mem: 8655M\n",
            "\u001b[32m[07/08 18:46:50 d2.utils.events]: \u001b[0m eta: 1:57:36  iter: 119  total_loss: 1.786  loss_cls: 0.593  loss_box_reg: 0.563  loss_mask: 0.439  loss_rpn_cls: 0.039  loss_rpn_loc: 0.135  time: 3.7717  data_time: 2.1813  lr: 0.000120  max_mem: 8655M\n",
            "\u001b[32m[07/08 18:48:07 d2.utils.events]: \u001b[0m eta: 1:56:44  iter: 139  total_loss: 1.611  loss_cls: 0.521  loss_box_reg: 0.554  loss_mask: 0.403  loss_rpn_cls: 0.030  loss_rpn_loc: 0.130  time: 3.7843  data_time: 2.2162  lr: 0.000140  max_mem: 8886M\n",
            "\u001b[32m[07/08 18:49:24 d2.utils.events]: \u001b[0m eta: 1:56:18  iter: 159  total_loss: 1.636  loss_cls: 0.519  loss_box_reg: 0.563  loss_mask: 0.383  loss_rpn_cls: 0.031  loss_rpn_loc: 0.132  time: 3.7867  data_time: 2.1766  lr: 0.000160  max_mem: 8886M\n",
            "\u001b[32m[07/08 18:50:40 d2.utils.events]: \u001b[0m eta: 1:54:52  iter: 179  total_loss: 1.609  loss_cls: 0.535  loss_box_reg: 0.571  loss_mask: 0.361  loss_rpn_cls: 0.027  loss_rpn_loc: 0.119  time: 3.7894  data_time: 2.1913  lr: 0.000180  max_mem: 8886M\n",
            "\u001b[32m[07/08 18:52:08 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 18:52:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/08 18:52:08 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_3_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/08 18:52:08 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_3_train' to COCO format ...)\n",
            "\u001b[32m[07/08 18:52:20 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/08 18:52:20 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 57, #annotations: 543\n",
            "\u001b[32m[07/08 18:52:20 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_3_train_coco_format.json' ...\n",
            "\u001b[32m[07/08 18:52:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0xc7cbe000 @  0x7f3a2a646b6b 0x7f3a2a666379 0x7f39cdd9b04e 0x7f39cdd9cf4a 0x7f3a06c8b67b 0x7f3a068da6be 0x7f3a06b437b5 0x7f3a06b357c1 0x7f3a06b34d0e 0x7f3a06b357c1 0x7f3a0858a93a 0x7f3a06b357c1 0x7f3a068d5457 0x7f3a068d6080 0x7f3a06bf471a 0x7f3a0867213e 0x7f3a06b35c72 0x7f3a14bcfa68 0x7f3a14c8ab04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/08 18:53:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.4795 s / img. ETA=0:06:33\n",
            "\u001b[32m[07/08 18:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 12/57. 0.4784 s / img. ETA=0:06:24\n",
            "\u001b[32m[07/08 18:54:14 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.4785 s / img. ETA=0:06:15\n",
            "\u001b[32m[07/08 18:54:23 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.4565 s / img. ETA=0:05:28\n",
            "\u001b[32m[07/08 18:54:33 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.4425 s / img. ETA=0:04:53\n",
            "\u001b[32m[07/08 18:54:43 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.4335 s / img. ETA=0:04:25\n",
            "\u001b[32m[07/08 18:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.4256 s / img. ETA=0:04:02\n",
            "\u001b[32m[07/08 18:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.4199 s / img. ETA=0:03:41\n",
            "\u001b[32m[07/08 18:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.4152 s / img. ETA=0:03:23\n",
            "\u001b[32m[07/08 18:55:22 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.4108 s / img. ETA=0:03:07\n",
            "\u001b[32m[07/08 18:55:32 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.4066 s / img. ETA=0:02:51\n",
            "\u001b[32m[07/08 18:55:42 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.4036 s / img. ETA=0:02:36\n",
            "\u001b[32m[07/08 18:55:52 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.4019 s / img. ETA=0:02:22\n",
            "\u001b[32m[07/08 18:56:01 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.4001 s / img. ETA=0:02:09\n",
            "\u001b[32m[07/08 18:56:11 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.3983 s / img. ETA=0:01:55\n",
            "\u001b[32m[07/08 18:56:20 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.3963 s / img. ETA=0:01:43\n",
            "\u001b[32m[07/08 18:56:30 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.3948 s / img. ETA=0:01:30\n",
            "\u001b[32m[07/08 18:56:41 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.3880 s / img. ETA=0:01:11\n",
            "\u001b[32m[07/08 18:56:49 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.3897 s / img. ETA=0:01:07\n",
            "\u001b[32m[07/08 18:56:56 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.3913 s / img. ETA=0:01:02\n",
            "\u001b[32m[07/08 18:57:04 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.3927 s / img. ETA=0:00:56\n",
            "\u001b[32m[07/08 18:57:12 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.3942 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/08 18:57:17 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.3956 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/08 18:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.3978 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/08 18:57:29 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.4002 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/08 18:57:34 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.4023 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/08 18:57:40 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.4045 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/08 18:57:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:35.159771 (5.291534 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 18:57:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.404488 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 18:57:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 18:57:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 18:57:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.59s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.056\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.045\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.176\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.282\n",
            "\u001b[32m[07/08 18:57:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.564 | 11.082 | 4.538  |  nan  |  nan  | 5.564 |\n",
            "\u001b[32m[07/08 18:57:41 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 18:57:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 14.251 | brec_Cht         | 0.000 | lam_Sltst  | 3.847 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 9.719 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.80s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.057\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.176\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n",
            "\u001b[32m[07/08 18:57:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.673 | 11.132 | 5.273  |  nan  |  nan  | 5.673 |\n",
            "\u001b[32m[07/08 18:57:42 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 18:57:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 15.642 | brec_Cht         | 0.000 | lam_Sltst  | 3.895 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 8.830 |            |       |\n",
            "\u001b[32m[07/08 18:57:42 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/08 18:57:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 18:57:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 18:57:42 d2.evaluation.testing]: \u001b[0mcopypaste: 5.5635,11.0821,4.5380,nan,nan,5.5635\n",
            "\u001b[32m[07/08 18:57:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 18:57:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 18:57:42 d2.evaluation.testing]: \u001b[0mcopypaste: 5.6732,11.1322,5.2728,nan,nan,5.6733\n",
            "\u001b[32m[07/08 18:57:46 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 66           |   brec_Cht    | 0            | lam_Sltst  | 25           |\n",
            "| skel_WkstPkst | 6            | strless_Slt.. | 16           |            |              |\n",
            "|     total     | 113          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/08 18:57:46 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 18:57:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/08 18:57:46 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_3_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/08 18:57:46 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_3_val' to COCO format ...)\n",
            "\u001b[32m[07/08 18:57:49 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/08 18:57:49 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 14, #annotations: 113\n",
            "\u001b[32m[07/08 18:57:49 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_3_val_coco_format.json' ...\n",
            "\u001b[32m[07/08 18:57:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 18:58:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.3703 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/08 18:58:31 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.3908 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.820234 (2.868915 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.397197 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.071\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.156\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.022\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.247\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.342\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 7.128 | 15.595 | 5.454  |  nan  |  nan  | 7.128 |\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 18.212 | brec_Cht         | nan   | lam_Sltst  | 3.654 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 6.646 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.023\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.249\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.348\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 7.373 | 15.076 | 6.640  |  nan  |  nan  | 7.373 |\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 19.519 | brec_Cht         | nan   | lam_Sltst  | 3.497 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 6.475 |            |       |\n",
            "\u001b[32m[07/08 18:58:34 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.testing]: \u001b[0mcopypaste: 7.1279,15.5950,5.4544,nan,nan,7.1279\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 18:58:34 d2.evaluation.testing]: \u001b[0mcopypaste: 7.3727,15.0760,6.6402,nan,nan,7.3727\n",
            "\u001b[32m[07/08 18:58:35 d2.utils.events]: \u001b[0m eta: 1:53:46  iter: 199  total_loss: 1.566  loss_cls: 0.507  loss_box_reg: 0.565  loss_mask: 0.340  loss_rpn_cls: 0.025  loss_rpn_loc: 0.118  time: 3.7889  data_time: 2.1190  lr: 0.000200  max_mem: 8886M\n",
            "\u001b[32m[07/08 18:59:51 d2.utils.events]: \u001b[0m eta: 1:52:26  iter: 219  total_loss: 1.511  loss_cls: 0.504  loss_box_reg: 0.548  loss_mask: 0.317  loss_rpn_cls: 0.024  loss_rpn_loc: 0.118  time: 3.7907  data_time: 2.1477  lr: 0.000220  max_mem: 8886M\n",
            "\u001b[32m[07/08 19:01:07 d2.utils.events]: \u001b[0m eta: 1:51:11  iter: 239  total_loss: 1.421  loss_cls: 0.483  loss_box_reg: 0.521  loss_mask: 0.295  loss_rpn_cls: 0.022  loss_rpn_loc: 0.111  time: 3.7933  data_time: 2.1466  lr: 0.000240  max_mem: 8886M\n",
            "\u001b[32m[07/08 19:02:24 d2.utils.events]: \u001b[0m eta: 1:49:55  iter: 259  total_loss: 1.424  loss_cls: 0.507  loss_box_reg: 0.522  loss_mask: 0.274  loss_rpn_cls: 0.021  loss_rpn_loc: 0.108  time: 3.7955  data_time: 2.1610  lr: 0.000260  max_mem: 8886M\n",
            "\u001b[32m[07/08 19:03:41 d2.utils.events]: \u001b[0m eta: 1:48:47  iter: 279  total_loss: 1.312  loss_cls: 0.458  loss_box_reg: 0.474  loss_mask: 0.256  loss_rpn_cls: 0.020  loss_rpn_loc: 0.109  time: 3.7994  data_time: 2.1485  lr: 0.000280  max_mem: 8886M\n",
            "\u001b[32m[07/08 19:04:58 d2.utils.events]: \u001b[0m eta: 1:47:37  iter: 299  total_loss: 1.244  loss_cls: 0.458  loss_box_reg: 0.418  loss_mask: 0.244  loss_rpn_cls: 0.018  loss_rpn_loc: 0.107  time: 3.8027  data_time: 2.1712  lr: 0.000300  max_mem: 8886M\n",
            "\u001b[32m[07/08 19:06:14 d2.utils.events]: \u001b[0m eta: 1:46:12  iter: 319  total_loss: 1.212  loss_cls: 0.452  loss_box_reg: 0.412  loss_mask: 0.222  loss_rpn_cls: 0.019  loss_rpn_loc: 0.105  time: 3.8044  data_time: 2.1541  lr: 0.000320  max_mem: 8886M\n",
            "\u001b[32m[07/08 19:07:32 d2.utils.events]: \u001b[0m eta: 1:45:05  iter: 339  total_loss: 1.118  loss_cls: 0.431  loss_box_reg: 0.351  loss_mask: 0.211  loss_rpn_cls: 0.014  loss_rpn_loc: 0.112  time: 3.8086  data_time: 2.1960  lr: 0.000340  max_mem: 8886M\n",
            "\u001b[32m[07/08 19:08:48 d2.utils.events]: \u001b[0m eta: 1:43:57  iter: 359  total_loss: 1.100  loss_cls: 0.428  loss_box_reg: 0.342  loss_mask: 0.204  loss_rpn_cls: 0.012  loss_rpn_loc: 0.099  time: 3.8097  data_time: 2.1299  lr: 0.000360  max_mem: 8886M\n",
            "\u001b[32m[07/08 19:10:05 d2.utils.events]: \u001b[0m eta: 1:42:45  iter: 379  total_loss: 1.044  loss_cls: 0.405  loss_box_reg: 0.323  loss_mask: 0.196  loss_rpn_cls: 0.011  loss_rpn_loc: 0.105  time: 3.8122  data_time: 2.1549  lr: 0.000380  max_mem: 8886M\n",
            "\u001b[32m[07/08 19:11:33 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 19:11:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 19:11:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 19:12:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.4175 s / img. ETA=0:03:28\n",
            "\u001b[32m[07/08 19:12:35 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.3883 s / img. ETA=0:03:04\n",
            "\u001b[32m[07/08 19:12:42 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.3070 s / img. ETA=0:01:59\n",
            "\u001b[32m[07/08 19:12:47 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2662 s / img. ETA=0:01:26\n",
            "\u001b[32m[07/08 19:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 27/57. 0.2504 s / img. ETA=0:01:09\n",
            "\u001b[32m[07/08 19:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.2359 s / img. ETA=0:00:53\n",
            "\u001b[32m[07/08 19:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.2364 s / img. ETA=0:00:49\n",
            "\u001b[32m[07/08 19:13:11 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.2389 s / img. ETA=0:00:46\n",
            "\u001b[32m[07/08 19:13:19 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.2440 s / img. ETA=0:00:44\n",
            "\u001b[32m[07/08 19:13:24 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.2484 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/08 19:13:30 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.2398 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/08 19:13:36 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.2434 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/08 19:13:43 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.2508 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/08 19:13:49 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.2591 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/08 19:13:55 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.2655 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/08 19:14:00 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.2717 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 19:14:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:00.132470 (2.310240 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:14:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.272125 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:14:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 19:14:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 19:14:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.41s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.463\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.631\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.631\n",
            "\u001b[32m[07/08 19:14:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 30.223 | 46.255 | 34.161 |  nan  |  nan  | 30.223 |\n",
            "\u001b[32m[07/08 19:14:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:14:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 43.424 | brec_Cht         | 20.502 | lam_Sltst  | 15.283 |\n",
            "| skel_WkstPkst | 27.078 | strless_SltstSst | 44.829 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.08s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.62s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.459\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.382\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.583\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.685\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685\n",
            "\u001b[32m[07/08 19:14:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 33.471 | 45.890 | 38.153 |  nan  |  nan  | 33.471 |\n",
            "\u001b[32m[07/08 19:14:03 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:14:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 46.064 | brec_Cht         | 25.947 | lam_Sltst  | 18.159 |\n",
            "| skel_WkstPkst | 32.902 | strless_SltstSst | 44.283 |            |        |\n",
            "\u001b[32m[07/08 19:14:03 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/08 19:14:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 19:14:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:14:03 d2.evaluation.testing]: \u001b[0mcopypaste: 30.2231,46.2554,34.1606,nan,nan,30.2231\n",
            "\u001b[32m[07/08 19:14:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 19:14:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:14:03 d2.evaluation.testing]: \u001b[0mcopypaste: 33.4708,45.8905,38.1530,nan,nan,33.4709\n",
            "\u001b[32m[07/08 19:14:06 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 19:14:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 19:14:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 19:14:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1926 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/08 19:14:43 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2383 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.419062 (2.046562 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.260438 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.207\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.329\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 20.727 | 32.934 | 23.508 |  nan  |  nan  | 20.727 |\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 37.016 | brec_Cht         | nan    | lam_Sltst  | 17.191 |\n",
            "| skel_WkstPkst | 12.836 | strless_SltstSst | 15.864 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.207\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.220\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.456\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.577\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 21.953 | 33.857 | 20.725 |  nan  |  nan  | 21.953 |\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 39.951 | brec_Cht         | nan    | lam_Sltst  | 15.369 |\n",
            "| skel_WkstPkst | 15.905 | strless_SltstSst | 16.588 |            |        |\n",
            "\u001b[32m[07/08 19:14:46 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.testing]: \u001b[0mcopypaste: 20.7266,32.9343,23.5081,nan,nan,20.7266\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:14:46 d2.evaluation.testing]: \u001b[0mcopypaste: 21.9532,33.8574,20.7253,nan,nan,21.9532\n",
            "\u001b[32m[07/08 19:14:46 d2.utils.events]: \u001b[0m eta: 1:41:25  iter: 399  total_loss: 0.949  loss_cls: 0.379  loss_box_reg: 0.282  loss_mask: 0.183  loss_rpn_cls: 0.010  loss_rpn_loc: 0.104  time: 3.8114  data_time: 2.1185  lr: 0.000400  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:16:02 d2.utils.events]: \u001b[0m eta: 1:40:09  iter: 419  total_loss: 0.905  loss_cls: 0.352  loss_box_reg: 0.276  loss_mask: 0.181  loss_rpn_cls: 0.009  loss_rpn_loc: 0.097  time: 3.8121  data_time: 2.1182  lr: 0.000420  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:17:19 d2.utils.events]: \u001b[0m eta: 1:39:00  iter: 439  total_loss: 0.928  loss_cls: 0.356  loss_box_reg: 0.276  loss_mask: 0.175  loss_rpn_cls: 0.011  loss_rpn_loc: 0.098  time: 3.8136  data_time: 2.1392  lr: 0.000440  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:18:37 d2.utils.events]: \u001b[0m eta: 1:37:48  iter: 459  total_loss: 0.852  loss_cls: 0.331  loss_box_reg: 0.259  loss_mask: 0.164  loss_rpn_cls: 0.009  loss_rpn_loc: 0.096  time: 3.8169  data_time: 2.1502  lr: 0.000460  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:19:54 d2.utils.events]: \u001b[0m eta: 1:36:35  iter: 479  total_loss: 0.813  loss_cls: 0.288  loss_box_reg: 0.247  loss_mask: 0.162  loss_rpn_cls: 0.010  loss_rpn_loc: 0.097  time: 3.8186  data_time: 2.1826  lr: 0.000480  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:21:13 d2.utils.events]: \u001b[0m eta: 1:35:20  iter: 499  total_loss: 0.772  loss_cls: 0.282  loss_box_reg: 0.247  loss_mask: 0.155  loss_rpn_cls: 0.006  loss_rpn_loc: 0.086  time: 3.8224  data_time: 2.1683  lr: 0.000500  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:22:30 d2.utils.events]: \u001b[0m eta: 1:34:08  iter: 519  total_loss: 0.707  loss_cls: 0.253  loss_box_reg: 0.217  loss_mask: 0.145  loss_rpn_cls: 0.008  loss_rpn_loc: 0.091  time: 3.8239  data_time: 2.1530  lr: 0.000519  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:23:48 d2.utils.events]: \u001b[0m eta: 1:32:53  iter: 539  total_loss: 0.698  loss_cls: 0.246  loss_box_reg: 0.218  loss_mask: 0.142  loss_rpn_cls: 0.007  loss_rpn_loc: 0.085  time: 3.8263  data_time: 2.1499  lr: 0.000539  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:25:05 d2.utils.events]: \u001b[0m eta: 1:31:37  iter: 559  total_loss: 0.656  loss_cls: 0.219  loss_box_reg: 0.193  loss_mask: 0.134  loss_rpn_cls: 0.006  loss_rpn_loc: 0.084  time: 3.8270  data_time: 2.1329  lr: 0.000559  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:26:22 d2.utils.events]: \u001b[0m eta: 1:30:25  iter: 579  total_loss: 0.640  loss_cls: 0.216  loss_box_reg: 0.208  loss_mask: 0.132  loss_rpn_cls: 0.006  loss_rpn_loc: 0.085  time: 3.8285  data_time: 2.1389  lr: 0.000579  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:27:51 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 19:27:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 19:27:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 19:28:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2756 s / img. ETA=0:02:08\n",
            "\u001b[32m[07/08 19:28:31 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.2291 s / img. ETA=0:01:32\n",
            "\u001b[32m[07/08 19:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.1812 s / img. ETA=0:00:52\n",
            "\u001b[32m[07/08 19:28:42 d2.evaluation.evaluator]: \u001b[0mInference done 30/57. 0.1643 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/08 19:28:49 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1669 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/08 19:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1689 s / img. ETA=0:00:28\n",
            "\u001b[32m[07/08 19:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1739 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/08 19:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1698 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/08 19:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1714 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/08 19:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1791 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/08 19:29:23 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1879 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/08 19:29:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:18.055225 (1.501062 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:29:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.190012 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:29:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 19:29:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 19:29:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.32s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.699\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.869\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.834\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.699\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.762\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.825\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.825\n",
            "\u001b[32m[07/08 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 69.896 | 86.931 | 83.386 |  nan  |  nan  | 69.896 |\n",
            "\u001b[32m[07/08 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 73.939 | brec_Cht         | 71.244 | lam_Sltst  | 56.086 |\n",
            "| skel_WkstPkst | 70.488 | strless_SltstSst | 77.722 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.43s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.719\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.867\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.820\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.846\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.846\n",
            "\u001b[32m[07/08 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 71.920 | 86.665 | 81.984 |  nan  |  nan  | 71.920 |\n",
            "\u001b[32m[07/08 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 76.562 | brec_Cht         | 76.090 | lam_Sltst  | 52.544 |\n",
            "| skel_WkstPkst | 75.447 | strless_SltstSst | 78.957 |            |        |\n",
            "\u001b[32m[07/08 19:29:28 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/08 19:29:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 19:29:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:29:28 d2.evaluation.testing]: \u001b[0mcopypaste: 69.8956,86.9312,83.3857,nan,nan,69.8956\n",
            "\u001b[32m[07/08 19:29:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 19:29:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:29:28 d2.evaluation.testing]: \u001b[0mcopypaste: 71.9202,86.6651,81.9842,nan,nan,71.9203\n",
            "\u001b[32m[07/08 19:29:31 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 19:29:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 19:29:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 19:29:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1369 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/08 19:29:54 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1836 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.869409 (1.318823 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.183582 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.413\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.246\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.409\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.595 | 41.293 | 24.570 |  nan  |  nan  | 25.595 |\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 33.552 | brec_Cht         | nan    | lam_Sltst  | 15.742 |\n",
            "| skel_WkstPkst | 24.686 | strless_SltstSst | 28.400 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.418\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.271\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.123\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.439\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.517\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 27.112 | 41.826 | 25.961 |  nan  |  nan  | 27.112 |\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 35.647 | brec_Cht         | nan    | lam_Sltst  | 15.849 |\n",
            "| skel_WkstPkst | 26.931 | strless_SltstSst | 30.021 |            |        |\n",
            "\u001b[32m[07/08 19:29:55 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.testing]: \u001b[0mcopypaste: 25.5952,41.2934,24.5700,nan,nan,25.5952\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:29:55 d2.evaluation.testing]: \u001b[0mcopypaste: 27.1118,41.8264,25.9613,nan,nan,27.1118\n",
            "\u001b[32m[07/08 19:29:55 d2.utils.events]: \u001b[0m eta: 1:29:08  iter: 599  total_loss: 0.601  loss_cls: 0.200  loss_box_reg: 0.189  loss_mask: 0.133  loss_rpn_cls: 0.005  loss_rpn_loc: 0.083  time: 3.8291  data_time: 2.1082  lr: 0.000599  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:31:11 d2.utils.events]: \u001b[0m eta: 1:27:53  iter: 619  total_loss: 0.579  loss_cls: 0.176  loss_box_reg: 0.177  loss_mask: 0.127  loss_rpn_cls: 0.005  loss_rpn_loc: 0.088  time: 3.8290  data_time: 2.1179  lr: 0.000619  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:32:28 d2.utils.events]: \u001b[0m eta: 1:26:36  iter: 639  total_loss: 0.524  loss_cls: 0.157  loss_box_reg: 0.161  loss_mask: 0.118  loss_rpn_cls: 0.005  loss_rpn_loc: 0.075  time: 3.8295  data_time: 2.1425  lr: 0.000639  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:33:48 d2.utils.events]: \u001b[0m eta: 1:25:23  iter: 659  total_loss: 0.535  loss_cls: 0.157  loss_box_reg: 0.180  loss_mask: 0.121  loss_rpn_cls: 0.006  loss_rpn_loc: 0.079  time: 3.8350  data_time: 2.2435  lr: 0.000659  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:35:06 d2.utils.events]: \u001b[0m eta: 1:24:10  iter: 679  total_loss: 0.506  loss_cls: 0.140  loss_box_reg: 0.156  loss_mask: 0.117  loss_rpn_cls: 0.005  loss_rpn_loc: 0.076  time: 3.8362  data_time: 2.1704  lr: 0.000679  max_mem: 9273M\n",
            "\u001b[32m[07/08 19:36:25 d2.utils.events]: \u001b[0m eta: 1:22:54  iter: 699  total_loss: 0.484  loss_cls: 0.132  loss_box_reg: 0.152  loss_mask: 0.114  loss_rpn_cls: 0.004  loss_rpn_loc: 0.073  time: 3.8393  data_time: 2.2110  lr: 0.000699  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:37:46 d2.utils.events]: \u001b[0m eta: 1:21:44  iter: 719  total_loss: 0.445  loss_cls: 0.117  loss_box_reg: 0.142  loss_mask: 0.112  loss_rpn_cls: 0.003  loss_rpn_loc: 0.077  time: 3.8449  data_time: 2.2839  lr: 0.000719  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:39:06 d2.utils.events]: \u001b[0m eta: 1:20:40  iter: 739  total_loss: 0.441  loss_cls: 0.111  loss_box_reg: 0.138  loss_mask: 0.102  loss_rpn_cls: 0.003  loss_rpn_loc: 0.077  time: 3.8494  data_time: 2.2770  lr: 0.000739  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:40:26 d2.utils.events]: \u001b[0m eta: 1:19:29  iter: 759  total_loss: 0.423  loss_cls: 0.111  loss_box_reg: 0.130  loss_mask: 0.106  loss_rpn_cls: 0.003  loss_rpn_loc: 0.074  time: 3.8530  data_time: 2.3006  lr: 0.000759  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:41:42 d2.utils.events]: \u001b[0m eta: 1:18:08  iter: 779  total_loss: 0.412  loss_cls: 0.096  loss_box_reg: 0.128  loss_mask: 0.103  loss_rpn_cls: 0.002  loss_rpn_loc: 0.068  time: 3.8523  data_time: 2.0803  lr: 0.000779  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:43:13 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 19:43:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 19:43:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 19:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1938 s / img. ETA=0:01:00\n",
            "\u001b[32m[07/08 19:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1496 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/08 19:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1356 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/08 19:43:47 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.1341 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/08 19:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1348 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/08 19:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1331 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/08 19:44:03 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1370 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/08 19:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1466 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/08 19:44:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:51.710946 (0.994441 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:44:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.149818 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:44:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 19:44:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 19:44:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.858\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.982\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.978\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.858\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.881\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.902\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.902\n",
            "\u001b[32m[07/08 19:44:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 85.772 | 98.203 | 97.796 |  nan  |  nan  | 85.772 |\n",
            "\u001b[32m[07/08 19:44:15 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:44:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 86.961 | brec_Cht         | 90.820 | lam_Sltst  | 80.886 |\n",
            "| skel_WkstPkst | 85.520 | strless_SltstSst | 84.672 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.36s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.852\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.982\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.964\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.852\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.872\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.893\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.893\n",
            "\u001b[32m[07/08 19:44:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 85.169 | 98.203 | 96.419 |  nan  |  nan  | 85.170 |\n",
            "\u001b[32m[07/08 19:44:15 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:44:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 87.102 | brec_Cht         | 87.774 | lam_Sltst  | 77.038 |\n",
            "| skel_WkstPkst | 87.575 | strless_SltstSst | 86.356 |            |        |\n",
            "\u001b[32m[07/08 19:44:15 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/08 19:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 19:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: 85.7720,98.2030,97.7958,nan,nan,85.7721\n",
            "\u001b[32m[07/08 19:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 19:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:44:15 d2.evaluation.testing]: \u001b[0mcopypaste: 85.1691,98.2030,96.4193,nan,nan,85.1701\n",
            "\u001b[32m[07/08 19:44:18 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 19:44:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 19:44:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 19:44:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1269 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.093425 (1.121492 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.159452 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.237\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.247\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.394\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.479\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 24.697 | 40.316 | 23.682 |  nan  |  nan  | 24.697 |\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 32.484 | brec_Cht         | nan    | lam_Sltst  | 13.569 |\n",
            "| skel_WkstPkst | 28.614 | strless_SltstSst | 24.120 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.254\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.406\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.256\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.490\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.435 | 40.594 | 25.552 |  nan  |  nan  | 25.435 |\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 32.905 | brec_Cht         | nan    | lam_Sltst  | 11.683 |\n",
            "| skel_WkstPkst | 31.475 | strless_SltstSst | 25.677 |            |        |\n",
            "\u001b[32m[07/08 19:44:36 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.testing]: \u001b[0mcopypaste: 24.6967,40.3163,23.6821,nan,nan,24.6967\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:44:36 d2.evaluation.testing]: \u001b[0mcopypaste: 25.4350,40.5941,25.5520,nan,nan,25.4350\n",
            "\u001b[32m[07/08 19:44:36 d2.utils.events]: \u001b[0m eta: 1:16:53  iter: 799  total_loss: 0.395  loss_cls: 0.101  loss_box_reg: 0.127  loss_mask: 0.099  loss_rpn_cls: 0.002  loss_rpn_loc: 0.070  time: 3.8543  data_time: 2.2215  lr: 0.000799  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:45:56 d2.utils.events]: \u001b[0m eta: 1:15:39  iter: 819  total_loss: 0.377  loss_cls: 0.086  loss_box_reg: 0.115  loss_mask: 0.097  loss_rpn_cls: 0.002  loss_rpn_loc: 0.072  time: 3.8578  data_time: 2.2356  lr: 0.000819  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:47:16 d2.utils.events]: \u001b[0m eta: 1:14:24  iter: 839  total_loss: 0.361  loss_cls: 0.083  loss_box_reg: 0.115  loss_mask: 0.095  loss_rpn_cls: 0.002  loss_rpn_loc: 0.061  time: 3.8608  data_time: 2.2377  lr: 0.000839  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:48:36 d2.utils.events]: \u001b[0m eta: 1:13:12  iter: 859  total_loss: 0.358  loss_cls: 0.079  loss_box_reg: 0.121  loss_mask: 0.095  loss_rpn_cls: 0.003  loss_rpn_loc: 0.070  time: 3.8644  data_time: 2.2666  lr: 0.000859  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:49:56 d2.utils.events]: \u001b[0m eta: 1:11:58  iter: 879  total_loss: 0.352  loss_cls: 0.076  loss_box_reg: 0.114  loss_mask: 0.094  loss_rpn_cls: 0.003  loss_rpn_loc: 0.068  time: 3.8677  data_time: 2.2495  lr: 0.000879  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:51:15 d2.utils.events]: \u001b[0m eta: 1:10:44  iter: 899  total_loss: 0.331  loss_cls: 0.071  loss_box_reg: 0.109  loss_mask: 0.089  loss_rpn_cls: 0.003  loss_rpn_loc: 0.056  time: 3.8697  data_time: 2.2225  lr: 0.000899  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:52:35 d2.utils.events]: \u001b[0m eta: 1:09:32  iter: 919  total_loss: 0.328  loss_cls: 0.066  loss_box_reg: 0.107  loss_mask: 0.090  loss_rpn_cls: 0.002  loss_rpn_loc: 0.061  time: 3.8721  data_time: 2.2294  lr: 0.000919  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:53:53 d2.utils.events]: \u001b[0m eta: 1:08:16  iter: 939  total_loss: 0.302  loss_cls: 0.063  loss_box_reg: 0.100  loss_mask: 0.088  loss_rpn_cls: 0.003  loss_rpn_loc: 0.058  time: 3.8727  data_time: 2.1830  lr: 0.000939  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:55:10 d2.utils.events]: \u001b[0m eta: 1:06:58  iter: 959  total_loss: 0.313  loss_cls: 0.058  loss_box_reg: 0.101  loss_mask: 0.088  loss_rpn_cls: 0.002  loss_rpn_loc: 0.058  time: 3.8724  data_time: 2.1457  lr: 0.000959  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:56:27 d2.utils.events]: \u001b[0m eta: 1:05:41  iter: 979  total_loss: 0.323  loss_cls: 0.061  loss_box_reg: 0.108  loss_mask: 0.084  loss_rpn_cls: 0.003  loss_rpn_loc: 0.062  time: 3.8718  data_time: 2.1341  lr: 0.000979  max_mem: 9282M\n",
            "\u001b[32m[07/08 19:57:56 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 19:57:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 19:57:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 19:58:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1690 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/08 19:58:16 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1306 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/08 19:58:21 d2.evaluation.evaluator]: \u001b[0mInference done 30/57. 0.1236 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/08 19:58:27 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.1221 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/08 19:58:32 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1187 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/08 19:58:37 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1224 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/08 19:58:43 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1298 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:40.337000 (0.775712 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.129849 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.890\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.998\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.998\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.890\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.205\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.900\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.918\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.918\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 88.971 | 99.828 | 99.828 |  nan  |  nan  | 88.971 |\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 90.691 | brec_Cht         | 90.302 | lam_Sltst  | 88.467 |\n",
            "| skel_WkstPkst | 86.335 | strless_SltstSst | 89.063 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.29s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.896\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.998\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.996\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.896\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.903\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.921\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.921\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 89.603 | 99.828 | 99.630 |  nan  |  nan  | 89.603 |\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 90.470 | brec_Cht         | 90.279 | lam_Sltst  | 86.386 |\n",
            "| skel_WkstPkst | 91.489 | strless_SltstSst | 89.392 |            |        |\n",
            "\u001b[32m[07/08 19:58:45 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.testing]: \u001b[0mcopypaste: 88.9715,99.8278,99.8278,nan,nan,88.9715\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:58:45 d2.evaluation.testing]: \u001b[0mcopypaste: 89.6031,99.8278,99.6296,nan,nan,89.6031\n",
            "\u001b[32m[07/08 19:58:48 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 19:58:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 19:58:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 19:58:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1066 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.402045 (0.822449 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.134296 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.442\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.122\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.401\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.441\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.105 | 44.237 | 27.906 |  nan  |  nan  | 28.105 |\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 36.164 | brec_Cht         | nan    | lam_Sltst  | 17.416 |\n",
            "| skel_WkstPkst | 30.297 | strless_SltstSst | 28.541 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.454\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.275\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.420\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.464\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 29.244 | 45.435 | 27.475 |  nan  |  nan  | 29.244 |\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 36.111 | brec_Cht         | nan    | lam_Sltst  | 15.990 |\n",
            "| skel_WkstPkst | 33.663 | strless_SltstSst | 31.211 |            |        |\n",
            "\u001b[32m[07/08 19:59:02 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.testing]: \u001b[0mcopypaste: 28.1046,44.2366,27.9057,nan,nan,28.1046\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 19:59:02 d2.evaluation.testing]: \u001b[0mcopypaste: 29.2438,45.4351,27.4747,nan,nan,29.2438\n",
            "\u001b[32m[07/08 19:59:02 d2.utils.events]: \u001b[0m eta: 1:04:24  iter: 999  total_loss: 0.312  loss_cls: 0.055  loss_box_reg: 0.103  loss_mask: 0.083  loss_rpn_cls: 0.002  loss_rpn_loc: 0.061  time: 3.8715  data_time: 2.1470  lr: 0.000999  max_mem: 9282M\n",
            "\u001b[32m[07/08 20:00:19 d2.utils.events]: \u001b[0m eta: 1:03:08  iter: 1019  total_loss: 0.291  loss_cls: 0.057  loss_box_reg: 0.096  loss_mask: 0.084  loss_rpn_cls: 0.002  loss_rpn_loc: 0.056  time: 3.8704  data_time: 2.0782  lr: 0.001000  max_mem: 9282M\n",
            "\u001b[32m[07/08 20:01:35 d2.utils.events]: \u001b[0m eta: 1:01:52  iter: 1039  total_loss: 0.287  loss_cls: 0.050  loss_box_reg: 0.092  loss_mask: 0.081  loss_rpn_cls: 0.001  loss_rpn_loc: 0.055  time: 3.8697  data_time: 2.1266  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:02:53 d2.utils.events]: \u001b[0m eta: 1:00:43  iter: 1059  total_loss: 0.288  loss_cls: 0.052  loss_box_reg: 0.100  loss_mask: 0.080  loss_rpn_cls: 0.001  loss_rpn_loc: 0.053  time: 3.8700  data_time: 2.1219  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:04:10 d2.utils.events]: \u001b[0m eta: 0:59:26  iter: 1079  total_loss: 0.278  loss_cls: 0.048  loss_box_reg: 0.096  loss_mask: 0.081  loss_rpn_cls: 0.001  loss_rpn_loc: 0.053  time: 3.8693  data_time: 2.1213  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:05:27 d2.utils.events]: \u001b[0m eta: 0:58:11  iter: 1099  total_loss: 0.283  loss_cls: 0.048  loss_box_reg: 0.099  loss_mask: 0.076  loss_rpn_cls: 0.003  loss_rpn_loc: 0.054  time: 3.8690  data_time: 2.1412  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:06:44 d2.utils.events]: \u001b[0m eta: 0:56:55  iter: 1119  total_loss: 0.280  loss_cls: 0.049  loss_box_reg: 0.098  loss_mask: 0.080  loss_rpn_cls: 0.002  loss_rpn_loc: 0.054  time: 3.8687  data_time: 2.1307  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:08:00 d2.utils.events]: \u001b[0m eta: 0:55:37  iter: 1139  total_loss: 0.265  loss_cls: 0.047  loss_box_reg: 0.089  loss_mask: 0.078  loss_rpn_cls: 0.002  loss_rpn_loc: 0.047  time: 3.8677  data_time: 2.0897  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:09:17 d2.utils.events]: \u001b[0m eta: 0:54:19  iter: 1159  total_loss: 0.271  loss_cls: 0.044  loss_box_reg: 0.092  loss_mask: 0.078  loss_rpn_cls: 0.001  loss_rpn_loc: 0.052  time: 3.8671  data_time: 2.1043  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:10:35 d2.utils.events]: \u001b[0m eta: 0:53:03  iter: 1179  total_loss: 0.264  loss_cls: 0.043  loss_box_reg: 0.091  loss_mask: 0.078  loss_rpn_cls: 0.001  loss_rpn_loc: 0.052  time: 3.8674  data_time: 2.1484  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:12:03 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 20:12:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 20:12:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 20:12:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1603 s / img. ETA=0:00:46\n",
            "\u001b[32m[07/08 20:12:22 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1247 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/08 20:12:28 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1186 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/08 20:12:33 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1170 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/08 20:12:39 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1166 s / img. ETA=0:00:09\n",
            "\u001b[32m[07/08 20:12:44 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1226 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/08 20:12:49 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1278 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:39.758515 (0.764587 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.128014 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.936\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.936\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.940\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.959\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.959\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 93.625 | 99.901 | 99.901 |  nan  |  nan  | 93.625 |\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 93.836 | brec_Cht         | 93.904 | lam_Sltst  | 92.250 |\n",
            "| skel_WkstPkst | 95.122 | strless_SltstSst | 93.012 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.914\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.914\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.919\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.937\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.937\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 91.398 | 99.901 | 99.901 |  nan  |  nan  | 91.398 |\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 91.341 | brec_Cht         | 90.105 | lam_Sltst  | 89.510 |\n",
            "| skel_WkstPkst | 95.853 | strless_SltstSst | 90.182 |            |        |\n",
            "\u001b[32m[07/08 20:12:51 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.testing]: \u001b[0mcopypaste: 93.6251,99.9013,99.9013,nan,nan,93.6251\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:12:51 d2.evaluation.testing]: \u001b[0mcopypaste: 91.3981,99.9013,99.9013,nan,nan,91.3981\n",
            "\u001b[32m[07/08 20:12:54 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 20:12:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 20:12:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 20:13:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1174 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 20:13:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.286907 (0.920767 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:13:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.143940 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:13:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 20:13:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 20:13:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.416\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.392\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.441\n",
            "\u001b[32m[07/08 20:13:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 26.216 | 41.577 | 27.152 |  nan  |  nan  | 26.216 |\n",
            "\u001b[32m[07/08 20:13:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:13:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 34.765 | brec_Cht         | nan    | lam_Sltst  | 12.244 |\n",
            "| skel_WkstPkst | 30.297 | strless_SltstSst | 27.558 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.382\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.116\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.394\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.447\n",
            "\u001b[32m[07/08 20:13:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 26.178 | 38.170 | 27.757 |  nan  |  nan  | 26.178 |\n",
            "\u001b[32m[07/08 20:13:10 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:13:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 34.344 | brec_Cht         | nan    | lam_Sltst  | 9.265 |\n",
            "| skel_WkstPkst | 31.980 | strless_SltstSst | 29.121 |            |       |\n",
            "\u001b[32m[07/08 20:13:10 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/08 20:13:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 20:13:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:13:10 d2.evaluation.testing]: \u001b[0mcopypaste: 26.2162,41.5767,27.1522,nan,nan,26.2162\n",
            "\u001b[32m[07/08 20:13:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 20:13:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:13:10 d2.evaluation.testing]: \u001b[0mcopypaste: 26.1778,38.1700,27.7573,nan,nan,26.1778\n",
            "\u001b[32m[07/08 20:13:10 d2.utils.events]: \u001b[0m eta: 0:51:45  iter: 1199  total_loss: 0.246  loss_cls: 0.041  loss_box_reg: 0.085  loss_mask: 0.075  loss_rpn_cls: 0.002  loss_rpn_loc: 0.042  time: 3.8668  data_time: 2.1043  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:14:26 d2.utils.events]: \u001b[0m eta: 0:50:28  iter: 1219  total_loss: 0.234  loss_cls: 0.038  loss_box_reg: 0.076  loss_mask: 0.075  loss_rpn_cls: 0.002  loss_rpn_loc: 0.042  time: 3.8658  data_time: 2.0824  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:15:44 d2.utils.events]: \u001b[0m eta: 0:49:11  iter: 1239  total_loss: 0.239  loss_cls: 0.039  loss_box_reg: 0.075  loss_mask: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.048  time: 3.8663  data_time: 2.1568  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:17:00 d2.utils.events]: \u001b[0m eta: 0:47:54  iter: 1259  total_loss: 0.237  loss_cls: 0.041  loss_box_reg: 0.074  loss_mask: 0.075  loss_rpn_cls: 0.001  loss_rpn_loc: 0.042  time: 3.8655  data_time: 2.1157  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:18:18 d2.utils.events]: \u001b[0m eta: 0:46:37  iter: 1279  total_loss: 0.228  loss_cls: 0.037  loss_box_reg: 0.075  loss_mask: 0.073  loss_rpn_cls: 0.001  loss_rpn_loc: 0.042  time: 3.8659  data_time: 2.1622  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:19:34 d2.utils.events]: \u001b[0m eta: 0:45:20  iter: 1299  total_loss: 0.222  loss_cls: 0.037  loss_box_reg: 0.074  loss_mask: 0.073  loss_rpn_cls: 0.001  loss_rpn_loc: 0.040  time: 3.8653  data_time: 2.1111  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:20:53 d2.utils.events]: \u001b[0m eta: 0:44:05  iter: 1319  total_loss: 0.224  loss_cls: 0.035  loss_box_reg: 0.071  loss_mask: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.039  time: 3.8660  data_time: 2.1979  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:22:09 d2.utils.events]: \u001b[0m eta: 0:42:45  iter: 1339  total_loss: 0.220  loss_cls: 0.035  loss_box_reg: 0.072  loss_mask: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.043  time: 3.8650  data_time: 2.0657  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:23:27 d2.utils.events]: \u001b[0m eta: 0:41:31  iter: 1359  total_loss: 0.229  loss_cls: 0.035  loss_box_reg: 0.081  loss_mask: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.037  time: 3.8656  data_time: 2.1800  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:24:44 d2.utils.events]: \u001b[0m eta: 0:40:13  iter: 1379  total_loss: 0.222  loss_cls: 0.036  loss_box_reg: 0.075  loss_mask: 0.073  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.8657  data_time: 2.1360  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:26:15 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 20:26:15 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 20:26:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 20:26:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1505 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/08 20:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1225 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/08 20:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1198 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/08 20:26:43 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1200 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/08 20:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.1182 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/08 20:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1243 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.936519 (0.710318 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.126617 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.929\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.929\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.930\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.949\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.949\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 92.933 | 99.961 | 99.961 |  nan  |  nan  | 92.933 |\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 92.584 | brec_Cht         | 93.733 | lam_Sltst  | 95.679 |\n",
            "| skel_WkstPkst | 91.966 | strless_SltstSst | 90.703 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.29s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.915\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.915\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.917\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.935\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.935\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 91.505 | 99.961 | 99.961 |  nan  |  nan  | 91.505 |\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 91.422 | brec_Cht         | 91.912 | lam_Sltst  | 91.261 |\n",
            "| skel_WkstPkst | 92.277 | strless_SltstSst | 90.655 |            |        |\n",
            "\u001b[32m[07/08 20:26:59 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.testing]: \u001b[0mcopypaste: 92.9330,99.9607,99.9607,nan,nan,92.9330\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:26:59 d2.evaluation.testing]: \u001b[0mcopypaste: 91.5054,99.9607,99.9607,nan,nan,91.5054\n",
            "\u001b[32m[07/08 20:27:02 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 20:27:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 20:27:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 20:27:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1123 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.410922 (0.823436 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.135345 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.467\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.423\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.469\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.848 | 46.725 | 28.524 |  nan  |  nan  | 28.848 |\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 36.976 | brec_Cht         | nan    | lam_Sltst  | 11.076 |\n",
            "| skel_WkstPkst | 36.609 | strless_SltstSst | 30.731 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.469\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.431\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.477\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 29.463 | 46.866 | 30.177 |  nan  |  nan  | 29.463 |\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 37.374 | brec_Cht         | nan    | lam_Sltst  | 8.971 |\n",
            "| skel_WkstPkst | 38.292 | strless_SltstSst | 33.215 |            |       |\n",
            "\u001b[32m[07/08 20:27:16 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.testing]: \u001b[0mcopypaste: 28.8480,46.7253,28.5242,nan,nan,28.8480\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:27:16 d2.evaluation.testing]: \u001b[0mcopypaste: 29.4630,46.8664,30.1771,nan,nan,29.4630\n",
            "\u001b[32m[07/08 20:27:16 d2.utils.events]: \u001b[0m eta: 0:38:56  iter: 1399  total_loss: 0.219  loss_cls: 0.035  loss_box_reg: 0.076  loss_mask: 0.071  loss_rpn_cls: 0.001  loss_rpn_loc: 0.039  time: 3.8662  data_time: 2.1876  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:28:34 d2.utils.events]: \u001b[0m eta: 0:37:39  iter: 1419  total_loss: 0.217  loss_cls: 0.035  loss_box_reg: 0.075  loss_mask: 0.070  loss_rpn_cls: 0.002  loss_rpn_loc: 0.038  time: 3.8664  data_time: 2.1328  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:29:51 d2.utils.events]: \u001b[0m eta: 0:36:21  iter: 1439  total_loss: 0.218  loss_cls: 0.033  loss_box_reg: 0.075  loss_mask: 0.070  loss_rpn_cls: 0.002  loss_rpn_loc: 0.044  time: 3.8666  data_time: 2.1873  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:31:08 d2.utils.events]: \u001b[0m eta: 0:35:03  iter: 1459  total_loss: 0.222  loss_cls: 0.034  loss_box_reg: 0.075  loss_mask: 0.070  loss_rpn_cls: 0.002  loss_rpn_loc: 0.038  time: 3.8665  data_time: 2.1359  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:32:25 d2.utils.events]: \u001b[0m eta: 0:33:43  iter: 1479  total_loss: 0.205  loss_cls: 0.035  loss_box_reg: 0.068  loss_mask: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.034  time: 3.8663  data_time: 2.1168  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:33:42 d2.utils.events]: \u001b[0m eta: 0:32:26  iter: 1499  total_loss: 0.196  loss_cls: 0.029  loss_box_reg: 0.062  loss_mask: 0.070  loss_rpn_cls: 0.001  loss_rpn_loc: 0.033  time: 3.8656  data_time: 2.0922  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:35:01 d2.utils.events]: \u001b[0m eta: 0:31:09  iter: 1519  total_loss: 0.210  loss_cls: 0.031  loss_box_reg: 0.067  loss_mask: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.8667  data_time: 2.2201  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:36:18 d2.utils.events]: \u001b[0m eta: 0:29:52  iter: 1539  total_loss: 0.204  loss_cls: 0.032  loss_box_reg: 0.066  loss_mask: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.036  time: 3.8668  data_time: 2.1573  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:37:36 d2.utils.events]: \u001b[0m eta: 0:28:34  iter: 1559  total_loss: 0.206  loss_cls: 0.032  loss_box_reg: 0.069  loss_mask: 0.067  loss_rpn_cls: 0.002  loss_rpn_loc: 0.039  time: 3.8670  data_time: 2.1798  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:38:53 d2.utils.events]: \u001b[0m eta: 0:27:16  iter: 1579  total_loss: 0.203  loss_cls: 0.029  loss_box_reg: 0.061  loss_mask: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.8669  data_time: 2.1372  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:40:23 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 20:40:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 20:40:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 20:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1499 s / img. ETA=0:00:41\n",
            "\u001b[32m[07/08 20:40:42 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1267 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/08 20:40:47 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1174 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/08 20:40:52 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1156 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/08 20:40:57 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1126 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/08 20:41:02 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1192 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/08 20:41:07 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1233 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.189736 (0.715187 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.123202 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.933\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.933\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.935\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.954\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.954\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 93.262 | 99.992 | 99.992 |  nan  |  nan  | 93.262 |\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 92.153 | brec_Cht         | 90.926 | lam_Sltst  | 92.762 |\n",
            "| skel_WkstPkst | 96.634 | strless_SltstSst | 93.837 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.930\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.930\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.215\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.931\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.950\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.950\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 93.026 | 99.992 | 99.992 |  nan  |  nan  | 93.026 |\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 93.968 | brec_Cht         | 92.805 | lam_Sltst  | 91.811 |\n",
            "| skel_WkstPkst | 94.761 | strless_SltstSst | 91.783 |            |        |\n",
            "\u001b[32m[07/08 20:41:08 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.testing]: \u001b[0mcopypaste: 93.2625,99.9918,99.9918,nan,nan,93.2625\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:41:08 d2.evaluation.testing]: \u001b[0mcopypaste: 93.0257,99.9918,99.9918,nan,nan,93.0257\n",
            "\u001b[32m[07/08 20:41:12 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 20:41:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 20:41:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 20:41:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1115 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 20:41:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.549434 (0.838826 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.135400 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.436\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.276\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.406\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 27.171 | 43.623 | 27.645 |  nan  |  nan  | 27.171 |\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 34.947 | brec_Cht         | nan    | lam_Sltst  | 13.500 |\n",
            "| skel_WkstPkst | 30.297 | strless_SltstSst | 29.940 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.416\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.123\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.421\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.517 | 41.625 | 30.139 |  nan  |  nan  | 28.517 |\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 35.728 | brec_Cht         | nan    | lam_Sltst  | 13.166 |\n",
            "| skel_WkstPkst | 33.663 | strless_SltstSst | 31.511 |            |        |\n",
            "\u001b[32m[07/08 20:41:26 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.testing]: \u001b[0mcopypaste: 27.1709,43.6231,27.6447,nan,nan,27.1709\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:41:26 d2.evaluation.testing]: \u001b[0mcopypaste: 28.5170,41.6253,30.1390,nan,nan,28.5170\n",
            "\u001b[32m[07/08 20:41:26 d2.utils.events]: \u001b[0m eta: 0:26:00  iter: 1599  total_loss: 0.210  loss_cls: 0.032  loss_box_reg: 0.072  loss_mask: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.039  time: 3.8673  data_time: 2.1793  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:42:42 d2.utils.events]: \u001b[0m eta: 0:24:42  iter: 1619  total_loss: 0.198  loss_cls: 0.030  loss_box_reg: 0.066  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.033  time: 3.8666  data_time: 2.0706  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:44:00 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 1639  total_loss: 0.211  loss_cls: 0.029  loss_box_reg: 0.065  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.039  time: 3.8673  data_time: 2.2127  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:45:18 d2.utils.events]: \u001b[0m eta: 0:22:07  iter: 1659  total_loss: 0.205  loss_cls: 0.031  loss_box_reg: 0.069  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.042  time: 3.8675  data_time: 2.1602  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:46:35 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 1679  total_loss: 0.195  loss_cls: 0.029  loss_box_reg: 0.065  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.035  time: 3.8673  data_time: 2.1198  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:47:52 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 1699  total_loss: 0.187  loss_cls: 0.028  loss_box_reg: 0.058  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 3.8671  data_time: 2.1603  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:49:11 d2.utils.events]: \u001b[0m eta: 0:18:13  iter: 1719  total_loss: 0.184  loss_cls: 0.027  loss_box_reg: 0.059  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.031  time: 3.8680  data_time: 2.2227  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:50:29 d2.utils.events]: \u001b[0m eta: 0:16:54  iter: 1739  total_loss: 0.194  loss_cls: 0.028  loss_box_reg: 0.061  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.034  time: 3.8685  data_time: 2.1886  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:51:46 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 1759  total_loss: 0.187  loss_cls: 0.027  loss_box_reg: 0.057  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 3.8679  data_time: 2.0957  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:53:02 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 1779  total_loss: 0.184  loss_cls: 0.026  loss_box_reg: 0.060  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 3.8675  data_time: 2.1283  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:54:31 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 20:54:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 20:54:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 20:54:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1468 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/08 20:54:49 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1227 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/08 20:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.1177 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/08 20:55:00 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1198 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/08 20:55:07 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1208 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/08 20:55:12 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1256 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 20:55:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.240301 (0.677698 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:55:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.125259 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:55:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 20:55:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 20:55:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.952\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.952\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.951\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.971\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.971\n",
            "\u001b[32m[07/08 20:55:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 95.233 | 99.983 | 99.983 |  nan  |  nan  | 95.233 |\n",
            "\u001b[32m[07/08 20:55:14 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:55:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 96.343 | brec_Cht         | 92.984 | lam_Sltst  | 94.850 |\n",
            "| skel_WkstPkst | 96.683 | strless_SltstSst | 95.302 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.935\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.935\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.215\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.934\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.953\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.953\n",
            "\u001b[32m[07/08 20:55:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 93.531 | 99.983 | 99.983 |  nan  |  nan  | 93.531 |\n",
            "\u001b[32m[07/08 20:55:14 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:55:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 95.207 | brec_Cht         | 92.164 | lam_Sltst  | 91.430 |\n",
            "| skel_WkstPkst | 96.188 | strless_SltstSst | 92.664 |            |        |\n",
            "\u001b[32m[07/08 20:55:14 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/08 20:55:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 20:55:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:55:14 d2.evaluation.testing]: \u001b[0mcopypaste: 95.2326,99.9827,99.9827,nan,nan,95.2326\n",
            "\u001b[32m[07/08 20:55:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 20:55:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:55:14 d2.evaluation.testing]: \u001b[0mcopypaste: 93.5306,99.9827,99.9827,nan,nan,93.5306\n",
            "\u001b[32m[07/08 20:55:17 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 20:55:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 20:55:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 20:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1205 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.371920 (0.819102 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.141059 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.434\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.255\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.273\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.136\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.464\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 27.324 | 43.424 | 25.493 |  nan  |  nan  | 27.324 |\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 34.774 | brec_Cht         | nan    | lam_Sltst  | 11.249 |\n",
            "| skel_WkstPkst | 34.224 | strless_SltstSst | 29.049 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.421\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.419\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.474\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.638 | 42.090 | 27.131 |  nan  |  nan  | 28.638 |\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 34.652 | brec_Cht         | nan    | lam_Sltst  | 9.033 |\n",
            "| skel_WkstPkst | 39.274 | strless_SltstSst | 31.594 |            |       |\n",
            "\u001b[32m[07/08 20:55:31 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.testing]: \u001b[0mcopypaste: 27.3244,43.4238,25.4932,nan,nan,27.3244\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 20:55:31 d2.evaluation.testing]: \u001b[0mcopypaste: 28.6383,42.0902,27.1313,nan,nan,28.6383\n",
            "\u001b[32m[07/08 20:55:31 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 1799  total_loss: 0.182  loss_cls: 0.027  loss_box_reg: 0.060  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.031  time: 3.8673  data_time: 2.1475  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:56:48 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 1819  total_loss: 0.180  loss_cls: 0.027  loss_box_reg: 0.056  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 3.8671  data_time: 2.1146  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:58:05 d2.utils.events]: \u001b[0m eta: 0:10:24  iter: 1839  total_loss: 0.178  loss_cls: 0.025  loss_box_reg: 0.059  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 3.8669  data_time: 2.1254  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 20:59:22 d2.utils.events]: \u001b[0m eta: 0:09:06  iter: 1859  total_loss: 0.180  loss_cls: 0.027  loss_box_reg: 0.055  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 3.8671  data_time: 2.1626  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 21:00:39 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 1879  total_loss: 0.177  loss_cls: 0.025  loss_box_reg: 0.053  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.031  time: 3.8667  data_time: 2.1113  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 21:01:57 d2.utils.events]: \u001b[0m eta: 0:06:30  iter: 1899  total_loss: 0.183  loss_cls: 0.025  loss_box_reg: 0.059  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.035  time: 3.8668  data_time: 2.1175  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 21:03:14 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 1919  total_loss: 0.192  loss_cls: 0.026  loss_box_reg: 0.063  loss_mask: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.036  time: 3.8667  data_time: 2.1611  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 21:04:32 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 1939  total_loss: 0.175  loss_cls: 0.025  loss_box_reg: 0.057  loss_mask: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.029  time: 3.8669  data_time: 2.1361  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 21:05:49 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 1959  total_loss: 0.179  loss_cls: 0.026  loss_box_reg: 0.055  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.035  time: 3.8667  data_time: 2.1494  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 21:07:06 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 1979  total_loss: 0.165  loss_cls: 0.023  loss_box_reg: 0.053  loss_mask: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.029  time: 3.8665  data_time: 2.1459  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 21:08:36 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 21:08:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 21:08:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 21:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1388 s / img. ETA=0:00:38\n",
            "\u001b[32m[07/08 21:08:53 d2.evaluation.evaluator]: \u001b[0mInference done 22/57. 0.1203 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/08 21:08:59 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.1167 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/08 21:09:04 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1151 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/08 21:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1174 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/08 21:09:16 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1237 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.942093 (0.671963 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.123439 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.958\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.958\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.952\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.972\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.972\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 95.789 | 99.997 | 99.997 |  nan  |  nan  | 95.789 |\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 97.841 | brec_Cht         | 91.594 | lam_Sltst  | 95.778 |\n",
            "| skel_WkstPkst | 97.588 | strless_SltstSst | 96.143 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.941\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.941\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.940\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.959\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.959\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 94.106 | 99.997 | 99.997 |  nan  |  nan  | 94.106 |\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 95.180 | brec_Cht         | 93.546 | lam_Sltst  | 93.937 |\n",
            "| skel_WkstPkst | 94.323 | strless_SltstSst | 93.544 |            |        |\n",
            "\u001b[32m[07/08 21:09:18 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_train in csv format:\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.testing]: \u001b[0mcopypaste: 95.7889,99.9968,99.9968,nan,nan,95.7889\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 21:09:18 d2.evaluation.testing]: \u001b[0mcopypaste: 94.1060,99.9968,99.9968,nan,nan,94.1060\n",
            "\u001b[32m[07/08 21:09:21 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 21:09:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 21:09:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 21:09:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1061 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.478427 (0.830936 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.131486 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.284\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.447\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.284\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.403\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.447\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.397 | 44.693 | 28.442 |  nan  |  nan  | 28.397 |\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 36.059 | brec_Cht         | nan    | lam_Sltst  | 13.928 |\n",
            "| skel_WkstPkst | 31.980 | strless_SltstSst | 31.619 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.426\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.291\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.456\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.602 | 42.619 | 29.123 |  nan  |  nan  | 28.602 |\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 36.780 | brec_Cht         | nan    | lam_Sltst  | 11.150 |\n",
            "| skel_WkstPkst | 33.663 | strless_SltstSst | 32.812 |            |        |\n",
            "\u001b[32m[07/08 21:09:35 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_3_val in csv format:\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.testing]: \u001b[0mcopypaste: 28.3966,44.6931,28.4420,nan,nan,28.3966\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/08 21:09:35 d2.evaluation.testing]: \u001b[0mcopypaste: 28.6016,42.6190,29.1227,nan,nan,28.6016\n",
            "\u001b[32m[07/08 21:09:35 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 1999  total_loss: 0.171  loss_cls: 0.026  loss_box_reg: 0.059  loss_mask: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.028  time: 3.8664  data_time: 2.1598  lr: 0.001000  max_mem: 9383M\n",
            "\u001b[32m[07/08 21:09:35 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 2:08:45 (3.8683 s / it)\n",
            "\u001b[32m[07/08 21:09:35 d2.engine.hooks]: \u001b[0mTotal training time: 2:30:09 (0:21:24 on hooks)\n",
            "\n",
            "\n",
            "**Starting train eval**\n",
            "\u001b[32m[07/08 21:09:48 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 21:09:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
            "\u001b[32m[07/08 21:09:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/08 21:10:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1517 s / img. ETA=0:01:04\n",
            "\u001b[32m[07/08 21:10:11 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1307 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/08 21:10:16 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1220 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/08 21:10:21 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.1181 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/08 21:10:26 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1166 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/08 21:10:32 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1163 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/08 21:10:38 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1212 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/08 21:10:43 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1261 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 21:10:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.584672 (0.934321 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 21:10:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.126859 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 21:10:46 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 21:10:46 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/08 21:10:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.958\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.958\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.952\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.972\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.972\n",
            "\u001b[32m[07/08 21:10:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 95.789 | 99.997 | 99.997 |  nan  |  nan  | 95.789 |\n",
            "\u001b[32m[07/08 21:10:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 21:10:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 97.841 | brec_Cht         | 91.594 | lam_Sltst  | 95.778 |\n",
            "| skel_WkstPkst | 97.588 | strless_SltstSst | 96.143 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.941\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.941\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.940\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.959\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.959\n",
            "\u001b[32m[07/08 21:10:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 94.106 | 99.997 | 99.997 |  nan  |  nan  | 94.106 |\n",
            "\u001b[32m[07/08 21:10:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 21:10:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 95.180 | brec_Cht         | 93.546 | lam_Sltst  | 93.937 |\n",
            "| skel_WkstPkst | 94.323 | strless_SltstSst | 93.544 |            |        |\n",
            "randomly selected cores/Box 8 Depths 10035-45.JPG\n",
            "\n",
            "\n",
            "**Starting val eval**\n",
            "\u001b[32m[07/08 21:11:23 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 21:11:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/08 21:11:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/08 21:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1066 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/08 21:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1264 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/08 21:11:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.936188 (1.437354 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 21:11:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.137798 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/08 21:11:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/08 21:11:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/08 21:11:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.284\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.447\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.284\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.403\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.447\n",
            "\u001b[32m[07/08 21:11:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.397 | 44.693 | 28.442 |  nan  |  nan  | 28.397 |\n",
            "\u001b[32m[07/08 21:11:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 21:11:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 36.059 | brec_Cht         | nan    | lam_Sltst  | 13.928 |\n",
            "| skel_WkstPkst | 31.980 | strless_SltstSst | 31.619 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.426\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.291\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.456\n",
            "\u001b[32m[07/08 21:11:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.602 | 42.619 | 29.123 |  nan  |  nan  | 28.602 |\n",
            "\u001b[32m[07/08 21:11:45 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/08 21:11:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 36.780 | brec_Cht         | nan    | lam_Sltst  | 11.150 |\n",
            "| skel_WkstPkst | 33.663 | strless_SltstSst | 32.812 |            |        |\n",
            "randomly selected cores/Boxes 22-24  Depths 7778.4-7786.5 (Dry).JPG\n",
            "Wed Jul  8 21:12:17 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0    45W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "CPU times: user 17.5 s, sys: 2.48 s, total: 20 s\n",
            "Wall time: 2h 33min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hUqQJAOLd-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee5a52b2-8615-4e7c-fcc0-79a936637958"
      },
      "source": [
        "%%time\n",
        "# train and evaluate\n",
        "!python train_eval.py --data_dir 'cores' --dataset_tag 'cores' --fold_idx '4' --max_iter 2000\n",
        "#check what gpu was used:\n",
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting fold 4\n",
            "\t cores_fold_4_train\n",
            "\t cores_fold_4_val\n",
            "\u001b[32m[07/08 23:56:28 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/08 23:56:40 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 56 images left.\n",
            "\u001b[32m[07/08 23:56:40 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 245          |   brec_Cht    | 17           | lam_Sltst  | 94           |\n",
            "| skel_WkstPkst | 16           | strless_Slt.. | 122          |            |              |\n",
            "|     total     | 494          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/08 23:56:40 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/08 23:56:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/08 23:56:40 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1000, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/08 23:56:40 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "2020-07-08 23:56:40.916948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model!\n",
            "Unable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model!\n",
            "\u001b[32m[07/08 23:56:43 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/08 23:57:56 d2.utils.events]: \u001b[0m eta: 1:59:22  iter: 19  total_loss: 3.400  loss_cls: 1.819  loss_box_reg: 0.342  loss_mask: 0.691  loss_rpn_cls: 0.469  loss_rpn_loc: 0.195  time: 3.6061  data_time: 2.3482  lr: 0.000020  max_mem: 7173M\n",
            "\u001b[32m[07/08 23:59:10 d2.utils.events]: \u001b[0m eta: 1:59:48  iter: 39  total_loss: 2.660  loss_cls: 1.227  loss_box_reg: 0.397  loss_mask: 0.670  loss_rpn_cls: 0.161  loss_rpn_loc: 0.170  time: 3.6480  data_time: 2.2102  lr: 0.000040  max_mem: 7680M\n",
            "\u001b[32m[07/09 00:00:23 d2.utils.events]: \u001b[0m eta: 1:58:09  iter: 59  total_loss: 1.983  loss_cls: 0.640  loss_box_reg: 0.444  loss_mask: 0.617  loss_rpn_cls: 0.075  loss_rpn_loc: 0.151  time: 3.6486  data_time: 2.1262  lr: 0.000060  max_mem: 8213M\n",
            "\u001b[32m[07/09 00:01:37 d2.utils.events]: \u001b[0m eta: 1:56:56  iter: 79  total_loss: 1.853  loss_cls: 0.605  loss_box_reg: 0.532  loss_mask: 0.552  loss_rpn_cls: 0.049  loss_rpn_loc: 0.135  time: 3.6595  data_time: 2.1175  lr: 0.000080  max_mem: 8254M\n",
            "\u001b[32m[07/09 00:02:50 d2.utils.events]: \u001b[0m eta: 1:56:36  iter: 99  total_loss: 1.755  loss_cls: 0.571  loss_box_reg: 0.520  loss_mask: 0.476  loss_rpn_cls: 0.039  loss_rpn_loc: 0.135  time: 3.6603  data_time: 2.1026  lr: 0.000100  max_mem: 8463M\n",
            "\u001b[32m[07/09 00:04:05 d2.utils.events]: \u001b[0m eta: 1:55:53  iter: 119  total_loss: 1.648  loss_cls: 0.540  loss_box_reg: 0.539  loss_mask: 0.425  loss_rpn_cls: 0.037  loss_rpn_loc: 0.132  time: 3.6749  data_time: 2.1446  lr: 0.000120  max_mem: 8463M\n",
            "\u001b[32m[07/09 00:05:19 d2.utils.events]: \u001b[0m eta: 1:54:28  iter: 139  total_loss: 1.611  loss_cls: 0.509  loss_box_reg: 0.548  loss_mask: 0.403  loss_rpn_cls: 0.027  loss_rpn_loc: 0.122  time: 3.6742  data_time: 2.0781  lr: 0.000140  max_mem: 8657M\n",
            "\u001b[32m[07/09 00:06:32 d2.utils.events]: \u001b[0m eta: 1:53:14  iter: 159  total_loss: 1.567  loss_cls: 0.490  loss_box_reg: 0.540  loss_mask: 0.374  loss_rpn_cls: 0.027  loss_rpn_loc: 0.126  time: 3.6732  data_time: 2.0490  lr: 0.000160  max_mem: 8657M\n",
            "\u001b[32m[07/09 00:07:46 d2.utils.events]: \u001b[0m eta: 1:51:57  iter: 179  total_loss: 1.628  loss_cls: 0.527  loss_box_reg: 0.585  loss_mask: 0.360  loss_rpn_cls: 0.022  loss_rpn_loc: 0.118  time: 3.6774  data_time: 2.1135  lr: 0.000180  max_mem: 8657M\n",
            "\u001b[32m[07/09 00:09:12 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 00:09:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 00:09:12 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_4_train'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/09 00:09:12 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_4_train' to COCO format ...)\n",
            "\u001b[32m[07/09 00:09:24 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/09 00:09:24 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 57, #annotations: 494\n",
            "\u001b[32m[07/09 00:09:24 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_4_train_coco_format.json' ...\n",
            "\u001b[32m[07/09 00:09:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "tcmalloc: large alloc 1136500736 bytes == 0xc6700000 @  0x7f1cf654ab6b 0x7f1cf656a379 0x7f1c99c9f04e 0x7f1c99ca0f4a 0x7f1cd2b8f67b 0x7f1cd27de6be 0x7f1cd2a477b5 0x7f1cd2a397c1 0x7f1cd2a38d0e 0x7f1cd2a397c1 0x7f1cd448e93a 0x7f1cd2a397c1 0x7f1cd27d9457 0x7f1cd27da080 0x7f1cd2af871a 0x7f1cd457613e 0x7f1cd2a39c72 0x7f1ce0ad3a68 0x7f1ce0b8eb04 0x50a635 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64\n",
            "\u001b[32m[07/09 00:11:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.4764 s / img. ETA=0:06:45\n",
            "\u001b[32m[07/09 00:11:13 d2.evaluation.evaluator]: \u001b[0mInference done 12/57. 0.4789 s / img. ETA=0:06:37\n",
            "\u001b[32m[07/09 00:11:21 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.4785 s / img. ETA=0:06:28\n",
            "\u001b[32m[07/09 00:11:30 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.4784 s / img. ETA=0:06:20\n",
            "\u001b[32m[07/09 00:11:36 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.4689 s / img. ETA=0:05:56\n",
            "\u001b[32m[07/09 00:11:41 d2.evaluation.evaluator]: \u001b[0mInference done 16/57. 0.4592 s / img. ETA=0:05:35\n",
            "\u001b[32m[07/09 00:11:46 d2.evaluation.evaluator]: \u001b[0mInference done 17/57. 0.4512 s / img. ETA=0:05:17\n",
            "\u001b[32m[07/09 00:11:51 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.4449 s / img. ETA=0:05:01\n",
            "\u001b[32m[07/09 00:11:57 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.4397 s / img. ETA=0:04:47\n",
            "\u001b[32m[07/09 00:12:02 d2.evaluation.evaluator]: \u001b[0mInference done 20/57. 0.4354 s / img. ETA=0:04:33\n",
            "\u001b[32m[07/09 00:12:07 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.4313 s / img. ETA=0:04:21\n",
            "\u001b[32m[07/09 00:12:13 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.4242 s / img. ETA=0:03:51\n",
            "\u001b[32m[07/09 00:12:20 d2.evaluation.evaluator]: \u001b[0mInference done 26/57. 0.4128 s / img. ETA=0:03:11\n",
            "\u001b[32m[07/09 00:12:27 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.4061 s / img. ETA=0:02:38\n",
            "\u001b[32m[07/09 00:12:34 d2.evaluation.evaluator]: \u001b[0mInference done 32/57. 0.3973 s / img. ETA=0:02:12\n",
            "\u001b[32m[07/09 00:12:40 d2.evaluation.evaluator]: \u001b[0mInference done 34/57. 0.3913 s / img. ETA=0:01:58\n",
            "\u001b[32m[07/09 00:12:47 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.3894 s / img. ETA=0:01:37\n",
            "\u001b[32m[07/09 00:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.3818 s / img. ETA=0:01:18\n",
            "\u001b[32m[07/09 00:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 42/57. 0.3810 s / img. ETA=0:01:09\n",
            "\u001b[32m[07/09 00:13:15 d2.evaluation.evaluator]: \u001b[0mInference done 45/57. 0.3744 s / img. ETA=0:00:55\n",
            "\u001b[32m[07/09 00:13:23 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.3762 s / img. ETA=0:00:51\n",
            "\u001b[32m[07/09 00:13:31 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.3784 s / img. ETA=0:00:47\n",
            "\u001b[32m[07/09 00:13:39 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.3806 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/09 00:13:47 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.3826 s / img. ETA=0:00:39\n",
            "\u001b[32m[07/09 00:13:55 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.3841 s / img. ETA=0:00:34\n",
            "\u001b[32m[07/09 00:14:03 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.3855 s / img. ETA=0:00:30\n",
            "\u001b[32m[07/09 00:14:10 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.3868 s / img. ETA=0:00:25\n",
            "\u001b[32m[07/09 00:14:18 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.3881 s / img. ETA=0:00:20\n",
            "\u001b[32m[07/09 00:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.3896 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/09 00:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.3910 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/09 00:14:42 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.3923 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/09 00:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.3932 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 00:14:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:38.775968 (5.361076 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 00:14:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.393192 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 00:14:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 00:14:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 00:14:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.62s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.059\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.122\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.046\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.197\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
            "\u001b[32m[07/09 00:14:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.942 | 12.223 | 4.605  |  nan  |  nan  | 5.942 |\n",
            "\u001b[32m[07/09 00:14:50 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 00:14:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 16.244 | brec_Cht         | 0.000 | lam_Sltst  | 3.680 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 9.788 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.72s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.061\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.121\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.061\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.197\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.287\n",
            "\u001b[32m[07/09 00:14:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 6.115 | 12.075 | 5.505  |  nan  |  nan  | 6.115 |\n",
            "\u001b[32m[07/09 00:14:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 00:14:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 18.470 | brec_Cht         | 0.000 | lam_Sltst  | 3.401 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 8.702 |            |       |\n",
            "\u001b[32m[07/09 00:14:51 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/09 00:14:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 00:14:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 00:14:51 d2.evaluation.testing]: \u001b[0mcopypaste: 5.9423,12.2230,4.6052,nan,nan,5.9423\n",
            "\u001b[32m[07/09 00:14:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 00:14:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 00:14:51 d2.evaluation.testing]: \u001b[0mcopypaste: 6.1145,12.0752,5.5053,nan,nan,6.1146\n",
            "\u001b[32m[07/09 00:14:54 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   bio_Sltst   | 64           |   brec_Cht    | 4            | lam_Sltst  | 33           |\n",
            "| skel_WkstPkst | 10           | strless_Slt.. | 51           |            |              |\n",
            "|     total     | 162          |               |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/09 00:14:54 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 00:14:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 00:14:54 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'cores_fold_4_val'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[07/09 00:14:54 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cores_fold_4_val' to COCO format ...)\n",
            "\u001b[32m[07/09 00:14:57 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[07/09 00:14:57 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 14, #annotations: 162\n",
            "\u001b[32m[07/09 00:14:57 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './coco_train/cores_fold_4_val_coco_format.json' ...\n",
            "\u001b[32m[07/09 00:14:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/09 00:16:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.3840 s / img. ETA=0:00:14\n",
            "\u001b[32m[07/09 00:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 12/14. 0.3939 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/09 00:16:25 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.4004 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/09 00:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.4052 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 00:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:51.849079 (5.761009 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 00:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.405167 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 00:16:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 00:16:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 00:16:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.051\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.104\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.051\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.051\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.023\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.149\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.220\n",
            "\u001b[32m[07/09 00:16:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.141 | 10.410 | 5.085  |  nan  |  nan  | 5.141 |\n",
            "\u001b[32m[07/09 00:16:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 00:16:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 16.466 | brec_Cht         | 0.000 | lam_Sltst  | 2.354 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 6.884 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.057\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.055\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.154\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\n",
            "\u001b[32m[07/09 00:16:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.506 | 9.945  | 5.685  |  nan  |  nan  | 5.506 |\n",
            "\u001b[32m[07/09 00:16:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 00:16:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP    | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:------|:-----------|:------|\n",
            "| bio_Sltst     | 18.388 | brec_Cht         | 0.000 | lam_Sltst  | 2.543 |\n",
            "| skel_WkstPkst | 0.000  | strless_SltstSst | 6.600 |            |       |\n",
            "\u001b[32m[07/09 00:16:34 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/09 00:16:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 00:16:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 00:16:34 d2.evaluation.testing]: \u001b[0mcopypaste: 5.1410,10.4099,5.0855,nan,nan,5.1410\n",
            "\u001b[32m[07/09 00:16:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 00:16:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 00:16:34 d2.evaluation.testing]: \u001b[0mcopypaste: 5.5062,9.9447,5.6851,nan,nan,5.5063\n",
            "\u001b[32m[07/09 00:16:34 d2.utils.events]: \u001b[0m eta: 1:50:47  iter: 199  total_loss: 1.512  loss_cls: 0.495  loss_box_reg: 0.572  loss_mask: 0.330  loss_rpn_cls: 0.021  loss_rpn_loc: 0.115  time: 3.6825  data_time: 2.0835  lr: 0.000200  max_mem: 8863M\n",
            "\u001b[32m[07/09 00:17:48 d2.utils.events]: \u001b[0m eta: 1:49:41  iter: 219  total_loss: 1.441  loss_cls: 0.474  loss_box_reg: 0.535  loss_mask: 0.310  loss_rpn_cls: 0.019  loss_rpn_loc: 0.111  time: 3.6857  data_time: 2.0641  lr: 0.000220  max_mem: 8863M\n",
            "\u001b[32m[07/09 00:19:04 d2.utils.events]: \u001b[0m eta: 1:48:55  iter: 239  total_loss: 1.425  loss_cls: 0.462  loss_box_reg: 0.527  loss_mask: 0.287  loss_rpn_cls: 0.020  loss_rpn_loc: 0.109  time: 3.6946  data_time: 2.1162  lr: 0.000240  max_mem: 8863M\n",
            "\u001b[32m[07/09 00:20:19 d2.utils.events]: \u001b[0m eta: 1:47:41  iter: 259  total_loss: 1.338  loss_cls: 0.457  loss_box_reg: 0.489  loss_mask: 0.266  loss_rpn_cls: 0.018  loss_rpn_loc: 0.106  time: 3.6993  data_time: 2.1067  lr: 0.000260  max_mem: 9182M\n",
            "\u001b[32m[07/09 00:21:34 d2.utils.events]: \u001b[0m eta: 1:46:33  iter: 279  total_loss: 1.234  loss_cls: 0.433  loss_box_reg: 0.432  loss_mask: 0.243  loss_rpn_cls: 0.017  loss_rpn_loc: 0.105  time: 3.7016  data_time: 2.0478  lr: 0.000280  max_mem: 9182M\n",
            "\u001b[32m[07/09 00:22:49 d2.utils.events]: \u001b[0m eta: 1:45:28  iter: 299  total_loss: 1.178  loss_cls: 0.449  loss_box_reg: 0.398  loss_mask: 0.227  loss_rpn_cls: 0.013  loss_rpn_loc: 0.105  time: 3.7060  data_time: 2.0935  lr: 0.000300  max_mem: 9182M\n",
            "\u001b[32m[07/09 00:24:04 d2.utils.events]: \u001b[0m eta: 1:44:08  iter: 319  total_loss: 1.058  loss_cls: 0.398  loss_box_reg: 0.347  loss_mask: 0.211  loss_rpn_cls: 0.014  loss_rpn_loc: 0.102  time: 3.7095  data_time: 2.0777  lr: 0.000320  max_mem: 9182M\n",
            "\u001b[32m[07/09 00:25:20 d2.utils.events]: \u001b[0m eta: 1:43:00  iter: 339  total_loss: 1.076  loss_cls: 0.423  loss_box_reg: 0.341  loss_mask: 0.201  loss_rpn_cls: 0.012  loss_rpn_loc: 0.102  time: 3.7136  data_time: 2.1062  lr: 0.000340  max_mem: 9182M\n",
            "\u001b[32m[07/09 00:26:35 d2.utils.events]: \u001b[0m eta: 1:41:55  iter: 359  total_loss: 1.014  loss_cls: 0.384  loss_box_reg: 0.319  loss_mask: 0.196  loss_rpn_cls: 0.012  loss_rpn_loc: 0.097  time: 3.7151  data_time: 2.0445  lr: 0.000360  max_mem: 9182M\n",
            "\u001b[32m[07/09 00:27:51 d2.utils.events]: \u001b[0m eta: 1:40:50  iter: 379  total_loss: 0.990  loss_cls: 0.376  loss_box_reg: 0.314  loss_mask: 0.191  loss_rpn_cls: 0.010  loss_rpn_loc: 0.099  time: 3.7209  data_time: 2.1472  lr: 0.000380  max_mem: 9182M\n",
            "\u001b[32m[07/09 00:29:20 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 00:29:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/09 00:29:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/09 00:30:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.3504 s / img. ETA=0:04:11\n",
            "\u001b[32m[07/09 00:30:32 d2.evaluation.evaluator]: \u001b[0mInference done 13/57. 0.3311 s / img. ETA=0:03:37\n",
            "\u001b[32m[07/09 00:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 15/57. 0.3162 s / img. ETA=0:03:09\n",
            "\u001b[32m[07/09 00:30:45 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.2953 s / img. ETA=0:02:36\n",
            "\u001b[32m[07/09 00:30:51 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.2777 s / img. ETA=0:02:11\n",
            "\u001b[32m[07/09 00:30:57 d2.evaluation.evaluator]: \u001b[0mInference done 23/57. 0.2709 s / img. ETA=0:02:00\n",
            "\u001b[32m[07/09 00:31:02 d2.evaluation.evaluator]: \u001b[0mInference done 25/57. 0.2694 s / img. ETA=0:01:50\n",
            "\u001b[32m[07/09 00:31:08 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.2626 s / img. ETA=0:01:35\n",
            "\u001b[32m[07/09 00:31:14 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.2514 s / img. ETA=0:01:20\n",
            "\u001b[32m[07/09 00:31:20 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.2507 s / img. ETA=0:01:14\n",
            "\u001b[32m[07/09 00:31:27 d2.evaluation.evaluator]: \u001b[0mInference done 35/57. 0.2547 s / img. ETA=0:01:09\n",
            "\u001b[32m[07/09 00:31:32 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.2547 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/09 00:31:40 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.2538 s / img. ETA=0:00:47\n",
            "\u001b[32m[07/09 00:31:45 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.2493 s / img. ETA=0:00:37\n",
            "\u001b[32m[07/09 00:31:50 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.2481 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/09 00:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.2511 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/09 00:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.2550 s / img. ETA=0:00:24\n",
            "\u001b[32m[07/09 00:32:12 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.2575 s / img. ETA=0:00:21\n",
            "\u001b[32m[07/09 00:32:19 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.2619 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/09 00:32:27 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.2658 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/09 00:32:33 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.2676 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/09 00:32:38 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.2694 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/09 00:32:43 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.2711 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/09 00:32:50 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.2742 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/09 00:32:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:00.397342 (3.469180 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 00:32:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.273878 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 00:32:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 00:32:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 00:32:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.34s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.468\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.607\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607\n",
            "\u001b[32m[07/09 00:32:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 30.549 | 46.822 | 31.487 |  nan  |  nan  | 30.549 |\n",
            "\u001b[32m[07/09 00:32:54 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 00:32:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 53.514 | brec_Cht         | 21.523 | lam_Sltst  | 21.396 |\n",
            "| skel_WkstPkst | 15.990 | strless_SltstSst | 40.320 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.50s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.468\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.359\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.561\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.645\n",
            "\u001b[32m[07/09 00:32:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 32.582 | 46.780 | 35.920 |  nan  |  nan  | 32.582 |\n",
            "\u001b[32m[07/09 00:32:54 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 00:32:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 55.514 | brec_Cht         | 24.534 | lam_Sltst  | 20.958 |\n",
            "| skel_WkstPkst | 22.893 | strless_SltstSst | 39.013 |            |        |\n",
            "\u001b[32m[07/09 00:32:54 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/09 00:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 00:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 00:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: 30.5486,46.8217,31.4870,nan,nan,30.5486\n",
            "\u001b[32m[07/09 00:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 00:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 00:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: 32.5824,46.7804,35.9200,nan,nan,32.5824\n",
            "\u001b[32m[07/09 00:32:57 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 00:32:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/09 00:32:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/09 00:33:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.2668 s / img. ETA=0:00:08\n",
            "\u001b[32m[07/09 00:33:54 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.2948 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/09 00:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.3044 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.024209 (3.891579 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.304421 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.152\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.134\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.152\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.061\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.318\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.213 | 28.839 | 13.367 |  nan  |  nan  | 15.213 |\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 25.123 | brec_Cht         | 2.034  | lam_Sltst  | 3.235 |\n",
            "| skel_WkstPkst | 25.521 | strless_SltstSst | 20.152 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.282\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.478\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.779 | 28.182 | 19.740 |  nan  |  nan  | 17.779 |\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 27.066 | brec_Cht         | 2.862  | lam_Sltst  | 3.314 |\n",
            "| skel_WkstPkst | 34.180 | strless_SltstSst | 21.472 |            |       |\n",
            "\u001b[32m[07/09 00:34:00 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.testing]: \u001b[0mcopypaste: 15.2130,28.8388,13.3671,nan,nan,15.2130\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 00:34:00 d2.evaluation.testing]: \u001b[0mcopypaste: 17.7789,28.1816,19.7405,nan,nan,17.7789\n",
            "\u001b[32m[07/09 00:34:00 d2.utils.events]: \u001b[0m eta: 1:39:41  iter: 399  total_loss: 0.904  loss_cls: 0.340  loss_box_reg: 0.276  loss_mask: 0.180  loss_rpn_cls: 0.011  loss_rpn_loc: 0.094  time: 3.7258  data_time: 2.1382  lr: 0.000400  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:35:15 d2.utils.events]: \u001b[0m eta: 1:38:24  iter: 419  total_loss: 0.881  loss_cls: 0.339  loss_box_reg: 0.255  loss_mask: 0.170  loss_rpn_cls: 0.009  loss_rpn_loc: 0.092  time: 3.7271  data_time: 2.0392  lr: 0.000420  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:36:30 d2.utils.events]: \u001b[0m eta: 1:37:06  iter: 439  total_loss: 0.865  loss_cls: 0.327  loss_box_reg: 0.260  loss_mask: 0.167  loss_rpn_cls: 0.008  loss_rpn_loc: 0.090  time: 3.7275  data_time: 2.0439  lr: 0.000440  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:37:45 d2.utils.events]: \u001b[0m eta: 1:35:59  iter: 459  total_loss: 0.815  loss_cls: 0.318  loss_box_reg: 0.235  loss_mask: 0.159  loss_rpn_cls: 0.009  loss_rpn_loc: 0.090  time: 3.7293  data_time: 2.0510  lr: 0.000460  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:38:59 d2.utils.events]: \u001b[0m eta: 1:34:42  iter: 479  total_loss: 0.762  loss_cls: 0.287  loss_box_reg: 0.241  loss_mask: 0.154  loss_rpn_cls: 0.006  loss_rpn_loc: 0.091  time: 3.7285  data_time: 2.0255  lr: 0.000480  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:40:15 d2.utils.events]: \u001b[0m eta: 1:33:30  iter: 499  total_loss: 0.755  loss_cls: 0.276  loss_box_reg: 0.240  loss_mask: 0.148  loss_rpn_cls: 0.005  loss_rpn_loc: 0.082  time: 3.7300  data_time: 2.0267  lr: 0.000500  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:41:28 d2.utils.events]: \u001b[0m eta: 1:32:07  iter: 519  total_loss: 0.641  loss_cls: 0.218  loss_box_reg: 0.195  loss_mask: 0.141  loss_rpn_cls: 0.007  loss_rpn_loc: 0.086  time: 3.7279  data_time: 2.0041  lr: 0.000519  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:42:43 d2.utils.events]: \u001b[0m eta: 1:30:52  iter: 539  total_loss: 0.635  loss_cls: 0.220  loss_box_reg: 0.197  loss_mask: 0.131  loss_rpn_cls: 0.005  loss_rpn_loc: 0.085  time: 3.7283  data_time: 2.0331  lr: 0.000539  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:43:57 d2.utils.events]: \u001b[0m eta: 1:29:36  iter: 559  total_loss: 0.621  loss_cls: 0.211  loss_box_reg: 0.190  loss_mask: 0.133  loss_rpn_cls: 0.005  loss_rpn_loc: 0.083  time: 3.7278  data_time: 1.9996  lr: 0.000559  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:45:13 d2.utils.events]: \u001b[0m eta: 1:28:21  iter: 579  total_loss: 0.563  loss_cls: 0.181  loss_box_reg: 0.175  loss_mask: 0.127  loss_rpn_cls: 0.004  loss_rpn_loc: 0.083  time: 3.7289  data_time: 2.0739  lr: 0.000579  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:46:38 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 00:46:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/09 00:46:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/09 00:47:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.2538 s / img. ETA=0:02:27\n",
            "\u001b[32m[07/09 00:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 14/57. 0.2256 s / img. ETA=0:01:55\n",
            "\u001b[32m[07/09 00:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 18/57. 0.1938 s / img. ETA=0:01:29\n",
            "\u001b[32m[07/09 00:47:34 d2.evaluation.evaluator]: \u001b[0mInference done 24/57. 0.1658 s / img. ETA=0:01:01\n",
            "\u001b[32m[07/09 00:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.1563 s / img. ETA=0:00:48\n",
            "\u001b[32m[07/09 00:47:46 d2.evaluation.evaluator]: \u001b[0mInference done 33/57. 0.1541 s / img. ETA=0:00:40\n",
            "\u001b[32m[07/09 00:47:52 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1575 s / img. ETA=0:00:33\n",
            "\u001b[32m[07/09 00:47:57 d2.evaluation.evaluator]: \u001b[0mInference done 41/57. 0.1583 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/09 00:48:03 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1577 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/09 00:48:10 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1591 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/09 00:48:19 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1658 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/09 00:48:25 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1703 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 00:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1735 s / img. ETA=0:00:03\n",
            "\u001b[32m[07/09 00:48:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:36.784326 (1.861237 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 00:48:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.175855 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 00:48:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 00:48:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 00:48:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.839\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.810\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.751\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.802\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802\n",
            "\u001b[32m[07/09 00:48:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 65.438 | 83.851 | 80.979 |  nan  |  nan  | 65.438 |\n",
            "\u001b[32m[07/09 00:48:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 00:48:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 78.616 | brec_Cht         | 60.845 | lam_Sltst  | 62.978 |\n",
            "| skel_WkstPkst | 43.244 | strless_SltstSst | 81.508 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.839\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.801\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.782\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.833\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.833\n",
            "\u001b[32m[07/09 00:48:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 67.638 | 83.851 | 80.075 |  nan  |  nan  | 67.638 |\n",
            "\u001b[32m[07/09 00:48:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 00:48:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 80.903 | brec_Cht         | 65.399 | lam_Sltst  | 59.642 |\n",
            "| skel_WkstPkst | 50.276 | strless_SltstSst | 81.971 |            |        |\n",
            "\u001b[32m[07/09 00:48:36 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/09 00:48:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 00:48:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 00:48:36 d2.evaluation.testing]: \u001b[0mcopypaste: 65.4382,83.8507,80.9793,nan,nan,65.4382\n",
            "\u001b[32m[07/09 00:48:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 00:48:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 00:48:36 d2.evaluation.testing]: \u001b[0mcopypaste: 67.6380,83.8507,80.0747,nan,nan,67.6383\n",
            "\u001b[32m[07/09 00:48:39 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 00:48:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/09 00:48:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/09 00:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1579 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/09 00:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 13/14. 0.1759 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.304482 (2.144942 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.188521 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.690 | 39.978 | 27.894 |  nan  |  nan  | 25.690 |\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 25.282 | brec_Cht         | 13.502 | lam_Sltst  | 5.633 |\n",
            "| skel_WkstPkst | 51.373 | strless_SltstSst | 32.661 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.319\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.557\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.557\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.079 | 40.002 | 31.929 |  nan  |  nan  | 28.079 |\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 27.009 | brec_Cht         | 13.877 | lam_Sltst  | 5.344 |\n",
            "| skel_WkstPkst | 59.954 | strless_SltstSst | 34.214 |            |       |\n",
            "\u001b[32m[07/09 00:49:16 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.testing]: \u001b[0mcopypaste: 25.6903,39.9779,27.8943,nan,nan,25.6903\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 00:49:16 d2.evaluation.testing]: \u001b[0mcopypaste: 28.0795,40.0015,31.9292,nan,nan,28.0795\n",
            "\u001b[32m[07/09 00:49:16 d2.utils.events]: \u001b[0m eta: 1:27:04  iter: 599  total_loss: 0.565  loss_cls: 0.167  loss_box_reg: 0.178  loss_mask: 0.125  loss_rpn_cls: 0.005  loss_rpn_loc: 0.079  time: 3.7279  data_time: 1.9639  lr: 0.000599  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:50:30 d2.utils.events]: \u001b[0m eta: 1:25:50  iter: 619  total_loss: 0.533  loss_cls: 0.162  loss_box_reg: 0.175  loss_mask: 0.119  loss_rpn_cls: 0.003  loss_rpn_loc: 0.076  time: 3.7276  data_time: 1.9881  lr: 0.000619  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:51:45 d2.utils.events]: \u001b[0m eta: 1:24:34  iter: 639  total_loss: 0.481  loss_cls: 0.133  loss_box_reg: 0.151  loss_mask: 0.110  loss_rpn_cls: 0.005  loss_rpn_loc: 0.073  time: 3.7274  data_time: 2.0206  lr: 0.000639  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:53:00 d2.utils.events]: \u001b[0m eta: 1:23:22  iter: 659  total_loss: 0.474  loss_cls: 0.126  loss_box_reg: 0.154  loss_mask: 0.110  loss_rpn_cls: 0.003  loss_rpn_loc: 0.077  time: 3.7284  data_time: 2.0304  lr: 0.000659  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:54:14 d2.utils.events]: \u001b[0m eta: 1:22:08  iter: 679  total_loss: 0.445  loss_cls: 0.121  loss_box_reg: 0.141  loss_mask: 0.107  loss_rpn_cls: 0.002  loss_rpn_loc: 0.076  time: 3.7276  data_time: 1.9927  lr: 0.000679  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:55:29 d2.utils.events]: \u001b[0m eta: 1:20:53  iter: 699  total_loss: 0.434  loss_cls: 0.120  loss_box_reg: 0.146  loss_mask: 0.105  loss_rpn_cls: 0.003  loss_rpn_loc: 0.069  time: 3.7283  data_time: 2.0282  lr: 0.000699  max_mem: 9311M\n",
            "\u001b[32m[07/09 00:56:45 d2.utils.events]: \u001b[0m eta: 1:19:39  iter: 719  total_loss: 0.421  loss_cls: 0.102  loss_box_reg: 0.149  loss_mask: 0.104  loss_rpn_cls: 0.003  loss_rpn_loc: 0.067  time: 3.7295  data_time: 2.0697  lr: 0.000719  max_mem: 9376M\n",
            "\u001b[32m[07/09 00:57:59 d2.utils.events]: \u001b[0m eta: 1:18:25  iter: 739  total_loss: 0.402  loss_cls: 0.108  loss_box_reg: 0.131  loss_mask: 0.096  loss_rpn_cls: 0.003  loss_rpn_loc: 0.062  time: 3.7296  data_time: 2.0408  lr: 0.000739  max_mem: 9376M\n",
            "\u001b[32m[07/09 00:59:14 d2.utils.events]: \u001b[0m eta: 1:17:11  iter: 759  total_loss: 0.419  loss_cls: 0.100  loss_box_reg: 0.144  loss_mask: 0.100  loss_rpn_cls: 0.002  loss_rpn_loc: 0.070  time: 3.7302  data_time: 2.0609  lr: 0.000759  max_mem: 9376M\n",
            "\u001b[32m[07/09 01:00:28 d2.utils.events]: \u001b[0m eta: 1:15:54  iter: 779  total_loss: 0.374  loss_cls: 0.079  loss_box_reg: 0.117  loss_mask: 0.094  loss_rpn_cls: 0.002  loss_rpn_loc: 0.067  time: 3.7289  data_time: 1.9806  lr: 0.000779  max_mem: 9376M\n",
            "\u001b[32m[07/09 01:01:55 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 01:01:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/09 01:01:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/09 01:02:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1920 s / img. ETA=0:01:27\n",
            "\u001b[32m[07/09 01:02:23 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1486 s / img. ETA=0:00:45\n",
            "\u001b[32m[07/09 01:02:28 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1339 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/09 01:02:34 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.1294 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/09 01:02:39 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1255 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/09 01:02:44 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1274 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/09 01:02:49 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1320 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.329407 (0.852489 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.132618 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.846\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.989\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.960\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.846\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.224\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.866\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.886\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.886\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 84.628 | 98.950 | 96.027 |  nan  |  nan  | 84.628 |\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 88.474 | brec_Cht         | 84.201 | lam_Sltst  | 86.674 |\n",
            "| skel_WkstPkst | 77.932 | strless_SltstSst | 85.859 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.852\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.987\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.959\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.852\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.221\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.871\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.890\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.890\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 85.191 | 98.668 | 95.919 |  nan  |  nan  | 85.191 |\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 87.750 | brec_Cht         | 88.838 | lam_Sltst  | 82.953 |\n",
            "| skel_WkstPkst | 78.830 | strless_SltstSst | 87.582 |            |        |\n",
            "\u001b[32m[07/09 01:02:51 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.testing]: \u001b[0mcopypaste: 84.6281,98.9496,96.0266,nan,nan,84.6281\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:02:51 d2.evaluation.testing]: \u001b[0mcopypaste: 85.1909,98.6681,95.9191,nan,nan,85.1909\n",
            "\u001b[32m[07/09 01:02:54 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 01:02:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/09 01:02:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/09 01:03:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1399 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.004066 (0.889341 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.150764 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.276\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.382\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.553\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.553\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 27.570 | 38.227 | 32.015 |  nan  |  nan  | 27.570 |\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.041 | brec_Cht         | 22.188 | lam_Sltst  | 7.688 |\n",
            "| skel_WkstPkst | 55.977 | strless_SltstSst | 30.955 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.330\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.603 | 38.373 | 32.957 |  nan  |  nan  | 28.603 |\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.815 | brec_Cht         | 21.766 | lam_Sltst  | 7.312 |\n",
            "| skel_WkstPkst | 59.176 | strless_SltstSst | 32.948 |            |       |\n",
            "\u001b[32m[07/09 01:03:13 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.testing]: \u001b[0mcopypaste: 27.5698,38.2273,32.0145,nan,nan,27.5698\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:03:13 d2.evaluation.testing]: \u001b[0mcopypaste: 28.6032,38.3726,32.9571,nan,nan,28.6032\n",
            "\u001b[32m[07/09 01:03:13 d2.utils.events]: \u001b[0m eta: 1:14:41  iter: 799  total_loss: 0.358  loss_cls: 0.082  loss_box_reg: 0.122  loss_mask: 0.091  loss_rpn_cls: 0.002  loss_rpn_loc: 0.065  time: 3.7292  data_time: 2.0371  lr: 0.000799  max_mem: 9376M\n",
            "\u001b[32m[07/09 01:04:29 d2.utils.events]: \u001b[0m eta: 1:13:27  iter: 819  total_loss: 0.363  loss_cls: 0.079  loss_box_reg: 0.121  loss_mask: 0.093  loss_rpn_cls: 0.002  loss_rpn_loc: 0.068  time: 3.7306  data_time: 2.0715  lr: 0.000819  max_mem: 9376M\n",
            "\u001b[32m[07/09 01:05:44 d2.utils.events]: \u001b[0m eta: 1:12:11  iter: 839  total_loss: 0.338  loss_cls: 0.075  loss_box_reg: 0.115  loss_mask: 0.089  loss_rpn_cls: 0.002  loss_rpn_loc: 0.063  time: 3.7304  data_time: 2.0034  lr: 0.000839  max_mem: 9376M\n",
            "\u001b[32m[07/09 01:06:58 d2.utils.events]: \u001b[0m eta: 1:10:57  iter: 859  total_loss: 0.335  loss_cls: 0.072  loss_box_reg: 0.108  loss_mask: 0.089  loss_rpn_cls: 0.002  loss_rpn_loc: 0.062  time: 3.7304  data_time: 2.0151  lr: 0.000859  max_mem: 9376M\n",
            "\u001b[32m[07/09 01:08:13 d2.utils.events]: \u001b[0m eta: 1:09:42  iter: 879  total_loss: 0.319  loss_cls: 0.063  loss_box_reg: 0.108  loss_mask: 0.087  loss_rpn_cls: 0.003  loss_rpn_loc: 0.059  time: 3.7305  data_time: 2.0004  lr: 0.000879  max_mem: 9376M\n",
            "\u001b[32m[07/09 01:09:27 d2.utils.events]: \u001b[0m eta: 1:08:25  iter: 899  total_loss: 0.306  loss_cls: 0.062  loss_box_reg: 0.101  loss_mask: 0.084  loss_rpn_cls: 0.002  loss_rpn_loc: 0.056  time: 3.7303  data_time: 1.9894  lr: 0.000899  max_mem: 9376M\n",
            "\u001b[32m[07/09 01:10:42 d2.utils.events]: \u001b[0m eta: 1:07:10  iter: 919  total_loss: 0.298  loss_cls: 0.060  loss_box_reg: 0.100  loss_mask: 0.086  loss_rpn_cls: 0.002  loss_rpn_loc: 0.050  time: 3.7306  data_time: 2.0371  lr: 0.000919  max_mem: 9376M\n",
            "\u001b[32m[07/09 01:11:57 d2.utils.events]: \u001b[0m eta: 1:05:58  iter: 939  total_loss: 0.291  loss_cls: 0.056  loss_box_reg: 0.102  loss_mask: 0.082  loss_rpn_cls: 0.003  loss_rpn_loc: 0.054  time: 3.7309  data_time: 2.0210  lr: 0.000939  max_mem: 9376M\n",
            "\u001b[32m[07/09 01:13:12 d2.utils.events]: \u001b[0m eta: 1:04:43  iter: 959  total_loss: 0.301  loss_cls: 0.057  loss_box_reg: 0.097  loss_mask: 0.083  loss_rpn_cls: 0.002  loss_rpn_loc: 0.059  time: 3.7313  data_time: 2.0491  lr: 0.000959  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:14:27 d2.utils.events]: \u001b[0m eta: 1:03:27  iter: 979  total_loss: 0.296  loss_cls: 0.059  loss_box_reg: 0.100  loss_mask: 0.083  loss_rpn_cls: 0.002  loss_rpn_loc: 0.055  time: 3.7311  data_time: 1.9869  lr: 0.000979  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:15:54 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 01:15:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/09 01:15:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/09 01:16:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1881 s / img. ETA=0:01:24\n",
            "\u001b[32m[07/09 01:16:21 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1430 s / img. ETA=0:00:43\n",
            "\u001b[32m[07/09 01:16:26 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1306 s / img. ETA=0:00:26\n",
            "\u001b[32m[07/09 01:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.1264 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/09 01:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 44/57. 0.1224 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/09 01:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 50/57. 0.1246 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/09 01:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 56/57. 0.1294 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 01:16:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.189280 (0.830563 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:16:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.129084 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:16:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 01:16:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 01:16:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.902\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.998\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.998\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.902\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.241\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.908\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.928\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.928\n",
            "\u001b[32m[07/09 01:16:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 90.174 | 99.843 | 99.843 |  nan  |  nan  | 90.174 |\n",
            "\u001b[32m[07/09 01:16:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:16:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 91.192 | brec_Cht         | 88.892 | lam_Sltst  | 89.981 |\n",
            "| skel_WkstPkst | 89.718 | strless_SltstSst | 91.085 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.889\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.998\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.998\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.889\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.231\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.899\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.919\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.919\n",
            "\u001b[32m[07/09 01:16:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 88.892 | 99.843 | 99.843 |  nan  |  nan  | 88.892 |\n",
            "\u001b[32m[07/09 01:16:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:16:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 90.500 | brec_Cht         | 90.899 | lam_Sltst  | 87.565 |\n",
            "| skel_WkstPkst | 85.882 | strless_SltstSst | 89.616 |            |        |\n",
            "\u001b[32m[07/09 01:16:49 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/09 01:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 01:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: 90.1738,99.8428,99.8428,nan,nan,90.1738\n",
            "\u001b[32m[07/09 01:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 01:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:16:49 d2.evaluation.testing]: \u001b[0mcopypaste: 88.8925,99.8428,99.8428,nan,nan,88.8925\n",
            "\u001b[32m[07/09 01:16:52 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 01:16:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/09 01:16:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/09 01:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1332 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.975265 (0.886141 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.148041 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.294\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.415\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.505\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 29.440 | 41.534 | 34.599 |  nan  |  nan  | 29.440 |\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 22.804 | brec_Cht         | 39.109 | lam_Sltst  | 6.090 |\n",
            "| skel_WkstPkst | 45.673 | strless_SltstSst | 33.523 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.416\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.352\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.547\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 30.218 | 41.618 | 35.186 |  nan  |  nan  | 30.218 |\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 24.536 | brec_Cht         | 39.281 | lam_Sltst  | 5.816 |\n",
            "| skel_WkstPkst | 46.117 | strless_SltstSst | 35.340 |            |       |\n",
            "\u001b[32m[07/09 01:17:11 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: 29.4398,41.5339,34.5986,nan,nan,29.4398\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:17:11 d2.evaluation.testing]: \u001b[0mcopypaste: 30.2178,41.6184,35.1855,nan,nan,30.2178\n",
            "\u001b[32m[07/09 01:17:11 d2.utils.events]: \u001b[0m eta: 1:02:15  iter: 999  total_loss: 0.299  loss_cls: 0.053  loss_box_reg: 0.102  loss_mask: 0.081  loss_rpn_cls: 0.002  loss_rpn_loc: 0.054  time: 3.7316  data_time: 2.0515  lr: 0.000999  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:18:27 d2.utils.events]: \u001b[0m eta: 1:01:05  iter: 1019  total_loss: 0.285  loss_cls: 0.056  loss_box_reg: 0.096  loss_mask: 0.079  loss_rpn_cls: 0.002  loss_rpn_loc: 0.051  time: 3.7328  data_time: 2.0791  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:19:42 d2.utils.events]: \u001b[0m eta: 0:59:51  iter: 1039  total_loss: 0.273  loss_cls: 0.051  loss_box_reg: 0.089  loss_mask: 0.080  loss_rpn_cls: 0.002  loss_rpn_loc: 0.054  time: 3.7333  data_time: 2.0396  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:20:57 d2.utils.events]: \u001b[0m eta: 0:58:37  iter: 1059  total_loss: 0.274  loss_cls: 0.050  loss_box_reg: 0.093  loss_mask: 0.079  loss_rpn_cls: 0.002  loss_rpn_loc: 0.050  time: 3.7330  data_time: 1.9938  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:22:12 d2.utils.events]: \u001b[0m eta: 0:57:25  iter: 1079  total_loss: 0.274  loss_cls: 0.044  loss_box_reg: 0.098  loss_mask: 0.076  loss_rpn_cls: 0.001  loss_rpn_loc: 0.048  time: 3.7332  data_time: 2.0490  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:23:26 d2.utils.events]: \u001b[0m eta: 0:56:11  iter: 1099  total_loss: 0.257  loss_cls: 0.045  loss_box_reg: 0.086  loss_mask: 0.076  loss_rpn_cls: 0.001  loss_rpn_loc: 0.051  time: 3.7329  data_time: 2.0269  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:24:41 d2.utils.events]: \u001b[0m eta: 0:54:57  iter: 1119  total_loss: 0.262  loss_cls: 0.044  loss_box_reg: 0.086  loss_mask: 0.077  loss_rpn_cls: 0.001  loss_rpn_loc: 0.048  time: 3.7336  data_time: 2.0724  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:25:57 d2.utils.events]: \u001b[0m eta: 0:53:42  iter: 1139  total_loss: 0.252  loss_cls: 0.043  loss_box_reg: 0.090  loss_mask: 0.075  loss_rpn_cls: 0.001  loss_rpn_loc: 0.044  time: 3.7340  data_time: 2.0561  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:27:12 d2.utils.events]: \u001b[0m eta: 0:52:29  iter: 1159  total_loss: 0.239  loss_cls: 0.041  loss_box_reg: 0.081  loss_mask: 0.074  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.7346  data_time: 2.0406  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:28:27 d2.utils.events]: \u001b[0m eta: 0:51:15  iter: 1179  total_loss: 0.238  loss_cls: 0.039  loss_box_reg: 0.078  loss_mask: 0.074  loss_rpn_cls: 0.001  loss_rpn_loc: 0.045  time: 3.7350  data_time: 2.0612  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:29:55 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 01:29:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/09 01:29:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/09 01:30:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1677 s / img. ETA=0:01:07\n",
            "\u001b[32m[07/09 01:30:19 d2.evaluation.evaluator]: \u001b[0mInference done 20/57. 0.1352 s / img. ETA=0:00:35\n",
            "\u001b[32m[07/09 01:30:24 d2.evaluation.evaluator]: \u001b[0mInference done 29/57. 0.1218 s / img. ETA=0:00:22\n",
            "\u001b[32m[07/09 01:30:29 d2.evaluation.evaluator]: \u001b[0mInference done 37/57. 0.1197 s / img. ETA=0:00:15\n",
            "\u001b[32m[07/09 01:30:35 d2.evaluation.evaluator]: \u001b[0mInference done 46/57. 0.1165 s / img. ETA=0:00:07\n",
            "\u001b[32m[07/09 01:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 51/57. 0.1210 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.980567 (0.749626 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.122548 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.907\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.998\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.998\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.907\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.912\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.933\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.933\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 90.727 | 99.822 | 99.822 |  nan  |  nan  | 90.727 |\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 89.016 | brec_Cht         | 90.822 | lam_Sltst  | 92.084 |\n",
            "| skel_WkstPkst | 91.386 | strless_SltstSst | 90.328 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.902\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.998\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.998\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.902\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.908\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.927\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.927\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 90.178 | 99.822 | 99.822 |  nan  |  nan  | 90.178 |\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 91.014 | brec_Cht         | 90.519 | lam_Sltst  | 89.817 |\n",
            "| skel_WkstPkst | 88.649 | strless_SltstSst | 90.893 |            |        |\n",
            "\u001b[32m[07/09 01:30:44 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: 90.7273,99.8216,99.8216,nan,nan,90.7273\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: 90.1783,99.8216,99.8216,nan,nan,90.1783\n",
            "\u001b[32m[07/09 01:30:47 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 01:30:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/09 01:30:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/09 01:31:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1480 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.239472 (0.915497 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.157586 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.274\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 27.356 | 38.411 | 31.487 |  nan  |  nan  | 27.356 |\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 17.807 | brec_Cht         | 39.208 | lam_Sltst  | 6.628 |\n",
            "| skel_WkstPkst | 41.183 | strless_SltstSst | 31.953 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.273\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.532\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 27.333 | 37.599 | 28.702 |  nan  |  nan  | 27.333 |\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 18.537 | brec_Cht         | 38.680 | lam_Sltst  | 6.337 |\n",
            "| skel_WkstPkst | 39.035 | strless_SltstSst | 34.075 |            |       |\n",
            "\u001b[32m[07/09 01:31:06 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.testing]: \u001b[0mcopypaste: 27.3560,38.4110,31.4866,nan,nan,27.3560\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:31:06 d2.evaluation.testing]: \u001b[0mcopypaste: 27.3327,37.5988,28.7023,nan,nan,27.3327\n",
            "\u001b[32m[07/09 01:31:06 d2.utils.events]: \u001b[0m eta: 0:50:00  iter: 1199  total_loss: 0.248  loss_cls: 0.041  loss_box_reg: 0.084  loss_mask: 0.073  loss_rpn_cls: 0.002  loss_rpn_loc: 0.050  time: 3.7358  data_time: 2.0342  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:32:21 d2.utils.events]: \u001b[0m eta: 0:48:44  iter: 1219  total_loss: 0.250  loss_cls: 0.042  loss_box_reg: 0.087  loss_mask: 0.073  loss_rpn_cls: 0.001  loss_rpn_loc: 0.046  time: 3.7361  data_time: 2.0515  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:33:37 d2.utils.events]: \u001b[0m eta: 0:47:30  iter: 1239  total_loss: 0.239  loss_cls: 0.038  loss_box_reg: 0.081  loss_mask: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.042  time: 3.7369  data_time: 2.0956  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:34:51 d2.utils.events]: \u001b[0m eta: 0:46:14  iter: 1259  total_loss: 0.228  loss_cls: 0.038  loss_box_reg: 0.074  loss_mask: 0.076  loss_rpn_cls: 0.002  loss_rpn_loc: 0.042  time: 3.7369  data_time: 2.0505  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:36:07 d2.utils.events]: \u001b[0m eta: 0:44:58  iter: 1279  total_loss: 0.226  loss_cls: 0.037  loss_box_reg: 0.075  loss_mask: 0.071  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.7372  data_time: 2.0711  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:37:21 d2.utils.events]: \u001b[0m eta: 0:43:41  iter: 1299  total_loss: 0.222  loss_cls: 0.033  loss_box_reg: 0.076  loss_mask: 0.073  loss_rpn_cls: 0.001  loss_rpn_loc: 0.042  time: 3.7369  data_time: 2.0010  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:38:36 d2.utils.events]: \u001b[0m eta: 0:42:26  iter: 1319  total_loss: 0.225  loss_cls: 0.037  loss_box_reg: 0.074  loss_mask: 0.070  loss_rpn_cls: 0.001  loss_rpn_loc: 0.040  time: 3.7368  data_time: 2.0430  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:39:49 d2.utils.events]: \u001b[0m eta: 0:41:10  iter: 1339  total_loss: 0.217  loss_cls: 0.032  loss_box_reg: 0.074  loss_mask: 0.070  loss_rpn_cls: 0.001  loss_rpn_loc: 0.040  time: 3.7360  data_time: 1.9901  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:41:04 d2.utils.events]: \u001b[0m eta: 0:39:55  iter: 1359  total_loss: 0.220  loss_cls: 0.034  loss_box_reg: 0.073  loss_mask: 0.070  loss_rpn_cls: 0.001  loss_rpn_loc: 0.037  time: 3.7362  data_time: 2.0384  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:42:18 d2.utils.events]: \u001b[0m eta: 0:38:38  iter: 1379  total_loss: 0.211  loss_cls: 0.034  loss_box_reg: 0.071  loss_mask: 0.071  loss_rpn_cls: 0.001  loss_rpn_loc: 0.035  time: 3.7358  data_time: 2.0077  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:43:45 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 01:43:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/09 01:43:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/09 01:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1583 s / img. ETA=0:01:03\n",
            "\u001b[32m[07/09 01:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 20/57. 0.1276 s / img. ETA=0:00:32\n",
            "\u001b[32m[07/09 01:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1188 s / img. ETA=0:00:18\n",
            "\u001b[32m[07/09 01:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1196 s / img. ETA=0:00:12\n",
            "\u001b[32m[07/09 01:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1186 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/09 01:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 54/57. 0.1222 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.632140 (0.685233 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.122380 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.938\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.938\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.933\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.953\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.953\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 93.773 | 99.951 | 99.951 |  nan  |  nan  | 93.773 |\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 96.323 | brec_Cht         | 89.988 | lam_Sltst  | 94.773 |\n",
            "| skel_WkstPkst | 95.127 | strless_SltstSst | 92.652 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.917\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.917\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.239\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.918\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.938\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.938\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 91.719 | 99.951 | 99.951 |  nan  |  nan  | 91.719 |\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 93.021 | brec_Cht         | 91.222 | lam_Sltst  | 91.863 |\n",
            "| skel_WkstPkst | 90.754 | strless_SltstSst | 91.734 |            |        |\n",
            "\u001b[32m[07/09 01:44:29 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.testing]: \u001b[0mcopypaste: 93.7728,99.9510,99.9510,nan,nan,93.7728\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:44:29 d2.evaluation.testing]: \u001b[0mcopypaste: 91.7189,99.9510,99.9510,nan,nan,91.7189\n",
            "\u001b[32m[07/09 01:44:32 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 01:44:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/09 01:44:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/09 01:44:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1291 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.013335 (0.779259 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.139319 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.522\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.522\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 29.062 | 40.261 | 34.418 |  nan  |  nan  | 29.062 |\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.010 | brec_Cht         | 42.900 | lam_Sltst  | 5.072 |\n",
            "| skel_WkstPkst | 44.622 | strless_SltstSst | 32.704 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.405\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.510\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.519\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.828 | 40.502 | 30.979 |  nan  |  nan  | 28.828 |\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.132 | brec_Cht         | 41.259 | lam_Sltst  | 5.693 |\n",
            "| skel_WkstPkst | 41.865 | strless_SltstSst | 34.194 |            |       |\n",
            "\u001b[32m[07/09 01:44:48 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.testing]: \u001b[0mcopypaste: 29.0616,40.2615,34.4184,nan,nan,29.0616\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:44:48 d2.evaluation.testing]: \u001b[0mcopypaste: 28.8285,40.5017,30.9790,nan,nan,28.8285\n",
            "\u001b[32m[07/09 01:44:48 d2.utils.events]: \u001b[0m eta: 0:37:22  iter: 1399  total_loss: 0.203  loss_cls: 0.033  loss_box_reg: 0.068  loss_mask: 0.069  loss_rpn_cls: 0.001  loss_rpn_loc: 0.034  time: 3.7356  data_time: 2.0061  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:46:03 d2.utils.events]: \u001b[0m eta: 0:36:08  iter: 1419  total_loss: 0.207  loss_cls: 0.033  loss_box_reg: 0.068  loss_mask: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.034  time: 3.7355  data_time: 2.0214  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:47:18 d2.utils.events]: \u001b[0m eta: 0:34:54  iter: 1439  total_loss: 0.209  loss_cls: 0.032  loss_box_reg: 0.067  loss_mask: 0.069  loss_rpn_cls: 0.001  loss_rpn_loc: 0.036  time: 3.7356  data_time: 2.0615  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:48:32 d2.utils.events]: \u001b[0m eta: 0:33:38  iter: 1459  total_loss: 0.197  loss_cls: 0.031  loss_box_reg: 0.062  loss_mask: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.034  time: 3.7352  data_time: 2.0215  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:49:46 d2.utils.events]: \u001b[0m eta: 0:32:23  iter: 1479  total_loss: 0.196  loss_cls: 0.031  loss_box_reg: 0.069  loss_mask: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.035  time: 3.7350  data_time: 2.0191  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:51:01 d2.utils.events]: \u001b[0m eta: 0:31:08  iter: 1499  total_loss: 0.200  loss_cls: 0.030  loss_box_reg: 0.064  loss_mask: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.034  time: 3.7350  data_time: 2.0414  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:52:16 d2.utils.events]: \u001b[0m eta: 0:29:54  iter: 1519  total_loss: 0.202  loss_cls: 0.031  loss_box_reg: 0.065  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.036  time: 3.7351  data_time: 2.0495  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:53:30 d2.utils.events]: \u001b[0m eta: 0:28:39  iter: 1539  total_loss: 0.204  loss_cls: 0.031  loss_box_reg: 0.066  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.043  time: 3.7346  data_time: 2.0158  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:54:44 d2.utils.events]: \u001b[0m eta: 0:27:25  iter: 1559  total_loss: 0.203  loss_cls: 0.030  loss_box_reg: 0.065  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.7345  data_time: 2.0294  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:55:59 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 1579  total_loss: 0.198  loss_cls: 0.028  loss_box_reg: 0.064  loss_mask: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.038  time: 3.7343  data_time: 2.0319  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:57:25 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 01:57:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/09 01:57:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/09 01:57:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1526 s / img. ETA=0:00:57\n",
            "\u001b[32m[07/09 01:57:46 d2.evaluation.evaluator]: \u001b[0mInference done 20/57. 0.1336 s / img. ETA=0:00:31\n",
            "\u001b[32m[07/09 01:57:51 d2.evaluation.evaluator]: \u001b[0mInference done 30/57. 0.1240 s / img. ETA=0:00:19\n",
            "\u001b[32m[07/09 01:57:57 d2.evaluation.evaluator]: \u001b[0mInference done 38/57. 0.1201 s / img. ETA=0:00:13\n",
            "\u001b[32m[07/09 01:58:02 d2.evaluation.evaluator]: \u001b[0mInference done 47/57. 0.1173 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/09 01:58:07 d2.evaluation.evaluator]: \u001b[0mInference done 53/57. 0.1215 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 01:58:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.470499 (0.682125 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:58:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.121759 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:58:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 01:58:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 01:58:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.939\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.939\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.938\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.959\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.959\n",
            "\u001b[32m[07/09 01:58:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 93.881 | 99.881 | 99.881 |  nan  |  nan  | 93.881 |\n",
            "\u001b[32m[07/09 01:58:09 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:58:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 91.597 | brec_Cht         | 91.712 | lam_Sltst  | 94.942 |\n",
            "| skel_WkstPkst | 96.041 | strless_SltstSst | 95.114 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.916\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.916\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.239\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.922\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.942\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.942\n",
            "\u001b[32m[07/09 01:58:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 91.584 | 99.881 | 99.881 |  nan  |  nan  | 91.584 |\n",
            "\u001b[32m[07/09 01:58:10 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:58:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 91.973 | brec_Cht         | 92.736 | lam_Sltst  | 91.681 |\n",
            "| skel_WkstPkst | 89.658 | strless_SltstSst | 91.871 |            |        |\n",
            "\u001b[32m[07/09 01:58:10 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/09 01:58:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 01:58:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:58:10 d2.evaluation.testing]: \u001b[0mcopypaste: 93.8814,99.8808,99.8808,nan,nan,93.8814\n",
            "\u001b[32m[07/09 01:58:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 01:58:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:58:10 d2.evaluation.testing]: \u001b[0mcopypaste: 91.5839,99.8808,99.8808,nan,nan,91.5839\n",
            "\u001b[32m[07/09 01:58:13 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 01:58:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/09 01:58:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/09 01:58:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1231 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.602410 (0.844712 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.137616 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.389\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.324\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.279\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.510\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 27.861 | 38.866 | 32.354 |  nan  |  nan  | 27.861 |\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 19.127 | brec_Cht         | 44.314 | lam_Sltst  | 7.989 |\n",
            "| skel_WkstPkst | 37.668 | strless_SltstSst | 30.210 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.273\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.504\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 27.300 | 38.436 | 29.626 |  nan  |  nan  | 27.300 |\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 21.070 | brec_Cht         | 39.887 | lam_Sltst  | 7.743 |\n",
            "| skel_WkstPkst | 36.876 | strless_SltstSst | 30.924 |            |       |\n",
            "\u001b[32m[07/09 01:58:29 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.testing]: \u001b[0mcopypaste: 27.8614,38.8660,32.3539,nan,nan,27.8614\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 01:58:29 d2.evaluation.testing]: \u001b[0mcopypaste: 27.2998,38.4362,29.6264,nan,nan,27.2998\n",
            "\u001b[32m[07/09 01:58:29 d2.utils.events]: \u001b[0m eta: 0:24:56  iter: 1599  total_loss: 0.193  loss_cls: 0.028  loss_box_reg: 0.061  loss_mask: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.033  time: 3.7342  data_time: 2.0019  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 01:59:43 d2.utils.events]: \u001b[0m eta: 0:23:41  iter: 1619  total_loss: 0.188  loss_cls: 0.028  loss_box_reg: 0.063  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 3.7339  data_time: 2.0377  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:00:58 d2.utils.events]: \u001b[0m eta: 0:22:27  iter: 1639  total_loss: 0.188  loss_cls: 0.028  loss_box_reg: 0.060  loss_mask: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.029  time: 3.7339  data_time: 2.0098  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:02:13 d2.utils.events]: \u001b[0m eta: 0:21:12  iter: 1659  total_loss: 0.185  loss_cls: 0.029  loss_box_reg: 0.062  loss_mask: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.029  time: 3.7340  data_time: 2.0510  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:03:27 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 1679  total_loss: 0.193  loss_cls: 0.027  loss_box_reg: 0.060  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.037  time: 3.7339  data_time: 2.0323  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:04:42 d2.utils.events]: \u001b[0m eta: 0:18:43  iter: 1699  total_loss: 0.191  loss_cls: 0.026  loss_box_reg: 0.063  loss_mask: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.036  time: 3.7340  data_time: 2.0385  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:05:57 d2.utils.events]: \u001b[0m eta: 0:17:28  iter: 1719  total_loss: 0.180  loss_cls: 0.028  loss_box_reg: 0.059  loss_mask: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 3.7338  data_time: 2.0401  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:07:12 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 1739  total_loss: 0.176  loss_cls: 0.026  loss_box_reg: 0.057  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.028  time: 3.7341  data_time: 2.0385  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:08:26 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 1759  total_loss: 0.180  loss_cls: 0.026  loss_box_reg: 0.053  loss_mask: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 3.7336  data_time: 2.0014  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:09:41 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 1779  total_loss: 0.176  loss_cls: 0.024  loss_box_reg: 0.055  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.035  time: 3.7337  data_time: 2.0691  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:11:06 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 02:11:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/09 02:11:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/09 02:11:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1624 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/09 02:11:27 d2.evaluation.evaluator]: \u001b[0mInference done 21/57. 0.1253 s / img. ETA=0:00:27\n",
            "\u001b[32m[07/09 02:11:32 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1187 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/09 02:11:37 d2.evaluation.evaluator]: \u001b[0mInference done 39/57. 0.1178 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/09 02:11:42 d2.evaluation.evaluator]: \u001b[0mInference done 48/57. 0.1169 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/09 02:11:48 d2.evaluation.evaluator]: \u001b[0mInference done 55/57. 0.1207 s / img. ETA=0:00:01\n",
            "\u001b[32m[07/09 02:11:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.129991 (0.656346 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 02:11:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.120595 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 02:11:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 02:11:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 02:11:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.946\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.946\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.943\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.965\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.965\n",
            "\u001b[32m[07/09 02:11:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 94.592 | 99.918 | 99.918 |  nan  |  nan  | 94.592 |\n",
            "\u001b[32m[07/09 02:11:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 02:11:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 95.399 | brec_Cht         | 94.047 | lam_Sltst  | 96.631 |\n",
            "| skel_WkstPkst | 93.755 | strless_SltstSst | 93.131 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.926\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.926\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.241\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.928\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.948\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.948\n",
            "\u001b[32m[07/09 02:11:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 92.558 | 99.918 | 99.918 |  nan  |  nan  | 92.558 |\n",
            "\u001b[32m[07/09 02:11:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 02:11:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 93.159 | brec_Cht         | 92.696 | lam_Sltst  | 93.171 |\n",
            "| skel_WkstPkst | 90.799 | strless_SltstSst | 92.968 |            |        |\n",
            "\u001b[32m[07/09 02:11:49 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/09 02:11:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 02:11:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 02:11:49 d2.evaluation.testing]: \u001b[0mcopypaste: 94.5923,99.9182,99.9182,nan,nan,94.5923\n",
            "\u001b[32m[07/09 02:11:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 02:11:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 02:11:49 d2.evaluation.testing]: \u001b[0mcopypaste: 92.5585,99.9182,99.9182,nan,nan,92.5585\n",
            "\u001b[32m[07/09 02:11:52 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 02:11:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/09 02:11:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/09 02:12:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1248 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 02:12:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.038363 (0.782040 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 02:12:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.137568 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 02:12:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 02:12:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 02:12:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.393\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.061\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n",
            "\u001b[32m[07/09 02:12:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.644 | 39.265 | 32.595 |  nan  |  nan  | 28.644 |\n",
            "\u001b[32m[07/09 02:12:07 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 02:12:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 20.643 | brec_Cht         | 39.844 | lam_Sltst  | 7.863 |\n",
            "| skel_WkstPkst | 38.777 | strless_SltstSst | 36.092 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.280\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.064\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n",
            "\u001b[32m[07/09 02:12:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.018 | 39.142 | 30.305 |  nan  |  nan  | 28.018 |\n",
            "\u001b[32m[07/09 02:12:08 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 02:12:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 22.083 | brec_Cht         | 36.983 | lam_Sltst  | 7.907 |\n",
            "| skel_WkstPkst | 36.785 | strless_SltstSst | 36.332 |            |       |\n",
            "\u001b[32m[07/09 02:12:08 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/09 02:12:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 02:12:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 02:12:08 d2.evaluation.testing]: \u001b[0mcopypaste: 28.6437,39.2648,32.5948,nan,nan,28.6437\n",
            "\u001b[32m[07/09 02:12:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 02:12:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 02:12:08 d2.evaluation.testing]: \u001b[0mcopypaste: 28.0179,39.1419,30.3055,nan,nan,28.0179\n",
            "\u001b[32m[07/09 02:12:08 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 1799  total_loss: 0.187  loss_cls: 0.026  loss_box_reg: 0.055  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.036  time: 3.7332  data_time: 2.0085  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:13:22 d2.utils.events]: \u001b[0m eta: 0:11:15  iter: 1819  total_loss: 0.173  loss_cls: 0.025  loss_box_reg: 0.056  loss_mask: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.029  time: 3.7334  data_time: 2.0117  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:14:36 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 1839  total_loss: 0.170  loss_cls: 0.026  loss_box_reg: 0.056  loss_mask: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.031  time: 3.7328  data_time: 2.0105  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:15:52 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 1859  total_loss: 0.174  loss_cls: 0.025  loss_box_reg: 0.057  loss_mask: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.029  time: 3.7333  data_time: 2.0705  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:17:06 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 1879  total_loss: 0.173  loss_cls: 0.025  loss_box_reg: 0.058  loss_mask: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.027  time: 3.7330  data_time: 2.0301  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:18:20 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 1899  total_loss: 0.169  loss_cls: 0.023  loss_box_reg: 0.051  loss_mask: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.030  time: 3.7330  data_time: 2.0261  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:19:35 d2.utils.events]: \u001b[0m eta: 0:05:02  iter: 1919  total_loss: 0.172  loss_cls: 0.023  loss_box_reg: 0.054  loss_mask: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.029  time: 3.7331  data_time: 2.0352  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:20:50 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 1939  total_loss: 0.169  loss_cls: 0.023  loss_box_reg: 0.053  loss_mask: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 3.7330  data_time: 2.0428  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:22:04 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 1959  total_loss: 0.188  loss_cls: 0.026  loss_box_reg: 0.064  loss_mask: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.034  time: 3.7329  data_time: 2.0280  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:23:19 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1979  total_loss: 0.174  loss_cls: 0.024  loss_box_reg: 0.056  loss_mask: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.032  time: 3.7327  data_time: 2.0317  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:24:46 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 02:24:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/09 02:24:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/09 02:25:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1563 s / img. ETA=0:00:54\n",
            "\u001b[32m[07/09 02:25:06 d2.evaluation.evaluator]: \u001b[0mInference done 20/57. 0.1264 s / img. ETA=0:00:29\n",
            "\u001b[32m[07/09 02:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 31/57. 0.1173 s / img. ETA=0:00:17\n",
            "\u001b[32m[07/09 02:25:17 d2.evaluation.evaluator]: \u001b[0mInference done 40/57. 0.1149 s / img. ETA=0:00:11\n",
            "\u001b[32m[07/09 02:25:23 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1159 s / img. ETA=0:00:05\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.evaluator]: \u001b[0mInference done 57/57. 0.1191 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.817475 (0.650336 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.119081 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.974\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.974\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.962\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.983\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.983\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 97.421 | 99.959 | 99.959 |  nan  |  nan  | 97.421 |\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 96.551 | brec_Cht         | 99.336 | lam_Sltst  | 97.980 |\n",
            "| skel_WkstPkst | 95.434 | strless_SltstSst | 97.804 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.22s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.949\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.949\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.944\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.965\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.965\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 94.869 | 99.959 | 99.959 |  nan  |  nan  | 94.869 |\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 94.809 | brec_Cht         | 92.931 | lam_Sltst  | 95.273 |\n",
            "| skel_WkstPkst | 96.597 | strless_SltstSst | 94.735 |            |        |\n",
            "\u001b[32m[07/09 02:25:28 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_train in csv format:\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.testing]: \u001b[0mcopypaste: 97.4210,99.9594,99.9594,nan,nan,97.4210\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 02:25:28 d2.evaluation.testing]: \u001b[0mcopypaste: 94.8688,99.9594,99.9594,nan,nan,94.8688\n",
            "\u001b[32m[07/09 02:25:31 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 02:25:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/09 02:25:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/09 02:25:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1251 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.889070 (0.765452 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.137052 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco_train/coco_instances_results.json\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.408\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 29.567 | 40.808 | 33.401 |  nan  |  nan  | 29.567 |\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 19.099 | brec_Cht         | 47.303 | lam_Sltst  | 5.969 |\n",
            "| skel_WkstPkst | 40.381 | strless_SltstSst | 35.086 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.410\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.905 | 40.955 | 30.280 |  nan  |  nan  | 28.905 |\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 19.880 | brec_Cht         | 43.289 | lam_Sltst  | 6.464 |\n",
            "| skel_WkstPkst | 38.042 | strless_SltstSst | 36.851 |            |       |\n",
            "\u001b[32m[07/09 02:25:47 d2.engine.defaults]: \u001b[0mEvaluation results for cores_fold_4_val in csv format:\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.testing]: \u001b[0mcopypaste: 29.5675,40.8081,33.4014,nan,nan,29.5675\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 02:25:47 d2.evaluation.testing]: \u001b[0mcopypaste: 28.9051,40.9549,30.2802,nan,nan,28.9051\n",
            "\u001b[32m[07/09 02:25:47 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 1999  total_loss: 0.164  loss_cls: 0.023  loss_box_reg: 0.051  loss_mask: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.029  time: 3.7327  data_time: 2.0647  lr: 0.001000  max_mem: 9380M\n",
            "\u001b[32m[07/09 02:25:47 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 2:04:17 (3.7346 s / it)\n",
            "\u001b[32m[07/09 02:25:47 d2.engine.hooks]: \u001b[0mTotal training time: 2:28:55 (0:24:37 on hooks)\n",
            "\n",
            "\n",
            "**Starting train eval**\n",
            "\u001b[32m[07/09 02:26:00 d2.data.common]: \u001b[0mSerializing 57 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 02:26:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/09 02:26:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 57 images\n",
            "\u001b[32m[07/09 02:26:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/57. 0.1492 s / img. ETA=0:01:04\n",
            "\u001b[32m[07/09 02:26:22 d2.evaluation.evaluator]: \u001b[0mInference done 19/57. 0.1241 s / img. ETA=0:00:36\n",
            "\u001b[32m[07/09 02:26:27 d2.evaluation.evaluator]: \u001b[0mInference done 28/57. 0.1171 s / img. ETA=0:00:23\n",
            "\u001b[32m[07/09 02:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 36/57. 0.1138 s / img. ETA=0:00:16\n",
            "\u001b[32m[07/09 02:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 43/57. 0.1099 s / img. ETA=0:00:10\n",
            "\u001b[32m[07/09 02:26:43 d2.evaluation.evaluator]: \u001b[0mInference done 49/57. 0.1125 s / img. ETA=0:00:06\n",
            "\u001b[32m[07/09 02:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 52/57. 0.1166 s / img. ETA=0:00:04\n",
            "\u001b[32m[07/09 02:26:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.984061 (0.845847 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 02:26:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.117139 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 02:26:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 02:26:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/09 02:26:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.974\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.974\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.962\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.983\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.983\n",
            "\u001b[32m[07/09 02:26:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 97.421 | 99.959 | 99.959 |  nan  |  nan  | 97.421 |\n",
            "\u001b[32m[07/09 02:26:53 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 02:26:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 96.551 | brec_Cht         | 99.336 | lam_Sltst  | 97.980 |\n",
            "| skel_WkstPkst | 95.434 | strless_SltstSst | 97.804 |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.22s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.949\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.949\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.944\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.965\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.965\n",
            "\u001b[32m[07/09 02:26:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 94.869 | 99.959 | 99.959 |  nan  |  nan  | 94.869 |\n",
            "\u001b[32m[07/09 02:26:53 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 02:26:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:-------|\n",
            "| bio_Sltst     | 94.809 | brec_Cht         | 92.931 | lam_Sltst  | 95.273 |\n",
            "| skel_WkstPkst | 96.597 | strless_SltstSst | 94.735 |            |        |\n",
            "randomly selected cores/Box 8 Depths 10035-45.JPG\n",
            "\n",
            "\n",
            "**Starting val eval**\n",
            "\u001b[32m[07/09 02:27:28 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 02:27:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[07/09 02:27:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 14 images\n",
            "\u001b[32m[07/09 02:27:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/14. 0.1342 s / img. ETA=0:00:02\n",
            "\u001b[32m[07/09 02:27:50 d2.evaluation.evaluator]: \u001b[0mInference done 14/14. 0.1510 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 02:27:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.461704 (1.273523 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 02:27:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.151034 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 02:27:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 02:27:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./coco/coco_instances_results.json\n",
            "\u001b[32m[07/09 02:27:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.408\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
            "\u001b[32m[07/09 02:27:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 29.567 | 40.808 | 33.401 |  nan  |  nan  | 29.567 |\n",
            "\u001b[32m[07/09 02:27:50 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 02:27:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 19.099 | brec_Cht         | 47.303 | lam_Sltst  | 5.969 |\n",
            "| skel_WkstPkst | 40.381 | strless_SltstSst | 35.086 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.410\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            "\u001b[32m[07/09 02:27:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 28.905 | 40.955 | 30.280 |  nan  |  nan  | 28.905 |\n",
            "\u001b[32m[07/09 02:27:50 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 02:27:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category   | AP    |\n",
            "|:--------------|:-------|:-----------------|:-------|:-----------|:------|\n",
            "| bio_Sltst     | 19.880 | brec_Cht         | 43.289 | lam_Sltst  | 6.464 |\n",
            "| skel_WkstPkst | 38.042 | strless_SltstSst | 36.851 |            |       |\n",
            "randomly selected cores/Boxes 19-21  Depths 7770.6-7778.4 (Dry).JPG\n",
            "Thu Jul  9 02:28:19 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0    46W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "CPU times: user 16 s, sys: 2.25 s, total: 18.3 s\n",
            "Wall time: 2h 31min 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m19G2u9UEw0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output_fold_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUNUX8qDNsLH",
        "colab_type": "text"
      },
      "source": [
        "# Wrap-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvUKOkjcCrET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "01ae513d-2c77-4197-a47b-9d8b8819f0bb"
      },
      "source": [
        "# donwload results to Google Drive\n",
        "! zip -r results.zip out* \n",
        "! cp results.zip 'gdrive/My Drive'\n",
        "! rm -r results.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: output_fold_4/ (stored 0%)\n",
            "  adding: output_fold_4/cores_fold_4_train_cores-Box 8 Depths 10035-45.JPG.pdf (deflated 0%)\n",
            "  adding: output_fold_4/model_final.pth (deflated 7%)\n",
            "  adding: output_fold_4/cocoeval_val_4.json (deflated 54%)\n",
            "  adding: output_fold_4/last_checkpoint (stored 0%)\n",
            "  adding: output_fold_4/cores_fold_4_val_cores-Boxes 19-21  Depths 7770.6-7778.4 (Dry).JPG.pdf (deflated 0%)\n",
            "  adding: output_fold_4/metrics.json (deflated 77%)\n",
            "  adding: output_fold_4/training_log.txt (deflated 89%)\n",
            "  adding: output_fold_4/events.out.tfevents.1594252602.c7edeaf5c1b3.4503.0 (deflated 72%)\n",
            "  adding: output_fold_4/cocoeval_train_4.json (deflated 61%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fi5O1ytFtDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean folders if upcoming experiment\n",
        "! rm -r *coco*\n",
        "! rm -r *output*"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}